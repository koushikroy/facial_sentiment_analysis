{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "00_sentiment_model.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNoiqwire4i+99IZKS5ByLd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koushikroy/facial_sentiment_analysis/blob/main/00_sentiment_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCXyx8lD8yuD"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZyNQK_p6gU3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvwNzEk69PpW"
      },
      "source": [
        "# Dateset Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLGsT1ORYjId"
      },
      "source": [
        "## Downloading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvhMNp1L9U-_",
        "outputId": "d8bba125-d42b-421f-ff14-d85f2509af20"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/koushikroy/facial_sentiment_analysis/main/dataset/dataset_sentiment_face_landmarks.csv"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-03 12:20:36--  https://raw.githubusercontent.com/koushikroy/facial_sentiment_analysis/main/dataset/dataset_sentiment_face_landmarks.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16276236 (16M) [text/plain]\n",
            "Saving to: ‘dataset_sentiment_face_landmarks.csv.1’\n",
            "\n",
            "dataset_sentiment_f 100%[===================>]  15.52M  75.8MB/s    in 0.2s    \n",
            "\n",
            "2021-07-03 12:20:36 (75.8 MB/s) - ‘dataset_sentiment_face_landmarks.csv.1’ saved [16276236/16276236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQnuCiaCYs2W"
      },
      "source": [
        "## Exploring and Cleaning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9COVLEMgBPcf"
      },
      "source": [
        "sentiment_data_original = pd.read_csv('/content/dataset_sentiment_face_landmarks.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "YUft2RE7BX-6",
        "outputId": "6c5815cd-28bc-4580-8e22-ab56b9b3b643"
      },
      "source": [
        "sentiment_data_original.head(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>1x</th>\n",
              "      <th>1y</th>\n",
              "      <th>2x</th>\n",
              "      <th>2y</th>\n",
              "      <th>3x</th>\n",
              "      <th>3y</th>\n",
              "      <th>4x</th>\n",
              "      <th>4y</th>\n",
              "      <th>5x</th>\n",
              "      <th>5y</th>\n",
              "      <th>6x</th>\n",
              "      <th>6y</th>\n",
              "      <th>7x</th>\n",
              "      <th>7y</th>\n",
              "      <th>8x</th>\n",
              "      <th>8y</th>\n",
              "      <th>9x</th>\n",
              "      <th>9y</th>\n",
              "      <th>10x</th>\n",
              "      <th>10y</th>\n",
              "      <th>11x</th>\n",
              "      <th>11y</th>\n",
              "      <th>12x</th>\n",
              "      <th>12y</th>\n",
              "      <th>13x</th>\n",
              "      <th>13y</th>\n",
              "      <th>14x</th>\n",
              "      <th>14y</th>\n",
              "      <th>15x</th>\n",
              "      <th>15y</th>\n",
              "      <th>16x</th>\n",
              "      <th>16y</th>\n",
              "      <th>17x</th>\n",
              "      <th>17y</th>\n",
              "      <th>18x</th>\n",
              "      <th>18y</th>\n",
              "      <th>19x</th>\n",
              "      <th>19y</th>\n",
              "      <th>20x</th>\n",
              "      <th>...</th>\n",
              "      <th>449y</th>\n",
              "      <th>450x</th>\n",
              "      <th>450y</th>\n",
              "      <th>451x</th>\n",
              "      <th>451y</th>\n",
              "      <th>452x</th>\n",
              "      <th>452y</th>\n",
              "      <th>453x</th>\n",
              "      <th>453y</th>\n",
              "      <th>454x</th>\n",
              "      <th>454y</th>\n",
              "      <th>455x</th>\n",
              "      <th>455y</th>\n",
              "      <th>456x</th>\n",
              "      <th>456y</th>\n",
              "      <th>457x</th>\n",
              "      <th>457y</th>\n",
              "      <th>458x</th>\n",
              "      <th>458y</th>\n",
              "      <th>459x</th>\n",
              "      <th>459y</th>\n",
              "      <th>460x</th>\n",
              "      <th>460y</th>\n",
              "      <th>461x</th>\n",
              "      <th>461y</th>\n",
              "      <th>462x</th>\n",
              "      <th>462y</th>\n",
              "      <th>463x</th>\n",
              "      <th>463y</th>\n",
              "      <th>464x</th>\n",
              "      <th>464y</th>\n",
              "      <th>465x</th>\n",
              "      <th>465y</th>\n",
              "      <th>466x</th>\n",
              "      <th>466y</th>\n",
              "      <th>467x</th>\n",
              "      <th>467y</th>\n",
              "      <th>468x</th>\n",
              "      <th>468y</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.471114</td>\n",
              "      <td>0.646392</td>\n",
              "      <td>0.462975</td>\n",
              "      <td>0.552659</td>\n",
              "      <td>0.466726</td>\n",
              "      <td>0.578822</td>\n",
              "      <td>0.434750</td>\n",
              "      <td>0.439725</td>\n",
              "      <td>0.461484</td>\n",
              "      <td>0.519575</td>\n",
              "      <td>0.460532</td>\n",
              "      <td>0.473270</td>\n",
              "      <td>0.459655</td>\n",
              "      <td>0.360723</td>\n",
              "      <td>0.248363</td>\n",
              "      <td>0.351089</td>\n",
              "      <td>0.458165</td>\n",
              "      <td>0.284641</td>\n",
              "      <td>0.456921</td>\n",
              "      <td>0.243084</td>\n",
              "      <td>0.453431</td>\n",
              "      <td>0.087810</td>\n",
              "      <td>0.471981</td>\n",
              "      <td>0.660933</td>\n",
              "      <td>0.472802</td>\n",
              "      <td>0.670488</td>\n",
              "      <td>0.473516</td>\n",
              "      <td>0.673532</td>\n",
              "      <td>0.474548</td>\n",
              "      <td>0.675410</td>\n",
              "      <td>0.475064</td>\n",
              "      <td>0.686886</td>\n",
              "      <td>0.475771</td>\n",
              "      <td>0.701211</td>\n",
              "      <td>0.476646</td>\n",
              "      <td>0.716253</td>\n",
              "      <td>0.477596</td>\n",
              "      <td>0.741880</td>\n",
              "      <td>0.464268</td>\n",
              "      <td>...</td>\n",
              "      <td>0.382331</td>\n",
              "      <td>0.667334</td>\n",
              "      <td>0.392538</td>\n",
              "      <td>0.626921</td>\n",
              "      <td>0.392877</td>\n",
              "      <td>0.588903</td>\n",
              "      <td>0.386264</td>\n",
              "      <td>0.560101</td>\n",
              "      <td>0.377370</td>\n",
              "      <td>0.539828</td>\n",
              "      <td>0.368396</td>\n",
              "      <td>0.807646</td>\n",
              "      <td>0.402829</td>\n",
              "      <td>0.552347</td>\n",
              "      <td>0.549719</td>\n",
              "      <td>0.511613</td>\n",
              "      <td>0.450629</td>\n",
              "      <td>0.511133</td>\n",
              "      <td>0.544056</td>\n",
              "      <td>0.495620</td>\n",
              "      <td>0.558106</td>\n",
              "      <td>0.511510</td>\n",
              "      <td>0.547564</td>\n",
              "      <td>0.544053</td>\n",
              "      <td>0.558156</td>\n",
              "      <td>0.490060</td>\n",
              "      <td>0.562254</td>\n",
              "      <td>0.487931</td>\n",
              "      <td>0.566759</td>\n",
              "      <td>0.541290</td>\n",
              "      <td>0.343106</td>\n",
              "      <td>0.523212</td>\n",
              "      <td>0.352673</td>\n",
              "      <td>0.513798</td>\n",
              "      <td>0.359954</td>\n",
              "      <td>0.684050</td>\n",
              "      <td>0.326306</td>\n",
              "      <td>0.698897</td>\n",
              "      <td>0.316221</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.530374</td>\n",
              "      <td>0.614034</td>\n",
              "      <td>0.531349</td>\n",
              "      <td>0.512339</td>\n",
              "      <td>0.528999</td>\n",
              "      <td>0.540964</td>\n",
              "      <td>0.500500</td>\n",
              "      <td>0.413760</td>\n",
              "      <td>0.531190</td>\n",
              "      <td>0.482696</td>\n",
              "      <td>0.529466</td>\n",
              "      <td>0.442167</td>\n",
              "      <td>0.523717</td>\n",
              "      <td>0.344421</td>\n",
              "      <td>0.297536</td>\n",
              "      <td>0.342679</td>\n",
              "      <td>0.521402</td>\n",
              "      <td>0.290264</td>\n",
              "      <td>0.520840</td>\n",
              "      <td>0.254662</td>\n",
              "      <td>0.514536</td>\n",
              "      <td>0.098683</td>\n",
              "      <td>0.530600</td>\n",
              "      <td>0.628268</td>\n",
              "      <td>0.530085</td>\n",
              "      <td>0.637578</td>\n",
              "      <td>0.529426</td>\n",
              "      <td>0.640497</td>\n",
              "      <td>0.529368</td>\n",
              "      <td>0.639768</td>\n",
              "      <td>0.529859</td>\n",
              "      <td>0.650274</td>\n",
              "      <td>0.530190</td>\n",
              "      <td>0.664070</td>\n",
              "      <td>0.529899</td>\n",
              "      <td>0.679439</td>\n",
              "      <td>0.528366</td>\n",
              "      <td>0.710455</td>\n",
              "      <td>0.530667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.368076</td>\n",
              "      <td>0.722751</td>\n",
              "      <td>0.377521</td>\n",
              "      <td>0.682221</td>\n",
              "      <td>0.377576</td>\n",
              "      <td>0.643719</td>\n",
              "      <td>0.370850</td>\n",
              "      <td>0.614945</td>\n",
              "      <td>0.362032</td>\n",
              "      <td>0.595026</td>\n",
              "      <td>0.353581</td>\n",
              "      <td>0.855087</td>\n",
              "      <td>0.397170</td>\n",
              "      <td>0.612071</td>\n",
              "      <td>0.514794</td>\n",
              "      <td>0.575969</td>\n",
              "      <td>0.423784</td>\n",
              "      <td>0.577334</td>\n",
              "      <td>0.503919</td>\n",
              "      <td>0.559598</td>\n",
              "      <td>0.517776</td>\n",
              "      <td>0.575699</td>\n",
              "      <td>0.507627</td>\n",
              "      <td>0.602376</td>\n",
              "      <td>0.523786</td>\n",
              "      <td>0.555060</td>\n",
              "      <td>0.521378</td>\n",
              "      <td>0.551001</td>\n",
              "      <td>0.526814</td>\n",
              "      <td>0.597014</td>\n",
              "      <td>0.330898</td>\n",
              "      <td>0.579347</td>\n",
              "      <td>0.339900</td>\n",
              "      <td>0.571792</td>\n",
              "      <td>0.346182</td>\n",
              "      <td>0.738742</td>\n",
              "      <td>0.315066</td>\n",
              "      <td>0.753040</td>\n",
              "      <td>0.309837</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.499339</td>\n",
              "      <td>0.608413</td>\n",
              "      <td>0.493128</td>\n",
              "      <td>0.508219</td>\n",
              "      <td>0.495579</td>\n",
              "      <td>0.535847</td>\n",
              "      <td>0.464834</td>\n",
              "      <td>0.407602</td>\n",
              "      <td>0.491925</td>\n",
              "      <td>0.478106</td>\n",
              "      <td>0.490625</td>\n",
              "      <td>0.437034</td>\n",
              "      <td>0.488284</td>\n",
              "      <td>0.336501</td>\n",
              "      <td>0.285974</td>\n",
              "      <td>0.332120</td>\n",
              "      <td>0.486582</td>\n",
              "      <td>0.272432</td>\n",
              "      <td>0.485704</td>\n",
              "      <td>0.234519</td>\n",
              "      <td>0.481379</td>\n",
              "      <td>0.085394</td>\n",
              "      <td>0.500151</td>\n",
              "      <td>0.622561</td>\n",
              "      <td>0.500575</td>\n",
              "      <td>0.631630</td>\n",
              "      <td>0.500789</td>\n",
              "      <td>0.634012</td>\n",
              "      <td>0.500746</td>\n",
              "      <td>0.637065</td>\n",
              "      <td>0.501155</td>\n",
              "      <td>0.647303</td>\n",
              "      <td>0.501701</td>\n",
              "      <td>0.660387</td>\n",
              "      <td>0.502103</td>\n",
              "      <td>0.674604</td>\n",
              "      <td>0.502113</td>\n",
              "      <td>0.700330</td>\n",
              "      <td>0.493903</td>\n",
              "      <td>...</td>\n",
              "      <td>0.361170</td>\n",
              "      <td>0.686117</td>\n",
              "      <td>0.370573</td>\n",
              "      <td>0.647025</td>\n",
              "      <td>0.371127</td>\n",
              "      <td>0.609848</td>\n",
              "      <td>0.364684</td>\n",
              "      <td>0.581429</td>\n",
              "      <td>0.355766</td>\n",
              "      <td>0.561706</td>\n",
              "      <td>0.347007</td>\n",
              "      <td>0.825761</td>\n",
              "      <td>0.385894</td>\n",
              "      <td>0.581577</td>\n",
              "      <td>0.509742</td>\n",
              "      <td>0.539283</td>\n",
              "      <td>0.418160</td>\n",
              "      <td>0.540178</td>\n",
              "      <td>0.500309</td>\n",
              "      <td>0.524545</td>\n",
              "      <td>0.514125</td>\n",
              "      <td>0.540220</td>\n",
              "      <td>0.503983</td>\n",
              "      <td>0.573293</td>\n",
              "      <td>0.518513</td>\n",
              "      <td>0.519078</td>\n",
              "      <td>0.517668</td>\n",
              "      <td>0.516920</td>\n",
              "      <td>0.522851</td>\n",
              "      <td>0.562427</td>\n",
              "      <td>0.324119</td>\n",
              "      <td>0.546049</td>\n",
              "      <td>0.332307</td>\n",
              "      <td>0.538086</td>\n",
              "      <td>0.338227</td>\n",
              "      <td>0.697591</td>\n",
              "      <td>0.309795</td>\n",
              "      <td>0.712155</td>\n",
              "      <td>0.301570</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.529479</td>\n",
              "      <td>0.596424</td>\n",
              "      <td>0.518820</td>\n",
              "      <td>0.487511</td>\n",
              "      <td>0.522396</td>\n",
              "      <td>0.519907</td>\n",
              "      <td>0.485652</td>\n",
              "      <td>0.392520</td>\n",
              "      <td>0.515976</td>\n",
              "      <td>0.457292</td>\n",
              "      <td>0.512458</td>\n",
              "      <td>0.418244</td>\n",
              "      <td>0.504405</td>\n",
              "      <td>0.323978</td>\n",
              "      <td>0.303410</td>\n",
              "      <td>0.329820</td>\n",
              "      <td>0.498773</td>\n",
              "      <td>0.258971</td>\n",
              "      <td>0.495628</td>\n",
              "      <td>0.220827</td>\n",
              "      <td>0.483342</td>\n",
              "      <td>0.075667</td>\n",
              "      <td>0.530859</td>\n",
              "      <td>0.611838</td>\n",
              "      <td>0.531853</td>\n",
              "      <td>0.622986</td>\n",
              "      <td>0.532254</td>\n",
              "      <td>0.627294</td>\n",
              "      <td>0.533231</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.534426</td>\n",
              "      <td>0.649277</td>\n",
              "      <td>0.535938</td>\n",
              "      <td>0.665309</td>\n",
              "      <td>0.537417</td>\n",
              "      <td>0.682307</td>\n",
              "      <td>0.539387</td>\n",
              "      <td>0.708519</td>\n",
              "      <td>0.520398</td>\n",
              "      <td>...</td>\n",
              "      <td>0.346405</td>\n",
              "      <td>0.700638</td>\n",
              "      <td>0.357059</td>\n",
              "      <td>0.662449</td>\n",
              "      <td>0.359155</td>\n",
              "      <td>0.625250</td>\n",
              "      <td>0.354061</td>\n",
              "      <td>0.596125</td>\n",
              "      <td>0.345545</td>\n",
              "      <td>0.575908</td>\n",
              "      <td>0.336774</td>\n",
              "      <td>0.835300</td>\n",
              "      <td>0.377961</td>\n",
              "      <td>0.599364</td>\n",
              "      <td>0.493469</td>\n",
              "      <td>0.557649</td>\n",
              "      <td>0.401755</td>\n",
              "      <td>0.561685</td>\n",
              "      <td>0.478897</td>\n",
              "      <td>0.547105</td>\n",
              "      <td>0.494426</td>\n",
              "      <td>0.561347</td>\n",
              "      <td>0.483553</td>\n",
              "      <td>0.591593</td>\n",
              "      <td>0.503534</td>\n",
              "      <td>0.542726</td>\n",
              "      <td>0.497738</td>\n",
              "      <td>0.540497</td>\n",
              "      <td>0.504409</td>\n",
              "      <td>0.574548</td>\n",
              "      <td>0.313745</td>\n",
              "      <td>0.559276</td>\n",
              "      <td>0.321806</td>\n",
              "      <td>0.552033</td>\n",
              "      <td>0.326915</td>\n",
              "      <td>0.708733</td>\n",
              "      <td>0.290693</td>\n",
              "      <td>0.722408</td>\n",
              "      <td>0.281697</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.525898</td>\n",
              "      <td>0.594125</td>\n",
              "      <td>0.530033</td>\n",
              "      <td>0.520760</td>\n",
              "      <td>0.526494</td>\n",
              "      <td>0.539220</td>\n",
              "      <td>0.501730</td>\n",
              "      <td>0.428694</td>\n",
              "      <td>0.529735</td>\n",
              "      <td>0.494154</td>\n",
              "      <td>0.527859</td>\n",
              "      <td>0.456417</td>\n",
              "      <td>0.521891</td>\n",
              "      <td>0.362743</td>\n",
              "      <td>0.314410</td>\n",
              "      <td>0.347706</td>\n",
              "      <td>0.519482</td>\n",
              "      <td>0.305851</td>\n",
              "      <td>0.518616</td>\n",
              "      <td>0.271582</td>\n",
              "      <td>0.510917</td>\n",
              "      <td>0.113934</td>\n",
              "      <td>0.525877</td>\n",
              "      <td>0.606459</td>\n",
              "      <td>0.525577</td>\n",
              "      <td>0.614201</td>\n",
              "      <td>0.525121</td>\n",
              "      <td>0.615786</td>\n",
              "      <td>0.525468</td>\n",
              "      <td>0.621487</td>\n",
              "      <td>0.526047</td>\n",
              "      <td>0.632069</td>\n",
              "      <td>0.526596</td>\n",
              "      <td>0.645588</td>\n",
              "      <td>0.526815</td>\n",
              "      <td>0.660449</td>\n",
              "      <td>0.527288</td>\n",
              "      <td>0.689682</td>\n",
              "      <td>0.529146</td>\n",
              "      <td>...</td>\n",
              "      <td>0.367748</td>\n",
              "      <td>0.702343</td>\n",
              "      <td>0.378468</td>\n",
              "      <td>0.665439</td>\n",
              "      <td>0.381132</td>\n",
              "      <td>0.630534</td>\n",
              "      <td>0.377438</td>\n",
              "      <td>0.604434</td>\n",
              "      <td>0.371070</td>\n",
              "      <td>0.586778</td>\n",
              "      <td>0.364706</td>\n",
              "      <td>0.819888</td>\n",
              "      <td>0.379130</td>\n",
              "      <td>0.605477</td>\n",
              "      <td>0.512631</td>\n",
              "      <td>0.570194</td>\n",
              "      <td>0.435722</td>\n",
              "      <td>0.571645</td>\n",
              "      <td>0.512119</td>\n",
              "      <td>0.555648</td>\n",
              "      <td>0.523526</td>\n",
              "      <td>0.570675</td>\n",
              "      <td>0.514408</td>\n",
              "      <td>0.597486</td>\n",
              "      <td>0.519641</td>\n",
              "      <td>0.551468</td>\n",
              "      <td>0.527428</td>\n",
              "      <td>0.547463</td>\n",
              "      <td>0.530250</td>\n",
              "      <td>0.587661</td>\n",
              "      <td>0.344591</td>\n",
              "      <td>0.572917</td>\n",
              "      <td>0.352940</td>\n",
              "      <td>0.566291</td>\n",
              "      <td>0.359595</td>\n",
              "      <td>0.716786</td>\n",
              "      <td>0.320512</td>\n",
              "      <td>0.729813</td>\n",
              "      <td>0.313735</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.519534</td>\n",
              "      <td>0.615290</td>\n",
              "      <td>0.515736</td>\n",
              "      <td>0.522739</td>\n",
              "      <td>0.516086</td>\n",
              "      <td>0.545503</td>\n",
              "      <td>0.486527</td>\n",
              "      <td>0.423944</td>\n",
              "      <td>0.514847</td>\n",
              "      <td>0.494210</td>\n",
              "      <td>0.513438</td>\n",
              "      <td>0.453852</td>\n",
              "      <td>0.509599</td>\n",
              "      <td>0.354413</td>\n",
              "      <td>0.295947</td>\n",
              "      <td>0.335304</td>\n",
              "      <td>0.508438</td>\n",
              "      <td>0.295260</td>\n",
              "      <td>0.508079</td>\n",
              "      <td>0.260036</td>\n",
              "      <td>0.503303</td>\n",
              "      <td>0.105900</td>\n",
              "      <td>0.520144</td>\n",
              "      <td>0.628425</td>\n",
              "      <td>0.520111</td>\n",
              "      <td>0.635577</td>\n",
              "      <td>0.519806</td>\n",
              "      <td>0.636110</td>\n",
              "      <td>0.520415</td>\n",
              "      <td>0.638024</td>\n",
              "      <td>0.520893</td>\n",
              "      <td>0.648267</td>\n",
              "      <td>0.521488</td>\n",
              "      <td>0.661223</td>\n",
              "      <td>0.521818</td>\n",
              "      <td>0.675959</td>\n",
              "      <td>0.521957</td>\n",
              "      <td>0.704541</td>\n",
              "      <td>0.515972</td>\n",
              "      <td>...</td>\n",
              "      <td>0.369646</td>\n",
              "      <td>0.707614</td>\n",
              "      <td>0.379262</td>\n",
              "      <td>0.667752</td>\n",
              "      <td>0.379917</td>\n",
              "      <td>0.629851</td>\n",
              "      <td>0.374300</td>\n",
              "      <td>0.601562</td>\n",
              "      <td>0.366673</td>\n",
              "      <td>0.582130</td>\n",
              "      <td>0.359329</td>\n",
              "      <td>0.841497</td>\n",
              "      <td>0.388615</td>\n",
              "      <td>0.602093</td>\n",
              "      <td>0.516653</td>\n",
              "      <td>0.561297</td>\n",
              "      <td>0.433417</td>\n",
              "      <td>0.562275</td>\n",
              "      <td>0.513789</td>\n",
              "      <td>0.545926</td>\n",
              "      <td>0.526211</td>\n",
              "      <td>0.561942</td>\n",
              "      <td>0.516391</td>\n",
              "      <td>0.593873</td>\n",
              "      <td>0.524491</td>\n",
              "      <td>0.540759</td>\n",
              "      <td>0.530218</td>\n",
              "      <td>0.537669</td>\n",
              "      <td>0.533853</td>\n",
              "      <td>0.583470</td>\n",
              "      <td>0.337830</td>\n",
              "      <td>0.566772</td>\n",
              "      <td>0.346556</td>\n",
              "      <td>0.558941</td>\n",
              "      <td>0.353421</td>\n",
              "      <td>0.723396</td>\n",
              "      <td>0.319327</td>\n",
              "      <td>0.735810</td>\n",
              "      <td>0.315076</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.480879</td>\n",
              "      <td>0.571856</td>\n",
              "      <td>0.473185</td>\n",
              "      <td>0.480232</td>\n",
              "      <td>0.477125</td>\n",
              "      <td>0.507109</td>\n",
              "      <td>0.445887</td>\n",
              "      <td>0.391286</td>\n",
              "      <td>0.471726</td>\n",
              "      <td>0.452471</td>\n",
              "      <td>0.471304</td>\n",
              "      <td>0.416039</td>\n",
              "      <td>0.471755</td>\n",
              "      <td>0.329542</td>\n",
              "      <td>0.265143</td>\n",
              "      <td>0.327739</td>\n",
              "      <td>0.471098</td>\n",
              "      <td>0.275817</td>\n",
              "      <td>0.469883</td>\n",
              "      <td>0.242374</td>\n",
              "      <td>0.465156</td>\n",
              "      <td>0.099532</td>\n",
              "      <td>0.481849</td>\n",
              "      <td>0.585954</td>\n",
              "      <td>0.482858</td>\n",
              "      <td>0.597378</td>\n",
              "      <td>0.483841</td>\n",
              "      <td>0.602978</td>\n",
              "      <td>0.484924</td>\n",
              "      <td>0.623896</td>\n",
              "      <td>0.485303</td>\n",
              "      <td>0.637311</td>\n",
              "      <td>0.486084</td>\n",
              "      <td>0.653690</td>\n",
              "      <td>0.487184</td>\n",
              "      <td>0.670160</td>\n",
              "      <td>0.488846</td>\n",
              "      <td>0.692930</td>\n",
              "      <td>0.474447</td>\n",
              "      <td>...</td>\n",
              "      <td>0.350845</td>\n",
              "      <td>0.681600</td>\n",
              "      <td>0.359538</td>\n",
              "      <td>0.641005</td>\n",
              "      <td>0.359437</td>\n",
              "      <td>0.602583</td>\n",
              "      <td>0.353559</td>\n",
              "      <td>0.573375</td>\n",
              "      <td>0.345682</td>\n",
              "      <td>0.552851</td>\n",
              "      <td>0.338066</td>\n",
              "      <td>0.828398</td>\n",
              "      <td>0.380364</td>\n",
              "      <td>0.562178</td>\n",
              "      <td>0.484920</td>\n",
              "      <td>0.523347</td>\n",
              "      <td>0.400871</td>\n",
              "      <td>0.520708</td>\n",
              "      <td>0.473019</td>\n",
              "      <td>0.504796</td>\n",
              "      <td>0.486413</td>\n",
              "      <td>0.520913</td>\n",
              "      <td>0.476864</td>\n",
              "      <td>0.553567</td>\n",
              "      <td>0.493697</td>\n",
              "      <td>0.499410</td>\n",
              "      <td>0.489386</td>\n",
              "      <td>0.497250</td>\n",
              "      <td>0.494826</td>\n",
              "      <td>0.554033</td>\n",
              "      <td>0.316412</td>\n",
              "      <td>0.536292</td>\n",
              "      <td>0.325111</td>\n",
              "      <td>0.526697</td>\n",
              "      <td>0.331002</td>\n",
              "      <td>0.694623</td>\n",
              "      <td>0.302722</td>\n",
              "      <td>0.710379</td>\n",
              "      <td>0.293809</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0.446599</td>\n",
              "      <td>0.620045</td>\n",
              "      <td>0.440565</td>\n",
              "      <td>0.515505</td>\n",
              "      <td>0.447041</td>\n",
              "      <td>0.545749</td>\n",
              "      <td>0.423165</td>\n",
              "      <td>0.428195</td>\n",
              "      <td>0.440413</td>\n",
              "      <td>0.488140</td>\n",
              "      <td>0.443282</td>\n",
              "      <td>0.453027</td>\n",
              "      <td>0.453301</td>\n",
              "      <td>0.367490</td>\n",
              "      <td>0.265570</td>\n",
              "      <td>0.359577</td>\n",
              "      <td>0.458201</td>\n",
              "      <td>0.314953</td>\n",
              "      <td>0.458913</td>\n",
              "      <td>0.281168</td>\n",
              "      <td>0.466090</td>\n",
              "      <td>0.132543</td>\n",
              "      <td>0.446623</td>\n",
              "      <td>0.634792</td>\n",
              "      <td>0.447756</td>\n",
              "      <td>0.645498</td>\n",
              "      <td>0.449322</td>\n",
              "      <td>0.650025</td>\n",
              "      <td>0.450565</td>\n",
              "      <td>0.658063</td>\n",
              "      <td>0.449883</td>\n",
              "      <td>0.669732</td>\n",
              "      <td>0.449581</td>\n",
              "      <td>0.684434</td>\n",
              "      <td>0.449991</td>\n",
              "      <td>0.699993</td>\n",
              "      <td>0.452021</td>\n",
              "      <td>0.724682</td>\n",
              "      <td>0.442538</td>\n",
              "      <td>...</td>\n",
              "      <td>0.403200</td>\n",
              "      <td>0.659798</td>\n",
              "      <td>0.410433</td>\n",
              "      <td>0.619164</td>\n",
              "      <td>0.409025</td>\n",
              "      <td>0.581506</td>\n",
              "      <td>0.401695</td>\n",
              "      <td>0.553049</td>\n",
              "      <td>0.392223</td>\n",
              "      <td>0.533308</td>\n",
              "      <td>0.383126</td>\n",
              "      <td>0.829076</td>\n",
              "      <td>0.441096</td>\n",
              "      <td>0.530470</td>\n",
              "      <td>0.528270</td>\n",
              "      <td>0.496177</td>\n",
              "      <td>0.441895</td>\n",
              "      <td>0.486746</td>\n",
              "      <td>0.510585</td>\n",
              "      <td>0.472089</td>\n",
              "      <td>0.524044</td>\n",
              "      <td>0.487664</td>\n",
              "      <td>0.514928</td>\n",
              "      <td>0.522516</td>\n",
              "      <td>0.537429</td>\n",
              "      <td>0.466135</td>\n",
              "      <td>0.526597</td>\n",
              "      <td>0.465304</td>\n",
              "      <td>0.532752</td>\n",
              "      <td>0.535273</td>\n",
              "      <td>0.361641</td>\n",
              "      <td>0.517759</td>\n",
              "      <td>0.368730</td>\n",
              "      <td>0.507539</td>\n",
              "      <td>0.373420</td>\n",
              "      <td>0.672913</td>\n",
              "      <td>0.353052</td>\n",
              "      <td>0.689814</td>\n",
              "      <td>0.346310</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.476332</td>\n",
              "      <td>0.594860</td>\n",
              "      <td>0.463823</td>\n",
              "      <td>0.494850</td>\n",
              "      <td>0.470582</td>\n",
              "      <td>0.527503</td>\n",
              "      <td>0.437224</td>\n",
              "      <td>0.398539</td>\n",
              "      <td>0.461705</td>\n",
              "      <td>0.463750</td>\n",
              "      <td>0.461173</td>\n",
              "      <td>0.424170</td>\n",
              "      <td>0.462620</td>\n",
              "      <td>0.333059</td>\n",
              "      <td>0.264908</td>\n",
              "      <td>0.344611</td>\n",
              "      <td>0.461587</td>\n",
              "      <td>0.278884</td>\n",
              "      <td>0.459829</td>\n",
              "      <td>0.243157</td>\n",
              "      <td>0.455787</td>\n",
              "      <td>0.098754</td>\n",
              "      <td>0.477617</td>\n",
              "      <td>0.609096</td>\n",
              "      <td>0.479063</td>\n",
              "      <td>0.619801</td>\n",
              "      <td>0.480517</td>\n",
              "      <td>0.624194</td>\n",
              "      <td>0.482076</td>\n",
              "      <td>0.626721</td>\n",
              "      <td>0.482529</td>\n",
              "      <td>0.636273</td>\n",
              "      <td>0.483252</td>\n",
              "      <td>0.649633</td>\n",
              "      <td>0.484614</td>\n",
              "      <td>0.665465</td>\n",
              "      <td>0.487414</td>\n",
              "      <td>0.699634</td>\n",
              "      <td>0.465983</td>\n",
              "      <td>...</td>\n",
              "      <td>0.365907</td>\n",
              "      <td>0.677126</td>\n",
              "      <td>0.373241</td>\n",
              "      <td>0.636372</td>\n",
              "      <td>0.372854</td>\n",
              "      <td>0.597600</td>\n",
              "      <td>0.366569</td>\n",
              "      <td>0.567802</td>\n",
              "      <td>0.357858</td>\n",
              "      <td>0.546891</td>\n",
              "      <td>0.348866</td>\n",
              "      <td>0.838614</td>\n",
              "      <td>0.416628</td>\n",
              "      <td>0.559292</td>\n",
              "      <td>0.501758</td>\n",
              "      <td>0.514263</td>\n",
              "      <td>0.409803</td>\n",
              "      <td>0.513080</td>\n",
              "      <td>0.488087</td>\n",
              "      <td>0.498081</td>\n",
              "      <td>0.503644</td>\n",
              "      <td>0.514244</td>\n",
              "      <td>0.493201</td>\n",
              "      <td>0.551073</td>\n",
              "      <td>0.511240</td>\n",
              "      <td>0.492077</td>\n",
              "      <td>0.506525</td>\n",
              "      <td>0.490911</td>\n",
              "      <td>0.513352</td>\n",
              "      <td>0.548837</td>\n",
              "      <td>0.326625</td>\n",
              "      <td>0.529629</td>\n",
              "      <td>0.334312</td>\n",
              "      <td>0.519015</td>\n",
              "      <td>0.338896</td>\n",
              "      <td>0.688099</td>\n",
              "      <td>0.315512</td>\n",
              "      <td>0.703610</td>\n",
              "      <td>0.307655</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0.499125</td>\n",
              "      <td>0.593863</td>\n",
              "      <td>0.500022</td>\n",
              "      <td>0.504512</td>\n",
              "      <td>0.498261</td>\n",
              "      <td>0.530666</td>\n",
              "      <td>0.473482</td>\n",
              "      <td>0.408667</td>\n",
              "      <td>0.499927</td>\n",
              "      <td>0.475022</td>\n",
              "      <td>0.498774</td>\n",
              "      <td>0.436040</td>\n",
              "      <td>0.495698</td>\n",
              "      <td>0.343141</td>\n",
              "      <td>0.293451</td>\n",
              "      <td>0.337265</td>\n",
              "      <td>0.494728</td>\n",
              "      <td>0.284052</td>\n",
              "      <td>0.494602</td>\n",
              "      <td>0.247371</td>\n",
              "      <td>0.492128</td>\n",
              "      <td>0.097765</td>\n",
              "      <td>0.499389</td>\n",
              "      <td>0.607105</td>\n",
              "      <td>0.499001</td>\n",
              "      <td>0.615179</td>\n",
              "      <td>0.498627</td>\n",
              "      <td>0.616581</td>\n",
              "      <td>0.498295</td>\n",
              "      <td>0.625103</td>\n",
              "      <td>0.498642</td>\n",
              "      <td>0.634641</td>\n",
              "      <td>0.498794</td>\n",
              "      <td>0.647373</td>\n",
              "      <td>0.498785</td>\n",
              "      <td>0.662741</td>\n",
              "      <td>0.498720</td>\n",
              "      <td>0.694691</td>\n",
              "      <td>0.499525</td>\n",
              "      <td>...</td>\n",
              "      <td>0.374549</td>\n",
              "      <td>0.679296</td>\n",
              "      <td>0.381398</td>\n",
              "      <td>0.642417</td>\n",
              "      <td>0.381580</td>\n",
              "      <td>0.607515</td>\n",
              "      <td>0.375779</td>\n",
              "      <td>0.581008</td>\n",
              "      <td>0.367247</td>\n",
              "      <td>0.563057</td>\n",
              "      <td>0.358486</td>\n",
              "      <td>0.801944</td>\n",
              "      <td>0.413947</td>\n",
              "      <td>0.582538</td>\n",
              "      <td>0.505770</td>\n",
              "      <td>0.543273</td>\n",
              "      <td>0.421014</td>\n",
              "      <td>0.543741</td>\n",
              "      <td>0.498776</td>\n",
              "      <td>0.527655</td>\n",
              "      <td>0.512130</td>\n",
              "      <td>0.543311</td>\n",
              "      <td>0.502729</td>\n",
              "      <td>0.575027</td>\n",
              "      <td>0.513646</td>\n",
              "      <td>0.522883</td>\n",
              "      <td>0.515289</td>\n",
              "      <td>0.519723</td>\n",
              "      <td>0.520112</td>\n",
              "      <td>0.564409</td>\n",
              "      <td>0.337568</td>\n",
              "      <td>0.549153</td>\n",
              "      <td>0.343890</td>\n",
              "      <td>0.541633</td>\n",
              "      <td>0.348500</td>\n",
              "      <td>0.691892</td>\n",
              "      <td>0.330071</td>\n",
              "      <td>0.706248</td>\n",
              "      <td>0.321705</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 938 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0        1x        1y  ...      468x      468y  output\n",
              "0           0  0.471114  0.646392  ...  0.698897  0.316221   anger\n",
              "1           1  0.530374  0.614034  ...  0.753040  0.309837   anger\n",
              "2           2  0.499339  0.608413  ...  0.712155  0.301570   anger\n",
              "3           3  0.529479  0.596424  ...  0.722408  0.281697   anger\n",
              "4           4  0.525898  0.594125  ...  0.729813  0.313735   anger\n",
              "5           5  0.519534  0.615290  ...  0.735810  0.315076   anger\n",
              "6           6  0.480879  0.571856  ...  0.710379  0.293809   anger\n",
              "7           7  0.446599  0.620045  ...  0.689814  0.346310   anger\n",
              "8           8  0.476332  0.594860  ...  0.703610  0.307655   anger\n",
              "9           9  0.499125  0.593863  ...  0.706248  0.321705   anger\n",
              "\n",
              "[10 rows x 938 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7f55_uZCFEG"
      },
      "source": [
        "\n",
        "**From the dataset, we can see that:**\n",
        "*   There are in total 937 Columns excluding the index column \n",
        "*   The first 936 columns represents the landmark points in the face and the 'output' column represnts the emotion\n",
        "*   The face has been cropped and resized thus no need for further normalization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQZ4VOKCBdTM",
        "outputId": "6686fc21-300a-4768-b7ea-40bf88697cbe"
      },
      "source": [
        "sentiment_data_original.info()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 920 entries, 0 to 919\n",
            "Columns: 938 entries, Unnamed: 0 to output\n",
            "dtypes: float64(936), int64(1), object(1)\n",
            "memory usage: 6.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcv0dQIABi8O",
        "outputId": "686337a0-efae-4519-98fc-a9c9b15cc2b9"
      },
      "source": [
        "#value_count in the output column \n",
        "sentiment_data_original['output'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral      593\n",
              "surprise      83\n",
              "happiness     69\n",
              "disgust       59\n",
              "anger         45\n",
              "sadness       28\n",
              "fear          25\n",
              "contempt      18\n",
              "Name: output, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh4iA1inDAXi"
      },
      "source": [
        "\n",
        "\n",
        "> So you can see that the neutral category has a staggering number of input compared to othet categories. This can be a later as the model might be overflitted. So, we need to take care of this.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqHvZrsMC_4a"
      },
      "source": [
        "all_neutral = sentiment_data_original['output'] == 'neutral' \n",
        "list_of_neutral_index = []   \n",
        "for i in range (len(all_neutral)):\n",
        "    if all_neutral[i]:\n",
        "        list_of_neutral_index.append(i)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CZP4zlaUs9i",
        "outputId": "77924c8a-d40e-46d6-969e-55c17dceaefe"
      },
      "source": [
        "# The first and last index number of neutral faces\n",
        "list_of_neutral_index[0], list_of_neutral_index[-1]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(216, 808)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E3FwbujWC6T"
      },
      "source": [
        "# Let's delete some of the neutral data \n",
        "sentiment_data_small_version = sentiment_data_original.drop(list(range(list_of_neutral_index[59] , list_of_neutral_index[-1])))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "csLqjscvWdWt",
        "outputId": "e2ec06b0-d676-43df-b6e2-d528b6aa23c4"
      },
      "source": [
        "sentiment_data_small_version.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>1x</th>\n",
              "      <th>1y</th>\n",
              "      <th>2x</th>\n",
              "      <th>2y</th>\n",
              "      <th>3x</th>\n",
              "      <th>3y</th>\n",
              "      <th>4x</th>\n",
              "      <th>4y</th>\n",
              "      <th>5x</th>\n",
              "      <th>5y</th>\n",
              "      <th>6x</th>\n",
              "      <th>6y</th>\n",
              "      <th>7x</th>\n",
              "      <th>7y</th>\n",
              "      <th>8x</th>\n",
              "      <th>8y</th>\n",
              "      <th>9x</th>\n",
              "      <th>9y</th>\n",
              "      <th>10x</th>\n",
              "      <th>10y</th>\n",
              "      <th>11x</th>\n",
              "      <th>11y</th>\n",
              "      <th>12x</th>\n",
              "      <th>12y</th>\n",
              "      <th>13x</th>\n",
              "      <th>13y</th>\n",
              "      <th>14x</th>\n",
              "      <th>14y</th>\n",
              "      <th>15x</th>\n",
              "      <th>15y</th>\n",
              "      <th>16x</th>\n",
              "      <th>16y</th>\n",
              "      <th>17x</th>\n",
              "      <th>17y</th>\n",
              "      <th>18x</th>\n",
              "      <th>18y</th>\n",
              "      <th>19x</th>\n",
              "      <th>19y</th>\n",
              "      <th>20x</th>\n",
              "      <th>...</th>\n",
              "      <th>449y</th>\n",
              "      <th>450x</th>\n",
              "      <th>450y</th>\n",
              "      <th>451x</th>\n",
              "      <th>451y</th>\n",
              "      <th>452x</th>\n",
              "      <th>452y</th>\n",
              "      <th>453x</th>\n",
              "      <th>453y</th>\n",
              "      <th>454x</th>\n",
              "      <th>454y</th>\n",
              "      <th>455x</th>\n",
              "      <th>455y</th>\n",
              "      <th>456x</th>\n",
              "      <th>456y</th>\n",
              "      <th>457x</th>\n",
              "      <th>457y</th>\n",
              "      <th>458x</th>\n",
              "      <th>458y</th>\n",
              "      <th>459x</th>\n",
              "      <th>459y</th>\n",
              "      <th>460x</th>\n",
              "      <th>460y</th>\n",
              "      <th>461x</th>\n",
              "      <th>461y</th>\n",
              "      <th>462x</th>\n",
              "      <th>462y</th>\n",
              "      <th>463x</th>\n",
              "      <th>463y</th>\n",
              "      <th>464x</th>\n",
              "      <th>464y</th>\n",
              "      <th>465x</th>\n",
              "      <th>465y</th>\n",
              "      <th>466x</th>\n",
              "      <th>466y</th>\n",
              "      <th>467x</th>\n",
              "      <th>467y</th>\n",
              "      <th>468x</th>\n",
              "      <th>468y</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.471114</td>\n",
              "      <td>0.646392</td>\n",
              "      <td>0.462975</td>\n",
              "      <td>0.552659</td>\n",
              "      <td>0.466726</td>\n",
              "      <td>0.578822</td>\n",
              "      <td>0.434750</td>\n",
              "      <td>0.439725</td>\n",
              "      <td>0.461484</td>\n",
              "      <td>0.519575</td>\n",
              "      <td>0.460532</td>\n",
              "      <td>0.473270</td>\n",
              "      <td>0.459655</td>\n",
              "      <td>0.360723</td>\n",
              "      <td>0.248363</td>\n",
              "      <td>0.351089</td>\n",
              "      <td>0.458165</td>\n",
              "      <td>0.284641</td>\n",
              "      <td>0.456921</td>\n",
              "      <td>0.243084</td>\n",
              "      <td>0.453431</td>\n",
              "      <td>0.087810</td>\n",
              "      <td>0.471981</td>\n",
              "      <td>0.660933</td>\n",
              "      <td>0.472802</td>\n",
              "      <td>0.670488</td>\n",
              "      <td>0.473516</td>\n",
              "      <td>0.673532</td>\n",
              "      <td>0.474548</td>\n",
              "      <td>0.675410</td>\n",
              "      <td>0.475064</td>\n",
              "      <td>0.686886</td>\n",
              "      <td>0.475771</td>\n",
              "      <td>0.701211</td>\n",
              "      <td>0.476646</td>\n",
              "      <td>0.716253</td>\n",
              "      <td>0.477596</td>\n",
              "      <td>0.741880</td>\n",
              "      <td>0.464268</td>\n",
              "      <td>...</td>\n",
              "      <td>0.382331</td>\n",
              "      <td>0.667334</td>\n",
              "      <td>0.392538</td>\n",
              "      <td>0.626921</td>\n",
              "      <td>0.392877</td>\n",
              "      <td>0.588903</td>\n",
              "      <td>0.386264</td>\n",
              "      <td>0.560101</td>\n",
              "      <td>0.377370</td>\n",
              "      <td>0.539828</td>\n",
              "      <td>0.368396</td>\n",
              "      <td>0.807646</td>\n",
              "      <td>0.402829</td>\n",
              "      <td>0.552347</td>\n",
              "      <td>0.549719</td>\n",
              "      <td>0.511613</td>\n",
              "      <td>0.450629</td>\n",
              "      <td>0.511133</td>\n",
              "      <td>0.544056</td>\n",
              "      <td>0.495620</td>\n",
              "      <td>0.558106</td>\n",
              "      <td>0.511510</td>\n",
              "      <td>0.547564</td>\n",
              "      <td>0.544053</td>\n",
              "      <td>0.558156</td>\n",
              "      <td>0.490060</td>\n",
              "      <td>0.562254</td>\n",
              "      <td>0.487931</td>\n",
              "      <td>0.566759</td>\n",
              "      <td>0.541290</td>\n",
              "      <td>0.343106</td>\n",
              "      <td>0.523212</td>\n",
              "      <td>0.352673</td>\n",
              "      <td>0.513798</td>\n",
              "      <td>0.359954</td>\n",
              "      <td>0.684050</td>\n",
              "      <td>0.326306</td>\n",
              "      <td>0.698897</td>\n",
              "      <td>0.316221</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.530374</td>\n",
              "      <td>0.614034</td>\n",
              "      <td>0.531349</td>\n",
              "      <td>0.512339</td>\n",
              "      <td>0.528999</td>\n",
              "      <td>0.540964</td>\n",
              "      <td>0.500500</td>\n",
              "      <td>0.413760</td>\n",
              "      <td>0.531190</td>\n",
              "      <td>0.482696</td>\n",
              "      <td>0.529466</td>\n",
              "      <td>0.442167</td>\n",
              "      <td>0.523717</td>\n",
              "      <td>0.344421</td>\n",
              "      <td>0.297536</td>\n",
              "      <td>0.342679</td>\n",
              "      <td>0.521402</td>\n",
              "      <td>0.290264</td>\n",
              "      <td>0.520840</td>\n",
              "      <td>0.254662</td>\n",
              "      <td>0.514536</td>\n",
              "      <td>0.098683</td>\n",
              "      <td>0.530600</td>\n",
              "      <td>0.628268</td>\n",
              "      <td>0.530085</td>\n",
              "      <td>0.637578</td>\n",
              "      <td>0.529426</td>\n",
              "      <td>0.640497</td>\n",
              "      <td>0.529368</td>\n",
              "      <td>0.639768</td>\n",
              "      <td>0.529859</td>\n",
              "      <td>0.650274</td>\n",
              "      <td>0.530190</td>\n",
              "      <td>0.664070</td>\n",
              "      <td>0.529899</td>\n",
              "      <td>0.679439</td>\n",
              "      <td>0.528366</td>\n",
              "      <td>0.710455</td>\n",
              "      <td>0.530667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.368076</td>\n",
              "      <td>0.722751</td>\n",
              "      <td>0.377521</td>\n",
              "      <td>0.682221</td>\n",
              "      <td>0.377576</td>\n",
              "      <td>0.643719</td>\n",
              "      <td>0.370850</td>\n",
              "      <td>0.614945</td>\n",
              "      <td>0.362032</td>\n",
              "      <td>0.595026</td>\n",
              "      <td>0.353581</td>\n",
              "      <td>0.855087</td>\n",
              "      <td>0.397170</td>\n",
              "      <td>0.612071</td>\n",
              "      <td>0.514794</td>\n",
              "      <td>0.575969</td>\n",
              "      <td>0.423784</td>\n",
              "      <td>0.577334</td>\n",
              "      <td>0.503919</td>\n",
              "      <td>0.559598</td>\n",
              "      <td>0.517776</td>\n",
              "      <td>0.575699</td>\n",
              "      <td>0.507627</td>\n",
              "      <td>0.602376</td>\n",
              "      <td>0.523786</td>\n",
              "      <td>0.555060</td>\n",
              "      <td>0.521378</td>\n",
              "      <td>0.551001</td>\n",
              "      <td>0.526814</td>\n",
              "      <td>0.597014</td>\n",
              "      <td>0.330898</td>\n",
              "      <td>0.579347</td>\n",
              "      <td>0.339900</td>\n",
              "      <td>0.571792</td>\n",
              "      <td>0.346182</td>\n",
              "      <td>0.738742</td>\n",
              "      <td>0.315066</td>\n",
              "      <td>0.753040</td>\n",
              "      <td>0.309837</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.499339</td>\n",
              "      <td>0.608413</td>\n",
              "      <td>0.493128</td>\n",
              "      <td>0.508219</td>\n",
              "      <td>0.495579</td>\n",
              "      <td>0.535847</td>\n",
              "      <td>0.464834</td>\n",
              "      <td>0.407602</td>\n",
              "      <td>0.491925</td>\n",
              "      <td>0.478106</td>\n",
              "      <td>0.490625</td>\n",
              "      <td>0.437034</td>\n",
              "      <td>0.488284</td>\n",
              "      <td>0.336501</td>\n",
              "      <td>0.285974</td>\n",
              "      <td>0.332120</td>\n",
              "      <td>0.486582</td>\n",
              "      <td>0.272432</td>\n",
              "      <td>0.485704</td>\n",
              "      <td>0.234519</td>\n",
              "      <td>0.481379</td>\n",
              "      <td>0.085394</td>\n",
              "      <td>0.500151</td>\n",
              "      <td>0.622561</td>\n",
              "      <td>0.500575</td>\n",
              "      <td>0.631630</td>\n",
              "      <td>0.500789</td>\n",
              "      <td>0.634012</td>\n",
              "      <td>0.500746</td>\n",
              "      <td>0.637065</td>\n",
              "      <td>0.501155</td>\n",
              "      <td>0.647303</td>\n",
              "      <td>0.501701</td>\n",
              "      <td>0.660387</td>\n",
              "      <td>0.502103</td>\n",
              "      <td>0.674604</td>\n",
              "      <td>0.502113</td>\n",
              "      <td>0.700330</td>\n",
              "      <td>0.493903</td>\n",
              "      <td>...</td>\n",
              "      <td>0.361170</td>\n",
              "      <td>0.686117</td>\n",
              "      <td>0.370573</td>\n",
              "      <td>0.647025</td>\n",
              "      <td>0.371127</td>\n",
              "      <td>0.609848</td>\n",
              "      <td>0.364684</td>\n",
              "      <td>0.581429</td>\n",
              "      <td>0.355766</td>\n",
              "      <td>0.561706</td>\n",
              "      <td>0.347007</td>\n",
              "      <td>0.825761</td>\n",
              "      <td>0.385894</td>\n",
              "      <td>0.581577</td>\n",
              "      <td>0.509742</td>\n",
              "      <td>0.539283</td>\n",
              "      <td>0.418160</td>\n",
              "      <td>0.540178</td>\n",
              "      <td>0.500309</td>\n",
              "      <td>0.524545</td>\n",
              "      <td>0.514125</td>\n",
              "      <td>0.540220</td>\n",
              "      <td>0.503983</td>\n",
              "      <td>0.573293</td>\n",
              "      <td>0.518513</td>\n",
              "      <td>0.519078</td>\n",
              "      <td>0.517668</td>\n",
              "      <td>0.516920</td>\n",
              "      <td>0.522851</td>\n",
              "      <td>0.562427</td>\n",
              "      <td>0.324119</td>\n",
              "      <td>0.546049</td>\n",
              "      <td>0.332307</td>\n",
              "      <td>0.538086</td>\n",
              "      <td>0.338227</td>\n",
              "      <td>0.697591</td>\n",
              "      <td>0.309795</td>\n",
              "      <td>0.712155</td>\n",
              "      <td>0.301570</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.529479</td>\n",
              "      <td>0.596424</td>\n",
              "      <td>0.518820</td>\n",
              "      <td>0.487511</td>\n",
              "      <td>0.522396</td>\n",
              "      <td>0.519907</td>\n",
              "      <td>0.485652</td>\n",
              "      <td>0.392520</td>\n",
              "      <td>0.515976</td>\n",
              "      <td>0.457292</td>\n",
              "      <td>0.512458</td>\n",
              "      <td>0.418244</td>\n",
              "      <td>0.504405</td>\n",
              "      <td>0.323978</td>\n",
              "      <td>0.303410</td>\n",
              "      <td>0.329820</td>\n",
              "      <td>0.498773</td>\n",
              "      <td>0.258971</td>\n",
              "      <td>0.495628</td>\n",
              "      <td>0.220827</td>\n",
              "      <td>0.483342</td>\n",
              "      <td>0.075667</td>\n",
              "      <td>0.530859</td>\n",
              "      <td>0.611838</td>\n",
              "      <td>0.531853</td>\n",
              "      <td>0.622986</td>\n",
              "      <td>0.532254</td>\n",
              "      <td>0.627294</td>\n",
              "      <td>0.533231</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.534426</td>\n",
              "      <td>0.649277</td>\n",
              "      <td>0.535938</td>\n",
              "      <td>0.665309</td>\n",
              "      <td>0.537417</td>\n",
              "      <td>0.682307</td>\n",
              "      <td>0.539387</td>\n",
              "      <td>0.708519</td>\n",
              "      <td>0.520398</td>\n",
              "      <td>...</td>\n",
              "      <td>0.346405</td>\n",
              "      <td>0.700638</td>\n",
              "      <td>0.357059</td>\n",
              "      <td>0.662449</td>\n",
              "      <td>0.359155</td>\n",
              "      <td>0.625250</td>\n",
              "      <td>0.354061</td>\n",
              "      <td>0.596125</td>\n",
              "      <td>0.345545</td>\n",
              "      <td>0.575908</td>\n",
              "      <td>0.336774</td>\n",
              "      <td>0.835300</td>\n",
              "      <td>0.377961</td>\n",
              "      <td>0.599364</td>\n",
              "      <td>0.493469</td>\n",
              "      <td>0.557649</td>\n",
              "      <td>0.401755</td>\n",
              "      <td>0.561685</td>\n",
              "      <td>0.478897</td>\n",
              "      <td>0.547105</td>\n",
              "      <td>0.494426</td>\n",
              "      <td>0.561347</td>\n",
              "      <td>0.483553</td>\n",
              "      <td>0.591593</td>\n",
              "      <td>0.503534</td>\n",
              "      <td>0.542726</td>\n",
              "      <td>0.497738</td>\n",
              "      <td>0.540497</td>\n",
              "      <td>0.504409</td>\n",
              "      <td>0.574548</td>\n",
              "      <td>0.313745</td>\n",
              "      <td>0.559276</td>\n",
              "      <td>0.321806</td>\n",
              "      <td>0.552033</td>\n",
              "      <td>0.326915</td>\n",
              "      <td>0.708733</td>\n",
              "      <td>0.290693</td>\n",
              "      <td>0.722408</td>\n",
              "      <td>0.281697</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.525898</td>\n",
              "      <td>0.594125</td>\n",
              "      <td>0.530033</td>\n",
              "      <td>0.520760</td>\n",
              "      <td>0.526494</td>\n",
              "      <td>0.539220</td>\n",
              "      <td>0.501730</td>\n",
              "      <td>0.428694</td>\n",
              "      <td>0.529735</td>\n",
              "      <td>0.494154</td>\n",
              "      <td>0.527859</td>\n",
              "      <td>0.456417</td>\n",
              "      <td>0.521891</td>\n",
              "      <td>0.362743</td>\n",
              "      <td>0.314410</td>\n",
              "      <td>0.347706</td>\n",
              "      <td>0.519482</td>\n",
              "      <td>0.305851</td>\n",
              "      <td>0.518616</td>\n",
              "      <td>0.271582</td>\n",
              "      <td>0.510917</td>\n",
              "      <td>0.113934</td>\n",
              "      <td>0.525877</td>\n",
              "      <td>0.606459</td>\n",
              "      <td>0.525577</td>\n",
              "      <td>0.614201</td>\n",
              "      <td>0.525121</td>\n",
              "      <td>0.615786</td>\n",
              "      <td>0.525468</td>\n",
              "      <td>0.621487</td>\n",
              "      <td>0.526047</td>\n",
              "      <td>0.632069</td>\n",
              "      <td>0.526596</td>\n",
              "      <td>0.645588</td>\n",
              "      <td>0.526815</td>\n",
              "      <td>0.660449</td>\n",
              "      <td>0.527288</td>\n",
              "      <td>0.689682</td>\n",
              "      <td>0.529146</td>\n",
              "      <td>...</td>\n",
              "      <td>0.367748</td>\n",
              "      <td>0.702343</td>\n",
              "      <td>0.378468</td>\n",
              "      <td>0.665439</td>\n",
              "      <td>0.381132</td>\n",
              "      <td>0.630534</td>\n",
              "      <td>0.377438</td>\n",
              "      <td>0.604434</td>\n",
              "      <td>0.371070</td>\n",
              "      <td>0.586778</td>\n",
              "      <td>0.364706</td>\n",
              "      <td>0.819888</td>\n",
              "      <td>0.379130</td>\n",
              "      <td>0.605477</td>\n",
              "      <td>0.512631</td>\n",
              "      <td>0.570194</td>\n",
              "      <td>0.435722</td>\n",
              "      <td>0.571645</td>\n",
              "      <td>0.512119</td>\n",
              "      <td>0.555648</td>\n",
              "      <td>0.523526</td>\n",
              "      <td>0.570675</td>\n",
              "      <td>0.514408</td>\n",
              "      <td>0.597486</td>\n",
              "      <td>0.519641</td>\n",
              "      <td>0.551468</td>\n",
              "      <td>0.527428</td>\n",
              "      <td>0.547463</td>\n",
              "      <td>0.530250</td>\n",
              "      <td>0.587661</td>\n",
              "      <td>0.344591</td>\n",
              "      <td>0.572917</td>\n",
              "      <td>0.352940</td>\n",
              "      <td>0.566291</td>\n",
              "      <td>0.359595</td>\n",
              "      <td>0.716786</td>\n",
              "      <td>0.320512</td>\n",
              "      <td>0.729813</td>\n",
              "      <td>0.313735</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 938 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0        1x        1y  ...      468x      468y  output\n",
              "0           0  0.471114  0.646392  ...  0.698897  0.316221   anger\n",
              "1           1  0.530374  0.614034  ...  0.753040  0.309837   anger\n",
              "2           2  0.499339  0.608413  ...  0.712155  0.301570   anger\n",
              "3           3  0.529479  0.596424  ...  0.722408  0.281697   anger\n",
              "4           4  0.525898  0.594125  ...  0.729813  0.313735   anger\n",
              "\n",
              "[5 rows x 938 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LojMwG4lWz7K",
        "outputId": "d5961ec5-2fcf-42b1-c159-89eac55c68b3"
      },
      "source": [
        "sentiment_data_small_version['output'].value_counts()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "surprise     83\n",
              "happiness    69\n",
              "neutral      60\n",
              "disgust      59\n",
              "anger        45\n",
              "sadness      28\n",
              "fear         25\n",
              "contempt     18\n",
              "Name: output, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvDgkKUsYy2D"
      },
      "source": [
        "## Mapping The Output Column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JmeYUMXY16u"
      },
      "source": [
        "input_df_copy = sentiment_data_small_version"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekyhnB5HY_Eb"
      },
      "source": [
        "uniqueValues = input_df_copy['output'].unique()\n",
        "input_df_copy['output'] = input_df_copy['output'].map({uniqueValues[0]:0,uniqueValues[1]:1,uniqueValues[2]:2,\n",
        "                                                       uniqueValues[3]:3,uniqueValues[4]:4,uniqueValues[5]:5,\n",
        "                                                       uniqueValues[6]:6,uniqueValues[7]:7})"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWoeBw72ZKUa",
        "outputId": "3ef46d69-83db-4595-f31b-309f1fea16fc"
      },
      "source": [
        "uniqueValues"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['anger', 'contempt', 'disgust', 'fear', 'happiness', 'neutral',\n",
              "       'sadness', 'surprise'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK1LdxEXZTRI"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wynE83nGZaAN"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56PAsc3mZbhG"
      },
      "source": [
        "# Create X & y\n",
        "X = input_df_copy.drop(\"output\", axis=1)\n",
        "y = input_df_copy[\"output\"]\n",
        "\n",
        "# Build our train and test sets (use random state to ensure same split as before)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKTrYiSkZfwM"
      },
      "source": [
        "# Model Declaration and Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GeMq8iWZjza"
      },
      "source": [
        "## Model 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrAdvUFIcsuY"
      },
      "source": [
        "### Declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLDNxnFAZhXs"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(256, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(128, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(8, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate = .0003),\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    patience=250,\n",
        "    min_delta=0.0001,\n",
        "    restore_best_weights=True,\n",
        ")"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt7Sb_fNcvWu"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGPlkzWGZpww",
        "outputId": "cc63b6c2-0991-4ec0-e0e2-d7a31e2072a9"
      },
      "source": [
        "history_1 = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=2000,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1, \n",
        ")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "10/10 [==============================] - 1s 34ms/step - loss: 2.3915 - accuracy: 0.1262 - val_loss: 2.0607 - val_accuracy: 0.1538\n",
            "Epoch 2/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.9815 - accuracy: 0.2557 - val_loss: 1.9408 - val_accuracy: 0.1667\n",
            "Epoch 3/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.9516 - accuracy: 0.2330 - val_loss: 1.8987 - val_accuracy: 0.1795\n",
            "Epoch 4/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.9696 - accuracy: 0.2006 - val_loss: 1.9024 - val_accuracy: 0.1667\n",
            "Epoch 5/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9176 - accuracy: 0.1877 - val_loss: 1.9027 - val_accuracy: 0.1538\n",
            "Epoch 6/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8712 - accuracy: 0.2104 - val_loss: 1.8845 - val_accuracy: 0.2179\n",
            "Epoch 7/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9088 - accuracy: 0.1942 - val_loss: 1.8873 - val_accuracy: 0.1410\n",
            "Epoch 8/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.9425 - accuracy: 0.1909 - val_loss: 1.8845 - val_accuracy: 0.1667\n",
            "Epoch 9/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.9082 - accuracy: 0.1942 - val_loss: 1.8725 - val_accuracy: 0.1667\n",
            "Epoch 10/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8663 - accuracy: 0.2071 - val_loss: 1.8671 - val_accuracy: 0.1538\n",
            "Epoch 11/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8698 - accuracy: 0.2168 - val_loss: 1.8632 - val_accuracy: 0.1282\n",
            "Epoch 12/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8280 - accuracy: 0.2168 - val_loss: 1.8672 - val_accuracy: 0.1538\n",
            "Epoch 13/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8124 - accuracy: 0.2718 - val_loss: 1.8546 - val_accuracy: 0.1410\n",
            "Epoch 14/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8296 - accuracy: 0.2071 - val_loss: 1.8626 - val_accuracy: 0.1538\n",
            "Epoch 15/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8322 - accuracy: 0.2006 - val_loss: 1.8542 - val_accuracy: 0.1538\n",
            "Epoch 16/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8370 - accuracy: 0.2071 - val_loss: 1.8517 - val_accuracy: 0.1667\n",
            "Epoch 17/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8257 - accuracy: 0.2362 - val_loss: 1.8515 - val_accuracy: 0.1667\n",
            "Epoch 18/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8465 - accuracy: 0.2039 - val_loss: 1.8604 - val_accuracy: 0.1410\n",
            "Epoch 19/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8576 - accuracy: 0.2718 - val_loss: 1.8436 - val_accuracy: 0.1410\n",
            "Epoch 20/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8167 - accuracy: 0.2039 - val_loss: 1.8397 - val_accuracy: 0.1667\n",
            "Epoch 21/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8017 - accuracy: 0.2751 - val_loss: 1.8411 - val_accuracy: 0.1282\n",
            "Epoch 22/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8108 - accuracy: 0.2006 - val_loss: 1.8372 - val_accuracy: 0.1282\n",
            "Epoch 23/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8121 - accuracy: 0.2201 - val_loss: 1.8312 - val_accuracy: 0.1667\n",
            "Epoch 24/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8016 - accuracy: 0.2621 - val_loss: 1.8299 - val_accuracy: 0.1923\n",
            "Epoch 25/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8224 - accuracy: 0.2492 - val_loss: 1.8323 - val_accuracy: 0.2308\n",
            "Epoch 26/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8007 - accuracy: 0.2330 - val_loss: 1.8249 - val_accuracy: 0.1923\n",
            "Epoch 27/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8018 - accuracy: 0.2395 - val_loss: 1.8194 - val_accuracy: 0.1538\n",
            "Epoch 28/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8142 - accuracy: 0.2136 - val_loss: 1.8222 - val_accuracy: 0.1667\n",
            "Epoch 29/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8030 - accuracy: 0.2330 - val_loss: 1.8201 - val_accuracy: 0.1795\n",
            "Epoch 30/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8058 - accuracy: 0.2104 - val_loss: 1.8349 - val_accuracy: 0.1410\n",
            "Epoch 31/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8002 - accuracy: 0.2557 - val_loss: 1.8201 - val_accuracy: 0.1795\n",
            "Epoch 32/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8000 - accuracy: 0.2460 - val_loss: 1.8060 - val_accuracy: 0.1667\n",
            "Epoch 33/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8050 - accuracy: 0.2427 - val_loss: 1.8099 - val_accuracy: 0.1667\n",
            "Epoch 34/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7975 - accuracy: 0.2557 - val_loss: 1.8053 - val_accuracy: 0.1538\n",
            "Epoch 35/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7921 - accuracy: 0.2265 - val_loss: 1.7940 - val_accuracy: 0.2308\n",
            "Epoch 36/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7945 - accuracy: 0.2395 - val_loss: 1.8200 - val_accuracy: 0.1667\n",
            "Epoch 37/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7694 - accuracy: 0.2977 - val_loss: 1.8205 - val_accuracy: 0.1410\n",
            "Epoch 38/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7829 - accuracy: 0.2686 - val_loss: 1.8165 - val_accuracy: 0.1538\n",
            "Epoch 39/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7905 - accuracy: 0.2880 - val_loss: 1.8008 - val_accuracy: 0.1667\n",
            "Epoch 40/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7824 - accuracy: 0.2330 - val_loss: 1.8034 - val_accuracy: 0.1538\n",
            "Epoch 41/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7950 - accuracy: 0.2330 - val_loss: 1.7962 - val_accuracy: 0.1410\n",
            "Epoch 42/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7811 - accuracy: 0.2362 - val_loss: 1.7813 - val_accuracy: 0.2308\n",
            "Epoch 43/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7396 - accuracy: 0.3042 - val_loss: 1.7855 - val_accuracy: 0.2179\n",
            "Epoch 44/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7432 - accuracy: 0.2816 - val_loss: 1.7719 - val_accuracy: 0.1667\n",
            "Epoch 45/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7687 - accuracy: 0.2686 - val_loss: 1.7620 - val_accuracy: 0.2436\n",
            "Epoch 46/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7579 - accuracy: 0.2427 - val_loss: 1.7550 - val_accuracy: 0.1923\n",
            "Epoch 47/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7560 - accuracy: 0.2330 - val_loss: 1.7599 - val_accuracy: 0.1923\n",
            "Epoch 48/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7833 - accuracy: 0.2524 - val_loss: 1.7621 - val_accuracy: 0.1923\n",
            "Epoch 49/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7358 - accuracy: 0.2783 - val_loss: 1.7477 - val_accuracy: 0.2821\n",
            "Epoch 50/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7414 - accuracy: 0.2880 - val_loss: 1.7560 - val_accuracy: 0.3205\n",
            "Epoch 51/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.7106 - accuracy: 0.2977 - val_loss: 1.7348 - val_accuracy: 0.2692\n",
            "Epoch 52/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7439 - accuracy: 0.2751 - val_loss: 1.7563 - val_accuracy: 0.2692\n",
            "Epoch 53/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7160 - accuracy: 0.3398 - val_loss: 1.7386 - val_accuracy: 0.3077\n",
            "Epoch 54/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7269 - accuracy: 0.2945 - val_loss: 1.7432 - val_accuracy: 0.2051\n",
            "Epoch 55/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7359 - accuracy: 0.2621 - val_loss: 1.7327 - val_accuracy: 0.2564\n",
            "Epoch 56/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7256 - accuracy: 0.3139 - val_loss: 1.7038 - val_accuracy: 0.2821\n",
            "Epoch 57/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7103 - accuracy: 0.2783 - val_loss: 1.7116 - val_accuracy: 0.2692\n",
            "Epoch 58/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7013 - accuracy: 0.3236 - val_loss: 1.7274 - val_accuracy: 0.2308\n",
            "Epoch 59/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.6930 - accuracy: 0.3301 - val_loss: 1.6820 - val_accuracy: 0.3205\n",
            "Epoch 60/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6741 - accuracy: 0.3495 - val_loss: 1.6601 - val_accuracy: 0.3077\n",
            "Epoch 61/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.6818 - accuracy: 0.3333 - val_loss: 1.6524 - val_accuracy: 0.3077\n",
            "Epoch 62/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6459 - accuracy: 0.3657 - val_loss: 1.6421 - val_accuracy: 0.2949\n",
            "Epoch 63/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.6902 - accuracy: 0.3398 - val_loss: 1.6267 - val_accuracy: 0.2949\n",
            "Epoch 64/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.6799 - accuracy: 0.3301 - val_loss: 1.6619 - val_accuracy: 0.2949\n",
            "Epoch 65/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6650 - accuracy: 0.3301 - val_loss: 1.6145 - val_accuracy: 0.2564\n",
            "Epoch 66/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6442 - accuracy: 0.3754 - val_loss: 1.6101 - val_accuracy: 0.3077\n",
            "Epoch 67/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7072 - accuracy: 0.3625 - val_loss: 1.5968 - val_accuracy: 0.3205\n",
            "Epoch 68/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.5885 - accuracy: 0.3916 - val_loss: 1.5854 - val_accuracy: 0.3333\n",
            "Epoch 69/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.6033 - accuracy: 0.3560 - val_loss: 1.6332 - val_accuracy: 0.2949\n",
            "Epoch 70/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.5998 - accuracy: 0.3722 - val_loss: 1.6322 - val_accuracy: 0.3077\n",
            "Epoch 71/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.6253 - accuracy: 0.3398 - val_loss: 1.5514 - val_accuracy: 0.3077\n",
            "Epoch 72/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.5944 - accuracy: 0.3689 - val_loss: 1.6130 - val_accuracy: 0.2436\n",
            "Epoch 73/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.6161 - accuracy: 0.3657 - val_loss: 1.5369 - val_accuracy: 0.3077\n",
            "Epoch 74/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.5623 - accuracy: 0.3754 - val_loss: 1.6583 - val_accuracy: 0.2564\n",
            "Epoch 75/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5499 - accuracy: 0.3463 - val_loss: 1.5755 - val_accuracy: 0.2692\n",
            "Epoch 76/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.5456 - accuracy: 0.3463 - val_loss: 1.4817 - val_accuracy: 0.3718\n",
            "Epoch 77/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.5564 - accuracy: 0.3560 - val_loss: 1.4842 - val_accuracy: 0.3333\n",
            "Epoch 78/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.5594 - accuracy: 0.3981 - val_loss: 1.5001 - val_accuracy: 0.3333\n",
            "Epoch 79/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.5540 - accuracy: 0.3560 - val_loss: 1.4928 - val_accuracy: 0.3205\n",
            "Epoch 80/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.5145 - accuracy: 0.3916 - val_loss: 1.4671 - val_accuracy: 0.3333\n",
            "Epoch 81/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.5074 - accuracy: 0.3657 - val_loss: 1.4310 - val_accuracy: 0.3590\n",
            "Epoch 82/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.4733 - accuracy: 0.4013 - val_loss: 1.4473 - val_accuracy: 0.3590\n",
            "Epoch 83/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4776 - accuracy: 0.3786 - val_loss: 1.4404 - val_accuracy: 0.3462\n",
            "Epoch 84/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.4646 - accuracy: 0.3851 - val_loss: 1.4568 - val_accuracy: 0.3846\n",
            "Epoch 85/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.4476 - accuracy: 0.4078 - val_loss: 1.4129 - val_accuracy: 0.3974\n",
            "Epoch 86/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.4354 - accuracy: 0.4078 - val_loss: 1.4124 - val_accuracy: 0.3846\n",
            "Epoch 87/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.4439 - accuracy: 0.3851 - val_loss: 1.4128 - val_accuracy: 0.3974\n",
            "Epoch 88/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.4608 - accuracy: 0.3916 - val_loss: 1.4047 - val_accuracy: 0.3846\n",
            "Epoch 89/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.4298 - accuracy: 0.4142 - val_loss: 1.3670 - val_accuracy: 0.4872\n",
            "Epoch 90/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.4077 - accuracy: 0.4369 - val_loss: 1.3885 - val_accuracy: 0.3974\n",
            "Epoch 91/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.4401 - accuracy: 0.4045 - val_loss: 1.4264 - val_accuracy: 0.3462\n",
            "Epoch 92/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4315 - accuracy: 0.4239 - val_loss: 1.3723 - val_accuracy: 0.3846\n",
            "Epoch 93/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.4412 - accuracy: 0.3916 - val_loss: 1.3588 - val_accuracy: 0.3846\n",
            "Epoch 94/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3850 - accuracy: 0.4304 - val_loss: 1.3772 - val_accuracy: 0.3590\n",
            "Epoch 95/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.4043 - accuracy: 0.4110 - val_loss: 1.3872 - val_accuracy: 0.3974\n",
            "Epoch 96/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.4447 - accuracy: 0.4369 - val_loss: 1.3858 - val_accuracy: 0.3333\n",
            "Epoch 97/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3867 - accuracy: 0.4207 - val_loss: 1.3461 - val_accuracy: 0.3590\n",
            "Epoch 98/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4183 - accuracy: 0.3916 - val_loss: 1.3739 - val_accuracy: 0.3590\n",
            "Epoch 99/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.3735 - accuracy: 0.4337 - val_loss: 1.3412 - val_accuracy: 0.4231\n",
            "Epoch 100/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.3647 - accuracy: 0.4304 - val_loss: 1.3669 - val_accuracy: 0.3205\n",
            "Epoch 101/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.3772 - accuracy: 0.4401 - val_loss: 1.3502 - val_accuracy: 0.3718\n",
            "Epoch 102/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3696 - accuracy: 0.4531 - val_loss: 1.3806 - val_accuracy: 0.3462\n",
            "Epoch 103/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.3979 - accuracy: 0.4337 - val_loss: 1.4039 - val_accuracy: 0.3205\n",
            "Epoch 104/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.4081 - accuracy: 0.4369 - val_loss: 1.3680 - val_accuracy: 0.3590\n",
            "Epoch 105/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.3641 - accuracy: 0.4595 - val_loss: 1.3971 - val_accuracy: 0.3333\n",
            "Epoch 106/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3861 - accuracy: 0.4078 - val_loss: 1.3979 - val_accuracy: 0.3205\n",
            "Epoch 107/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4080 - accuracy: 0.4078 - val_loss: 1.4006 - val_accuracy: 0.3077\n",
            "Epoch 108/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3726 - accuracy: 0.4401 - val_loss: 1.3285 - val_accuracy: 0.3846\n",
            "Epoch 109/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3561 - accuracy: 0.4272 - val_loss: 1.3322 - val_accuracy: 0.3590\n",
            "Epoch 110/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3708 - accuracy: 0.4563 - val_loss: 1.3439 - val_accuracy: 0.3718\n",
            "Epoch 111/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.3346 - accuracy: 0.4498 - val_loss: 1.3300 - val_accuracy: 0.3846\n",
            "Epoch 112/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.3289 - accuracy: 0.4434 - val_loss: 1.3427 - val_accuracy: 0.3590\n",
            "Epoch 113/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3326 - accuracy: 0.4369 - val_loss: 1.3054 - val_accuracy: 0.3846\n",
            "Epoch 114/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3161 - accuracy: 0.4660 - val_loss: 1.3201 - val_accuracy: 0.3974\n",
            "Epoch 115/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2976 - accuracy: 0.4466 - val_loss: 1.3142 - val_accuracy: 0.4103\n",
            "Epoch 116/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.3420 - accuracy: 0.4272 - val_loss: 1.3590 - val_accuracy: 0.3846\n",
            "Epoch 117/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3517 - accuracy: 0.4337 - val_loss: 1.4165 - val_accuracy: 0.3718\n",
            "Epoch 118/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3855 - accuracy: 0.4369 - val_loss: 1.3560 - val_accuracy: 0.4103\n",
            "Epoch 119/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.3523 - accuracy: 0.4110 - val_loss: 1.3591 - val_accuracy: 0.3974\n",
            "Epoch 120/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3850 - accuracy: 0.4272 - val_loss: 1.3553 - val_accuracy: 0.3846\n",
            "Epoch 121/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3692 - accuracy: 0.4207 - val_loss: 1.3223 - val_accuracy: 0.3846\n",
            "Epoch 122/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3388 - accuracy: 0.4401 - val_loss: 1.3061 - val_accuracy: 0.4103\n",
            "Epoch 123/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3329 - accuracy: 0.4693 - val_loss: 1.3067 - val_accuracy: 0.3590\n",
            "Epoch 124/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3197 - accuracy: 0.4531 - val_loss: 1.2961 - val_accuracy: 0.4103\n",
            "Epoch 125/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3115 - accuracy: 0.4466 - val_loss: 1.2966 - val_accuracy: 0.3846\n",
            "Epoch 126/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2886 - accuracy: 0.4822 - val_loss: 1.2914 - val_accuracy: 0.4231\n",
            "Epoch 127/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2722 - accuracy: 0.4660 - val_loss: 1.2624 - val_accuracy: 0.3974\n",
            "Epoch 128/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2874 - accuracy: 0.4563 - val_loss: 1.2753 - val_accuracy: 0.4231\n",
            "Epoch 129/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.2943 - accuracy: 0.4531 - val_loss: 1.2845 - val_accuracy: 0.3846\n",
            "Epoch 130/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.2917 - accuracy: 0.4887 - val_loss: 1.2932 - val_accuracy: 0.3846\n",
            "Epoch 131/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2939 - accuracy: 0.4628 - val_loss: 1.3359 - val_accuracy: 0.3846\n",
            "Epoch 132/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2827 - accuracy: 0.4790 - val_loss: 1.2947 - val_accuracy: 0.3846\n",
            "Epoch 133/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2654 - accuracy: 0.4725 - val_loss: 1.2697 - val_accuracy: 0.3974\n",
            "Epoch 134/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2990 - accuracy: 0.4434 - val_loss: 1.2725 - val_accuracy: 0.3974\n",
            "Epoch 135/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2370 - accuracy: 0.5081 - val_loss: 1.2577 - val_accuracy: 0.4359\n",
            "Epoch 136/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2826 - accuracy: 0.4951 - val_loss: 1.2513 - val_accuracy: 0.4359\n",
            "Epoch 137/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.2504 - accuracy: 0.4822 - val_loss: 1.3037 - val_accuracy: 0.3718\n",
            "Epoch 138/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2686 - accuracy: 0.4693 - val_loss: 1.3540 - val_accuracy: 0.3462\n",
            "Epoch 139/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2862 - accuracy: 0.4531 - val_loss: 1.3132 - val_accuracy: 0.3846\n",
            "Epoch 140/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2539 - accuracy: 0.5016 - val_loss: 1.2486 - val_accuracy: 0.3974\n",
            "Epoch 141/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.2549 - accuracy: 0.5146 - val_loss: 1.2643 - val_accuracy: 0.3846\n",
            "Epoch 142/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.2510 - accuracy: 0.4822 - val_loss: 1.3061 - val_accuracy: 0.3846\n",
            "Epoch 143/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2890 - accuracy: 0.4693 - val_loss: 1.2405 - val_accuracy: 0.4615\n",
            "Epoch 144/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2644 - accuracy: 0.4790 - val_loss: 1.2583 - val_accuracy: 0.4231\n",
            "Epoch 145/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2530 - accuracy: 0.4563 - val_loss: 1.2938 - val_accuracy: 0.3718\n",
            "Epoch 146/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2764 - accuracy: 0.4790 - val_loss: 1.3000 - val_accuracy: 0.3718\n",
            "Epoch 147/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2622 - accuracy: 0.4628 - val_loss: 1.3245 - val_accuracy: 0.3590\n",
            "Epoch 148/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2646 - accuracy: 0.4660 - val_loss: 1.2660 - val_accuracy: 0.4359\n",
            "Epoch 149/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3010 - accuracy: 0.4790 - val_loss: 1.2377 - val_accuracy: 0.4231\n",
            "Epoch 150/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2392 - accuracy: 0.5049 - val_loss: 1.2470 - val_accuracy: 0.4103\n",
            "Epoch 151/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.3052 - accuracy: 0.4531 - val_loss: 1.3605 - val_accuracy: 0.3333\n",
            "Epoch 152/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3183 - accuracy: 0.4595 - val_loss: 1.3755 - val_accuracy: 0.3333\n",
            "Epoch 153/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.2668 - accuracy: 0.4790 - val_loss: 1.3044 - val_accuracy: 0.3846\n",
            "Epoch 154/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.2376 - accuracy: 0.5113 - val_loss: 1.2330 - val_accuracy: 0.4231\n",
            "Epoch 155/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2391 - accuracy: 0.5016 - val_loss: 1.2662 - val_accuracy: 0.4103\n",
            "Epoch 156/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2501 - accuracy: 0.4628 - val_loss: 1.2768 - val_accuracy: 0.3974\n",
            "Epoch 157/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.2824 - accuracy: 0.4434 - val_loss: 1.2495 - val_accuracy: 0.4231\n",
            "Epoch 158/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2343 - accuracy: 0.4887 - val_loss: 1.2494 - val_accuracy: 0.4231\n",
            "Epoch 159/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.2482 - accuracy: 0.4854 - val_loss: 1.2358 - val_accuracy: 0.4231\n",
            "Epoch 160/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2872 - accuracy: 0.4919 - val_loss: 1.2378 - val_accuracy: 0.3974\n",
            "Epoch 161/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.2229 - accuracy: 0.5016 - val_loss: 1.2364 - val_accuracy: 0.4615\n",
            "Epoch 162/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2358 - accuracy: 0.4854 - val_loss: 1.2363 - val_accuracy: 0.4103\n",
            "Epoch 163/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.2081 - accuracy: 0.4951 - val_loss: 1.2446 - val_accuracy: 0.4231\n",
            "Epoch 164/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2386 - accuracy: 0.4531 - val_loss: 1.2269 - val_accuracy: 0.4615\n",
            "Epoch 165/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3171 - accuracy: 0.4434 - val_loss: 1.3701 - val_accuracy: 0.3974\n",
            "Epoch 166/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2899 - accuracy: 0.4822 - val_loss: 1.2826 - val_accuracy: 0.4103\n",
            "Epoch 167/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.2750 - accuracy: 0.4951 - val_loss: 1.2499 - val_accuracy: 0.4359\n",
            "Epoch 168/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2580 - accuracy: 0.4757 - val_loss: 1.2617 - val_accuracy: 0.4615\n",
            "Epoch 169/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2462 - accuracy: 0.5049 - val_loss: 1.2970 - val_accuracy: 0.3974\n",
            "Epoch 170/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2764 - accuracy: 0.4660 - val_loss: 1.2776 - val_accuracy: 0.3974\n",
            "Epoch 171/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2003 - accuracy: 0.5178 - val_loss: 1.2414 - val_accuracy: 0.4103\n",
            "Epoch 172/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2496 - accuracy: 0.4887 - val_loss: 1.2034 - val_accuracy: 0.4615\n",
            "Epoch 173/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2081 - accuracy: 0.5178 - val_loss: 1.2106 - val_accuracy: 0.4103\n",
            "Epoch 174/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2499 - accuracy: 0.5016 - val_loss: 1.2268 - val_accuracy: 0.4359\n",
            "Epoch 175/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2695 - accuracy: 0.4563 - val_loss: 1.2171 - val_accuracy: 0.4359\n",
            "Epoch 176/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.2843 - accuracy: 0.4790 - val_loss: 1.2329 - val_accuracy: 0.3846\n",
            "Epoch 177/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2209 - accuracy: 0.5113 - val_loss: 1.3147 - val_accuracy: 0.3718\n",
            "Epoch 178/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1867 - accuracy: 0.4984 - val_loss: 1.2427 - val_accuracy: 0.3718\n",
            "Epoch 179/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2181 - accuracy: 0.5178 - val_loss: 1.3076 - val_accuracy: 0.3974\n",
            "Epoch 180/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.2557 - accuracy: 0.5016 - val_loss: 1.1951 - val_accuracy: 0.5000\n",
            "Epoch 181/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.2138 - accuracy: 0.5372 - val_loss: 1.2222 - val_accuracy: 0.4359\n",
            "Epoch 182/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1825 - accuracy: 0.5081 - val_loss: 1.2112 - val_accuracy: 0.4231\n",
            "Epoch 183/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2363 - accuracy: 0.4693 - val_loss: 1.3251 - val_accuracy: 0.3590\n",
            "Epoch 184/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2341 - accuracy: 0.5113 - val_loss: 1.2260 - val_accuracy: 0.4103\n",
            "Epoch 185/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1947 - accuracy: 0.5178 - val_loss: 1.2033 - val_accuracy: 0.4487\n",
            "Epoch 186/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1865 - accuracy: 0.5146 - val_loss: 1.2005 - val_accuracy: 0.4231\n",
            "Epoch 187/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1942 - accuracy: 0.5049 - val_loss: 1.2513 - val_accuracy: 0.4103\n",
            "Epoch 188/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2467 - accuracy: 0.4854 - val_loss: 1.2077 - val_accuracy: 0.4231\n",
            "Epoch 189/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.2223 - accuracy: 0.5243 - val_loss: 1.2433 - val_accuracy: 0.4103\n",
            "Epoch 190/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2084 - accuracy: 0.5502 - val_loss: 1.2073 - val_accuracy: 0.4103\n",
            "Epoch 191/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.2543 - accuracy: 0.5081 - val_loss: 1.1789 - val_accuracy: 0.4615\n",
            "Epoch 192/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2278 - accuracy: 0.5081 - val_loss: 1.2557 - val_accuracy: 0.4615\n",
            "Epoch 193/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1807 - accuracy: 0.5307 - val_loss: 1.2347 - val_accuracy: 0.4872\n",
            "Epoch 194/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1671 - accuracy: 0.5275 - val_loss: 1.1716 - val_accuracy: 0.5000\n",
            "Epoch 195/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1747 - accuracy: 0.5210 - val_loss: 1.1882 - val_accuracy: 0.3846\n",
            "Epoch 196/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1872 - accuracy: 0.5113 - val_loss: 1.1805 - val_accuracy: 0.4231\n",
            "Epoch 197/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1815 - accuracy: 0.5243 - val_loss: 1.1808 - val_accuracy: 0.5000\n",
            "Epoch 198/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1536 - accuracy: 0.5566 - val_loss: 1.1745 - val_accuracy: 0.5000\n",
            "Epoch 199/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1882 - accuracy: 0.5340 - val_loss: 1.2061 - val_accuracy: 0.3846\n",
            "Epoch 200/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.1592 - accuracy: 0.5372 - val_loss: 1.2753 - val_accuracy: 0.3590\n",
            "Epoch 201/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1712 - accuracy: 0.5178 - val_loss: 1.1552 - val_accuracy: 0.4872\n",
            "Epoch 202/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.1025 - accuracy: 0.5761 - val_loss: 1.2729 - val_accuracy: 0.4103\n",
            "Epoch 203/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1787 - accuracy: 0.5243 - val_loss: 1.1686 - val_accuracy: 0.4744\n",
            "Epoch 204/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.1596 - accuracy: 0.5146 - val_loss: 1.1623 - val_accuracy: 0.5385\n",
            "Epoch 205/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.1404 - accuracy: 0.5437 - val_loss: 1.1301 - val_accuracy: 0.5256\n",
            "Epoch 206/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1254 - accuracy: 0.5858 - val_loss: 1.1509 - val_accuracy: 0.4744\n",
            "Epoch 207/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1469 - accuracy: 0.5146 - val_loss: 1.1705 - val_accuracy: 0.4487\n",
            "Epoch 208/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.1298 - accuracy: 0.5696 - val_loss: 1.2745 - val_accuracy: 0.3846\n",
            "Epoch 209/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1720 - accuracy: 0.5243 - val_loss: 1.1789 - val_accuracy: 0.4103\n",
            "Epoch 210/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1631 - accuracy: 0.5307 - val_loss: 1.2114 - val_accuracy: 0.4103\n",
            "Epoch 211/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1347 - accuracy: 0.5761 - val_loss: 1.1230 - val_accuracy: 0.4872\n",
            "Epoch 212/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2621 - accuracy: 0.5178 - val_loss: 1.2517 - val_accuracy: 0.5000\n",
            "Epoch 213/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1394 - accuracy: 0.5599 - val_loss: 1.2057 - val_accuracy: 0.4872\n",
            "Epoch 214/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1760 - accuracy: 0.5307 - val_loss: 1.1480 - val_accuracy: 0.5000\n",
            "Epoch 215/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.1225 - accuracy: 0.5534 - val_loss: 1.1714 - val_accuracy: 0.5000\n",
            "Epoch 216/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1498 - accuracy: 0.5275 - val_loss: 1.2111 - val_accuracy: 0.3846\n",
            "Epoch 217/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.1413 - accuracy: 0.5340 - val_loss: 1.1888 - val_accuracy: 0.4103\n",
            "Epoch 218/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1367 - accuracy: 0.5469 - val_loss: 1.1695 - val_accuracy: 0.4615\n",
            "Epoch 219/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1350 - accuracy: 0.5178 - val_loss: 1.1463 - val_accuracy: 0.5000\n",
            "Epoch 220/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.1403 - accuracy: 0.5534 - val_loss: 1.1411 - val_accuracy: 0.4744\n",
            "Epoch 221/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.1147 - accuracy: 0.5599 - val_loss: 1.1287 - val_accuracy: 0.5000\n",
            "Epoch 222/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.1117 - accuracy: 0.5534 - val_loss: 1.1420 - val_accuracy: 0.5128\n",
            "Epoch 223/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.0941 - accuracy: 0.5696 - val_loss: 1.1134 - val_accuracy: 0.5128\n",
            "Epoch 224/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1282 - accuracy: 0.5761 - val_loss: 1.1425 - val_accuracy: 0.4872\n",
            "Epoch 225/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1646 - accuracy: 0.5502 - val_loss: 1.1013 - val_accuracy: 0.5385\n",
            "Epoch 226/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.1488 - accuracy: 0.5210 - val_loss: 1.1521 - val_accuracy: 0.4744\n",
            "Epoch 227/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.1294 - accuracy: 0.5437 - val_loss: 1.0974 - val_accuracy: 0.5128\n",
            "Epoch 228/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.0904 - accuracy: 0.5663 - val_loss: 1.1129 - val_accuracy: 0.5385\n",
            "Epoch 229/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.1115 - accuracy: 0.5534 - val_loss: 1.1603 - val_accuracy: 0.5641\n",
            "Epoch 230/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1352 - accuracy: 0.5534 - val_loss: 1.1013 - val_accuracy: 0.5000\n",
            "Epoch 231/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1039 - accuracy: 0.5372 - val_loss: 1.1007 - val_accuracy: 0.4872\n",
            "Epoch 232/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0860 - accuracy: 0.5340 - val_loss: 1.1793 - val_accuracy: 0.4744\n",
            "Epoch 233/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.0793 - accuracy: 0.5890 - val_loss: 1.2198 - val_accuracy: 0.4103\n",
            "Epoch 234/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0676 - accuracy: 0.5858 - val_loss: 1.1565 - val_accuracy: 0.4487\n",
            "Epoch 235/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0598 - accuracy: 0.5663 - val_loss: 1.0781 - val_accuracy: 0.5128\n",
            "Epoch 236/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0706 - accuracy: 0.5793 - val_loss: 1.0637 - val_accuracy: 0.5769\n",
            "Epoch 237/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0867 - accuracy: 0.5437 - val_loss: 1.1223 - val_accuracy: 0.5128\n",
            "Epoch 238/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0774 - accuracy: 0.5469 - val_loss: 1.1077 - val_accuracy: 0.5385\n",
            "Epoch 239/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0529 - accuracy: 0.5761 - val_loss: 1.1206 - val_accuracy: 0.5000\n",
            "Epoch 240/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.1065 - accuracy: 0.5566 - val_loss: 1.1185 - val_accuracy: 0.4744\n",
            "Epoch 241/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.0380 - accuracy: 0.5955 - val_loss: 1.0943 - val_accuracy: 0.5513\n",
            "Epoch 242/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0947 - accuracy: 0.5469 - val_loss: 1.2264 - val_accuracy: 0.4615\n",
            "Epoch 243/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1356 - accuracy: 0.5210 - val_loss: 1.1761 - val_accuracy: 0.4231\n",
            "Epoch 244/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1163 - accuracy: 0.5566 - val_loss: 1.1072 - val_accuracy: 0.5128\n",
            "Epoch 245/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0897 - accuracy: 0.5793 - val_loss: 1.1503 - val_accuracy: 0.4615\n",
            "Epoch 246/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0532 - accuracy: 0.6019 - val_loss: 1.0672 - val_accuracy: 0.5641\n",
            "Epoch 247/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0557 - accuracy: 0.5825 - val_loss: 1.0682 - val_accuracy: 0.5256\n",
            "Epoch 248/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0794 - accuracy: 0.5210 - val_loss: 1.1130 - val_accuracy: 0.4487\n",
            "Epoch 249/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0279 - accuracy: 0.6052 - val_loss: 1.0488 - val_accuracy: 0.5385\n",
            "Epoch 250/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0420 - accuracy: 0.5761 - val_loss: 1.0577 - val_accuracy: 0.5641\n",
            "Epoch 251/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0637 - accuracy: 0.5566 - val_loss: 1.0679 - val_accuracy: 0.5513\n",
            "Epoch 252/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0212 - accuracy: 0.5922 - val_loss: 1.0949 - val_accuracy: 0.5000\n",
            "Epoch 253/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0237 - accuracy: 0.5987 - val_loss: 1.0886 - val_accuracy: 0.5000\n",
            "Epoch 254/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0557 - accuracy: 0.5890 - val_loss: 1.0871 - val_accuracy: 0.5256\n",
            "Epoch 255/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0494 - accuracy: 0.5599 - val_loss: 1.0838 - val_accuracy: 0.5128\n",
            "Epoch 256/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0011 - accuracy: 0.6052 - val_loss: 1.0685 - val_accuracy: 0.5897\n",
            "Epoch 257/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.9985 - accuracy: 0.6117 - val_loss: 1.0449 - val_accuracy: 0.5256\n",
            "Epoch 258/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0064 - accuracy: 0.6246 - val_loss: 1.0366 - val_accuracy: 0.5256\n",
            "Epoch 259/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9923 - accuracy: 0.5825 - val_loss: 1.1300 - val_accuracy: 0.5385\n",
            "Epoch 260/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0218 - accuracy: 0.6117 - val_loss: 1.0105 - val_accuracy: 0.5897\n",
            "Epoch 261/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0137 - accuracy: 0.6052 - val_loss: 1.1679 - val_accuracy: 0.5641\n",
            "Epoch 262/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0970 - accuracy: 0.5566 - val_loss: 1.1111 - val_accuracy: 0.5641\n",
            "Epoch 263/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1383 - accuracy: 0.5502 - val_loss: 1.0573 - val_accuracy: 0.5769\n",
            "Epoch 264/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.0970 - accuracy: 0.5534 - val_loss: 1.1207 - val_accuracy: 0.5000\n",
            "Epoch 265/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1249 - accuracy: 0.5502 - val_loss: 1.0719 - val_accuracy: 0.5513\n",
            "Epoch 266/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0708 - accuracy: 0.5825 - val_loss: 1.1153 - val_accuracy: 0.5641\n",
            "Epoch 267/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0539 - accuracy: 0.5825 - val_loss: 1.0587 - val_accuracy: 0.5513\n",
            "Epoch 268/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9847 - accuracy: 0.6019 - val_loss: 1.0995 - val_accuracy: 0.5128\n",
            "Epoch 269/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0509 - accuracy: 0.5858 - val_loss: 1.1435 - val_accuracy: 0.5385\n",
            "Epoch 270/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0492 - accuracy: 0.5663 - val_loss: 1.0309 - val_accuracy: 0.5769\n",
            "Epoch 271/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9751 - accuracy: 0.5955 - val_loss: 1.0198 - val_accuracy: 0.5385\n",
            "Epoch 272/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9962 - accuracy: 0.6181 - val_loss: 0.9876 - val_accuracy: 0.6154\n",
            "Epoch 273/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9504 - accuracy: 0.5922 - val_loss: 1.0340 - val_accuracy: 0.5385\n",
            "Epoch 274/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9383 - accuracy: 0.6084 - val_loss: 1.1653 - val_accuracy: 0.5000\n",
            "Epoch 275/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.0827 - accuracy: 0.5631 - val_loss: 1.1748 - val_accuracy: 0.5256\n",
            "Epoch 276/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1473 - accuracy: 0.5469 - val_loss: 1.0626 - val_accuracy: 0.5641\n",
            "Epoch 277/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0162 - accuracy: 0.6117 - val_loss: 1.0149 - val_accuracy: 0.5513\n",
            "Epoch 278/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9874 - accuracy: 0.6117 - val_loss: 1.0649 - val_accuracy: 0.5641\n",
            "Epoch 279/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0069 - accuracy: 0.5890 - val_loss: 1.0012 - val_accuracy: 0.5385\n",
            "Epoch 280/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9612 - accuracy: 0.6375 - val_loss: 0.9844 - val_accuracy: 0.5385\n",
            "Epoch 281/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9568 - accuracy: 0.6149 - val_loss: 1.0032 - val_accuracy: 0.5385\n",
            "Epoch 282/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9704 - accuracy: 0.6311 - val_loss: 1.0663 - val_accuracy: 0.5128\n",
            "Epoch 283/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9550 - accuracy: 0.6246 - val_loss: 1.1345 - val_accuracy: 0.4872\n",
            "Epoch 284/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.9723 - accuracy: 0.6278 - val_loss: 1.0129 - val_accuracy: 0.5128\n",
            "Epoch 285/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9442 - accuracy: 0.6472 - val_loss: 1.0348 - val_accuracy: 0.5000\n",
            "Epoch 286/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9586 - accuracy: 0.6343 - val_loss: 0.9784 - val_accuracy: 0.5641\n",
            "Epoch 287/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9952 - accuracy: 0.5890 - val_loss: 1.0187 - val_accuracy: 0.5897\n",
            "Epoch 288/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9595 - accuracy: 0.6246 - val_loss: 0.9795 - val_accuracy: 0.6154\n",
            "Epoch 289/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9163 - accuracy: 0.6278 - val_loss: 0.9682 - val_accuracy: 0.5385\n",
            "Epoch 290/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9227 - accuracy: 0.6375 - val_loss: 0.9871 - val_accuracy: 0.5769\n",
            "Epoch 291/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9246 - accuracy: 0.6440 - val_loss: 0.9778 - val_accuracy: 0.5641\n",
            "Epoch 292/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8946 - accuracy: 0.6408 - val_loss: 1.0053 - val_accuracy: 0.5513\n",
            "Epoch 293/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9277 - accuracy: 0.6408 - val_loss: 0.9873 - val_accuracy: 0.5769\n",
            "Epoch 294/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9867 - accuracy: 0.5890 - val_loss: 1.0281 - val_accuracy: 0.6538\n",
            "Epoch 295/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0651 - accuracy: 0.5761 - val_loss: 0.9943 - val_accuracy: 0.6026\n",
            "Epoch 296/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9676 - accuracy: 0.6181 - val_loss: 1.0439 - val_accuracy: 0.5256\n",
            "Epoch 297/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9570 - accuracy: 0.6375 - val_loss: 1.1184 - val_accuracy: 0.5000\n",
            "Epoch 298/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0096 - accuracy: 0.5890 - val_loss: 1.0508 - val_accuracy: 0.4744\n",
            "Epoch 299/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9393 - accuracy: 0.6278 - val_loss: 1.0134 - val_accuracy: 0.5128\n",
            "Epoch 300/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9254 - accuracy: 0.6505 - val_loss: 0.9978 - val_accuracy: 0.5641\n",
            "Epoch 301/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9221 - accuracy: 0.6278 - val_loss: 0.9960 - val_accuracy: 0.5769\n",
            "Epoch 302/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.9148 - accuracy: 0.6828 - val_loss: 0.9844 - val_accuracy: 0.5641\n",
            "Epoch 303/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9576 - accuracy: 0.6181 - val_loss: 0.9688 - val_accuracy: 0.5769\n",
            "Epoch 304/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8843 - accuracy: 0.6505 - val_loss: 0.9986 - val_accuracy: 0.5385\n",
            "Epoch 305/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9095 - accuracy: 0.6311 - val_loss: 0.9918 - val_accuracy: 0.5385\n",
            "Epoch 306/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9396 - accuracy: 0.6634 - val_loss: 1.1470 - val_accuracy: 0.4872\n",
            "Epoch 307/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9100 - accuracy: 0.6246 - val_loss: 0.9694 - val_accuracy: 0.5769\n",
            "Epoch 308/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9332 - accuracy: 0.6537 - val_loss: 0.9678 - val_accuracy: 0.5641\n",
            "Epoch 309/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9686 - accuracy: 0.5922 - val_loss: 1.0451 - val_accuracy: 0.5513\n",
            "Epoch 310/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9662 - accuracy: 0.6052 - val_loss: 1.0914 - val_accuracy: 0.5256\n",
            "Epoch 311/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0576 - accuracy: 0.5955 - val_loss: 1.0692 - val_accuracy: 0.5513\n",
            "Epoch 312/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9963 - accuracy: 0.6181 - val_loss: 1.0059 - val_accuracy: 0.5513\n",
            "Epoch 313/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9549 - accuracy: 0.6634 - val_loss: 1.0125 - val_accuracy: 0.5769\n",
            "Epoch 314/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9120 - accuracy: 0.6537 - val_loss: 0.9738 - val_accuracy: 0.5641\n",
            "Epoch 315/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9174 - accuracy: 0.6343 - val_loss: 1.0006 - val_accuracy: 0.5641\n",
            "Epoch 316/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9715 - accuracy: 0.6375 - val_loss: 0.9678 - val_accuracy: 0.5641\n",
            "Epoch 317/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9810 - accuracy: 0.5858 - val_loss: 0.9566 - val_accuracy: 0.6026\n",
            "Epoch 318/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0129 - accuracy: 0.6019 - val_loss: 1.0068 - val_accuracy: 0.5769\n",
            "Epoch 319/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9256 - accuracy: 0.6278 - val_loss: 0.9700 - val_accuracy: 0.5769\n",
            "Epoch 320/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9683 - accuracy: 0.6181 - val_loss: 0.9725 - val_accuracy: 0.6026\n",
            "Epoch 321/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8837 - accuracy: 0.6667 - val_loss: 0.9941 - val_accuracy: 0.5769\n",
            "Epoch 322/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8858 - accuracy: 0.6537 - val_loss: 0.9698 - val_accuracy: 0.5641\n",
            "Epoch 323/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8958 - accuracy: 0.6375 - val_loss: 1.0057 - val_accuracy: 0.5897\n",
            "Epoch 324/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.8850 - accuracy: 0.6440 - val_loss: 0.9799 - val_accuracy: 0.5641\n",
            "Epoch 325/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8544 - accuracy: 0.6570 - val_loss: 0.9857 - val_accuracy: 0.6026\n",
            "Epoch 326/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9186 - accuracy: 0.6278 - val_loss: 0.9798 - val_accuracy: 0.5641\n",
            "Epoch 327/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9298 - accuracy: 0.6634 - val_loss: 1.0098 - val_accuracy: 0.5897\n",
            "Epoch 328/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8697 - accuracy: 0.6796 - val_loss: 0.9475 - val_accuracy: 0.5641\n",
            "Epoch 329/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8852 - accuracy: 0.6472 - val_loss: 0.9633 - val_accuracy: 0.5256\n",
            "Epoch 330/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8585 - accuracy: 0.6764 - val_loss: 0.9352 - val_accuracy: 0.5513\n",
            "Epoch 331/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9017 - accuracy: 0.6278 - val_loss: 0.9474 - val_accuracy: 0.5513\n",
            "Epoch 332/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8979 - accuracy: 0.6408 - val_loss: 1.0793 - val_accuracy: 0.5385\n",
            "Epoch 333/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9588 - accuracy: 0.6019 - val_loss: 1.1804 - val_accuracy: 0.5128\n",
            "Epoch 334/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9981 - accuracy: 0.5987 - val_loss: 1.0413 - val_accuracy: 0.5256\n",
            "Epoch 335/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9047 - accuracy: 0.6440 - val_loss: 0.9132 - val_accuracy: 0.5769\n",
            "Epoch 336/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8734 - accuracy: 0.6440 - val_loss: 0.9942 - val_accuracy: 0.5256\n",
            "Epoch 337/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9006 - accuracy: 0.6472 - val_loss: 1.0156 - val_accuracy: 0.5769\n",
            "Epoch 338/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9541 - accuracy: 0.6343 - val_loss: 1.0209 - val_accuracy: 0.5000\n",
            "Epoch 339/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9244 - accuracy: 0.6214 - val_loss: 0.9478 - val_accuracy: 0.5641\n",
            "Epoch 340/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9241 - accuracy: 0.6246 - val_loss: 1.0512 - val_accuracy: 0.5769\n",
            "Epoch 341/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9191 - accuracy: 0.6343 - val_loss: 1.0351 - val_accuracy: 0.5513\n",
            "Epoch 342/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8884 - accuracy: 0.6602 - val_loss: 0.9658 - val_accuracy: 0.5513\n",
            "Epoch 343/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8875 - accuracy: 0.6667 - val_loss: 0.9592 - val_accuracy: 0.5769\n",
            "Epoch 344/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8589 - accuracy: 0.6926 - val_loss: 0.9529 - val_accuracy: 0.5385\n",
            "Epoch 345/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8530 - accuracy: 0.6699 - val_loss: 0.9711 - val_accuracy: 0.5385\n",
            "Epoch 346/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8784 - accuracy: 0.6505 - val_loss: 0.9222 - val_accuracy: 0.5897\n",
            "Epoch 347/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8757 - accuracy: 0.6731 - val_loss: 0.9778 - val_accuracy: 0.5641\n",
            "Epoch 348/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8312 - accuracy: 0.6796 - val_loss: 0.9113 - val_accuracy: 0.5769\n",
            "Epoch 349/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8730 - accuracy: 0.6634 - val_loss: 0.9301 - val_accuracy: 0.6026\n",
            "Epoch 350/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8669 - accuracy: 0.6472 - val_loss: 0.9122 - val_accuracy: 0.5641\n",
            "Epoch 351/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8708 - accuracy: 0.6634 - val_loss: 0.9362 - val_accuracy: 0.5641\n",
            "Epoch 352/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8723 - accuracy: 0.6602 - val_loss: 0.9763 - val_accuracy: 0.5513\n",
            "Epoch 353/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.8347 - accuracy: 0.6731 - val_loss: 0.9353 - val_accuracy: 0.5256\n",
            "Epoch 354/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8591 - accuracy: 0.6634 - val_loss: 0.9497 - val_accuracy: 0.5769\n",
            "Epoch 355/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8463 - accuracy: 0.6796 - val_loss: 0.9338 - val_accuracy: 0.5513\n",
            "Epoch 356/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8519 - accuracy: 0.6440 - val_loss: 0.9285 - val_accuracy: 0.6026\n",
            "Epoch 357/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8139 - accuracy: 0.6861 - val_loss: 0.9860 - val_accuracy: 0.6026\n",
            "Epoch 358/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8963 - accuracy: 0.6634 - val_loss: 0.9694 - val_accuracy: 0.5769\n",
            "Epoch 359/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8698 - accuracy: 0.6796 - val_loss: 0.9716 - val_accuracy: 0.6154\n",
            "Epoch 360/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8367 - accuracy: 0.6408 - val_loss: 0.9207 - val_accuracy: 0.5641\n",
            "Epoch 361/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8519 - accuracy: 0.6667 - val_loss: 0.9406 - val_accuracy: 0.5513\n",
            "Epoch 362/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8486 - accuracy: 0.6796 - val_loss: 0.9772 - val_accuracy: 0.5513\n",
            "Epoch 363/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8059 - accuracy: 0.6828 - val_loss: 0.9208 - val_accuracy: 0.5641\n",
            "Epoch 364/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8668 - accuracy: 0.6505 - val_loss: 0.9305 - val_accuracy: 0.5897\n",
            "Epoch 365/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8638 - accuracy: 0.6505 - val_loss: 0.9326 - val_accuracy: 0.5385\n",
            "Epoch 366/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8227 - accuracy: 0.6861 - val_loss: 0.9174 - val_accuracy: 0.5385\n",
            "Epoch 367/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8715 - accuracy: 0.6343 - val_loss: 0.9314 - val_accuracy: 0.6026\n",
            "Epoch 368/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7883 - accuracy: 0.6926 - val_loss: 0.9028 - val_accuracy: 0.5769\n",
            "Epoch 369/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8017 - accuracy: 0.7120 - val_loss: 0.9506 - val_accuracy: 0.5769\n",
            "Epoch 370/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8640 - accuracy: 0.6731 - val_loss: 0.9265 - val_accuracy: 0.5513\n",
            "Epoch 371/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8545 - accuracy: 0.6699 - val_loss: 0.9518 - val_accuracy: 0.5897\n",
            "Epoch 372/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8055 - accuracy: 0.6667 - val_loss: 0.9812 - val_accuracy: 0.6026\n",
            "Epoch 373/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8780 - accuracy: 0.6505 - val_loss: 0.9091 - val_accuracy: 0.5769\n",
            "Epoch 374/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8182 - accuracy: 0.6667 - val_loss: 0.9561 - val_accuracy: 0.6026\n",
            "Epoch 375/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8421 - accuracy: 0.6828 - val_loss: 0.8793 - val_accuracy: 0.6026\n",
            "Epoch 376/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8231 - accuracy: 0.6796 - val_loss: 0.8945 - val_accuracy: 0.5641\n",
            "Epoch 377/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8452 - accuracy: 0.6764 - val_loss: 0.9120 - val_accuracy: 0.5769\n",
            "Epoch 378/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8858 - accuracy: 0.6440 - val_loss: 1.0219 - val_accuracy: 0.5385\n",
            "Epoch 379/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8103 - accuracy: 0.6828 - val_loss: 0.8919 - val_accuracy: 0.6026\n",
            "Epoch 380/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8008 - accuracy: 0.6764 - val_loss: 0.9550 - val_accuracy: 0.6026\n",
            "Epoch 381/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8051 - accuracy: 0.6537 - val_loss: 1.0222 - val_accuracy: 0.5641\n",
            "Epoch 382/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8466 - accuracy: 0.6699 - val_loss: 0.9699 - val_accuracy: 0.5513\n",
            "Epoch 383/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.8403 - accuracy: 0.6731 - val_loss: 0.9133 - val_accuracy: 0.6026\n",
            "Epoch 384/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8341 - accuracy: 0.6634 - val_loss: 0.8887 - val_accuracy: 0.5897\n",
            "Epoch 385/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8053 - accuracy: 0.6861 - val_loss: 0.9297 - val_accuracy: 0.5641\n",
            "Epoch 386/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8124 - accuracy: 0.6893 - val_loss: 0.9038 - val_accuracy: 0.5769\n",
            "Epoch 387/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8391 - accuracy: 0.6667 - val_loss: 1.0834 - val_accuracy: 0.5256\n",
            "Epoch 388/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8516 - accuracy: 0.6602 - val_loss: 0.9098 - val_accuracy: 0.5769\n",
            "Epoch 389/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8133 - accuracy: 0.6861 - val_loss: 1.0417 - val_accuracy: 0.4872\n",
            "Epoch 390/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8891 - accuracy: 0.6731 - val_loss: 0.9294 - val_accuracy: 0.6154\n",
            "Epoch 391/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8781 - accuracy: 0.6472 - val_loss: 0.9347 - val_accuracy: 0.6026\n",
            "Epoch 392/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8677 - accuracy: 0.6796 - val_loss: 0.9280 - val_accuracy: 0.5897\n",
            "Epoch 393/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8483 - accuracy: 0.6375 - val_loss: 0.8810 - val_accuracy: 0.6154\n",
            "Epoch 394/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8338 - accuracy: 0.6731 - val_loss: 0.9820 - val_accuracy: 0.5513\n",
            "Epoch 395/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8241 - accuracy: 0.6634 - val_loss: 0.8992 - val_accuracy: 0.5641\n",
            "Epoch 396/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8052 - accuracy: 0.6990 - val_loss: 0.9219 - val_accuracy: 0.5769\n",
            "Epoch 397/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8204 - accuracy: 0.6634 - val_loss: 0.9320 - val_accuracy: 0.6154\n",
            "Epoch 398/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8772 - accuracy: 0.6699 - val_loss: 0.9692 - val_accuracy: 0.5513\n",
            "Epoch 399/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8211 - accuracy: 0.6828 - val_loss: 0.9252 - val_accuracy: 0.5769\n",
            "Epoch 400/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7747 - accuracy: 0.6926 - val_loss: 0.8952 - val_accuracy: 0.5513\n",
            "Epoch 401/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8281 - accuracy: 0.6634 - val_loss: 0.9031 - val_accuracy: 0.6154\n",
            "Epoch 402/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8750 - accuracy: 0.6408 - val_loss: 0.9013 - val_accuracy: 0.5769\n",
            "Epoch 403/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8180 - accuracy: 0.6634 - val_loss: 0.8846 - val_accuracy: 0.5641\n",
            "Epoch 404/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8190 - accuracy: 0.6893 - val_loss: 0.9139 - val_accuracy: 0.6026\n",
            "Epoch 405/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7983 - accuracy: 0.6764 - val_loss: 0.9196 - val_accuracy: 0.5897\n",
            "Epoch 406/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8191 - accuracy: 0.6667 - val_loss: 0.9157 - val_accuracy: 0.6026\n",
            "Epoch 407/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7931 - accuracy: 0.6764 - val_loss: 0.9765 - val_accuracy: 0.5641\n",
            "Epoch 408/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8533 - accuracy: 0.6602 - val_loss: 0.9053 - val_accuracy: 0.5641\n",
            "Epoch 409/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7431 - accuracy: 0.7217 - val_loss: 0.9030 - val_accuracy: 0.6026\n",
            "Epoch 410/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7599 - accuracy: 0.6958 - val_loss: 0.9126 - val_accuracy: 0.5641\n",
            "Epoch 411/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7800 - accuracy: 0.6764 - val_loss: 0.9640 - val_accuracy: 0.5385\n",
            "Epoch 412/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7847 - accuracy: 0.6796 - val_loss: 0.8813 - val_accuracy: 0.5641\n",
            "Epoch 413/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8074 - accuracy: 0.6828 - val_loss: 0.9898 - val_accuracy: 0.5641\n",
            "Epoch 414/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8360 - accuracy: 0.6634 - val_loss: 0.8598 - val_accuracy: 0.5513\n",
            "Epoch 415/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7887 - accuracy: 0.6796 - val_loss: 1.0175 - val_accuracy: 0.5128\n",
            "Epoch 416/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7876 - accuracy: 0.6828 - val_loss: 0.8642 - val_accuracy: 0.5641\n",
            "Epoch 417/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8232 - accuracy: 0.6343 - val_loss: 0.9026 - val_accuracy: 0.6026\n",
            "Epoch 418/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7993 - accuracy: 0.6893 - val_loss: 0.8984 - val_accuracy: 0.5769\n",
            "Epoch 419/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8384 - accuracy: 0.6667 - val_loss: 0.9598 - val_accuracy: 0.5897\n",
            "Epoch 420/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8304 - accuracy: 0.6505 - val_loss: 0.9895 - val_accuracy: 0.5897\n",
            "Epoch 421/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8342 - accuracy: 0.6667 - val_loss: 0.8836 - val_accuracy: 0.5897\n",
            "Epoch 422/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7993 - accuracy: 0.6731 - val_loss: 0.9625 - val_accuracy: 0.5897\n",
            "Epoch 423/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.8319 - accuracy: 0.6796 - val_loss: 0.9074 - val_accuracy: 0.5897\n",
            "Epoch 424/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7982 - accuracy: 0.6731 - val_loss: 0.8858 - val_accuracy: 0.5769\n",
            "Epoch 425/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7977 - accuracy: 0.7087 - val_loss: 0.8719 - val_accuracy: 0.5513\n",
            "Epoch 426/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8071 - accuracy: 0.6990 - val_loss: 0.9273 - val_accuracy: 0.5769\n",
            "Epoch 427/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7560 - accuracy: 0.7087 - val_loss: 0.8927 - val_accuracy: 0.5641\n",
            "Epoch 428/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7915 - accuracy: 0.6731 - val_loss: 0.8998 - val_accuracy: 0.6026\n",
            "Epoch 429/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7980 - accuracy: 0.6990 - val_loss: 0.9055 - val_accuracy: 0.5769\n",
            "Epoch 430/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8128 - accuracy: 0.6828 - val_loss: 1.0194 - val_accuracy: 0.5897\n",
            "Epoch 431/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7773 - accuracy: 0.6764 - val_loss: 0.8822 - val_accuracy: 0.6026\n",
            "Epoch 432/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7561 - accuracy: 0.7087 - val_loss: 0.8788 - val_accuracy: 0.5769\n",
            "Epoch 433/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7408 - accuracy: 0.6828 - val_loss: 0.9563 - val_accuracy: 0.5897\n",
            "Epoch 434/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7850 - accuracy: 0.6861 - val_loss: 1.0707 - val_accuracy: 0.5513\n",
            "Epoch 435/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8429 - accuracy: 0.6699 - val_loss: 0.9401 - val_accuracy: 0.5513\n",
            "Epoch 436/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7734 - accuracy: 0.7055 - val_loss: 0.9310 - val_accuracy: 0.5897\n",
            "Epoch 437/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7657 - accuracy: 0.6796 - val_loss: 0.9034 - val_accuracy: 0.5769\n",
            "Epoch 438/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7758 - accuracy: 0.6828 - val_loss: 0.8857 - val_accuracy: 0.5897\n",
            "Epoch 439/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7164 - accuracy: 0.7282 - val_loss: 0.9241 - val_accuracy: 0.5513\n",
            "Epoch 440/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7845 - accuracy: 0.6861 - val_loss: 0.8459 - val_accuracy: 0.5769\n",
            "Epoch 441/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7396 - accuracy: 0.6796 - val_loss: 0.8464 - val_accuracy: 0.5769\n",
            "Epoch 442/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7329 - accuracy: 0.7055 - val_loss: 0.8821 - val_accuracy: 0.5897\n",
            "Epoch 443/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7309 - accuracy: 0.7282 - val_loss: 0.9764 - val_accuracy: 0.5897\n",
            "Epoch 444/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7930 - accuracy: 0.6634 - val_loss: 0.8705 - val_accuracy: 0.6282\n",
            "Epoch 445/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7554 - accuracy: 0.6828 - val_loss: 0.9335 - val_accuracy: 0.5897\n",
            "Epoch 446/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7487 - accuracy: 0.6926 - val_loss: 0.8805 - val_accuracy: 0.5897\n",
            "Epoch 447/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7524 - accuracy: 0.7087 - val_loss: 0.8841 - val_accuracy: 0.5769\n",
            "Epoch 448/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8211 - accuracy: 0.6602 - val_loss: 1.0108 - val_accuracy: 0.5769\n",
            "Epoch 449/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7798 - accuracy: 0.6537 - val_loss: 0.9433 - val_accuracy: 0.5513\n",
            "Epoch 450/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8258 - accuracy: 0.6634 - val_loss: 0.8752 - val_accuracy: 0.5513\n",
            "Epoch 451/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7822 - accuracy: 0.6926 - val_loss: 0.8978 - val_accuracy: 0.5641\n",
            "Epoch 452/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7990 - accuracy: 0.6796 - val_loss: 0.9337 - val_accuracy: 0.5897\n",
            "Epoch 453/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7504 - accuracy: 0.6926 - val_loss: 0.8814 - val_accuracy: 0.5641\n",
            "Epoch 454/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7476 - accuracy: 0.7346 - val_loss: 0.8974 - val_accuracy: 0.5513\n",
            "Epoch 455/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7172 - accuracy: 0.7055 - val_loss: 0.8763 - val_accuracy: 0.5769\n",
            "Epoch 456/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7074 - accuracy: 0.7217 - val_loss: 0.9054 - val_accuracy: 0.5769\n",
            "Epoch 457/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7482 - accuracy: 0.7087 - val_loss: 0.8404 - val_accuracy: 0.5897\n",
            "Epoch 458/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7826 - accuracy: 0.6796 - val_loss: 0.9682 - val_accuracy: 0.6026\n",
            "Epoch 459/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8742 - accuracy: 0.6602 - val_loss: 0.9535 - val_accuracy: 0.6026\n",
            "Epoch 460/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8422 - accuracy: 0.6699 - val_loss: 0.9365 - val_accuracy: 0.5641\n",
            "Epoch 461/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7868 - accuracy: 0.6893 - val_loss: 1.0748 - val_accuracy: 0.5513\n",
            "Epoch 462/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8467 - accuracy: 0.6699 - val_loss: 0.9353 - val_accuracy: 0.5641\n",
            "Epoch 463/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7630 - accuracy: 0.6796 - val_loss: 0.9199 - val_accuracy: 0.6026\n",
            "Epoch 464/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8039 - accuracy: 0.6634 - val_loss: 0.9194 - val_accuracy: 0.5513\n",
            "Epoch 465/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7375 - accuracy: 0.7055 - val_loss: 0.8786 - val_accuracy: 0.5256\n",
            "Epoch 466/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7760 - accuracy: 0.6861 - val_loss: 1.0303 - val_accuracy: 0.5513\n",
            "Epoch 467/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7949 - accuracy: 0.6764 - val_loss: 0.9462 - val_accuracy: 0.5513\n",
            "Epoch 468/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7822 - accuracy: 0.6828 - val_loss: 0.9013 - val_accuracy: 0.5769\n",
            "Epoch 469/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8104 - accuracy: 0.6828 - val_loss: 0.9147 - val_accuracy: 0.5385\n",
            "Epoch 470/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8401 - accuracy: 0.6731 - val_loss: 0.8776 - val_accuracy: 0.5769\n",
            "Epoch 471/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8109 - accuracy: 0.6634 - val_loss: 0.9231 - val_accuracy: 0.6026\n",
            "Epoch 472/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7790 - accuracy: 0.7055 - val_loss: 0.9215 - val_accuracy: 0.5256\n",
            "Epoch 473/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7515 - accuracy: 0.7249 - val_loss: 0.8884 - val_accuracy: 0.5256\n",
            "Epoch 474/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7832 - accuracy: 0.7120 - val_loss: 0.8911 - val_accuracy: 0.6154\n",
            "Epoch 475/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7007 - accuracy: 0.7314 - val_loss: 0.8704 - val_accuracy: 0.6026\n",
            "Epoch 476/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7823 - accuracy: 0.6796 - val_loss: 0.9128 - val_accuracy: 0.5769\n",
            "Epoch 477/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7901 - accuracy: 0.6731 - val_loss: 0.9087 - val_accuracy: 0.5897\n",
            "Epoch 478/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7644 - accuracy: 0.6828 - val_loss: 0.9638 - val_accuracy: 0.5897\n",
            "Epoch 479/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7183 - accuracy: 0.7023 - val_loss: 0.8805 - val_accuracy: 0.5897\n",
            "Epoch 480/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7386 - accuracy: 0.6926 - val_loss: 0.9123 - val_accuracy: 0.6026\n",
            "Epoch 481/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7401 - accuracy: 0.6861 - val_loss: 0.9212 - val_accuracy: 0.5897\n",
            "Epoch 482/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7431 - accuracy: 0.7346 - val_loss: 0.8690 - val_accuracy: 0.5641\n",
            "Epoch 483/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8049 - accuracy: 0.6764 - val_loss: 0.8773 - val_accuracy: 0.5769\n",
            "Epoch 484/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7870 - accuracy: 0.6958 - val_loss: 0.8742 - val_accuracy: 0.6154\n",
            "Epoch 485/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7966 - accuracy: 0.6667 - val_loss: 0.8952 - val_accuracy: 0.5769\n",
            "Epoch 486/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7712 - accuracy: 0.6731 - val_loss: 0.8733 - val_accuracy: 0.6026\n",
            "Epoch 487/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7396 - accuracy: 0.7087 - val_loss: 0.8776 - val_accuracy: 0.5641\n",
            "Epoch 488/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7868 - accuracy: 0.6893 - val_loss: 1.0038 - val_accuracy: 0.5897\n",
            "Epoch 489/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7216 - accuracy: 0.6958 - val_loss: 0.8895 - val_accuracy: 0.5385\n",
            "Epoch 490/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7277 - accuracy: 0.7055 - val_loss: 0.8178 - val_accuracy: 0.6154\n",
            "Epoch 491/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7500 - accuracy: 0.6861 - val_loss: 0.9440 - val_accuracy: 0.5641\n",
            "Epoch 492/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7310 - accuracy: 0.7120 - val_loss: 0.8640 - val_accuracy: 0.6154\n",
            "Epoch 493/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7442 - accuracy: 0.6893 - val_loss: 0.8551 - val_accuracy: 0.5769\n",
            "Epoch 494/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7003 - accuracy: 0.7055 - val_loss: 0.8953 - val_accuracy: 0.6154\n",
            "Epoch 495/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7374 - accuracy: 0.6926 - val_loss: 0.8775 - val_accuracy: 0.5641\n",
            "Epoch 496/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7348 - accuracy: 0.6990 - val_loss: 0.8637 - val_accuracy: 0.5897\n",
            "Epoch 497/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6897 - accuracy: 0.7346 - val_loss: 0.9145 - val_accuracy: 0.5513\n",
            "Epoch 498/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6889 - accuracy: 0.7120 - val_loss: 0.8553 - val_accuracy: 0.5769\n",
            "Epoch 499/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7086 - accuracy: 0.7087 - val_loss: 0.8507 - val_accuracy: 0.5769\n",
            "Epoch 500/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7361 - accuracy: 0.6861 - val_loss: 0.8457 - val_accuracy: 0.5513\n",
            "Epoch 501/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7360 - accuracy: 0.7249 - val_loss: 0.9109 - val_accuracy: 0.5897\n",
            "Epoch 502/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7065 - accuracy: 0.7282 - val_loss: 0.8780 - val_accuracy: 0.5513\n",
            "Epoch 503/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7439 - accuracy: 0.7087 - val_loss: 0.8239 - val_accuracy: 0.5769\n",
            "Epoch 504/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7258 - accuracy: 0.6893 - val_loss: 0.8799 - val_accuracy: 0.5769\n",
            "Epoch 505/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6839 - accuracy: 0.7217 - val_loss: 0.8503 - val_accuracy: 0.6026\n",
            "Epoch 506/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.7573 - val_loss: 0.9377 - val_accuracy: 0.6026\n",
            "Epoch 507/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7357 - accuracy: 0.6893 - val_loss: 0.8916 - val_accuracy: 0.5769\n",
            "Epoch 508/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7514 - accuracy: 0.7087 - val_loss: 0.8763 - val_accuracy: 0.6026\n",
            "Epoch 509/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7856 - accuracy: 0.6861 - val_loss: 0.8934 - val_accuracy: 0.5769\n",
            "Epoch 510/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7561 - accuracy: 0.7023 - val_loss: 0.9392 - val_accuracy: 0.5769\n",
            "Epoch 511/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7968 - accuracy: 0.6537 - val_loss: 0.9061 - val_accuracy: 0.5256\n",
            "Epoch 512/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7345 - accuracy: 0.7249 - val_loss: 0.9151 - val_accuracy: 0.5769\n",
            "Epoch 513/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6965 - accuracy: 0.7249 - val_loss: 0.9042 - val_accuracy: 0.5256\n",
            "Epoch 514/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7275 - accuracy: 0.7087 - val_loss: 0.8656 - val_accuracy: 0.5641\n",
            "Epoch 515/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7067 - accuracy: 0.7217 - val_loss: 0.9290 - val_accuracy: 0.5641\n",
            "Epoch 516/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6709 - accuracy: 0.7184 - val_loss: 0.8258 - val_accuracy: 0.5769\n",
            "Epoch 517/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7145 - accuracy: 0.7055 - val_loss: 0.9674 - val_accuracy: 0.5897\n",
            "Epoch 518/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6900 - accuracy: 0.7282 - val_loss: 0.8935 - val_accuracy: 0.5769\n",
            "Epoch 519/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7793 - accuracy: 0.6764 - val_loss: 0.8959 - val_accuracy: 0.6026\n",
            "Epoch 520/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6903 - accuracy: 0.7152 - val_loss: 0.8309 - val_accuracy: 0.5513\n",
            "Epoch 521/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7327 - accuracy: 0.6893 - val_loss: 0.9788 - val_accuracy: 0.5897\n",
            "Epoch 522/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7221 - accuracy: 0.6958 - val_loss: 0.9106 - val_accuracy: 0.5641\n",
            "Epoch 523/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7308 - accuracy: 0.6828 - val_loss: 0.8170 - val_accuracy: 0.6282\n",
            "Epoch 524/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7577 - accuracy: 0.6828 - val_loss: 0.8374 - val_accuracy: 0.6026\n",
            "Epoch 525/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7504 - accuracy: 0.6990 - val_loss: 0.8862 - val_accuracy: 0.5769\n",
            "Epoch 526/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7570 - accuracy: 0.7055 - val_loss: 0.9073 - val_accuracy: 0.6026\n",
            "Epoch 527/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7733 - accuracy: 0.6958 - val_loss: 0.9351 - val_accuracy: 0.5769\n",
            "Epoch 528/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7528 - accuracy: 0.7055 - val_loss: 0.9060 - val_accuracy: 0.5769\n",
            "Epoch 529/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7130 - accuracy: 0.7023 - val_loss: 0.9325 - val_accuracy: 0.5769\n",
            "Epoch 530/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7094 - accuracy: 0.7087 - val_loss: 0.7969 - val_accuracy: 0.6154\n",
            "Epoch 531/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7326 - accuracy: 0.7184 - val_loss: 0.9595 - val_accuracy: 0.5897\n",
            "Epoch 532/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7008 - accuracy: 0.7055 - val_loss: 0.8607 - val_accuracy: 0.6026\n",
            "Epoch 533/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7437 - accuracy: 0.6990 - val_loss: 0.8993 - val_accuracy: 0.6026\n",
            "Epoch 534/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6742 - accuracy: 0.7184 - val_loss: 0.9042 - val_accuracy: 0.5897\n",
            "Epoch 535/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7523 - accuracy: 0.6796 - val_loss: 0.9023 - val_accuracy: 0.5769\n",
            "Epoch 536/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7199 - accuracy: 0.7055 - val_loss: 0.8382 - val_accuracy: 0.5641\n",
            "Epoch 537/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6682 - accuracy: 0.7217 - val_loss: 0.8998 - val_accuracy: 0.5897\n",
            "Epoch 538/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6920 - accuracy: 0.7120 - val_loss: 1.0062 - val_accuracy: 0.5897\n",
            "Epoch 539/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7386 - accuracy: 0.6861 - val_loss: 0.9350 - val_accuracy: 0.5769\n",
            "Epoch 540/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7148 - accuracy: 0.7152 - val_loss: 0.8521 - val_accuracy: 0.5641\n",
            "Epoch 541/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7108 - accuracy: 0.6958 - val_loss: 0.9295 - val_accuracy: 0.5641\n",
            "Epoch 542/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7495 - accuracy: 0.7055 - val_loss: 0.8634 - val_accuracy: 0.6154\n",
            "Epoch 543/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7606 - accuracy: 0.6731 - val_loss: 0.8091 - val_accuracy: 0.5769\n",
            "Epoch 544/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7266 - accuracy: 0.6828 - val_loss: 0.8784 - val_accuracy: 0.5897\n",
            "Epoch 545/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7189 - accuracy: 0.6990 - val_loss: 0.8157 - val_accuracy: 0.5897\n",
            "Epoch 546/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6861 - accuracy: 0.7023 - val_loss: 0.8420 - val_accuracy: 0.5769\n",
            "Epoch 547/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6853 - accuracy: 0.7023 - val_loss: 0.8086 - val_accuracy: 0.6026\n",
            "Epoch 548/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7369 - accuracy: 0.7087 - val_loss: 0.8320 - val_accuracy: 0.5897\n",
            "Epoch 549/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6484 - accuracy: 0.7314 - val_loss: 0.8676 - val_accuracy: 0.6282\n",
            "Epoch 550/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6991 - accuracy: 0.7249 - val_loss: 0.9459 - val_accuracy: 0.6410\n",
            "Epoch 551/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7070 - accuracy: 0.7087 - val_loss: 0.8887 - val_accuracy: 0.5897\n",
            "Epoch 552/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6957 - accuracy: 0.7249 - val_loss: 0.8295 - val_accuracy: 0.5769\n",
            "Epoch 553/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7022 - accuracy: 0.7152 - val_loss: 0.9245 - val_accuracy: 0.5897\n",
            "Epoch 554/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6651 - accuracy: 0.7443 - val_loss: 0.8370 - val_accuracy: 0.6154\n",
            "Epoch 555/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6994 - accuracy: 0.7249 - val_loss: 0.8182 - val_accuracy: 0.5769\n",
            "Epoch 556/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6601 - accuracy: 0.7476 - val_loss: 0.8781 - val_accuracy: 0.5897\n",
            "Epoch 557/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6960 - accuracy: 0.7152 - val_loss: 0.9336 - val_accuracy: 0.6026\n",
            "Epoch 558/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6579 - accuracy: 0.7476 - val_loss: 0.8383 - val_accuracy: 0.5897\n",
            "Epoch 559/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6661 - accuracy: 0.7443 - val_loss: 0.8959 - val_accuracy: 0.6282\n",
            "Epoch 560/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6877 - accuracy: 0.6861 - val_loss: 0.9298 - val_accuracy: 0.5897\n",
            "Epoch 561/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6722 - accuracy: 0.7379 - val_loss: 0.9417 - val_accuracy: 0.6026\n",
            "Epoch 562/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6831 - accuracy: 0.7346 - val_loss: 0.9394 - val_accuracy: 0.5769\n",
            "Epoch 563/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7449 - accuracy: 0.6893 - val_loss: 0.8717 - val_accuracy: 0.6154\n",
            "Epoch 564/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7819 - accuracy: 0.6828 - val_loss: 0.9288 - val_accuracy: 0.6282\n",
            "Epoch 565/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7215 - accuracy: 0.7152 - val_loss: 0.8499 - val_accuracy: 0.5513\n",
            "Epoch 566/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7065 - accuracy: 0.6958 - val_loss: 0.9937 - val_accuracy: 0.6026\n",
            "Epoch 567/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7248 - accuracy: 0.6926 - val_loss: 0.8709 - val_accuracy: 0.6026\n",
            "Epoch 568/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7117 - accuracy: 0.6958 - val_loss: 0.9147 - val_accuracy: 0.6154\n",
            "Epoch 569/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7353 - accuracy: 0.7087 - val_loss: 0.9164 - val_accuracy: 0.6026\n",
            "Epoch 570/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7283 - accuracy: 0.7087 - val_loss: 0.9665 - val_accuracy: 0.6026\n",
            "Epoch 571/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7046 - accuracy: 0.7379 - val_loss: 0.9046 - val_accuracy: 0.5769\n",
            "Epoch 572/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6920 - accuracy: 0.7314 - val_loss: 0.9408 - val_accuracy: 0.5897\n",
            "Epoch 573/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7017 - accuracy: 0.7055 - val_loss: 0.8807 - val_accuracy: 0.6154\n",
            "Epoch 574/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7166 - accuracy: 0.6731 - val_loss: 0.9561 - val_accuracy: 0.5641\n",
            "Epoch 575/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7058 - accuracy: 0.7379 - val_loss: 0.9031 - val_accuracy: 0.5641\n",
            "Epoch 576/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7864 - accuracy: 0.6764 - val_loss: 0.8776 - val_accuracy: 0.6154\n",
            "Epoch 577/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7075 - accuracy: 0.7087 - val_loss: 0.8732 - val_accuracy: 0.5513\n",
            "Epoch 578/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7330 - accuracy: 0.7120 - val_loss: 0.8358 - val_accuracy: 0.6410\n",
            "Epoch 579/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6674 - accuracy: 0.7346 - val_loss: 0.9224 - val_accuracy: 0.5513\n",
            "Epoch 580/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7452 - accuracy: 0.6796 - val_loss: 0.8006 - val_accuracy: 0.6026\n",
            "Epoch 581/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6718 - accuracy: 0.7023 - val_loss: 0.8581 - val_accuracy: 0.6410\n",
            "Epoch 582/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.7059 - accuracy: 0.6990 - val_loss: 0.9536 - val_accuracy: 0.5641\n",
            "Epoch 583/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.7120 - val_loss: 0.8965 - val_accuracy: 0.5769\n",
            "Epoch 584/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6779 - accuracy: 0.7282 - val_loss: 0.8795 - val_accuracy: 0.5641\n",
            "Epoch 585/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6659 - accuracy: 0.7249 - val_loss: 0.8344 - val_accuracy: 0.6026\n",
            "Epoch 586/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.7282 - val_loss: 0.8998 - val_accuracy: 0.6154\n",
            "Epoch 587/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6480 - accuracy: 0.7379 - val_loss: 0.8353 - val_accuracy: 0.5513\n",
            "Epoch 588/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6905 - accuracy: 0.7184 - val_loss: 0.8880 - val_accuracy: 0.5897\n",
            "Epoch 589/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6683 - accuracy: 0.7411 - val_loss: 0.8979 - val_accuracy: 0.5897\n",
            "Epoch 590/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6751 - accuracy: 0.7217 - val_loss: 0.9309 - val_accuracy: 0.6154\n",
            "Epoch 591/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7260 - accuracy: 0.7184 - val_loss: 0.9016 - val_accuracy: 0.6154\n",
            "Epoch 592/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6963 - accuracy: 0.7023 - val_loss: 0.9066 - val_accuracy: 0.6026\n",
            "Epoch 593/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6881 - accuracy: 0.7087 - val_loss: 0.8782 - val_accuracy: 0.5769\n",
            "Epoch 594/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6443 - accuracy: 0.7379 - val_loss: 0.8983 - val_accuracy: 0.6154\n",
            "Epoch 595/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7620 - accuracy: 0.6570 - val_loss: 0.9316 - val_accuracy: 0.6154\n",
            "Epoch 596/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7422 - accuracy: 0.6958 - val_loss: 0.9688 - val_accuracy: 0.6026\n",
            "Epoch 597/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7081 - accuracy: 0.7152 - val_loss: 0.9645 - val_accuracy: 0.5897\n",
            "Epoch 598/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7294 - accuracy: 0.7023 - val_loss: 0.8477 - val_accuracy: 0.5897\n",
            "Epoch 599/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6840 - accuracy: 0.7282 - val_loss: 0.9081 - val_accuracy: 0.6026\n",
            "Epoch 600/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7525 - accuracy: 0.6958 - val_loss: 0.8174 - val_accuracy: 0.6538\n",
            "Epoch 601/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6827 - accuracy: 0.7346 - val_loss: 0.9088 - val_accuracy: 0.5641\n",
            "Epoch 602/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7343 - accuracy: 0.6926 - val_loss: 0.8682 - val_accuracy: 0.6282\n",
            "Epoch 603/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6996 - accuracy: 0.7184 - val_loss: 0.8542 - val_accuracy: 0.6154\n",
            "Epoch 604/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7056 - accuracy: 0.7184 - val_loss: 0.8397 - val_accuracy: 0.5385\n",
            "Epoch 605/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6702 - accuracy: 0.7184 - val_loss: 0.8666 - val_accuracy: 0.5897\n",
            "Epoch 606/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7173 - accuracy: 0.7249 - val_loss: 0.8135 - val_accuracy: 0.5769\n",
            "Epoch 607/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6310 - accuracy: 0.7476 - val_loss: 0.8333 - val_accuracy: 0.5769\n",
            "Epoch 608/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6368 - accuracy: 0.7411 - val_loss: 0.8403 - val_accuracy: 0.6026\n",
            "Epoch 609/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6867 - accuracy: 0.7379 - val_loss: 0.8876 - val_accuracy: 0.5897\n",
            "Epoch 610/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6693 - accuracy: 0.7314 - val_loss: 0.7886 - val_accuracy: 0.6026\n",
            "Epoch 611/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6823 - accuracy: 0.7540 - val_loss: 0.8968 - val_accuracy: 0.5769\n",
            "Epoch 612/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6827 - accuracy: 0.7476 - val_loss: 0.8307 - val_accuracy: 0.6282\n",
            "Epoch 613/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6707 - accuracy: 0.7249 - val_loss: 0.8461 - val_accuracy: 0.5897\n",
            "Epoch 614/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6776 - accuracy: 0.7152 - val_loss: 0.8626 - val_accuracy: 0.6154\n",
            "Epoch 615/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6801 - accuracy: 0.7314 - val_loss: 0.8191 - val_accuracy: 0.6282\n",
            "Epoch 616/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6572 - accuracy: 0.7379 - val_loss: 0.8894 - val_accuracy: 0.6026\n",
            "Epoch 617/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7237 - accuracy: 0.7152 - val_loss: 0.8301 - val_accuracy: 0.5769\n",
            "Epoch 618/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7396 - accuracy: 0.6958 - val_loss: 0.9960 - val_accuracy: 0.5641\n",
            "Epoch 619/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7612 - accuracy: 0.7152 - val_loss: 0.8529 - val_accuracy: 0.5897\n",
            "Epoch 620/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7123 - accuracy: 0.6926 - val_loss: 0.8328 - val_accuracy: 0.6154\n",
            "Epoch 621/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6684 - accuracy: 0.7023 - val_loss: 0.9193 - val_accuracy: 0.5897\n",
            "Epoch 622/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6653 - accuracy: 0.7249 - val_loss: 0.8874 - val_accuracy: 0.5769\n",
            "Epoch 623/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6339 - accuracy: 0.7508 - val_loss: 0.8239 - val_accuracy: 0.6410\n",
            "Epoch 624/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6707 - accuracy: 0.7346 - val_loss: 0.8833 - val_accuracy: 0.6154\n",
            "Epoch 625/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7107 - accuracy: 0.6990 - val_loss: 1.0082 - val_accuracy: 0.6026\n",
            "Epoch 626/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.7424 - accuracy: 0.6699 - val_loss: 0.9361 - val_accuracy: 0.6026\n",
            "Epoch 627/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7273 - accuracy: 0.6796 - val_loss: 0.9681 - val_accuracy: 0.6026\n",
            "Epoch 628/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7006 - accuracy: 0.7508 - val_loss: 0.8532 - val_accuracy: 0.5385\n",
            "Epoch 629/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6811 - accuracy: 0.7282 - val_loss: 0.9586 - val_accuracy: 0.6026\n",
            "Epoch 630/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7053 - accuracy: 0.7184 - val_loss: 0.9201 - val_accuracy: 0.6410\n",
            "Epoch 631/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7177 - accuracy: 0.7087 - val_loss: 0.8845 - val_accuracy: 0.6538\n",
            "Epoch 632/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7110 - accuracy: 0.6990 - val_loss: 0.9140 - val_accuracy: 0.5897\n",
            "Epoch 633/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7337 - accuracy: 0.6731 - val_loss: 0.8488 - val_accuracy: 0.5385\n",
            "Epoch 634/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6862 - accuracy: 0.7314 - val_loss: 0.9235 - val_accuracy: 0.6154\n",
            "Epoch 635/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6472 - accuracy: 0.7282 - val_loss: 1.0064 - val_accuracy: 0.6410\n",
            "Epoch 636/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6990 - accuracy: 0.7023 - val_loss: 0.9017 - val_accuracy: 0.5769\n",
            "Epoch 637/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6404 - accuracy: 0.7346 - val_loss: 0.8506 - val_accuracy: 0.5769\n",
            "Epoch 638/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6672 - accuracy: 0.6958 - val_loss: 0.8650 - val_accuracy: 0.6026\n",
            "Epoch 639/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6978 - accuracy: 0.7023 - val_loss: 0.9093 - val_accuracy: 0.5641\n",
            "Epoch 640/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6839 - accuracy: 0.7217 - val_loss: 0.8658 - val_accuracy: 0.5769\n",
            "Epoch 641/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6607 - accuracy: 0.7605 - val_loss: 0.8662 - val_accuracy: 0.6026\n",
            "Epoch 642/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6309 - accuracy: 0.7605 - val_loss: 0.8541 - val_accuracy: 0.5769\n",
            "Epoch 643/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6074 - accuracy: 0.7735 - val_loss: 0.9486 - val_accuracy: 0.5897\n",
            "Epoch 644/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6729 - accuracy: 0.7314 - val_loss: 0.8721 - val_accuracy: 0.5769\n",
            "Epoch 645/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7109 - accuracy: 0.7087 - val_loss: 0.9205 - val_accuracy: 0.5769\n",
            "Epoch 646/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7802 - accuracy: 0.7055 - val_loss: 0.8242 - val_accuracy: 0.5641\n",
            "Epoch 647/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8006 - accuracy: 0.6828 - val_loss: 0.9547 - val_accuracy: 0.5897\n",
            "Epoch 648/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7385 - accuracy: 0.7087 - val_loss: 0.9293 - val_accuracy: 0.6026\n",
            "Epoch 649/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7011 - accuracy: 0.7055 - val_loss: 0.9886 - val_accuracy: 0.6282\n",
            "Epoch 650/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7516 - accuracy: 0.6828 - val_loss: 1.0035 - val_accuracy: 0.6026\n",
            "Epoch 651/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7977 - accuracy: 0.6699 - val_loss: 0.8992 - val_accuracy: 0.6026\n",
            "Epoch 652/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7085 - accuracy: 0.7087 - val_loss: 0.8402 - val_accuracy: 0.6282\n",
            "Epoch 653/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7609 - accuracy: 0.6667 - val_loss: 0.9487 - val_accuracy: 0.5256\n",
            "Epoch 654/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7189 - accuracy: 0.7120 - val_loss: 0.7934 - val_accuracy: 0.6410\n",
            "Epoch 655/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7799 - accuracy: 0.6828 - val_loss: 0.8352 - val_accuracy: 0.6282\n",
            "Epoch 656/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8032 - accuracy: 0.6893 - val_loss: 0.8554 - val_accuracy: 0.6154\n",
            "Epoch 657/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7699 - accuracy: 0.7217 - val_loss: 0.8894 - val_accuracy: 0.6154\n",
            "Epoch 658/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7520 - accuracy: 0.6990 - val_loss: 0.9471 - val_accuracy: 0.5641\n",
            "Epoch 659/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8067 - accuracy: 0.6764 - val_loss: 0.8232 - val_accuracy: 0.6282\n",
            "Epoch 660/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7405 - accuracy: 0.6958 - val_loss: 0.8541 - val_accuracy: 0.6282\n",
            "Epoch 661/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7658 - accuracy: 0.6764 - val_loss: 0.9303 - val_accuracy: 0.5641\n",
            "Epoch 662/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.8026 - accuracy: 0.6505 - val_loss: 0.9868 - val_accuracy: 0.5385\n",
            "Epoch 663/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.8464 - accuracy: 0.6570 - val_loss: 0.9004 - val_accuracy: 0.6026\n",
            "Epoch 664/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.8026 - accuracy: 0.6731 - val_loss: 0.8529 - val_accuracy: 0.5769\n",
            "Epoch 665/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7258 - accuracy: 0.7055 - val_loss: 0.8857 - val_accuracy: 0.6154\n",
            "Epoch 666/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.7257 - accuracy: 0.6861 - val_loss: 0.8475 - val_accuracy: 0.5769\n",
            "Epoch 667/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7657 - accuracy: 0.7055 - val_loss: 0.9734 - val_accuracy: 0.5513\n",
            "Epoch 668/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7412 - accuracy: 0.6926 - val_loss: 0.8200 - val_accuracy: 0.5769\n",
            "Epoch 669/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7170 - accuracy: 0.7023 - val_loss: 0.8274 - val_accuracy: 0.5897\n",
            "Epoch 670/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6912 - accuracy: 0.7282 - val_loss: 0.8371 - val_accuracy: 0.6154\n",
            "Epoch 671/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7020 - accuracy: 0.7087 - val_loss: 0.8414 - val_accuracy: 0.6410\n",
            "Epoch 672/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7160 - accuracy: 0.6861 - val_loss: 0.8510 - val_accuracy: 0.6410\n",
            "Epoch 673/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6885 - accuracy: 0.7217 - val_loss: 0.8290 - val_accuracy: 0.6154\n",
            "Epoch 674/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6856 - accuracy: 0.7379 - val_loss: 0.8016 - val_accuracy: 0.6410\n",
            "Epoch 675/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6728 - accuracy: 0.7411 - val_loss: 0.8095 - val_accuracy: 0.5641\n",
            "Epoch 676/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7311 - accuracy: 0.7120 - val_loss: 0.8831 - val_accuracy: 0.5897\n",
            "Epoch 677/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.7083 - accuracy: 0.6958 - val_loss: 1.0488 - val_accuracy: 0.5769\n",
            "Epoch 678/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7231 - accuracy: 0.7023 - val_loss: 0.8496 - val_accuracy: 0.5641\n",
            "Epoch 679/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6660 - accuracy: 0.7346 - val_loss: 0.8394 - val_accuracy: 0.5897\n",
            "Epoch 680/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7101 - accuracy: 0.7055 - val_loss: 0.8321 - val_accuracy: 0.6410\n",
            "Epoch 681/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6649 - accuracy: 0.7249 - val_loss: 0.8683 - val_accuracy: 0.5897\n",
            "Epoch 682/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6586 - accuracy: 0.7152 - val_loss: 0.9247 - val_accuracy: 0.6154\n",
            "Epoch 683/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7268 - accuracy: 0.6828 - val_loss: 0.8754 - val_accuracy: 0.6026\n",
            "Epoch 684/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6595 - accuracy: 0.7249 - val_loss: 0.9180 - val_accuracy: 0.5769\n",
            "Epoch 685/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7256 - accuracy: 0.6893 - val_loss: 1.0387 - val_accuracy: 0.5641\n",
            "Epoch 686/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6888 - accuracy: 0.7282 - val_loss: 0.9044 - val_accuracy: 0.6154\n",
            "Epoch 687/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6951 - accuracy: 0.7152 - val_loss: 0.9788 - val_accuracy: 0.6154\n",
            "Epoch 688/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7623 - accuracy: 0.6828 - val_loss: 1.0143 - val_accuracy: 0.5769\n",
            "Epoch 689/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7162 - accuracy: 0.7087 - val_loss: 0.9971 - val_accuracy: 0.5897\n",
            "Epoch 690/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7873 - accuracy: 0.6505 - val_loss: 1.1388 - val_accuracy: 0.5897\n",
            "Epoch 691/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7903 - accuracy: 0.6764 - val_loss: 0.9291 - val_accuracy: 0.6282\n",
            "Epoch 692/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6749 - accuracy: 0.7411 - val_loss: 0.8345 - val_accuracy: 0.6154\n",
            "Epoch 693/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6560 - accuracy: 0.7152 - val_loss: 0.9306 - val_accuracy: 0.5897\n",
            "Epoch 694/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.7851 - accuracy: 0.6667 - val_loss: 0.8653 - val_accuracy: 0.6154\n",
            "Epoch 695/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6871 - accuracy: 0.7023 - val_loss: 0.8266 - val_accuracy: 0.6026\n",
            "Epoch 696/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7248 - accuracy: 0.6796 - val_loss: 0.8735 - val_accuracy: 0.5769\n",
            "Epoch 697/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6885 - accuracy: 0.7217 - val_loss: 0.8532 - val_accuracy: 0.6538\n",
            "Epoch 698/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6531 - accuracy: 0.7379 - val_loss: 0.8275 - val_accuracy: 0.5385\n",
            "Epoch 699/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6717 - accuracy: 0.7152 - val_loss: 0.9156 - val_accuracy: 0.5769\n",
            "Epoch 700/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6464 - accuracy: 0.7476 - val_loss: 0.9321 - val_accuracy: 0.6026\n",
            "Epoch 701/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6453 - accuracy: 0.7282 - val_loss: 0.8731 - val_accuracy: 0.5769\n",
            "Epoch 702/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6304 - accuracy: 0.7476 - val_loss: 0.9387 - val_accuracy: 0.5897\n",
            "Epoch 703/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6710 - accuracy: 0.7217 - val_loss: 0.8605 - val_accuracy: 0.5897\n",
            "Epoch 704/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6554 - accuracy: 0.7314 - val_loss: 0.9143 - val_accuracy: 0.6282\n",
            "Epoch 705/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6236 - accuracy: 0.7282 - val_loss: 0.8832 - val_accuracy: 0.5769\n",
            "Epoch 706/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6307 - accuracy: 0.7411 - val_loss: 0.8779 - val_accuracy: 0.6154\n",
            "Epoch 707/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7079 - accuracy: 0.6926 - val_loss: 0.9469 - val_accuracy: 0.6282\n",
            "Epoch 708/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6576 - accuracy: 0.7184 - val_loss: 0.9112 - val_accuracy: 0.5513\n",
            "Epoch 709/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6836 - accuracy: 0.7055 - val_loss: 0.8758 - val_accuracy: 0.5641\n",
            "Epoch 710/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7156 - accuracy: 0.6893 - val_loss: 0.8630 - val_accuracy: 0.6154\n",
            "Epoch 711/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6985 - accuracy: 0.7282 - val_loss: 0.8878 - val_accuracy: 0.5769\n",
            "Epoch 712/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6472 - accuracy: 0.7282 - val_loss: 0.9858 - val_accuracy: 0.6026\n",
            "Epoch 713/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7422 - accuracy: 0.6893 - val_loss: 0.9193 - val_accuracy: 0.6026\n",
            "Epoch 714/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7131 - accuracy: 0.7282 - val_loss: 0.8474 - val_accuracy: 0.5897\n",
            "Epoch 715/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7175 - accuracy: 0.6731 - val_loss: 0.8182 - val_accuracy: 0.5641\n",
            "Epoch 716/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7086 - accuracy: 0.6958 - val_loss: 0.8258 - val_accuracy: 0.6026\n",
            "Epoch 717/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6571 - accuracy: 0.7249 - val_loss: 0.8797 - val_accuracy: 0.6154\n",
            "Epoch 718/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6709 - accuracy: 0.7314 - val_loss: 0.8485 - val_accuracy: 0.6154\n",
            "Epoch 719/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6498 - accuracy: 0.7476 - val_loss: 0.8610 - val_accuracy: 0.6282\n",
            "Epoch 720/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6779 - accuracy: 0.7120 - val_loss: 0.8278 - val_accuracy: 0.6154\n",
            "Epoch 721/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6742 - accuracy: 0.7217 - val_loss: 0.8220 - val_accuracy: 0.6410\n",
            "Epoch 722/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6907 - accuracy: 0.7023 - val_loss: 0.9578 - val_accuracy: 0.6026\n",
            "Epoch 723/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6356 - accuracy: 0.7314 - val_loss: 0.8767 - val_accuracy: 0.6154\n",
            "Epoch 724/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6441 - accuracy: 0.7314 - val_loss: 0.8040 - val_accuracy: 0.5769\n",
            "Epoch 725/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6457 - accuracy: 0.7055 - val_loss: 0.8260 - val_accuracy: 0.5769\n",
            "Epoch 726/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6488 - accuracy: 0.7217 - val_loss: 0.9514 - val_accuracy: 0.5897\n",
            "Epoch 727/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6157 - accuracy: 0.7346 - val_loss: 0.8377 - val_accuracy: 0.5641\n",
            "Epoch 728/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6506 - accuracy: 0.7217 - val_loss: 0.8775 - val_accuracy: 0.6154\n",
            "Epoch 729/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6835 - accuracy: 0.7120 - val_loss: 0.9991 - val_accuracy: 0.6026\n",
            "Epoch 730/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6976 - accuracy: 0.7120 - val_loss: 1.0813 - val_accuracy: 0.5641\n",
            "Epoch 731/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6638 - accuracy: 0.7314 - val_loss: 0.8608 - val_accuracy: 0.6154\n",
            "Epoch 732/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6845 - accuracy: 0.7314 - val_loss: 0.9597 - val_accuracy: 0.5897\n",
            "Epoch 733/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6836 - accuracy: 0.7282 - val_loss: 0.9452 - val_accuracy: 0.6154\n",
            "Epoch 734/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7003 - accuracy: 0.7023 - val_loss: 0.8810 - val_accuracy: 0.6026\n",
            "Epoch 735/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.7443 - val_loss: 0.9582 - val_accuracy: 0.6282\n",
            "Epoch 736/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.7159 - accuracy: 0.6990 - val_loss: 0.8653 - val_accuracy: 0.5769\n",
            "Epoch 737/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6458 - accuracy: 0.7379 - val_loss: 0.9498 - val_accuracy: 0.6026\n",
            "Epoch 738/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6230 - accuracy: 0.7411 - val_loss: 0.8443 - val_accuracy: 0.5385\n",
            "Epoch 739/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6194 - accuracy: 0.7379 - val_loss: 0.9677 - val_accuracy: 0.6154\n",
            "Epoch 740/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6573 - accuracy: 0.7249 - val_loss: 0.9155 - val_accuracy: 0.6026\n",
            "Epoch 741/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6692 - accuracy: 0.7217 - val_loss: 0.8588 - val_accuracy: 0.5897\n",
            "Epoch 742/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6170 - accuracy: 0.7379 - val_loss: 0.8626 - val_accuracy: 0.5897\n",
            "Epoch 743/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6547 - accuracy: 0.7087 - val_loss: 0.8415 - val_accuracy: 0.6410\n",
            "Epoch 744/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6732 - accuracy: 0.7023 - val_loss: 0.9233 - val_accuracy: 0.5641\n",
            "Epoch 745/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6821 - accuracy: 0.7120 - val_loss: 0.9733 - val_accuracy: 0.5641\n",
            "Epoch 746/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7295 - accuracy: 0.6958 - val_loss: 0.8880 - val_accuracy: 0.5897\n",
            "Epoch 747/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6745 - accuracy: 0.6926 - val_loss: 0.8275 - val_accuracy: 0.5769\n",
            "Epoch 748/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6610 - accuracy: 0.7023 - val_loss: 0.9358 - val_accuracy: 0.5897\n",
            "Epoch 749/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6553 - accuracy: 0.7443 - val_loss: 1.0521 - val_accuracy: 0.6154\n",
            "Epoch 750/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7352 - accuracy: 0.7120 - val_loss: 1.0069 - val_accuracy: 0.6282\n",
            "Epoch 751/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7290 - accuracy: 0.7184 - val_loss: 0.9602 - val_accuracy: 0.6026\n",
            "Epoch 752/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6554 - accuracy: 0.7508 - val_loss: 0.8877 - val_accuracy: 0.5513\n",
            "Epoch 753/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6654 - accuracy: 0.7314 - val_loss: 0.9821 - val_accuracy: 0.6026\n",
            "Epoch 754/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6513 - accuracy: 0.7314 - val_loss: 0.8457 - val_accuracy: 0.6154\n",
            "Epoch 755/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6499 - accuracy: 0.7346 - val_loss: 0.8112 - val_accuracy: 0.5641\n",
            "Epoch 756/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6441 - accuracy: 0.7379 - val_loss: 0.9378 - val_accuracy: 0.6026\n",
            "Epoch 757/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7239 - accuracy: 0.7184 - val_loss: 1.0097 - val_accuracy: 0.6026\n",
            "Epoch 758/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6535 - accuracy: 0.7443 - val_loss: 0.9516 - val_accuracy: 0.5641\n",
            "Epoch 759/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6538 - accuracy: 0.7152 - val_loss: 0.8835 - val_accuracy: 0.6154\n",
            "Epoch 760/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6628 - accuracy: 0.7443 - val_loss: 0.8836 - val_accuracy: 0.5513\n",
            "Epoch 761/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6963 - accuracy: 0.7055 - val_loss: 0.9147 - val_accuracy: 0.5641\n",
            "Epoch 762/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6590 - accuracy: 0.7184 - val_loss: 0.8279 - val_accuracy: 0.5641\n",
            "Epoch 763/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6450 - accuracy: 0.7184 - val_loss: 0.8541 - val_accuracy: 0.5385\n",
            "Epoch 764/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6355 - accuracy: 0.7443 - val_loss: 0.8435 - val_accuracy: 0.5513\n",
            "Epoch 765/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6401 - accuracy: 0.7346 - val_loss: 1.0500 - val_accuracy: 0.5513\n",
            "Epoch 766/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6533 - accuracy: 0.7379 - val_loss: 0.9130 - val_accuracy: 0.6026\n",
            "Epoch 767/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.7111 - accuracy: 0.7055 - val_loss: 1.0093 - val_accuracy: 0.5513\n",
            "Epoch 768/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.7395 - accuracy: 0.6990 - val_loss: 0.8236 - val_accuracy: 0.6026\n",
            "Epoch 769/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6988 - accuracy: 0.7023 - val_loss: 0.8497 - val_accuracy: 0.5769\n",
            "Epoch 770/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7272 - accuracy: 0.6861 - val_loss: 0.8662 - val_accuracy: 0.6026\n",
            "Epoch 771/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6910 - accuracy: 0.7120 - val_loss: 0.8856 - val_accuracy: 0.5769\n",
            "Epoch 772/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6798 - accuracy: 0.7249 - val_loss: 0.8782 - val_accuracy: 0.6282\n",
            "Epoch 773/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6940 - accuracy: 0.7184 - val_loss: 0.8577 - val_accuracy: 0.5769\n",
            "Epoch 774/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7477 - accuracy: 0.6828 - val_loss: 0.9290 - val_accuracy: 0.6154\n",
            "Epoch 775/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6580 - accuracy: 0.7282 - val_loss: 1.0031 - val_accuracy: 0.5769\n",
            "Epoch 776/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6489 - accuracy: 0.7217 - val_loss: 0.8727 - val_accuracy: 0.5513\n",
            "Epoch 777/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6420 - accuracy: 0.7540 - val_loss: 0.8168 - val_accuracy: 0.5513\n",
            "Epoch 778/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6559 - accuracy: 0.7249 - val_loss: 0.8170 - val_accuracy: 0.5513\n",
            "Epoch 779/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6024 - accuracy: 0.7476 - val_loss: 0.8475 - val_accuracy: 0.5256\n",
            "Epoch 780/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6186 - accuracy: 0.7120 - val_loss: 0.8630 - val_accuracy: 0.5256\n",
            "Epoch 781/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6225 - accuracy: 0.7540 - val_loss: 0.8368 - val_accuracy: 0.6026\n",
            "Epoch 782/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6721 - accuracy: 0.7282 - val_loss: 0.8891 - val_accuracy: 0.5897\n",
            "Epoch 783/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6492 - accuracy: 0.7476 - val_loss: 0.8344 - val_accuracy: 0.5513\n",
            "Epoch 784/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6243 - accuracy: 0.7249 - val_loss: 0.9416 - val_accuracy: 0.6154\n",
            "Epoch 785/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6466 - accuracy: 0.7443 - val_loss: 0.8834 - val_accuracy: 0.5897\n",
            "Epoch 786/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6699 - accuracy: 0.7379 - val_loss: 0.9051 - val_accuracy: 0.6026\n",
            "Epoch 787/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6649 - accuracy: 0.7184 - val_loss: 0.8582 - val_accuracy: 0.5513\n",
            "Epoch 788/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6819 - accuracy: 0.7152 - val_loss: 0.8969 - val_accuracy: 0.6026\n",
            "Epoch 789/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6520 - accuracy: 0.7573 - val_loss: 0.8807 - val_accuracy: 0.6026\n",
            "Epoch 790/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6606 - accuracy: 0.7087 - val_loss: 0.9817 - val_accuracy: 0.5769\n",
            "Epoch 791/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6996 - accuracy: 0.6958 - val_loss: 0.8813 - val_accuracy: 0.5641\n",
            "Epoch 792/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7304 - accuracy: 0.7120 - val_loss: 0.8167 - val_accuracy: 0.6282\n",
            "Epoch 793/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7250 - accuracy: 0.7314 - val_loss: 0.8457 - val_accuracy: 0.5897\n",
            "Epoch 794/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7020 - accuracy: 0.7087 - val_loss: 0.8497 - val_accuracy: 0.6282\n",
            "Epoch 795/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6919 - accuracy: 0.6990 - val_loss: 0.8850 - val_accuracy: 0.5769\n",
            "Epoch 796/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6844 - accuracy: 0.7184 - val_loss: 0.7895 - val_accuracy: 0.6154\n",
            "Epoch 797/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6445 - accuracy: 0.7443 - val_loss: 0.8742 - val_accuracy: 0.6154\n",
            "Epoch 798/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6143 - accuracy: 0.7346 - val_loss: 0.8869 - val_accuracy: 0.5897\n",
            "Epoch 799/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7332 - accuracy: 0.6958 - val_loss: 0.8984 - val_accuracy: 0.6282\n",
            "Epoch 800/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6750 - accuracy: 0.6764 - val_loss: 0.9138 - val_accuracy: 0.6026\n",
            "Epoch 801/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6462 - accuracy: 0.7184 - val_loss: 0.9109 - val_accuracy: 0.5769\n",
            "Epoch 802/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6792 - accuracy: 0.7476 - val_loss: 0.9040 - val_accuracy: 0.6154\n",
            "Epoch 803/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6177 - accuracy: 0.7055 - val_loss: 0.8204 - val_accuracy: 0.5769\n",
            "Epoch 804/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6476 - accuracy: 0.7217 - val_loss: 0.8558 - val_accuracy: 0.6154\n",
            "Epoch 805/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5793 - accuracy: 0.7605 - val_loss: 0.8196 - val_accuracy: 0.5513\n",
            "Epoch 806/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6536 - accuracy: 0.7476 - val_loss: 0.9724 - val_accuracy: 0.5769\n",
            "Epoch 807/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6123 - accuracy: 0.7346 - val_loss: 0.7861 - val_accuracy: 0.5641\n",
            "Epoch 808/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6317 - accuracy: 0.7508 - val_loss: 0.8711 - val_accuracy: 0.5641\n",
            "Epoch 809/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.7184 - val_loss: 0.9587 - val_accuracy: 0.6282\n",
            "Epoch 810/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7307 - accuracy: 0.7184 - val_loss: 0.9164 - val_accuracy: 0.5897\n",
            "Epoch 811/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6818 - accuracy: 0.7282 - val_loss: 0.8086 - val_accuracy: 0.5769\n",
            "Epoch 812/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6423 - accuracy: 0.7443 - val_loss: 0.9283 - val_accuracy: 0.6154\n",
            "Epoch 813/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6342 - accuracy: 0.7508 - val_loss: 0.9158 - val_accuracy: 0.5385\n",
            "Epoch 814/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5893 - accuracy: 0.7540 - val_loss: 0.8353 - val_accuracy: 0.5897\n",
            "Epoch 815/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5718 - accuracy: 0.7411 - val_loss: 0.8998 - val_accuracy: 0.5897\n",
            "Epoch 816/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5940 - accuracy: 0.7508 - val_loss: 0.9779 - val_accuracy: 0.6026\n",
            "Epoch 817/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6619 - accuracy: 0.7346 - val_loss: 0.8599 - val_accuracy: 0.6154\n",
            "Epoch 818/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6452 - accuracy: 0.7638 - val_loss: 0.7941 - val_accuracy: 0.5641\n",
            "Epoch 819/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6047 - accuracy: 0.7314 - val_loss: 0.8803 - val_accuracy: 0.6026\n",
            "Epoch 820/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6410 - accuracy: 0.7184 - val_loss: 0.8061 - val_accuracy: 0.6026\n",
            "Epoch 821/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6131 - accuracy: 0.7476 - val_loss: 0.7990 - val_accuracy: 0.6154\n",
            "Epoch 822/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5674 - accuracy: 0.7799 - val_loss: 0.9323 - val_accuracy: 0.6026\n",
            "Epoch 823/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6582 - accuracy: 0.7217 - val_loss: 0.9181 - val_accuracy: 0.6026\n",
            "Epoch 824/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6211 - accuracy: 0.7087 - val_loss: 0.9357 - val_accuracy: 0.6154\n",
            "Epoch 825/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6340 - accuracy: 0.7282 - val_loss: 0.8647 - val_accuracy: 0.6026\n",
            "Epoch 826/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6024 - accuracy: 0.7346 - val_loss: 0.9666 - val_accuracy: 0.6154\n",
            "Epoch 827/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6222 - accuracy: 0.7379 - val_loss: 1.1473 - val_accuracy: 0.6154\n",
            "Epoch 828/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7190 - accuracy: 0.7249 - val_loss: 0.9363 - val_accuracy: 0.6026\n",
            "Epoch 829/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.6893 - val_loss: 1.0746 - val_accuracy: 0.6154\n",
            "Epoch 830/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6955 - accuracy: 0.7152 - val_loss: 0.8562 - val_accuracy: 0.5769\n",
            "Epoch 831/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6295 - accuracy: 0.7443 - val_loss: 0.8422 - val_accuracy: 0.5256\n",
            "Epoch 832/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6344 - accuracy: 0.7508 - val_loss: 0.7985 - val_accuracy: 0.6282\n",
            "Epoch 833/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6043 - accuracy: 0.7476 - val_loss: 0.8221 - val_accuracy: 0.5897\n",
            "Epoch 834/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6182 - accuracy: 0.7314 - val_loss: 0.9435 - val_accuracy: 0.5769\n",
            "Epoch 835/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6241 - accuracy: 0.7346 - val_loss: 0.8496 - val_accuracy: 0.6026\n",
            "Epoch 836/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5890 - accuracy: 0.7670 - val_loss: 0.8106 - val_accuracy: 0.6154\n",
            "Epoch 837/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6242 - accuracy: 0.7476 - val_loss: 0.9833 - val_accuracy: 0.6026\n",
            "Epoch 838/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6493 - accuracy: 0.7314 - val_loss: 0.8497 - val_accuracy: 0.6410\n",
            "Epoch 839/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7228 - accuracy: 0.6990 - val_loss: 0.9409 - val_accuracy: 0.5897\n",
            "Epoch 840/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7169 - accuracy: 0.7055 - val_loss: 0.8293 - val_accuracy: 0.5641\n",
            "Epoch 841/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6506 - accuracy: 0.7314 - val_loss: 0.8269 - val_accuracy: 0.5897\n",
            "Epoch 842/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5828 - accuracy: 0.7638 - val_loss: 0.8894 - val_accuracy: 0.5769\n",
            "Epoch 843/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5834 - accuracy: 0.7443 - val_loss: 0.9283 - val_accuracy: 0.5385\n",
            "Epoch 844/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6003 - accuracy: 0.7573 - val_loss: 0.9446 - val_accuracy: 0.5641\n",
            "Epoch 845/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5757 - accuracy: 0.7605 - val_loss: 0.8844 - val_accuracy: 0.6154\n",
            "Epoch 846/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6443 - accuracy: 0.7152 - val_loss: 0.8323 - val_accuracy: 0.5897\n",
            "Epoch 847/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6003 - accuracy: 0.7443 - val_loss: 0.9628 - val_accuracy: 0.5769\n",
            "Epoch 848/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6242 - accuracy: 0.7217 - val_loss: 0.9136 - val_accuracy: 0.6026\n",
            "Epoch 849/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5907 - accuracy: 0.7767 - val_loss: 0.8501 - val_accuracy: 0.5897\n",
            "Epoch 850/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5942 - accuracy: 0.7443 - val_loss: 0.7878 - val_accuracy: 0.6282\n",
            "Epoch 851/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6152 - accuracy: 0.7443 - val_loss: 0.8428 - val_accuracy: 0.5897\n",
            "Epoch 852/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5970 - accuracy: 0.7605 - val_loss: 0.8652 - val_accuracy: 0.5769\n",
            "Epoch 853/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6285 - accuracy: 0.7476 - val_loss: 0.8267 - val_accuracy: 0.5769\n",
            "Epoch 854/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6356 - accuracy: 0.7346 - val_loss: 0.7905 - val_accuracy: 0.5769\n",
            "Epoch 855/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5959 - accuracy: 0.7605 - val_loss: 0.8440 - val_accuracy: 0.5769\n",
            "Epoch 856/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6161 - accuracy: 0.7282 - val_loss: 0.8628 - val_accuracy: 0.5897\n",
            "Epoch 857/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6508 - accuracy: 0.7314 - val_loss: 0.8630 - val_accuracy: 0.6282\n",
            "Epoch 858/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6012 - accuracy: 0.7540 - val_loss: 0.8279 - val_accuracy: 0.5513\n",
            "Epoch 859/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6064 - accuracy: 0.7476 - val_loss: 0.9216 - val_accuracy: 0.5513\n",
            "Epoch 860/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5728 - accuracy: 0.7670 - val_loss: 0.9094 - val_accuracy: 0.5897\n",
            "Epoch 861/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6705 - accuracy: 0.7314 - val_loss: 1.0245 - val_accuracy: 0.5897\n",
            "Epoch 862/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7607 - accuracy: 0.6667 - val_loss: 0.8095 - val_accuracy: 0.6026\n",
            "Epoch 863/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6274 - accuracy: 0.7346 - val_loss: 0.8728 - val_accuracy: 0.6282\n",
            "Epoch 864/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7127 - accuracy: 0.6926 - val_loss: 1.0494 - val_accuracy: 0.5641\n",
            "Epoch 865/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6099 - accuracy: 0.7152 - val_loss: 0.8940 - val_accuracy: 0.5385\n",
            "Epoch 866/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6128 - accuracy: 0.7508 - val_loss: 0.8413 - val_accuracy: 0.6026\n",
            "Epoch 867/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6078 - accuracy: 0.7282 - val_loss: 0.8014 - val_accuracy: 0.5513\n",
            "Epoch 868/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5836 - accuracy: 0.7540 - val_loss: 0.9445 - val_accuracy: 0.5513\n",
            "Epoch 869/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6049 - accuracy: 0.7443 - val_loss: 0.8192 - val_accuracy: 0.6154\n",
            "Epoch 870/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5760 - accuracy: 0.7638 - val_loss: 0.8253 - val_accuracy: 0.6026\n",
            "Epoch 871/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5967 - accuracy: 0.7573 - val_loss: 0.9583 - val_accuracy: 0.5897\n",
            "Epoch 872/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5997 - accuracy: 0.7605 - val_loss: 0.9716 - val_accuracy: 0.6026\n",
            "Epoch 873/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6224 - accuracy: 0.7638 - val_loss: 0.8123 - val_accuracy: 0.6282\n",
            "Epoch 874/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6079 - accuracy: 0.7443 - val_loss: 0.8731 - val_accuracy: 0.6154\n",
            "Epoch 875/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5911 - accuracy: 0.7379 - val_loss: 0.8827 - val_accuracy: 0.5897\n",
            "Epoch 876/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5971 - accuracy: 0.7638 - val_loss: 0.8794 - val_accuracy: 0.6026\n",
            "Epoch 877/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6344 - accuracy: 0.7346 - val_loss: 0.8191 - val_accuracy: 0.5897\n",
            "Epoch 878/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6052 - accuracy: 0.7411 - val_loss: 0.7705 - val_accuracy: 0.5641\n",
            "Epoch 879/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6658 - accuracy: 0.7605 - val_loss: 0.8742 - val_accuracy: 0.5897\n",
            "Epoch 880/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.6470 - accuracy: 0.7379 - val_loss: 0.8287 - val_accuracy: 0.6154\n",
            "Epoch 881/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5805 - accuracy: 0.7476 - val_loss: 0.9754 - val_accuracy: 0.6154\n",
            "Epoch 882/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6319 - accuracy: 0.7411 - val_loss: 0.8618 - val_accuracy: 0.5769\n",
            "Epoch 883/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6290 - accuracy: 0.7540 - val_loss: 0.8857 - val_accuracy: 0.5641\n",
            "Epoch 884/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6269 - accuracy: 0.7476 - val_loss: 0.7917 - val_accuracy: 0.5897\n",
            "Epoch 885/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7261 - accuracy: 0.6990 - val_loss: 0.8694 - val_accuracy: 0.6282\n",
            "Epoch 886/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6806 - accuracy: 0.6893 - val_loss: 0.9279 - val_accuracy: 0.6026\n",
            "Epoch 887/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6824 - accuracy: 0.7087 - val_loss: 0.9070 - val_accuracy: 0.5897\n",
            "Epoch 888/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6734 - accuracy: 0.7249 - val_loss: 0.8230 - val_accuracy: 0.5897\n",
            "Epoch 889/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6831 - accuracy: 0.7023 - val_loss: 0.8326 - val_accuracy: 0.5769\n",
            "Epoch 890/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6204 - accuracy: 0.7443 - val_loss: 0.8251 - val_accuracy: 0.5641\n",
            "Epoch 891/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5694 - accuracy: 0.7670 - val_loss: 0.8713 - val_accuracy: 0.5513\n",
            "Epoch 892/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6524 - accuracy: 0.7314 - val_loss: 0.8031 - val_accuracy: 0.6026\n",
            "Epoch 893/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6116 - accuracy: 0.7346 - val_loss: 0.9096 - val_accuracy: 0.6282\n",
            "Epoch 894/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7160 - accuracy: 0.7023 - val_loss: 0.8580 - val_accuracy: 0.5897\n",
            "Epoch 895/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7272 - accuracy: 0.6958 - val_loss: 0.8389 - val_accuracy: 0.5385\n",
            "Epoch 896/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6430 - accuracy: 0.7314 - val_loss: 0.8272 - val_accuracy: 0.6154\n",
            "Epoch 897/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6790 - accuracy: 0.7152 - val_loss: 0.7865 - val_accuracy: 0.6538\n",
            "Epoch 898/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6479 - accuracy: 0.7023 - val_loss: 0.8747 - val_accuracy: 0.6410\n",
            "Epoch 899/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6477 - accuracy: 0.7379 - val_loss: 0.7977 - val_accuracy: 0.5897\n",
            "Epoch 900/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6149 - accuracy: 0.7217 - val_loss: 0.8113 - val_accuracy: 0.5513\n",
            "Epoch 901/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5623 - accuracy: 0.7638 - val_loss: 0.8009 - val_accuracy: 0.5769\n",
            "Epoch 902/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6147 - accuracy: 0.7476 - val_loss: 0.8358 - val_accuracy: 0.6154\n",
            "Epoch 903/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6285 - accuracy: 0.7540 - val_loss: 0.9508 - val_accuracy: 0.6026\n",
            "Epoch 904/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6762 - accuracy: 0.7443 - val_loss: 1.2092 - val_accuracy: 0.5769\n",
            "Epoch 905/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.8107 - accuracy: 0.7023 - val_loss: 1.1399 - val_accuracy: 0.6154\n",
            "Epoch 906/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7046 - accuracy: 0.7055 - val_loss: 1.0371 - val_accuracy: 0.5897\n",
            "Epoch 907/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.7591 - accuracy: 0.6926 - val_loss: 0.8515 - val_accuracy: 0.6026\n",
            "Epoch 908/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6901 - accuracy: 0.6990 - val_loss: 0.9416 - val_accuracy: 0.6154\n",
            "Epoch 909/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6822 - accuracy: 0.7184 - val_loss: 0.9399 - val_accuracy: 0.5897\n",
            "Epoch 910/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5867 - accuracy: 0.7670 - val_loss: 0.9000 - val_accuracy: 0.6026\n",
            "Epoch 911/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6170 - accuracy: 0.7476 - val_loss: 0.9167 - val_accuracy: 0.5641\n",
            "Epoch 912/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5672 - accuracy: 0.7638 - val_loss: 0.8689 - val_accuracy: 0.5513\n",
            "Epoch 913/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5639 - accuracy: 0.7767 - val_loss: 0.8605 - val_accuracy: 0.5897\n",
            "Epoch 914/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5973 - accuracy: 0.7638 - val_loss: 0.9608 - val_accuracy: 0.5641\n",
            "Epoch 915/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6252 - accuracy: 0.7508 - val_loss: 0.9884 - val_accuracy: 0.6282\n",
            "Epoch 916/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6337 - accuracy: 0.7476 - val_loss: 0.9362 - val_accuracy: 0.6026\n",
            "Epoch 917/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6256 - accuracy: 0.7476 - val_loss: 1.0570 - val_accuracy: 0.5769\n",
            "Epoch 918/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6741 - accuracy: 0.7152 - val_loss: 0.8619 - val_accuracy: 0.6282\n",
            "Epoch 919/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6288 - accuracy: 0.7670 - val_loss: 0.8659 - val_accuracy: 0.5641\n",
            "Epoch 920/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6403 - accuracy: 0.7249 - val_loss: 0.8241 - val_accuracy: 0.5385\n",
            "Epoch 921/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5910 - accuracy: 0.7476 - val_loss: 0.8713 - val_accuracy: 0.5897\n",
            "Epoch 922/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5696 - accuracy: 0.7670 - val_loss: 0.8929 - val_accuracy: 0.5897\n",
            "Epoch 923/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5806 - accuracy: 0.7573 - val_loss: 0.9142 - val_accuracy: 0.5897\n",
            "Epoch 924/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6497 - accuracy: 0.7217 - val_loss: 0.9927 - val_accuracy: 0.6026\n",
            "Epoch 925/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5951 - accuracy: 0.7314 - val_loss: 0.9002 - val_accuracy: 0.5641\n",
            "Epoch 926/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5971 - accuracy: 0.7799 - val_loss: 0.9233 - val_accuracy: 0.5897\n",
            "Epoch 927/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5583 - accuracy: 0.7799 - val_loss: 0.8269 - val_accuracy: 0.5897\n",
            "Epoch 928/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5815 - accuracy: 0.7670 - val_loss: 0.8764 - val_accuracy: 0.5769\n",
            "Epoch 929/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6206 - accuracy: 0.7314 - val_loss: 1.0028 - val_accuracy: 0.6154\n",
            "Epoch 930/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7427 - accuracy: 0.6602 - val_loss: 0.8174 - val_accuracy: 0.5897\n",
            "Epoch 931/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6392 - accuracy: 0.7120 - val_loss: 0.8711 - val_accuracy: 0.5897\n",
            "Epoch 932/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6110 - accuracy: 0.7508 - val_loss: 0.8571 - val_accuracy: 0.5769\n",
            "Epoch 933/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6168 - accuracy: 0.7735 - val_loss: 0.9326 - val_accuracy: 0.6026\n",
            "Epoch 934/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6266 - accuracy: 0.7282 - val_loss: 0.9319 - val_accuracy: 0.5897\n",
            "Epoch 935/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6083 - accuracy: 0.7314 - val_loss: 1.0539 - val_accuracy: 0.6154\n",
            "Epoch 936/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6504 - accuracy: 0.7282 - val_loss: 0.8598 - val_accuracy: 0.6026\n",
            "Epoch 937/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6300 - accuracy: 0.7411 - val_loss: 0.9494 - val_accuracy: 0.6026\n",
            "Epoch 938/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6163 - accuracy: 0.7346 - val_loss: 0.9170 - val_accuracy: 0.6154\n",
            "Epoch 939/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6242 - accuracy: 0.7282 - val_loss: 0.7722 - val_accuracy: 0.6538\n",
            "Epoch 940/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6033 - accuracy: 0.7443 - val_loss: 0.8206 - val_accuracy: 0.6154\n",
            "Epoch 941/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6471 - accuracy: 0.7540 - val_loss: 1.0039 - val_accuracy: 0.5769\n",
            "Epoch 942/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6156 - accuracy: 0.7702 - val_loss: 0.8897 - val_accuracy: 0.6154\n",
            "Epoch 943/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5866 - accuracy: 0.7411 - val_loss: 0.9530 - val_accuracy: 0.6154\n",
            "Epoch 944/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5736 - accuracy: 0.7443 - val_loss: 0.9957 - val_accuracy: 0.5897\n",
            "Epoch 945/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5856 - accuracy: 0.7670 - val_loss: 0.8456 - val_accuracy: 0.6026\n",
            "Epoch 946/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5746 - accuracy: 0.7702 - val_loss: 0.9060 - val_accuracy: 0.5769\n",
            "Epoch 947/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5832 - accuracy: 0.7638 - val_loss: 0.7989 - val_accuracy: 0.6026\n",
            "Epoch 948/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6028 - accuracy: 0.7540 - val_loss: 0.8386 - val_accuracy: 0.6154\n",
            "Epoch 949/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5670 - accuracy: 0.7735 - val_loss: 0.8385 - val_accuracy: 0.6154\n",
            "Epoch 950/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6002 - accuracy: 0.7249 - val_loss: 0.9446 - val_accuracy: 0.6282\n",
            "Epoch 951/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5812 - accuracy: 0.7411 - val_loss: 0.8810 - val_accuracy: 0.6026\n",
            "Epoch 952/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6317 - accuracy: 0.7314 - val_loss: 0.9640 - val_accuracy: 0.5769\n",
            "Epoch 953/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6364 - accuracy: 0.7249 - val_loss: 0.8195 - val_accuracy: 0.6282\n",
            "Epoch 954/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6078 - accuracy: 0.7346 - val_loss: 0.8430 - val_accuracy: 0.5897\n",
            "Epoch 955/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5331 - accuracy: 0.7961 - val_loss: 0.8450 - val_accuracy: 0.6026\n",
            "Epoch 956/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6103 - accuracy: 0.7605 - val_loss: 0.8473 - val_accuracy: 0.5769\n",
            "Epoch 957/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5546 - accuracy: 0.7670 - val_loss: 0.8905 - val_accuracy: 0.6282\n",
            "Epoch 958/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5469 - accuracy: 0.7702 - val_loss: 0.8989 - val_accuracy: 0.5769\n",
            "Epoch 959/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5734 - accuracy: 0.7670 - val_loss: 0.8145 - val_accuracy: 0.6154\n",
            "Epoch 960/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5927 - accuracy: 0.7573 - val_loss: 0.8741 - val_accuracy: 0.5897\n",
            "Epoch 961/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5362 - accuracy: 0.7670 - val_loss: 0.8437 - val_accuracy: 0.5897\n",
            "Epoch 962/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5250 - accuracy: 0.7929 - val_loss: 0.8752 - val_accuracy: 0.5769\n",
            "Epoch 963/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5655 - accuracy: 0.7476 - val_loss: 0.8264 - val_accuracy: 0.5513\n",
            "Epoch 964/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6169 - accuracy: 0.7379 - val_loss: 0.8216 - val_accuracy: 0.6410\n",
            "Epoch 965/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5745 - accuracy: 0.7638 - val_loss: 0.8308 - val_accuracy: 0.6410\n",
            "Epoch 966/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5834 - accuracy: 0.7735 - val_loss: 0.8421 - val_accuracy: 0.5385\n",
            "Epoch 967/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6015 - accuracy: 0.7540 - val_loss: 0.8045 - val_accuracy: 0.5385\n",
            "Epoch 968/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6458 - accuracy: 0.7379 - val_loss: 0.8406 - val_accuracy: 0.6154\n",
            "Epoch 969/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6145 - accuracy: 0.7605 - val_loss: 0.9602 - val_accuracy: 0.5641\n",
            "Epoch 970/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6067 - accuracy: 0.7443 - val_loss: 0.8582 - val_accuracy: 0.5641\n",
            "Epoch 971/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5522 - accuracy: 0.7735 - val_loss: 0.9541 - val_accuracy: 0.5897\n",
            "Epoch 972/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6369 - accuracy: 0.7314 - val_loss: 0.9920 - val_accuracy: 0.5769\n",
            "Epoch 973/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6155 - accuracy: 0.7508 - val_loss: 0.8329 - val_accuracy: 0.5897\n",
            "Epoch 974/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6016 - accuracy: 0.7573 - val_loss: 0.8765 - val_accuracy: 0.6154\n",
            "Epoch 975/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5738 - accuracy: 0.7929 - val_loss: 0.7717 - val_accuracy: 0.6410\n",
            "Epoch 976/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5910 - accuracy: 0.7508 - val_loss: 0.9757 - val_accuracy: 0.6026\n",
            "Epoch 977/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7068 - accuracy: 0.7217 - val_loss: 0.8888 - val_accuracy: 0.5897\n",
            "Epoch 978/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6961 - accuracy: 0.7087 - val_loss: 0.8040 - val_accuracy: 0.6795\n",
            "Epoch 979/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6591 - accuracy: 0.7314 - val_loss: 0.8698 - val_accuracy: 0.6026\n",
            "Epoch 980/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6291 - accuracy: 0.7282 - val_loss: 0.8015 - val_accuracy: 0.6026\n",
            "Epoch 981/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6470 - accuracy: 0.7314 - val_loss: 0.9136 - val_accuracy: 0.6026\n",
            "Epoch 982/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6399 - accuracy: 0.7152 - val_loss: 0.8512 - val_accuracy: 0.5897\n",
            "Epoch 983/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5883 - accuracy: 0.7411 - val_loss: 0.8648 - val_accuracy: 0.6410\n",
            "Epoch 984/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5817 - accuracy: 0.7573 - val_loss: 0.8550 - val_accuracy: 0.6538\n",
            "Epoch 985/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5965 - accuracy: 0.7443 - val_loss: 0.7839 - val_accuracy: 0.6026\n",
            "Epoch 986/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5782 - accuracy: 0.7605 - val_loss: 0.8121 - val_accuracy: 0.6154\n",
            "Epoch 987/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5875 - accuracy: 0.7282 - val_loss: 1.0747 - val_accuracy: 0.6154\n",
            "Epoch 988/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6385 - accuracy: 0.7282 - val_loss: 0.9093 - val_accuracy: 0.5641\n",
            "Epoch 989/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6216 - accuracy: 0.7314 - val_loss: 0.9873 - val_accuracy: 0.6154\n",
            "Epoch 990/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6117 - accuracy: 0.7799 - val_loss: 0.8985 - val_accuracy: 0.6538\n",
            "Epoch 991/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6895 - accuracy: 0.7055 - val_loss: 0.9670 - val_accuracy: 0.5897\n",
            "Epoch 992/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6263 - accuracy: 0.7314 - val_loss: 0.8406 - val_accuracy: 0.5769\n",
            "Epoch 993/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5826 - accuracy: 0.7508 - val_loss: 0.8462 - val_accuracy: 0.5769\n",
            "Epoch 994/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6179 - accuracy: 0.7799 - val_loss: 0.8397 - val_accuracy: 0.6026\n",
            "Epoch 995/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5649 - accuracy: 0.7638 - val_loss: 0.9132 - val_accuracy: 0.6026\n",
            "Epoch 996/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6243 - accuracy: 0.7282 - val_loss: 0.9041 - val_accuracy: 0.6026\n",
            "Epoch 997/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6213 - accuracy: 0.7379 - val_loss: 0.8676 - val_accuracy: 0.6154\n",
            "Epoch 998/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6246 - accuracy: 0.7411 - val_loss: 0.8488 - val_accuracy: 0.6026\n",
            "Epoch 999/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5484 - accuracy: 0.7638 - val_loss: 0.8719 - val_accuracy: 0.5897\n",
            "Epoch 1000/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6064 - accuracy: 0.7346 - val_loss: 0.9377 - val_accuracy: 0.5641\n",
            "Epoch 1001/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7152 - accuracy: 0.6926 - val_loss: 0.9182 - val_accuracy: 0.6026\n",
            "Epoch 1002/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6746 - accuracy: 0.7314 - val_loss: 0.9209 - val_accuracy: 0.5897\n",
            "Epoch 1003/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5944 - accuracy: 0.7508 - val_loss: 0.8866 - val_accuracy: 0.5897\n",
            "Epoch 1004/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6157 - accuracy: 0.7508 - val_loss: 0.9067 - val_accuracy: 0.6410\n",
            "Epoch 1005/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6346 - accuracy: 0.7443 - val_loss: 0.9089 - val_accuracy: 0.5897\n",
            "Epoch 1006/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6523 - accuracy: 0.7314 - val_loss: 0.8397 - val_accuracy: 0.6026\n",
            "Epoch 1007/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5874 - accuracy: 0.7702 - val_loss: 0.8520 - val_accuracy: 0.6282\n",
            "Epoch 1008/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.6441 - accuracy: 0.7184 - val_loss: 0.9005 - val_accuracy: 0.5897\n",
            "Epoch 1009/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6872 - accuracy: 0.6634 - val_loss: 0.9962 - val_accuracy: 0.5641\n",
            "Epoch 1010/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6170 - accuracy: 0.7184 - val_loss: 0.8590 - val_accuracy: 0.6410\n",
            "Epoch 1011/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6005 - accuracy: 0.7573 - val_loss: 0.8491 - val_accuracy: 0.5641\n",
            "Epoch 1012/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5490 - accuracy: 0.7929 - val_loss: 0.8051 - val_accuracy: 0.5769\n",
            "Epoch 1013/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5595 - accuracy: 0.7638 - val_loss: 0.8388 - val_accuracy: 0.5769\n",
            "Epoch 1014/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5956 - accuracy: 0.7476 - val_loss: 0.8316 - val_accuracy: 0.6282\n",
            "Epoch 1015/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5527 - accuracy: 0.7864 - val_loss: 0.8888 - val_accuracy: 0.5128\n",
            "Epoch 1016/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5994 - accuracy: 0.7411 - val_loss: 0.8700 - val_accuracy: 0.6026\n",
            "Epoch 1017/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5773 - accuracy: 0.7476 - val_loss: 0.9266 - val_accuracy: 0.5897\n",
            "Epoch 1018/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5646 - accuracy: 0.7670 - val_loss: 0.7886 - val_accuracy: 0.6026\n",
            "Epoch 1019/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6136 - accuracy: 0.7249 - val_loss: 0.8276 - val_accuracy: 0.6282\n",
            "Epoch 1020/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5769 - accuracy: 0.7832 - val_loss: 0.7847 - val_accuracy: 0.6026\n",
            "Epoch 1021/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5788 - accuracy: 0.7443 - val_loss: 0.7733 - val_accuracy: 0.6410\n",
            "Epoch 1022/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5366 - accuracy: 0.7767 - val_loss: 0.8234 - val_accuracy: 0.6026\n",
            "Epoch 1023/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5880 - accuracy: 0.7670 - val_loss: 0.9189 - val_accuracy: 0.5769\n",
            "Epoch 1024/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6035 - accuracy: 0.7864 - val_loss: 0.9325 - val_accuracy: 0.6154\n",
            "Epoch 1025/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6108 - accuracy: 0.7443 - val_loss: 0.7788 - val_accuracy: 0.6026\n",
            "Epoch 1026/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5812 - accuracy: 0.7767 - val_loss: 0.7365 - val_accuracy: 0.6410\n",
            "Epoch 1027/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5929 - accuracy: 0.7476 - val_loss: 0.9176 - val_accuracy: 0.5897\n",
            "Epoch 1028/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5963 - accuracy: 0.7573 - val_loss: 0.8101 - val_accuracy: 0.6154\n",
            "Epoch 1029/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6063 - accuracy: 0.7217 - val_loss: 0.8500 - val_accuracy: 0.5641\n",
            "Epoch 1030/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5412 - accuracy: 0.7638 - val_loss: 0.8845 - val_accuracy: 0.6410\n",
            "Epoch 1031/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5270 - accuracy: 0.7832 - val_loss: 1.0408 - val_accuracy: 0.5641\n",
            "Epoch 1032/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5771 - accuracy: 0.7670 - val_loss: 0.9314 - val_accuracy: 0.5769\n",
            "Epoch 1033/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5659 - accuracy: 0.7540 - val_loss: 0.9687 - val_accuracy: 0.5897\n",
            "Epoch 1034/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5567 - accuracy: 0.7379 - val_loss: 0.9850 - val_accuracy: 0.6154\n",
            "Epoch 1035/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5706 - accuracy: 0.7508 - val_loss: 1.0077 - val_accuracy: 0.6026\n",
            "Epoch 1036/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6219 - accuracy: 0.7411 - val_loss: 0.8544 - val_accuracy: 0.5513\n",
            "Epoch 1037/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5496 - accuracy: 0.7638 - val_loss: 0.8250 - val_accuracy: 0.6026\n",
            "Epoch 1038/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4843 - accuracy: 0.8091 - val_loss: 0.9056 - val_accuracy: 0.6026\n",
            "Epoch 1039/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5957 - accuracy: 0.7314 - val_loss: 0.8653 - val_accuracy: 0.6026\n",
            "Epoch 1040/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5558 - accuracy: 0.7832 - val_loss: 0.8346 - val_accuracy: 0.6282\n",
            "Epoch 1041/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5496 - accuracy: 0.7767 - val_loss: 0.7749 - val_accuracy: 0.5897\n",
            "Epoch 1042/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5656 - accuracy: 0.7735 - val_loss: 0.9186 - val_accuracy: 0.6026\n",
            "Epoch 1043/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5341 - accuracy: 0.8123 - val_loss: 0.8111 - val_accuracy: 0.5897\n",
            "Epoch 1044/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6017 - accuracy: 0.7508 - val_loss: 0.8649 - val_accuracy: 0.6154\n",
            "Epoch 1045/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5964 - accuracy: 0.7379 - val_loss: 0.8556 - val_accuracy: 0.6154\n",
            "Epoch 1046/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5411 - accuracy: 0.7767 - val_loss: 0.8707 - val_accuracy: 0.5897\n",
            "Epoch 1047/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5868 - accuracy: 0.7573 - val_loss: 0.8284 - val_accuracy: 0.6154\n",
            "Epoch 1048/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6053 - accuracy: 0.7379 - val_loss: 0.8366 - val_accuracy: 0.6154\n",
            "Epoch 1049/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5675 - accuracy: 0.7670 - val_loss: 1.0038 - val_accuracy: 0.5769\n",
            "Epoch 1050/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5553 - accuracy: 0.7767 - val_loss: 0.8547 - val_accuracy: 0.5897\n",
            "Epoch 1051/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5504 - accuracy: 0.7767 - val_loss: 0.8368 - val_accuracy: 0.6282\n",
            "Epoch 1052/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5082 - accuracy: 0.7961 - val_loss: 0.8817 - val_accuracy: 0.5769\n",
            "Epoch 1053/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5571 - accuracy: 0.7799 - val_loss: 0.8348 - val_accuracy: 0.6154\n",
            "Epoch 1054/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5529 - accuracy: 0.7670 - val_loss: 0.9763 - val_accuracy: 0.5513\n",
            "Epoch 1055/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5532 - accuracy: 0.7767 - val_loss: 0.7981 - val_accuracy: 0.6154\n",
            "Epoch 1056/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5594 - accuracy: 0.7767 - val_loss: 0.8195 - val_accuracy: 0.5385\n",
            "Epoch 1057/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5655 - accuracy: 0.7540 - val_loss: 0.9394 - val_accuracy: 0.6282\n",
            "Epoch 1058/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5819 - accuracy: 0.7638 - val_loss: 0.9857 - val_accuracy: 0.5897\n",
            "Epoch 1059/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6722 - accuracy: 0.7314 - val_loss: 0.8290 - val_accuracy: 0.5769\n",
            "Epoch 1060/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5891 - accuracy: 0.7573 - val_loss: 0.8750 - val_accuracy: 0.5897\n",
            "Epoch 1061/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5784 - accuracy: 0.7702 - val_loss: 0.8481 - val_accuracy: 0.5513\n",
            "Epoch 1062/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5469 - accuracy: 0.7638 - val_loss: 0.7928 - val_accuracy: 0.6026\n",
            "Epoch 1063/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5596 - accuracy: 0.7638 - val_loss: 0.8176 - val_accuracy: 0.6154\n",
            "Epoch 1064/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5523 - accuracy: 0.7702 - val_loss: 0.8497 - val_accuracy: 0.6026\n",
            "Epoch 1065/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5660 - accuracy: 0.7249 - val_loss: 0.8682 - val_accuracy: 0.6026\n",
            "Epoch 1066/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5395 - accuracy: 0.7767 - val_loss: 0.8178 - val_accuracy: 0.6154\n",
            "Epoch 1067/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6262 - accuracy: 0.7379 - val_loss: 0.8532 - val_accuracy: 0.6154\n",
            "Epoch 1068/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6597 - accuracy: 0.7120 - val_loss: 0.8177 - val_accuracy: 0.6282\n",
            "Epoch 1069/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5513 - accuracy: 0.7799 - val_loss: 0.9053 - val_accuracy: 0.5897\n",
            "Epoch 1070/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5724 - accuracy: 0.7573 - val_loss: 0.8821 - val_accuracy: 0.6154\n",
            "Epoch 1071/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6251 - accuracy: 0.7411 - val_loss: 1.0189 - val_accuracy: 0.6154\n",
            "Epoch 1072/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6563 - accuracy: 0.7282 - val_loss: 1.0816 - val_accuracy: 0.6410\n",
            "Epoch 1073/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6479 - accuracy: 0.7120 - val_loss: 0.8744 - val_accuracy: 0.6026\n",
            "Epoch 1074/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5817 - accuracy: 0.7605 - val_loss: 0.7918 - val_accuracy: 0.6154\n",
            "Epoch 1075/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5815 - accuracy: 0.7605 - val_loss: 0.8453 - val_accuracy: 0.6026\n",
            "Epoch 1076/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5369 - accuracy: 0.7864 - val_loss: 0.8095 - val_accuracy: 0.5897\n",
            "Epoch 1077/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5279 - accuracy: 0.7864 - val_loss: 0.8716 - val_accuracy: 0.5385\n",
            "Epoch 1078/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5799 - accuracy: 0.7605 - val_loss: 0.8043 - val_accuracy: 0.6282\n",
            "Epoch 1079/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5753 - accuracy: 0.7540 - val_loss: 0.8790 - val_accuracy: 0.5256\n",
            "Epoch 1080/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5353 - accuracy: 0.7767 - val_loss: 0.8239 - val_accuracy: 0.6026\n",
            "Epoch 1081/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5640 - accuracy: 0.7638 - val_loss: 0.9080 - val_accuracy: 0.6154\n",
            "Epoch 1082/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5845 - accuracy: 0.7670 - val_loss: 0.9408 - val_accuracy: 0.5897\n",
            "Epoch 1083/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5450 - accuracy: 0.7605 - val_loss: 0.8810 - val_accuracy: 0.6026\n",
            "Epoch 1084/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5848 - accuracy: 0.7476 - val_loss: 0.8798 - val_accuracy: 0.5897\n",
            "Epoch 1085/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5600 - accuracy: 0.7476 - val_loss: 0.7923 - val_accuracy: 0.6410\n",
            "Epoch 1086/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5373 - accuracy: 0.7832 - val_loss: 0.8808 - val_accuracy: 0.6026\n",
            "Epoch 1087/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5616 - accuracy: 0.7411 - val_loss: 0.9297 - val_accuracy: 0.6026\n",
            "Epoch 1088/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5519 - accuracy: 0.7832 - val_loss: 0.8314 - val_accuracy: 0.6026\n",
            "Epoch 1089/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5356 - accuracy: 0.7767 - val_loss: 0.8626 - val_accuracy: 0.5513\n",
            "Epoch 1090/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5191 - accuracy: 0.7799 - val_loss: 0.8917 - val_accuracy: 0.6026\n",
            "Epoch 1091/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5552 - accuracy: 0.7605 - val_loss: 0.8087 - val_accuracy: 0.6282\n",
            "Epoch 1092/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5238 - accuracy: 0.7929 - val_loss: 0.7861 - val_accuracy: 0.6538\n",
            "Epoch 1093/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5583 - accuracy: 0.7735 - val_loss: 0.7802 - val_accuracy: 0.6154\n",
            "Epoch 1094/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5336 - accuracy: 0.7832 - val_loss: 0.8269 - val_accuracy: 0.6026\n",
            "Epoch 1095/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5656 - accuracy: 0.7605 - val_loss: 0.8855 - val_accuracy: 0.5897\n",
            "Epoch 1096/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5863 - accuracy: 0.7346 - val_loss: 1.0056 - val_accuracy: 0.5769\n",
            "Epoch 1097/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6248 - accuracy: 0.7508 - val_loss: 0.9194 - val_accuracy: 0.5897\n",
            "Epoch 1098/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5461 - accuracy: 0.7670 - val_loss: 0.8144 - val_accuracy: 0.6282\n",
            "Epoch 1099/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5782 - accuracy: 0.7702 - val_loss: 0.8275 - val_accuracy: 0.6026\n",
            "Epoch 1100/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5754 - accuracy: 0.7379 - val_loss: 1.0665 - val_accuracy: 0.5897\n",
            "Epoch 1101/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5639 - accuracy: 0.7411 - val_loss: 1.1167 - val_accuracy: 0.5897\n",
            "Epoch 1102/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6414 - accuracy: 0.7282 - val_loss: 0.8048 - val_accuracy: 0.6410\n",
            "Epoch 1103/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5408 - accuracy: 0.7540 - val_loss: 0.9534 - val_accuracy: 0.5897\n",
            "Epoch 1104/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5838 - accuracy: 0.7638 - val_loss: 0.8228 - val_accuracy: 0.5897\n",
            "Epoch 1105/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5819 - accuracy: 0.7799 - val_loss: 0.9188 - val_accuracy: 0.6410\n",
            "Epoch 1106/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6467 - accuracy: 0.7443 - val_loss: 0.7862 - val_accuracy: 0.6410\n",
            "Epoch 1107/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5706 - accuracy: 0.7540 - val_loss: 0.7908 - val_accuracy: 0.6154\n",
            "Epoch 1108/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5867 - accuracy: 0.7735 - val_loss: 0.9650 - val_accuracy: 0.5897\n",
            "Epoch 1109/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6135 - accuracy: 0.7379 - val_loss: 0.9014 - val_accuracy: 0.5641\n",
            "Epoch 1110/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5974 - accuracy: 0.7411 - val_loss: 0.8359 - val_accuracy: 0.5897\n",
            "Epoch 1111/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5890 - accuracy: 0.7476 - val_loss: 0.7870 - val_accuracy: 0.6026\n",
            "Epoch 1112/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5430 - accuracy: 0.7605 - val_loss: 0.8239 - val_accuracy: 0.6026\n",
            "Epoch 1113/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5420 - accuracy: 0.7735 - val_loss: 0.9301 - val_accuracy: 0.5769\n",
            "Epoch 1114/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5703 - accuracy: 0.7735 - val_loss: 0.9174 - val_accuracy: 0.5897\n",
            "Epoch 1115/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5228 - accuracy: 0.7638 - val_loss: 0.8677 - val_accuracy: 0.6026\n",
            "Epoch 1116/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5636 - accuracy: 0.7540 - val_loss: 0.8382 - val_accuracy: 0.5897\n",
            "Epoch 1117/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5549 - accuracy: 0.7735 - val_loss: 0.8664 - val_accuracy: 0.6026\n",
            "Epoch 1118/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5529 - accuracy: 0.7767 - val_loss: 0.8364 - val_accuracy: 0.6026\n",
            "Epoch 1119/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5991 - accuracy: 0.7411 - val_loss: 0.8511 - val_accuracy: 0.6154\n",
            "Epoch 1120/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5446 - accuracy: 0.7735 - val_loss: 0.9249 - val_accuracy: 0.5641\n",
            "Epoch 1121/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6534 - accuracy: 0.7217 - val_loss: 0.7903 - val_accuracy: 0.6154\n",
            "Epoch 1122/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5680 - accuracy: 0.7638 - val_loss: 0.9231 - val_accuracy: 0.6026\n",
            "Epoch 1123/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6172 - accuracy: 0.7411 - val_loss: 0.9519 - val_accuracy: 0.6282\n",
            "Epoch 1124/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5595 - accuracy: 0.7864 - val_loss: 1.0020 - val_accuracy: 0.5897\n",
            "Epoch 1125/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6182 - accuracy: 0.7832 - val_loss: 0.8272 - val_accuracy: 0.6154\n",
            "Epoch 1126/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6045 - accuracy: 0.7152 - val_loss: 0.8087 - val_accuracy: 0.6282\n",
            "Epoch 1127/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5796 - accuracy: 0.7508 - val_loss: 0.7422 - val_accuracy: 0.6282\n",
            "Epoch 1128/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5708 - accuracy: 0.7735 - val_loss: 0.7850 - val_accuracy: 0.6410\n",
            "Epoch 1129/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5144 - accuracy: 0.7605 - val_loss: 0.9597 - val_accuracy: 0.6154\n",
            "Epoch 1130/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5680 - accuracy: 0.7832 - val_loss: 0.8346 - val_accuracy: 0.6154\n",
            "Epoch 1131/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5808 - accuracy: 0.7605 - val_loss: 0.8484 - val_accuracy: 0.5897\n",
            "Epoch 1132/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5124 - accuracy: 0.7896 - val_loss: 0.7517 - val_accuracy: 0.6410\n",
            "Epoch 1133/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4874 - accuracy: 0.8026 - val_loss: 0.7977 - val_accuracy: 0.6282\n",
            "Epoch 1134/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5615 - accuracy: 0.7670 - val_loss: 0.7901 - val_accuracy: 0.5769\n",
            "Epoch 1135/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5805 - accuracy: 0.7638 - val_loss: 0.7930 - val_accuracy: 0.6282\n",
            "Epoch 1136/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5782 - accuracy: 0.7670 - val_loss: 0.9745 - val_accuracy: 0.6154\n",
            "Epoch 1137/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6461 - accuracy: 0.7411 - val_loss: 0.8699 - val_accuracy: 0.6154\n",
            "Epoch 1138/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5595 - accuracy: 0.7605 - val_loss: 0.8295 - val_accuracy: 0.6154\n",
            "Epoch 1139/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5351 - accuracy: 0.7929 - val_loss: 0.9742 - val_accuracy: 0.6154\n",
            "Epoch 1140/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5534 - accuracy: 0.7735 - val_loss: 0.8287 - val_accuracy: 0.5897\n",
            "Epoch 1141/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5830 - accuracy: 0.7346 - val_loss: 0.8083 - val_accuracy: 0.5897\n",
            "Epoch 1142/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5131 - accuracy: 0.8058 - val_loss: 0.9137 - val_accuracy: 0.6026\n",
            "Epoch 1143/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6026 - accuracy: 0.7540 - val_loss: 0.9526 - val_accuracy: 0.5897\n",
            "Epoch 1144/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5563 - accuracy: 0.7540 - val_loss: 0.9297 - val_accuracy: 0.5897\n",
            "Epoch 1145/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6021 - accuracy: 0.7249 - val_loss: 0.9025 - val_accuracy: 0.5897\n",
            "Epoch 1146/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6156 - accuracy: 0.7346 - val_loss: 0.7197 - val_accuracy: 0.6795\n",
            "Epoch 1147/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5703 - accuracy: 0.7573 - val_loss: 0.8634 - val_accuracy: 0.6026\n",
            "Epoch 1148/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5871 - accuracy: 0.7379 - val_loss: 0.8230 - val_accuracy: 0.5641\n",
            "Epoch 1149/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5903 - accuracy: 0.7605 - val_loss: 0.9811 - val_accuracy: 0.5897\n",
            "Epoch 1150/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5876 - accuracy: 0.7605 - val_loss: 0.8748 - val_accuracy: 0.5897\n",
            "Epoch 1151/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5682 - accuracy: 0.7540 - val_loss: 0.8253 - val_accuracy: 0.6154\n",
            "Epoch 1152/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6460 - accuracy: 0.7217 - val_loss: 0.8536 - val_accuracy: 0.6282\n",
            "Epoch 1153/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5624 - accuracy: 0.7508 - val_loss: 0.8339 - val_accuracy: 0.6026\n",
            "Epoch 1154/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5315 - accuracy: 0.7961 - val_loss: 0.8004 - val_accuracy: 0.6026\n",
            "Epoch 1155/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5291 - accuracy: 0.7638 - val_loss: 0.7652 - val_accuracy: 0.6282\n",
            "Epoch 1156/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5394 - accuracy: 0.7929 - val_loss: 0.8454 - val_accuracy: 0.6410\n",
            "Epoch 1157/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5562 - accuracy: 0.7702 - val_loss: 0.8797 - val_accuracy: 0.6154\n",
            "Epoch 1158/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5759 - accuracy: 0.7508 - val_loss: 0.9382 - val_accuracy: 0.5897\n",
            "Epoch 1159/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5884 - accuracy: 0.7346 - val_loss: 1.0466 - val_accuracy: 0.6538\n",
            "Epoch 1160/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6202 - accuracy: 0.7411 - val_loss: 0.8371 - val_accuracy: 0.5769\n",
            "Epoch 1161/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5221 - accuracy: 0.7573 - val_loss: 0.8739 - val_accuracy: 0.5897\n",
            "Epoch 1162/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5453 - accuracy: 0.7573 - val_loss: 0.8484 - val_accuracy: 0.5513\n",
            "Epoch 1163/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5343 - accuracy: 0.7864 - val_loss: 0.8876 - val_accuracy: 0.5513\n",
            "Epoch 1164/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5356 - accuracy: 0.7799 - val_loss: 0.8613 - val_accuracy: 0.5897\n",
            "Epoch 1165/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5185 - accuracy: 0.8026 - val_loss: 0.8901 - val_accuracy: 0.6154\n",
            "Epoch 1166/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5231 - accuracy: 0.7767 - val_loss: 0.9166 - val_accuracy: 0.6026\n",
            "Epoch 1167/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5253 - accuracy: 0.7832 - val_loss: 1.0308 - val_accuracy: 0.6026\n",
            "Epoch 1168/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6230 - accuracy: 0.7508 - val_loss: 0.9486 - val_accuracy: 0.6154\n",
            "Epoch 1169/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5765 - accuracy: 0.7573 - val_loss: 0.7984 - val_accuracy: 0.5769\n",
            "Epoch 1170/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5180 - accuracy: 0.7832 - val_loss: 0.9493 - val_accuracy: 0.6154\n",
            "Epoch 1171/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5252 - accuracy: 0.7929 - val_loss: 0.7787 - val_accuracy: 0.6538\n",
            "Epoch 1172/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5391 - accuracy: 0.7702 - val_loss: 0.8014 - val_accuracy: 0.6026\n",
            "Epoch 1173/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5179 - accuracy: 0.7961 - val_loss: 1.0768 - val_accuracy: 0.5897\n",
            "Epoch 1174/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6439 - accuracy: 0.7443 - val_loss: 0.7817 - val_accuracy: 0.6154\n",
            "Epoch 1175/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5913 - accuracy: 0.7573 - val_loss: 0.7865 - val_accuracy: 0.6026\n",
            "Epoch 1176/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5677 - accuracy: 0.7702 - val_loss: 0.8375 - val_accuracy: 0.6026\n",
            "Epoch 1177/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5829 - accuracy: 0.7702 - val_loss: 0.8260 - val_accuracy: 0.6538\n",
            "Epoch 1178/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5599 - accuracy: 0.7638 - val_loss: 0.8091 - val_accuracy: 0.5769\n",
            "Epoch 1179/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4936 - accuracy: 0.7961 - val_loss: 0.8681 - val_accuracy: 0.6154\n",
            "Epoch 1180/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5620 - accuracy: 0.7832 - val_loss: 0.9067 - val_accuracy: 0.5897\n",
            "Epoch 1181/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5064 - accuracy: 0.7735 - val_loss: 0.8577 - val_accuracy: 0.5769\n",
            "Epoch 1182/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4802 - accuracy: 0.7994 - val_loss: 0.8151 - val_accuracy: 0.6282\n",
            "Epoch 1183/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5335 - accuracy: 0.7638 - val_loss: 0.8125 - val_accuracy: 0.5641\n",
            "Epoch 1184/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5748 - accuracy: 0.7573 - val_loss: 0.8916 - val_accuracy: 0.5385\n",
            "Epoch 1185/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5740 - accuracy: 0.7767 - val_loss: 0.8692 - val_accuracy: 0.5897\n",
            "Epoch 1186/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5452 - accuracy: 0.7670 - val_loss: 0.9512 - val_accuracy: 0.5769\n",
            "Epoch 1187/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5563 - accuracy: 0.7702 - val_loss: 0.8940 - val_accuracy: 0.5897\n",
            "Epoch 1188/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5252 - accuracy: 0.7896 - val_loss: 0.9478 - val_accuracy: 0.6282\n",
            "Epoch 1189/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5629 - accuracy: 0.7799 - val_loss: 0.8942 - val_accuracy: 0.5769\n",
            "Epoch 1190/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5718 - accuracy: 0.7832 - val_loss: 0.9672 - val_accuracy: 0.5897\n",
            "Epoch 1191/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5692 - accuracy: 0.7476 - val_loss: 0.9732 - val_accuracy: 0.6154\n",
            "Epoch 1192/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5426 - accuracy: 0.7605 - val_loss: 0.8444 - val_accuracy: 0.6154\n",
            "Epoch 1193/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5312 - accuracy: 0.7767 - val_loss: 0.7880 - val_accuracy: 0.6282\n",
            "Epoch 1194/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5470 - accuracy: 0.7670 - val_loss: 0.8671 - val_accuracy: 0.6026\n",
            "Epoch 1195/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5802 - accuracy: 0.7605 - val_loss: 0.8756 - val_accuracy: 0.6667\n",
            "Epoch 1196/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5283 - accuracy: 0.8188 - val_loss: 0.9007 - val_accuracy: 0.6154\n",
            "Epoch 1197/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5826 - accuracy: 0.7217 - val_loss: 0.9244 - val_accuracy: 0.6026\n",
            "Epoch 1198/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5322 - accuracy: 0.7735 - val_loss: 0.9009 - val_accuracy: 0.5769\n",
            "Epoch 1199/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5364 - accuracy: 0.7670 - val_loss: 0.8320 - val_accuracy: 0.6026\n",
            "Epoch 1200/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5112 - accuracy: 0.7767 - val_loss: 0.8891 - val_accuracy: 0.5897\n",
            "Epoch 1201/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5687 - accuracy: 0.7605 - val_loss: 0.9090 - val_accuracy: 0.6538\n",
            "Epoch 1202/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5108 - accuracy: 0.7702 - val_loss: 0.8575 - val_accuracy: 0.5769\n",
            "Epoch 1203/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5199 - accuracy: 0.7864 - val_loss: 0.8764 - val_accuracy: 0.5897\n",
            "Epoch 1204/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5368 - accuracy: 0.7702 - val_loss: 0.8305 - val_accuracy: 0.6282\n",
            "Epoch 1205/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5566 - accuracy: 0.7767 - val_loss: 0.9109 - val_accuracy: 0.6410\n",
            "Epoch 1206/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5995 - accuracy: 0.7638 - val_loss: 0.9399 - val_accuracy: 0.5897\n",
            "Epoch 1207/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5376 - accuracy: 0.7799 - val_loss: 0.8167 - val_accuracy: 0.6282\n",
            "Epoch 1208/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5420 - accuracy: 0.7670 - val_loss: 0.9726 - val_accuracy: 0.5641\n",
            "Epoch 1209/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5129 - accuracy: 0.8026 - val_loss: 0.8169 - val_accuracy: 0.5641\n",
            "Epoch 1210/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5100 - accuracy: 0.7832 - val_loss: 0.9212 - val_accuracy: 0.6026\n",
            "Epoch 1211/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5096 - accuracy: 0.8058 - val_loss: 0.8846 - val_accuracy: 0.6026\n",
            "Epoch 1212/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5381 - accuracy: 0.7540 - val_loss: 1.0423 - val_accuracy: 0.6154\n",
            "Epoch 1213/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5738 - accuracy: 0.7540 - val_loss: 1.0537 - val_accuracy: 0.6282\n",
            "Epoch 1214/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5710 - accuracy: 0.7799 - val_loss: 0.8918 - val_accuracy: 0.6026\n",
            "Epoch 1215/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5830 - accuracy: 0.7411 - val_loss: 0.8081 - val_accuracy: 0.6026\n",
            "Epoch 1216/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5220 - accuracy: 0.7799 - val_loss: 0.8337 - val_accuracy: 0.6154\n",
            "Epoch 1217/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5723 - accuracy: 0.7605 - val_loss: 0.8102 - val_accuracy: 0.5897\n",
            "Epoch 1218/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5806 - accuracy: 0.7573 - val_loss: 0.7837 - val_accuracy: 0.6154\n",
            "Epoch 1219/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5038 - accuracy: 0.7929 - val_loss: 0.9339 - val_accuracy: 0.5897\n",
            "Epoch 1220/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5275 - accuracy: 0.7832 - val_loss: 0.9614 - val_accuracy: 0.6410\n",
            "Epoch 1221/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5365 - accuracy: 0.7735 - val_loss: 0.8291 - val_accuracy: 0.6410\n",
            "Epoch 1222/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5777 - accuracy: 0.7540 - val_loss: 0.8423 - val_accuracy: 0.5897\n",
            "Epoch 1223/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5466 - accuracy: 0.7638 - val_loss: 0.8301 - val_accuracy: 0.6026\n",
            "Epoch 1224/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5424 - accuracy: 0.7411 - val_loss: 0.8749 - val_accuracy: 0.6154\n",
            "Epoch 1225/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5671 - accuracy: 0.7379 - val_loss: 0.9943 - val_accuracy: 0.6154\n",
            "Epoch 1226/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.6689 - accuracy: 0.7023 - val_loss: 0.8661 - val_accuracy: 0.5897\n",
            "Epoch 1227/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6035 - accuracy: 0.7379 - val_loss: 0.8703 - val_accuracy: 0.5897\n",
            "Epoch 1228/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5388 - accuracy: 0.7896 - val_loss: 0.8602 - val_accuracy: 0.6410\n",
            "Epoch 1229/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5102 - accuracy: 0.7832 - val_loss: 0.8877 - val_accuracy: 0.6026\n",
            "Epoch 1230/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5044 - accuracy: 0.7864 - val_loss: 0.9566 - val_accuracy: 0.6154\n",
            "Epoch 1231/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5682 - accuracy: 0.7702 - val_loss: 0.8752 - val_accuracy: 0.6154\n",
            "Epoch 1232/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5788 - accuracy: 0.7184 - val_loss: 0.8923 - val_accuracy: 0.6026\n",
            "Epoch 1233/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5220 - accuracy: 0.7929 - val_loss: 0.7534 - val_accuracy: 0.5897\n",
            "Epoch 1234/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5848 - accuracy: 0.7508 - val_loss: 0.9396 - val_accuracy: 0.6154\n",
            "Epoch 1235/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5620 - accuracy: 0.7638 - val_loss: 1.0588 - val_accuracy: 0.6026\n",
            "Epoch 1236/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5490 - accuracy: 0.7379 - val_loss: 0.9315 - val_accuracy: 0.6026\n",
            "Epoch 1237/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5437 - accuracy: 0.7864 - val_loss: 0.8030 - val_accuracy: 0.6282\n",
            "Epoch 1238/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5964 - accuracy: 0.7573 - val_loss: 0.9107 - val_accuracy: 0.5769\n",
            "Epoch 1239/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5461 - accuracy: 0.7702 - val_loss: 0.8223 - val_accuracy: 0.6154\n",
            "Epoch 1240/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5164 - accuracy: 0.7767 - val_loss: 0.7730 - val_accuracy: 0.6282\n",
            "Epoch 1241/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5653 - accuracy: 0.7767 - val_loss: 0.8723 - val_accuracy: 0.6282\n",
            "Epoch 1242/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5239 - accuracy: 0.7832 - val_loss: 0.8632 - val_accuracy: 0.6026\n",
            "Epoch 1243/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5121 - accuracy: 0.7767 - val_loss: 0.8084 - val_accuracy: 0.5897\n",
            "Epoch 1244/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5428 - accuracy: 0.7443 - val_loss: 0.7927 - val_accuracy: 0.6026\n",
            "Epoch 1245/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5305 - accuracy: 0.7896 - val_loss: 0.7686 - val_accuracy: 0.5641\n",
            "Epoch 1246/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5414 - accuracy: 0.7864 - val_loss: 0.8666 - val_accuracy: 0.6282\n",
            "Epoch 1247/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5075 - accuracy: 0.7929 - val_loss: 0.8655 - val_accuracy: 0.5897\n",
            "Epoch 1248/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5182 - accuracy: 0.7799 - val_loss: 0.7548 - val_accuracy: 0.6410\n",
            "Epoch 1249/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5146 - accuracy: 0.7799 - val_loss: 0.8336 - val_accuracy: 0.6154\n",
            "Epoch 1250/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5325 - accuracy: 0.8026 - val_loss: 0.9602 - val_accuracy: 0.6282\n",
            "Epoch 1251/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6053 - accuracy: 0.7540 - val_loss: 1.0395 - val_accuracy: 0.6026\n",
            "Epoch 1252/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6029 - accuracy: 0.7152 - val_loss: 1.0108 - val_accuracy: 0.6026\n",
            "Epoch 1253/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5109 - accuracy: 0.7799 - val_loss: 0.8710 - val_accuracy: 0.5769\n",
            "Epoch 1254/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5170 - accuracy: 0.7929 - val_loss: 0.8545 - val_accuracy: 0.6410\n",
            "Epoch 1255/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5222 - accuracy: 0.7638 - val_loss: 0.8257 - val_accuracy: 0.6282\n",
            "Epoch 1256/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5602 - accuracy: 0.7767 - val_loss: 0.8914 - val_accuracy: 0.5641\n",
            "Epoch 1257/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4463 - accuracy: 0.8091 - val_loss: 0.9202 - val_accuracy: 0.5641\n",
            "Epoch 1258/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5231 - accuracy: 0.7605 - val_loss: 0.9656 - val_accuracy: 0.6026\n",
            "Epoch 1259/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5115 - accuracy: 0.7670 - val_loss: 0.8783 - val_accuracy: 0.6154\n",
            "Epoch 1260/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4983 - accuracy: 0.7961 - val_loss: 0.9229 - val_accuracy: 0.5897\n",
            "Epoch 1261/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5037 - accuracy: 0.7864 - val_loss: 0.9355 - val_accuracy: 0.5897\n",
            "Epoch 1262/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5810 - accuracy: 0.7476 - val_loss: 0.9183 - val_accuracy: 0.6154\n",
            "Epoch 1263/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5591 - accuracy: 0.7508 - val_loss: 0.8381 - val_accuracy: 0.5897\n",
            "Epoch 1264/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5000 - accuracy: 0.8091 - val_loss: 0.8567 - val_accuracy: 0.6282\n",
            "Epoch 1265/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4932 - accuracy: 0.8155 - val_loss: 0.7884 - val_accuracy: 0.6667\n",
            "Epoch 1266/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4797 - accuracy: 0.8091 - val_loss: 0.8831 - val_accuracy: 0.6282\n",
            "Epoch 1267/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5411 - accuracy: 0.7573 - val_loss: 0.8336 - val_accuracy: 0.6026\n",
            "Epoch 1268/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4749 - accuracy: 0.8026 - val_loss: 0.8443 - val_accuracy: 0.6282\n",
            "Epoch 1269/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5604 - accuracy: 0.7670 - val_loss: 0.8065 - val_accuracy: 0.5897\n",
            "Epoch 1270/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5373 - accuracy: 0.7767 - val_loss: 0.8153 - val_accuracy: 0.5769\n",
            "Epoch 1271/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5060 - accuracy: 0.7896 - val_loss: 0.8718 - val_accuracy: 0.6154\n",
            "Epoch 1272/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6029 - accuracy: 0.7249 - val_loss: 0.9093 - val_accuracy: 0.6154\n",
            "Epoch 1273/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5800 - accuracy: 0.7638 - val_loss: 0.9452 - val_accuracy: 0.6154\n",
            "Epoch 1274/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5269 - accuracy: 0.7702 - val_loss: 1.0118 - val_accuracy: 0.5897\n",
            "Epoch 1275/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5576 - accuracy: 0.7994 - val_loss: 0.9885 - val_accuracy: 0.6154\n",
            "Epoch 1276/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4975 - accuracy: 0.7864 - val_loss: 0.9995 - val_accuracy: 0.5641\n",
            "Epoch 1277/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4948 - accuracy: 0.7540 - val_loss: 0.8996 - val_accuracy: 0.6026\n",
            "Epoch 1278/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5226 - accuracy: 0.7961 - val_loss: 0.8628 - val_accuracy: 0.6410\n",
            "Epoch 1279/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6023 - accuracy: 0.7508 - val_loss: 0.8697 - val_accuracy: 0.5897\n",
            "Epoch 1280/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5607 - accuracy: 0.7767 - val_loss: 0.8245 - val_accuracy: 0.6410\n",
            "Epoch 1281/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5849 - accuracy: 0.7670 - val_loss: 0.9168 - val_accuracy: 0.5897\n",
            "Epoch 1282/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6145 - accuracy: 0.7314 - val_loss: 0.9874 - val_accuracy: 0.6282\n",
            "Epoch 1283/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5770 - accuracy: 0.7638 - val_loss: 0.9267 - val_accuracy: 0.6538\n",
            "Epoch 1284/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6101 - accuracy: 0.7638 - val_loss: 0.7718 - val_accuracy: 0.6667\n",
            "Epoch 1285/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5506 - accuracy: 0.7670 - val_loss: 0.8562 - val_accuracy: 0.6026\n",
            "Epoch 1286/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5282 - accuracy: 0.7864 - val_loss: 0.8485 - val_accuracy: 0.6026\n",
            "Epoch 1287/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5495 - accuracy: 0.7638 - val_loss: 0.8341 - val_accuracy: 0.6154\n",
            "Epoch 1288/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5492 - accuracy: 0.7735 - val_loss: 0.8949 - val_accuracy: 0.6154\n",
            "Epoch 1289/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5433 - accuracy: 0.7767 - val_loss: 0.8988 - val_accuracy: 0.6282\n",
            "Epoch 1290/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5285 - accuracy: 0.7864 - val_loss: 0.7953 - val_accuracy: 0.6026\n",
            "Epoch 1291/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5236 - accuracy: 0.7735 - val_loss: 0.9045 - val_accuracy: 0.6282\n",
            "Epoch 1292/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5609 - accuracy: 0.7702 - val_loss: 0.7714 - val_accuracy: 0.6154\n",
            "Epoch 1293/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5296 - accuracy: 0.7929 - val_loss: 0.9420 - val_accuracy: 0.6026\n",
            "Epoch 1294/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5756 - accuracy: 0.7702 - val_loss: 0.7743 - val_accuracy: 0.6410\n",
            "Epoch 1295/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5613 - accuracy: 0.7832 - val_loss: 0.8309 - val_accuracy: 0.6282\n",
            "Epoch 1296/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5858 - accuracy: 0.7411 - val_loss: 0.8062 - val_accuracy: 0.6154\n",
            "Epoch 1297/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5404 - accuracy: 0.7638 - val_loss: 0.8889 - val_accuracy: 0.6026\n",
            "Epoch 1298/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5595 - accuracy: 0.7702 - val_loss: 0.9510 - val_accuracy: 0.6026\n",
            "Epoch 1299/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5561 - accuracy: 0.7638 - val_loss: 0.8731 - val_accuracy: 0.6154\n",
            "Epoch 1300/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5468 - accuracy: 0.7767 - val_loss: 0.9101 - val_accuracy: 0.6538\n",
            "Epoch 1301/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5675 - accuracy: 0.7605 - val_loss: 0.9052 - val_accuracy: 0.6282\n",
            "Epoch 1302/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5674 - accuracy: 0.7670 - val_loss: 0.9180 - val_accuracy: 0.5897\n",
            "Epoch 1303/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5528 - accuracy: 0.7799 - val_loss: 0.8049 - val_accuracy: 0.6538\n",
            "Epoch 1304/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5797 - accuracy: 0.7411 - val_loss: 0.9671 - val_accuracy: 0.5897\n",
            "Epoch 1305/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5174 - accuracy: 0.7832 - val_loss: 0.8161 - val_accuracy: 0.6154\n",
            "Epoch 1306/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5318 - accuracy: 0.7735 - val_loss: 0.8496 - val_accuracy: 0.5897\n",
            "Epoch 1307/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4977 - accuracy: 0.7994 - val_loss: 0.7981 - val_accuracy: 0.6282\n",
            "Epoch 1308/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4778 - accuracy: 0.7735 - val_loss: 0.8773 - val_accuracy: 0.6154\n",
            "Epoch 1309/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5586 - accuracy: 0.7670 - val_loss: 0.8483 - val_accuracy: 0.6026\n",
            "Epoch 1310/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5329 - accuracy: 0.7735 - val_loss: 0.8830 - val_accuracy: 0.5513\n",
            "Epoch 1311/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5075 - accuracy: 0.7961 - val_loss: 0.8573 - val_accuracy: 0.6026\n",
            "Epoch 1312/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5161 - accuracy: 0.7638 - val_loss: 0.8936 - val_accuracy: 0.5897\n",
            "Epoch 1313/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5191 - accuracy: 0.7961 - val_loss: 1.0028 - val_accuracy: 0.6154\n",
            "Epoch 1314/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5484 - accuracy: 0.7864 - val_loss: 1.1855 - val_accuracy: 0.5769\n",
            "Epoch 1315/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6989 - accuracy: 0.7120 - val_loss: 0.9630 - val_accuracy: 0.6154\n",
            "Epoch 1316/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.6062 - accuracy: 0.7638 - val_loss: 0.8237 - val_accuracy: 0.6282\n",
            "Epoch 1317/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5417 - accuracy: 0.7799 - val_loss: 0.8193 - val_accuracy: 0.6282\n",
            "Epoch 1318/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.4962 - accuracy: 0.7896 - val_loss: 0.8653 - val_accuracy: 0.6154\n",
            "Epoch 1319/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6246 - accuracy: 0.7476 - val_loss: 0.8694 - val_accuracy: 0.5769\n",
            "Epoch 1320/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6373 - accuracy: 0.7249 - val_loss: 0.8603 - val_accuracy: 0.6026\n",
            "Epoch 1321/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6406 - accuracy: 0.7443 - val_loss: 0.9770 - val_accuracy: 0.6026\n",
            "Epoch 1322/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5809 - accuracy: 0.7605 - val_loss: 0.9891 - val_accuracy: 0.5769\n",
            "Epoch 1323/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5837 - accuracy: 0.7346 - val_loss: 1.0125 - val_accuracy: 0.5897\n",
            "Epoch 1324/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5123 - accuracy: 0.7864 - val_loss: 0.8222 - val_accuracy: 0.6410\n",
            "Epoch 1325/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5384 - accuracy: 0.7702 - val_loss: 0.9044 - val_accuracy: 0.6282\n",
            "Epoch 1326/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5569 - accuracy: 0.7702 - val_loss: 0.8028 - val_accuracy: 0.6667\n",
            "Epoch 1327/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5688 - accuracy: 0.7767 - val_loss: 0.8373 - val_accuracy: 0.6026\n",
            "Epoch 1328/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5256 - accuracy: 0.7638 - val_loss: 0.8118 - val_accuracy: 0.6026\n",
            "Epoch 1329/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5194 - accuracy: 0.7735 - val_loss: 1.0611 - val_accuracy: 0.5769\n",
            "Epoch 1330/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5761 - accuracy: 0.7508 - val_loss: 1.0433 - val_accuracy: 0.6154\n",
            "Epoch 1331/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6059 - accuracy: 0.7346 - val_loss: 1.0404 - val_accuracy: 0.6026\n",
            "Epoch 1332/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6395 - accuracy: 0.7443 - val_loss: 0.8910 - val_accuracy: 0.6282\n",
            "Epoch 1333/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.6029 - accuracy: 0.7411 - val_loss: 0.8033 - val_accuracy: 0.6154\n",
            "Epoch 1334/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5962 - accuracy: 0.7249 - val_loss: 0.8496 - val_accuracy: 0.6154\n",
            "Epoch 1335/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5696 - accuracy: 0.7508 - val_loss: 0.8619 - val_accuracy: 0.6282\n",
            "Epoch 1336/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5461 - accuracy: 0.7670 - val_loss: 0.9969 - val_accuracy: 0.6282\n",
            "Epoch 1337/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5911 - accuracy: 0.7508 - val_loss: 0.9475 - val_accuracy: 0.5897\n",
            "Epoch 1338/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5920 - accuracy: 0.7702 - val_loss: 0.9177 - val_accuracy: 0.5897\n",
            "Epoch 1339/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5486 - accuracy: 0.7540 - val_loss: 1.1476 - val_accuracy: 0.6154\n",
            "Epoch 1340/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6169 - accuracy: 0.7702 - val_loss: 1.0748 - val_accuracy: 0.5897\n",
            "Epoch 1341/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5735 - accuracy: 0.7476 - val_loss: 1.0818 - val_accuracy: 0.6154\n",
            "Epoch 1342/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5853 - accuracy: 0.7832 - val_loss: 0.8238 - val_accuracy: 0.6538\n",
            "Epoch 1343/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5691 - accuracy: 0.7508 - val_loss: 0.8856 - val_accuracy: 0.6026\n",
            "Epoch 1344/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.6010 - accuracy: 0.7314 - val_loss: 0.8650 - val_accuracy: 0.6282\n",
            "Epoch 1345/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5699 - accuracy: 0.7638 - val_loss: 0.9188 - val_accuracy: 0.5513\n",
            "Epoch 1346/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5228 - accuracy: 0.8026 - val_loss: 0.9523 - val_accuracy: 0.5897\n",
            "Epoch 1347/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5361 - accuracy: 0.7702 - val_loss: 0.8701 - val_accuracy: 0.6154\n",
            "Epoch 1348/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5330 - accuracy: 0.7767 - val_loss: 0.8688 - val_accuracy: 0.6154\n",
            "Epoch 1349/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5491 - accuracy: 0.7508 - val_loss: 0.9450 - val_accuracy: 0.5641\n",
            "Epoch 1350/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5411 - accuracy: 0.7799 - val_loss: 0.9183 - val_accuracy: 0.6154\n",
            "Epoch 1351/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5113 - accuracy: 0.8058 - val_loss: 0.8001 - val_accuracy: 0.6795\n",
            "Epoch 1352/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5248 - accuracy: 0.7799 - val_loss: 0.8982 - val_accuracy: 0.5897\n",
            "Epoch 1353/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4957 - accuracy: 0.7961 - val_loss: 0.8622 - val_accuracy: 0.6154\n",
            "Epoch 1354/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5224 - accuracy: 0.7864 - val_loss: 0.8472 - val_accuracy: 0.6410\n",
            "Epoch 1355/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5459 - accuracy: 0.7573 - val_loss: 0.9340 - val_accuracy: 0.5897\n",
            "Epoch 1356/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5318 - accuracy: 0.7638 - val_loss: 0.8809 - val_accuracy: 0.5897\n",
            "Epoch 1357/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5633 - accuracy: 0.7508 - val_loss: 0.9073 - val_accuracy: 0.6026\n",
            "Epoch 1358/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5233 - accuracy: 0.8188 - val_loss: 0.8254 - val_accuracy: 0.5897\n",
            "Epoch 1359/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5525 - accuracy: 0.7832 - val_loss: 0.9091 - val_accuracy: 0.5897\n",
            "Epoch 1360/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5375 - accuracy: 0.7896 - val_loss: 0.8634 - val_accuracy: 0.6538\n",
            "Epoch 1361/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5926 - accuracy: 0.7638 - val_loss: 1.0145 - val_accuracy: 0.6026\n",
            "Epoch 1362/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5778 - accuracy: 0.7605 - val_loss: 1.0030 - val_accuracy: 0.5769\n",
            "Epoch 1363/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5861 - accuracy: 0.7540 - val_loss: 1.0565 - val_accuracy: 0.6538\n",
            "Epoch 1364/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5642 - accuracy: 0.7605 - val_loss: 0.8789 - val_accuracy: 0.5769\n",
            "Epoch 1365/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5915 - accuracy: 0.7638 - val_loss: 0.9467 - val_accuracy: 0.5513\n",
            "Epoch 1366/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5447 - accuracy: 0.7929 - val_loss: 0.8898 - val_accuracy: 0.6282\n",
            "Epoch 1367/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5438 - accuracy: 0.7929 - val_loss: 0.9133 - val_accuracy: 0.6026\n",
            "Epoch 1368/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5187 - accuracy: 0.7735 - val_loss: 0.8927 - val_accuracy: 0.6026\n",
            "Epoch 1369/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.5573 - accuracy: 0.7670 - val_loss: 0.8659 - val_accuracy: 0.6282\n",
            "Epoch 1370/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5841 - accuracy: 0.7605 - val_loss: 0.9400 - val_accuracy: 0.5897\n",
            "Epoch 1371/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5051 - accuracy: 0.7573 - val_loss: 1.0003 - val_accuracy: 0.6282\n",
            "Epoch 1372/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5089 - accuracy: 0.7767 - val_loss: 0.9266 - val_accuracy: 0.6154\n",
            "Epoch 1373/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4907 - accuracy: 0.7767 - val_loss: 1.0435 - val_accuracy: 0.6026\n",
            "Epoch 1374/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5121 - accuracy: 0.7767 - val_loss: 0.9790 - val_accuracy: 0.5769\n",
            "Epoch 1375/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5118 - accuracy: 0.7864 - val_loss: 0.9198 - val_accuracy: 0.6282\n",
            "Epoch 1376/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6046 - accuracy: 0.7443 - val_loss: 0.8450 - val_accuracy: 0.6026\n",
            "Epoch 1377/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4866 - accuracy: 0.7994 - val_loss: 0.9127 - val_accuracy: 0.5513\n",
            "Epoch 1378/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5437 - accuracy: 0.7476 - val_loss: 0.8160 - val_accuracy: 0.6410\n",
            "Epoch 1379/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4883 - accuracy: 0.7799 - val_loss: 0.8734 - val_accuracy: 0.5769\n",
            "Epoch 1380/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5282 - accuracy: 0.7670 - val_loss: 0.8966 - val_accuracy: 0.6154\n",
            "Epoch 1381/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5507 - accuracy: 0.7670 - val_loss: 0.9255 - val_accuracy: 0.6026\n",
            "Epoch 1382/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5565 - accuracy: 0.7540 - val_loss: 0.8282 - val_accuracy: 0.6026\n",
            "Epoch 1383/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5811 - accuracy: 0.7508 - val_loss: 0.8612 - val_accuracy: 0.6026\n",
            "Epoch 1384/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5529 - accuracy: 0.7638 - val_loss: 0.8763 - val_accuracy: 0.6026\n",
            "Epoch 1385/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5313 - accuracy: 0.7605 - val_loss: 0.8583 - val_accuracy: 0.5897\n",
            "Epoch 1386/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5442 - accuracy: 0.7638 - val_loss: 1.0168 - val_accuracy: 0.6282\n",
            "Epoch 1387/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5130 - accuracy: 0.7896 - val_loss: 0.8315 - val_accuracy: 0.5769\n",
            "Epoch 1388/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4687 - accuracy: 0.8026 - val_loss: 0.9723 - val_accuracy: 0.5769\n",
            "Epoch 1389/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5610 - accuracy: 0.7799 - val_loss: 0.8861 - val_accuracy: 0.6154\n",
            "Epoch 1390/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5131 - accuracy: 0.7832 - val_loss: 0.8548 - val_accuracy: 0.5897\n",
            "Epoch 1391/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4952 - accuracy: 0.8058 - val_loss: 0.8433 - val_accuracy: 0.5769\n",
            "Epoch 1392/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5240 - accuracy: 0.7929 - val_loss: 0.9929 - val_accuracy: 0.6410\n",
            "Epoch 1393/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5294 - accuracy: 0.7670 - val_loss: 1.2087 - val_accuracy: 0.6026\n",
            "Epoch 1394/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5451 - accuracy: 0.7864 - val_loss: 1.0501 - val_accuracy: 0.6026\n",
            "Epoch 1395/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5813 - accuracy: 0.7767 - val_loss: 1.0045 - val_accuracy: 0.5897\n",
            "Epoch 1396/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5422 - accuracy: 0.7896 - val_loss: 0.8563 - val_accuracy: 0.5897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hdE6EQfZ6tU"
      },
      "source": [
        "### Evaluation and Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gLH2mdEZ74z",
        "outputId": "de95efac-5fc7-484d-868d-47cffbff7ff1"
      },
      "source": [
        "# Evaluate our model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Model loss on the test set: {loss}\")\n",
        "print(f\"Model accuracy on the test set: {100*accuracy:.2f}%\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 5ms/step - loss: 0.7197 - accuracy: 0.6795\n",
            "Model loss on the test set: 0.719667375087738\n",
            "Model accuracy on the test set: 67.95%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Zr5zUN7waFYr",
        "outputId": "38d7f074-6299-47be-fcd9-784b85c7a127"
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history_1.history['loss'])#[5:])\n",
        "plt.plot(history_1.history['val_loss'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Ol8la_eiaHBH",
        "outputId": "ee6e2ec8-e0dd-4d21-9c30-1fb1c2f89cc1"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history_1.history['accuracy'])#[5:])\n",
        "plt.plot(history_1.history['val_accuracy'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Binary Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpjBSazcc9L9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvLBB1x4c9g2"
      },
      "source": [
        "## Model 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTEe3fbAc9g3"
      },
      "source": [
        "### Declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd08u9vRc9g3"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model_2 = keras.Sequential([\n",
        "    layers.Dense(512, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(256, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(128, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(8, activation='softmax')\n",
        "])\n",
        "\n",
        "model_2.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate = .0003),\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    patience=250,\n",
        "    min_delta=0.0001,\n",
        "    restore_best_weights=True,\n",
        ")"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUgoNB_Ic9g3"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHPgDrOyc9g4",
        "outputId": "fc659d1f-5157-4cea-bf9c-8a0cca3b73cd"
      },
      "source": [
        "history_2 = model_2.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=2000,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1, \n",
        ")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "10/10 [==============================] - 1s 40ms/step - loss: 2.3370 - accuracy: 0.1197 - val_loss: 2.0476 - val_accuracy: 0.1923\n",
            "Epoch 2/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.1680 - accuracy: 0.1521 - val_loss: 2.0481 - val_accuracy: 0.2308\n",
            "Epoch 3/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.0783 - accuracy: 0.1748 - val_loss: 2.0494 - val_accuracy: 0.2179\n",
            "Epoch 4/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.0566 - accuracy: 0.1877 - val_loss: 2.0518 - val_accuracy: 0.2179\n",
            "Epoch 5/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.0354 - accuracy: 0.1974 - val_loss: 2.0357 - val_accuracy: 0.2179\n",
            "Epoch 6/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 2.0093 - accuracy: 0.2136 - val_loss: 2.0471 - val_accuracy: 0.2179\n",
            "Epoch 7/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 2.0490 - accuracy: 0.1942 - val_loss: 2.0366 - val_accuracy: 0.2051\n",
            "Epoch 8/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.0294 - accuracy: 0.2071 - val_loss: 2.0210 - val_accuracy: 0.2179\n",
            "Epoch 9/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.0306 - accuracy: 0.1618 - val_loss: 2.0315 - val_accuracy: 0.2179\n",
            "Epoch 10/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 2.0132 - accuracy: 0.1715 - val_loss: 2.0334 - val_accuracy: 0.1667\n",
            "Epoch 11/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.9519 - accuracy: 0.2168 - val_loss: 2.0289 - val_accuracy: 0.1410\n",
            "Epoch 12/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.0298 - accuracy: 0.2298 - val_loss: 2.0057 - val_accuracy: 0.0897\n",
            "Epoch 13/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.9677 - accuracy: 0.2136 - val_loss: 1.9988 - val_accuracy: 0.1282\n",
            "Epoch 14/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.9634 - accuracy: 0.2039 - val_loss: 1.9680 - val_accuracy: 0.2051\n",
            "Epoch 15/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.9597 - accuracy: 0.1942 - val_loss: 1.9811 - val_accuracy: 0.1538\n",
            "Epoch 16/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.9563 - accuracy: 0.1942 - val_loss: 1.9999 - val_accuracy: 0.1026\n",
            "Epoch 17/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.9493 - accuracy: 0.1715 - val_loss: 1.9905 - val_accuracy: 0.1410\n",
            "Epoch 18/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.9941 - accuracy: 0.1877 - val_loss: 1.9841 - val_accuracy: 0.1154\n",
            "Epoch 19/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.9127 - accuracy: 0.2104 - val_loss: 1.9805 - val_accuracy: 0.1026\n",
            "Epoch 20/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.9606 - accuracy: 0.1845 - val_loss: 1.9634 - val_accuracy: 0.1026\n",
            "Epoch 21/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8969 - accuracy: 0.2006 - val_loss: 1.9297 - val_accuracy: 0.1538\n",
            "Epoch 22/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8828 - accuracy: 0.2298 - val_loss: 1.9449 - val_accuracy: 0.1282\n",
            "Epoch 23/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8956 - accuracy: 0.2006 - val_loss: 1.9270 - val_accuracy: 0.1538\n",
            "Epoch 24/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8748 - accuracy: 0.2265 - val_loss: 1.9051 - val_accuracy: 0.1667\n",
            "Epoch 25/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8933 - accuracy: 0.2168 - val_loss: 1.9244 - val_accuracy: 0.1026\n",
            "Epoch 26/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8906 - accuracy: 0.2168 - val_loss: 1.9158 - val_accuracy: 0.1410\n",
            "Epoch 27/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8666 - accuracy: 0.2201 - val_loss: 1.9138 - val_accuracy: 0.1538\n",
            "Epoch 28/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.9205 - accuracy: 0.1748 - val_loss: 1.9072 - val_accuracy: 0.2436\n",
            "Epoch 29/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.9226 - accuracy: 0.2201 - val_loss: 1.9167 - val_accuracy: 0.2308\n",
            "Epoch 30/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8680 - accuracy: 0.2136 - val_loss: 1.9103 - val_accuracy: 0.2179\n",
            "Epoch 31/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8774 - accuracy: 0.2201 - val_loss: 1.9210 - val_accuracy: 0.1538\n",
            "Epoch 32/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8649 - accuracy: 0.2136 - val_loss: 1.9093 - val_accuracy: 0.1282\n",
            "Epoch 33/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8438 - accuracy: 0.2265 - val_loss: 1.9031 - val_accuracy: 0.1538\n",
            "Epoch 34/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8799 - accuracy: 0.2395 - val_loss: 1.8929 - val_accuracy: 0.1667\n",
            "Epoch 35/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8700 - accuracy: 0.1845 - val_loss: 1.8907 - val_accuracy: 0.1410\n",
            "Epoch 36/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8592 - accuracy: 0.2168 - val_loss: 1.8935 - val_accuracy: 0.1538\n",
            "Epoch 37/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8707 - accuracy: 0.2298 - val_loss: 1.8887 - val_accuracy: 0.1667\n",
            "Epoch 38/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8500 - accuracy: 0.2233 - val_loss: 1.8715 - val_accuracy: 0.1667\n",
            "Epoch 39/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8324 - accuracy: 0.2265 - val_loss: 1.8643 - val_accuracy: 0.1538\n",
            "Epoch 40/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8303 - accuracy: 0.2460 - val_loss: 1.8680 - val_accuracy: 0.1282\n",
            "Epoch 41/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8665 - accuracy: 0.2427 - val_loss: 1.8712 - val_accuracy: 0.1410\n",
            "Epoch 42/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8463 - accuracy: 0.2039 - val_loss: 1.8756 - val_accuracy: 0.1282\n",
            "Epoch 43/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8120 - accuracy: 0.2395 - val_loss: 1.8550 - val_accuracy: 0.1667\n",
            "Epoch 44/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8423 - accuracy: 0.2071 - val_loss: 1.8528 - val_accuracy: 0.1795\n",
            "Epoch 45/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.8583 - accuracy: 0.2006 - val_loss: 1.8615 - val_accuracy: 0.1282\n",
            "Epoch 46/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8398 - accuracy: 0.2104 - val_loss: 1.8739 - val_accuracy: 0.1410\n",
            "Epoch 47/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8332 - accuracy: 0.2298 - val_loss: 1.8700 - val_accuracy: 0.1538\n",
            "Epoch 48/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8207 - accuracy: 0.2298 - val_loss: 1.8542 - val_accuracy: 0.1538\n",
            "Epoch 49/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8166 - accuracy: 0.2298 - val_loss: 1.8283 - val_accuracy: 0.1795\n",
            "Epoch 50/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8146 - accuracy: 0.2718 - val_loss: 1.8304 - val_accuracy: 0.1795\n",
            "Epoch 51/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8167 - accuracy: 0.2104 - val_loss: 1.8391 - val_accuracy: 0.1923\n",
            "Epoch 52/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8287 - accuracy: 0.2071 - val_loss: 1.8451 - val_accuracy: 0.1795\n",
            "Epoch 53/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8116 - accuracy: 0.2460 - val_loss: 1.8578 - val_accuracy: 0.1538\n",
            "Epoch 54/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7941 - accuracy: 0.2298 - val_loss: 1.8376 - val_accuracy: 0.1795\n",
            "Epoch 55/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8180 - accuracy: 0.2201 - val_loss: 1.8336 - val_accuracy: 0.1923\n",
            "Epoch 56/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8088 - accuracy: 0.2298 - val_loss: 1.8427 - val_accuracy: 0.1795\n",
            "Epoch 57/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8114 - accuracy: 0.1974 - val_loss: 1.8475 - val_accuracy: 0.1410\n",
            "Epoch 58/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8218 - accuracy: 0.1845 - val_loss: 1.8416 - val_accuracy: 0.1795\n",
            "Epoch 59/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8322 - accuracy: 0.2362 - val_loss: 1.8415 - val_accuracy: 0.1282\n",
            "Epoch 60/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8207 - accuracy: 0.2427 - val_loss: 1.8389 - val_accuracy: 0.1538\n",
            "Epoch 61/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8372 - accuracy: 0.2265 - val_loss: 1.8517 - val_accuracy: 0.1538\n",
            "Epoch 62/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8118 - accuracy: 0.2168 - val_loss: 1.8526 - val_accuracy: 0.1538\n",
            "Epoch 63/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8091 - accuracy: 0.2298 - val_loss: 1.8424 - val_accuracy: 0.1538\n",
            "Epoch 64/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7983 - accuracy: 0.2265 - val_loss: 1.8383 - val_accuracy: 0.1410\n",
            "Epoch 65/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7999 - accuracy: 0.2233 - val_loss: 1.8365 - val_accuracy: 0.1410\n",
            "Epoch 66/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8376 - accuracy: 0.2006 - val_loss: 1.8380 - val_accuracy: 0.1667\n",
            "Epoch 67/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.8140 - accuracy: 0.2168 - val_loss: 1.8438 - val_accuracy: 0.1410\n",
            "Epoch 68/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8207 - accuracy: 0.2071 - val_loss: 1.8326 - val_accuracy: 0.1410\n",
            "Epoch 69/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8015 - accuracy: 0.2265 - val_loss: 1.8360 - val_accuracy: 0.1282\n",
            "Epoch 70/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7945 - accuracy: 0.2460 - val_loss: 1.8372 - val_accuracy: 0.1154\n",
            "Epoch 71/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8369 - accuracy: 0.2395 - val_loss: 1.8280 - val_accuracy: 0.1282\n",
            "Epoch 72/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.7985 - accuracy: 0.2330 - val_loss: 1.8232 - val_accuracy: 0.1667\n",
            "Epoch 73/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8011 - accuracy: 0.2168 - val_loss: 1.8319 - val_accuracy: 0.1667\n",
            "Epoch 74/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.7781 - accuracy: 0.2168 - val_loss: 1.8321 - val_accuracy: 0.1282\n",
            "Epoch 75/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7857 - accuracy: 0.2330 - val_loss: 1.8293 - val_accuracy: 0.1538\n",
            "Epoch 76/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7640 - accuracy: 0.2654 - val_loss: 1.8312 - val_accuracy: 0.1795\n",
            "Epoch 77/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.7889 - accuracy: 0.2718 - val_loss: 1.8377 - val_accuracy: 0.1410\n",
            "Epoch 78/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8264 - accuracy: 0.2168 - val_loss: 1.8301 - val_accuracy: 0.1410\n",
            "Epoch 79/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7783 - accuracy: 0.2330 - val_loss: 1.8156 - val_accuracy: 0.1410\n",
            "Epoch 80/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7880 - accuracy: 0.2168 - val_loss: 1.8125 - val_accuracy: 0.1538\n",
            "Epoch 81/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7949 - accuracy: 0.2492 - val_loss: 1.8157 - val_accuracy: 0.1538\n",
            "Epoch 82/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.7827 - accuracy: 0.2718 - val_loss: 1.8181 - val_accuracy: 0.1538\n",
            "Epoch 83/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7801 - accuracy: 0.2427 - val_loss: 1.8154 - val_accuracy: 0.1538\n",
            "Epoch 84/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7835 - accuracy: 0.2589 - val_loss: 1.8087 - val_accuracy: 0.1538\n",
            "Epoch 85/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7828 - accuracy: 0.2492 - val_loss: 1.8077 - val_accuracy: 0.1410\n",
            "Epoch 86/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7772 - accuracy: 0.2460 - val_loss: 1.8090 - val_accuracy: 0.1667\n",
            "Epoch 87/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7535 - accuracy: 0.2492 - val_loss: 1.8031 - val_accuracy: 0.1667\n",
            "Epoch 88/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7541 - accuracy: 0.2265 - val_loss: 1.8083 - val_accuracy: 0.1538\n",
            "Epoch 89/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7758 - accuracy: 0.2686 - val_loss: 1.8184 - val_accuracy: 0.1410\n",
            "Epoch 90/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7759 - accuracy: 0.2621 - val_loss: 1.7812 - val_accuracy: 0.1667\n",
            "Epoch 91/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7724 - accuracy: 0.2395 - val_loss: 1.7989 - val_accuracy: 0.1667\n",
            "Epoch 92/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7754 - accuracy: 0.2557 - val_loss: 1.7977 - val_accuracy: 0.1538\n",
            "Epoch 93/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7790 - accuracy: 0.2460 - val_loss: 1.7981 - val_accuracy: 0.1538\n",
            "Epoch 94/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7581 - accuracy: 0.2330 - val_loss: 1.7854 - val_accuracy: 0.1667\n",
            "Epoch 95/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7896 - accuracy: 0.2524 - val_loss: 1.7967 - val_accuracy: 0.1538\n",
            "Epoch 96/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7939 - accuracy: 0.2362 - val_loss: 1.8069 - val_accuracy: 0.1538\n",
            "Epoch 97/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7590 - accuracy: 0.2654 - val_loss: 1.7782 - val_accuracy: 0.1667\n",
            "Epoch 98/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7483 - accuracy: 0.2751 - val_loss: 1.7648 - val_accuracy: 0.1923\n",
            "Epoch 99/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.7796 - accuracy: 0.2492 - val_loss: 1.7601 - val_accuracy: 0.2436\n",
            "Epoch 100/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7538 - accuracy: 0.2557 - val_loss: 1.7380 - val_accuracy: 0.2821\n",
            "Epoch 101/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7569 - accuracy: 0.2557 - val_loss: 1.7582 - val_accuracy: 0.1667\n",
            "Epoch 102/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7362 - accuracy: 0.2880 - val_loss: 1.7545 - val_accuracy: 0.2821\n",
            "Epoch 103/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7666 - accuracy: 0.2589 - val_loss: 1.7670 - val_accuracy: 0.2564\n",
            "Epoch 104/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7616 - accuracy: 0.2816 - val_loss: 1.7822 - val_accuracy: 0.1795\n",
            "Epoch 105/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7796 - accuracy: 0.2557 - val_loss: 1.7545 - val_accuracy: 0.2308\n",
            "Epoch 106/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7228 - accuracy: 0.2913 - val_loss: 1.7606 - val_accuracy: 0.1923\n",
            "Epoch 107/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7445 - accuracy: 0.2589 - val_loss: 1.7643 - val_accuracy: 0.1410\n",
            "Epoch 108/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7266 - accuracy: 0.3301 - val_loss: 1.7406 - val_accuracy: 0.1923\n",
            "Epoch 109/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7335 - accuracy: 0.3301 - val_loss: 1.7224 - val_accuracy: 0.2179\n",
            "Epoch 110/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7161 - accuracy: 0.2751 - val_loss: 1.7063 - val_accuracy: 0.2821\n",
            "Epoch 111/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7065 - accuracy: 0.2945 - val_loss: 1.7000 - val_accuracy: 0.2692\n",
            "Epoch 112/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7156 - accuracy: 0.3172 - val_loss: 1.6986 - val_accuracy: 0.2179\n",
            "Epoch 113/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7577 - accuracy: 0.2848 - val_loss: 1.6848 - val_accuracy: 0.2949\n",
            "Epoch 114/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7049 - accuracy: 0.3042 - val_loss: 1.6621 - val_accuracy: 0.3205\n",
            "Epoch 115/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7076 - accuracy: 0.3074 - val_loss: 1.7154 - val_accuracy: 0.2436\n",
            "Epoch 116/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.7017 - accuracy: 0.3269 - val_loss: 1.6580 - val_accuracy: 0.3205\n",
            "Epoch 117/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.6712 - accuracy: 0.3301 - val_loss: 1.7175 - val_accuracy: 0.2308\n",
            "Epoch 118/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.6832 - accuracy: 0.3010 - val_loss: 1.6368 - val_accuracy: 0.2949\n",
            "Epoch 119/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.6379 - accuracy: 0.3333 - val_loss: 1.6348 - val_accuracy: 0.3077\n",
            "Epoch 120/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.6569 - accuracy: 0.3398 - val_loss: 1.6340 - val_accuracy: 0.3077\n",
            "Epoch 121/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.6054 - accuracy: 0.3366 - val_loss: 1.6162 - val_accuracy: 0.3077\n",
            "Epoch 122/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.6415 - accuracy: 0.3269 - val_loss: 1.6614 - val_accuracy: 0.3333\n",
            "Epoch 123/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5978 - accuracy: 0.3592 - val_loss: 1.5114 - val_accuracy: 0.3205\n",
            "Epoch 124/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6324 - accuracy: 0.3236 - val_loss: 1.4859 - val_accuracy: 0.3333\n",
            "Epoch 125/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.5781 - accuracy: 0.3657 - val_loss: 1.5389 - val_accuracy: 0.3077\n",
            "Epoch 126/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5833 - accuracy: 0.3366 - val_loss: 1.4828 - val_accuracy: 0.3205\n",
            "Epoch 127/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.6167 - accuracy: 0.3689 - val_loss: 1.4845 - val_accuracy: 0.3590\n",
            "Epoch 128/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5634 - accuracy: 0.3819 - val_loss: 1.4822 - val_accuracy: 0.3205\n",
            "Epoch 129/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.6097 - accuracy: 0.3722 - val_loss: 1.4871 - val_accuracy: 0.3333\n",
            "Epoch 130/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.5143 - accuracy: 0.3819 - val_loss: 1.4837 - val_accuracy: 0.3205\n",
            "Epoch 131/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.5350 - accuracy: 0.3625 - val_loss: 1.4468 - val_accuracy: 0.3590\n",
            "Epoch 132/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5049 - accuracy: 0.3981 - val_loss: 1.4545 - val_accuracy: 0.3333\n",
            "Epoch 133/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4767 - accuracy: 0.3981 - val_loss: 1.4462 - val_accuracy: 0.3333\n",
            "Epoch 134/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.4941 - accuracy: 0.3657 - val_loss: 1.4118 - val_accuracy: 0.3462\n",
            "Epoch 135/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5277 - accuracy: 0.3657 - val_loss: 1.4440 - val_accuracy: 0.3590\n",
            "Epoch 136/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4565 - accuracy: 0.3948 - val_loss: 1.4291 - val_accuracy: 0.3205\n",
            "Epoch 137/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.4505 - accuracy: 0.4045 - val_loss: 1.4011 - val_accuracy: 0.3333\n",
            "Epoch 138/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4284 - accuracy: 0.4239 - val_loss: 1.4173 - val_accuracy: 0.3205\n",
            "Epoch 139/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4443 - accuracy: 0.3883 - val_loss: 1.4344 - val_accuracy: 0.3333\n",
            "Epoch 140/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4924 - accuracy: 0.3560 - val_loss: 1.3979 - val_accuracy: 0.3462\n",
            "Epoch 141/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.4623 - accuracy: 0.3851 - val_loss: 1.3945 - val_accuracy: 0.3462\n",
            "Epoch 142/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4550 - accuracy: 0.4078 - val_loss: 1.4803 - val_accuracy: 0.2949\n",
            "Epoch 143/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.5422 - accuracy: 0.3301 - val_loss: 1.4113 - val_accuracy: 0.3590\n",
            "Epoch 144/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4708 - accuracy: 0.3851 - val_loss: 1.4357 - val_accuracy: 0.3205\n",
            "Epoch 145/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4098 - accuracy: 0.4110 - val_loss: 1.4157 - val_accuracy: 0.3333\n",
            "Epoch 146/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4094 - accuracy: 0.4207 - val_loss: 1.3901 - val_accuracy: 0.3333\n",
            "Epoch 147/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.4138 - accuracy: 0.4013 - val_loss: 1.3894 - val_accuracy: 0.3718\n",
            "Epoch 148/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4240 - accuracy: 0.4013 - val_loss: 1.3781 - val_accuracy: 0.3462\n",
            "Epoch 149/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.4424 - accuracy: 0.4175 - val_loss: 1.4324 - val_accuracy: 0.3590\n",
            "Epoch 150/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4552 - accuracy: 0.3786 - val_loss: 1.4212 - val_accuracy: 0.3333\n",
            "Epoch 151/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.5278 - accuracy: 0.3722 - val_loss: 1.6025 - val_accuracy: 0.3077\n",
            "Epoch 152/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4625 - accuracy: 0.3786 - val_loss: 1.3966 - val_accuracy: 0.3462\n",
            "Epoch 153/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4351 - accuracy: 0.3819 - val_loss: 1.4338 - val_accuracy: 0.3205\n",
            "Epoch 154/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.4505 - accuracy: 0.3592 - val_loss: 1.3841 - val_accuracy: 0.3333\n",
            "Epoch 155/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3680 - accuracy: 0.4142 - val_loss: 1.3340 - val_accuracy: 0.3462\n",
            "Epoch 156/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.4000 - accuracy: 0.4142 - val_loss: 1.3420 - val_accuracy: 0.3462\n",
            "Epoch 157/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3413 - accuracy: 0.4142 - val_loss: 1.3749 - val_accuracy: 0.3333\n",
            "Epoch 158/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4115 - accuracy: 0.4272 - val_loss: 1.3384 - val_accuracy: 0.3462\n",
            "Epoch 159/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3663 - accuracy: 0.4175 - val_loss: 1.3640 - val_accuracy: 0.3205\n",
            "Epoch 160/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3412 - accuracy: 0.4175 - val_loss: 1.3464 - val_accuracy: 0.3462\n",
            "Epoch 161/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3494 - accuracy: 0.4466 - val_loss: 1.3719 - val_accuracy: 0.3333\n",
            "Epoch 162/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3389 - accuracy: 0.4401 - val_loss: 1.3454 - val_accuracy: 0.3205\n",
            "Epoch 163/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.3742 - accuracy: 0.4401 - val_loss: 1.3972 - val_accuracy: 0.3077\n",
            "Epoch 164/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.3678 - accuracy: 0.4142 - val_loss: 1.3518 - val_accuracy: 0.3333\n",
            "Epoch 165/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3870 - accuracy: 0.4078 - val_loss: 1.3606 - val_accuracy: 0.3462\n",
            "Epoch 166/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3382 - accuracy: 0.4498 - val_loss: 1.3600 - val_accuracy: 0.3333\n",
            "Epoch 167/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3450 - accuracy: 0.4304 - val_loss: 1.3283 - val_accuracy: 0.3333\n",
            "Epoch 168/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3308 - accuracy: 0.4304 - val_loss: 1.3523 - val_accuracy: 0.3718\n",
            "Epoch 169/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3566 - accuracy: 0.4466 - val_loss: 1.3655 - val_accuracy: 0.3333\n",
            "Epoch 170/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3461 - accuracy: 0.4369 - val_loss: 1.3295 - val_accuracy: 0.3333\n",
            "Epoch 171/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.3654 - accuracy: 0.4078 - val_loss: 1.3441 - val_accuracy: 0.3205\n",
            "Epoch 172/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3895 - accuracy: 0.4207 - val_loss: 1.3320 - val_accuracy: 0.3333\n",
            "Epoch 173/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3753 - accuracy: 0.4239 - val_loss: 1.3343 - val_accuracy: 0.3205\n",
            "Epoch 174/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3585 - accuracy: 0.4207 - val_loss: 1.3297 - val_accuracy: 0.3462\n",
            "Epoch 175/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3884 - accuracy: 0.4304 - val_loss: 1.5212 - val_accuracy: 0.3718\n",
            "Epoch 176/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4583 - accuracy: 0.4013 - val_loss: 1.3781 - val_accuracy: 0.3333\n",
            "Epoch 177/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.3718 - accuracy: 0.4304 - val_loss: 1.3358 - val_accuracy: 0.3590\n",
            "Epoch 178/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3833 - accuracy: 0.4563 - val_loss: 1.3032 - val_accuracy: 0.3718\n",
            "Epoch 179/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3817 - accuracy: 0.3819 - val_loss: 1.3492 - val_accuracy: 0.3590\n",
            "Epoch 180/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3904 - accuracy: 0.4239 - val_loss: 1.3491 - val_accuracy: 0.3718\n",
            "Epoch 181/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3641 - accuracy: 0.4272 - val_loss: 1.3773 - val_accuracy: 0.3333\n",
            "Epoch 182/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3340 - accuracy: 0.4369 - val_loss: 1.3198 - val_accuracy: 0.3333\n",
            "Epoch 183/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3397 - accuracy: 0.4207 - val_loss: 1.3911 - val_accuracy: 0.3846\n",
            "Epoch 184/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3876 - accuracy: 0.4013 - val_loss: 1.3724 - val_accuracy: 0.3462\n",
            "Epoch 185/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3648 - accuracy: 0.4304 - val_loss: 1.3042 - val_accuracy: 0.3462\n",
            "Epoch 186/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.3288 - accuracy: 0.4272 - val_loss: 1.3166 - val_accuracy: 0.3590\n",
            "Epoch 187/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3323 - accuracy: 0.4369 - val_loss: 1.3204 - val_accuracy: 0.3333\n",
            "Epoch 188/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3266 - accuracy: 0.4563 - val_loss: 1.4025 - val_accuracy: 0.3333\n",
            "Epoch 189/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3341 - accuracy: 0.4369 - val_loss: 1.3362 - val_accuracy: 0.3462\n",
            "Epoch 190/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.3213 - accuracy: 0.4628 - val_loss: 1.3421 - val_accuracy: 0.3333\n",
            "Epoch 191/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2993 - accuracy: 0.4272 - val_loss: 1.3306 - val_accuracy: 0.3974\n",
            "Epoch 192/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3027 - accuracy: 0.4498 - val_loss: 1.3456 - val_accuracy: 0.3846\n",
            "Epoch 193/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3978 - accuracy: 0.4175 - val_loss: 1.3601 - val_accuracy: 0.3462\n",
            "Epoch 194/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3036 - accuracy: 0.4628 - val_loss: 1.3138 - val_accuracy: 0.3718\n",
            "Epoch 195/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3430 - accuracy: 0.4207 - val_loss: 1.3834 - val_accuracy: 0.3590\n",
            "Epoch 196/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3483 - accuracy: 0.4304 - val_loss: 1.3129 - val_accuracy: 0.3846\n",
            "Epoch 197/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4173 - accuracy: 0.4045 - val_loss: 1.3346 - val_accuracy: 0.3205\n",
            "Epoch 198/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3846 - accuracy: 0.3754 - val_loss: 1.4057 - val_accuracy: 0.2949\n",
            "Epoch 199/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3286 - accuracy: 0.4272 - val_loss: 1.3435 - val_accuracy: 0.3333\n",
            "Epoch 200/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3310 - accuracy: 0.4337 - val_loss: 1.3875 - val_accuracy: 0.3333\n",
            "Epoch 201/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.3851 - accuracy: 0.4304 - val_loss: 1.3064 - val_accuracy: 0.3462\n",
            "Epoch 202/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3115 - accuracy: 0.4531 - val_loss: 1.3500 - val_accuracy: 0.3718\n",
            "Epoch 203/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3331 - accuracy: 0.4401 - val_loss: 1.2944 - val_accuracy: 0.3974\n",
            "Epoch 204/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3328 - accuracy: 0.4239 - val_loss: 1.2918 - val_accuracy: 0.3718\n",
            "Epoch 205/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3308 - accuracy: 0.4304 - val_loss: 1.3222 - val_accuracy: 0.3333\n",
            "Epoch 206/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3407 - accuracy: 0.4563 - val_loss: 1.3216 - val_accuracy: 0.3462\n",
            "Epoch 207/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3384 - accuracy: 0.4434 - val_loss: 1.3279 - val_accuracy: 0.3462\n",
            "Epoch 208/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3378 - accuracy: 0.3916 - val_loss: 1.3314 - val_accuracy: 0.3462\n",
            "Epoch 209/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3468 - accuracy: 0.4531 - val_loss: 1.3326 - val_accuracy: 0.3590\n",
            "Epoch 210/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3032 - accuracy: 0.4207 - val_loss: 1.3488 - val_accuracy: 0.3462\n",
            "Epoch 211/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3496 - accuracy: 0.4078 - val_loss: 1.3250 - val_accuracy: 0.3590\n",
            "Epoch 212/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3050 - accuracy: 0.4304 - val_loss: 1.3249 - val_accuracy: 0.3590\n",
            "Epoch 213/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2954 - accuracy: 0.4725 - val_loss: 1.3074 - val_accuracy: 0.3718\n",
            "Epoch 214/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3223 - accuracy: 0.4239 - val_loss: 1.3639 - val_accuracy: 0.3077\n",
            "Epoch 215/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3128 - accuracy: 0.4304 - val_loss: 1.3664 - val_accuracy: 0.3462\n",
            "Epoch 216/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3028 - accuracy: 0.4693 - val_loss: 1.3446 - val_accuracy: 0.3205\n",
            "Epoch 217/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3190 - accuracy: 0.4175 - val_loss: 1.3176 - val_accuracy: 0.3462\n",
            "Epoch 218/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3143 - accuracy: 0.4207 - val_loss: 1.3549 - val_accuracy: 0.3462\n",
            "Epoch 219/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3186 - accuracy: 0.4434 - val_loss: 1.3134 - val_accuracy: 0.3590\n",
            "Epoch 220/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2981 - accuracy: 0.4304 - val_loss: 1.3671 - val_accuracy: 0.3205\n",
            "Epoch 221/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2899 - accuracy: 0.4531 - val_loss: 1.3174 - val_accuracy: 0.3590\n",
            "Epoch 222/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2803 - accuracy: 0.4660 - val_loss: 1.3220 - val_accuracy: 0.3590\n",
            "Epoch 223/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2953 - accuracy: 0.4725 - val_loss: 1.3273 - val_accuracy: 0.3462\n",
            "Epoch 224/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2772 - accuracy: 0.4595 - val_loss: 1.3520 - val_accuracy: 0.3205\n",
            "Epoch 225/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3051 - accuracy: 0.4272 - val_loss: 1.3591 - val_accuracy: 0.3333\n",
            "Epoch 226/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3124 - accuracy: 0.4434 - val_loss: 1.3195 - val_accuracy: 0.4103\n",
            "Epoch 227/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.3097 - accuracy: 0.4272 - val_loss: 1.3144 - val_accuracy: 0.3718\n",
            "Epoch 228/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2681 - accuracy: 0.4693 - val_loss: 1.2969 - val_accuracy: 0.3590\n",
            "Epoch 229/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2737 - accuracy: 0.4822 - val_loss: 1.3291 - val_accuracy: 0.3590\n",
            "Epoch 230/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2857 - accuracy: 0.4693 - val_loss: 1.3069 - val_accuracy: 0.3590\n",
            "Epoch 231/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2671 - accuracy: 0.4725 - val_loss: 1.3013 - val_accuracy: 0.3974\n",
            "Epoch 232/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2741 - accuracy: 0.4595 - val_loss: 1.3133 - val_accuracy: 0.3462\n",
            "Epoch 233/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2929 - accuracy: 0.4498 - val_loss: 1.2974 - val_accuracy: 0.3846\n",
            "Epoch 234/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2853 - accuracy: 0.4725 - val_loss: 1.3308 - val_accuracy: 0.3846\n",
            "Epoch 235/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3095 - accuracy: 0.4401 - val_loss: 1.3132 - val_accuracy: 0.3462\n",
            "Epoch 236/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2747 - accuracy: 0.4595 - val_loss: 1.2721 - val_accuracy: 0.3974\n",
            "Epoch 237/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2696 - accuracy: 0.4434 - val_loss: 1.3119 - val_accuracy: 0.3462\n",
            "Epoch 238/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2814 - accuracy: 0.4531 - val_loss: 1.3442 - val_accuracy: 0.3462\n",
            "Epoch 239/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2939 - accuracy: 0.4110 - val_loss: 1.3348 - val_accuracy: 0.3718\n",
            "Epoch 240/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3055 - accuracy: 0.4531 - val_loss: 1.2953 - val_accuracy: 0.3974\n",
            "Epoch 241/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2873 - accuracy: 0.4628 - val_loss: 1.2588 - val_accuracy: 0.3974\n",
            "Epoch 242/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2885 - accuracy: 0.4628 - val_loss: 1.4025 - val_accuracy: 0.3846\n",
            "Epoch 243/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3097 - accuracy: 0.4563 - val_loss: 1.3100 - val_accuracy: 0.3846\n",
            "Epoch 244/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2922 - accuracy: 0.4531 - val_loss: 1.3508 - val_accuracy: 0.3846\n",
            "Epoch 245/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3141 - accuracy: 0.4466 - val_loss: 1.3130 - val_accuracy: 0.3718\n",
            "Epoch 246/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3023 - accuracy: 0.4304 - val_loss: 1.3082 - val_accuracy: 0.3846\n",
            "Epoch 247/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2807 - accuracy: 0.4401 - val_loss: 1.3194 - val_accuracy: 0.3718\n",
            "Epoch 248/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2881 - accuracy: 0.4628 - val_loss: 1.3225 - val_accuracy: 0.3974\n",
            "Epoch 249/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2625 - accuracy: 0.4595 - val_loss: 1.2820 - val_accuracy: 0.3974\n",
            "Epoch 250/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2652 - accuracy: 0.4628 - val_loss: 1.2808 - val_accuracy: 0.3974\n",
            "Epoch 251/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2672 - accuracy: 0.4854 - val_loss: 1.3190 - val_accuracy: 0.3974\n",
            "Epoch 252/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2705 - accuracy: 0.4919 - val_loss: 1.3525 - val_accuracy: 0.3590\n",
            "Epoch 253/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2903 - accuracy: 0.4563 - val_loss: 1.3325 - val_accuracy: 0.3846\n",
            "Epoch 254/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2948 - accuracy: 0.4531 - val_loss: 1.3025 - val_accuracy: 0.4103\n",
            "Epoch 255/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2707 - accuracy: 0.4531 - val_loss: 1.3164 - val_accuracy: 0.3718\n",
            "Epoch 256/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2606 - accuracy: 0.4434 - val_loss: 1.2954 - val_accuracy: 0.3846\n",
            "Epoch 257/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2723 - accuracy: 0.4725 - val_loss: 1.2676 - val_accuracy: 0.3974\n",
            "Epoch 258/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.3255 - accuracy: 0.4304 - val_loss: 1.4618 - val_accuracy: 0.3205\n",
            "Epoch 259/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2911 - accuracy: 0.4628 - val_loss: 1.2806 - val_accuracy: 0.3974\n",
            "Epoch 260/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2902 - accuracy: 0.4660 - val_loss: 1.3636 - val_accuracy: 0.3462\n",
            "Epoch 261/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.3227 - accuracy: 0.4369 - val_loss: 1.2570 - val_accuracy: 0.3718\n",
            "Epoch 262/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2769 - accuracy: 0.4660 - val_loss: 1.3554 - val_accuracy: 0.3590\n",
            "Epoch 263/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2703 - accuracy: 0.4628 - val_loss: 1.2770 - val_accuracy: 0.4103\n",
            "Epoch 264/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2966 - accuracy: 0.4531 - val_loss: 1.3162 - val_accuracy: 0.4231\n",
            "Epoch 265/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2583 - accuracy: 0.4951 - val_loss: 1.2558 - val_accuracy: 0.3974\n",
            "Epoch 266/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2471 - accuracy: 0.4822 - val_loss: 1.3389 - val_accuracy: 0.3590\n",
            "Epoch 267/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2353 - accuracy: 0.4854 - val_loss: 1.2860 - val_accuracy: 0.3974\n",
            "Epoch 268/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2502 - accuracy: 0.4822 - val_loss: 1.2974 - val_accuracy: 0.3974\n",
            "Epoch 269/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2862 - accuracy: 0.4498 - val_loss: 1.3913 - val_accuracy: 0.3205\n",
            "Epoch 270/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3749 - accuracy: 0.4045 - val_loss: 1.3377 - val_accuracy: 0.3974\n",
            "Epoch 271/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.2640 - accuracy: 0.5210 - val_loss: 1.3177 - val_accuracy: 0.4103\n",
            "Epoch 272/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2431 - accuracy: 0.4725 - val_loss: 1.3435 - val_accuracy: 0.3846\n",
            "Epoch 273/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2316 - accuracy: 0.4757 - val_loss: 1.2649 - val_accuracy: 0.4231\n",
            "Epoch 274/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3123 - accuracy: 0.4369 - val_loss: 1.3497 - val_accuracy: 0.4103\n",
            "Epoch 275/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2862 - accuracy: 0.4369 - val_loss: 1.3314 - val_accuracy: 0.4103\n",
            "Epoch 276/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2676 - accuracy: 0.4628 - val_loss: 1.2938 - val_accuracy: 0.3846\n",
            "Epoch 277/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2691 - accuracy: 0.4466 - val_loss: 1.2686 - val_accuracy: 0.4103\n",
            "Epoch 278/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2551 - accuracy: 0.4790 - val_loss: 1.2779 - val_accuracy: 0.3846\n",
            "Epoch 279/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3122 - accuracy: 0.4531 - val_loss: 1.4363 - val_accuracy: 0.3333\n",
            "Epoch 280/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2855 - accuracy: 0.4693 - val_loss: 1.2830 - val_accuracy: 0.3974\n",
            "Epoch 281/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3027 - accuracy: 0.4239 - val_loss: 1.3239 - val_accuracy: 0.3974\n",
            "Epoch 282/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2761 - accuracy: 0.4660 - val_loss: 1.3756 - val_accuracy: 0.3846\n",
            "Epoch 283/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3039 - accuracy: 0.4531 - val_loss: 1.2558 - val_accuracy: 0.4103\n",
            "Epoch 284/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2474 - accuracy: 0.4531 - val_loss: 1.3195 - val_accuracy: 0.3590\n",
            "Epoch 285/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2603 - accuracy: 0.4757 - val_loss: 1.2515 - val_accuracy: 0.3974\n",
            "Epoch 286/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2098 - accuracy: 0.5113 - val_loss: 1.2727 - val_accuracy: 0.3846\n",
            "Epoch 287/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2506 - accuracy: 0.4984 - val_loss: 1.2571 - val_accuracy: 0.3974\n",
            "Epoch 288/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2223 - accuracy: 0.4919 - val_loss: 1.2934 - val_accuracy: 0.3846\n",
            "Epoch 289/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2860 - accuracy: 0.4337 - val_loss: 1.3609 - val_accuracy: 0.4103\n",
            "Epoch 290/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2676 - accuracy: 0.4660 - val_loss: 1.2805 - val_accuracy: 0.3974\n",
            "Epoch 291/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2594 - accuracy: 0.4466 - val_loss: 1.3038 - val_accuracy: 0.3846\n",
            "Epoch 292/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2506 - accuracy: 0.4563 - val_loss: 1.2322 - val_accuracy: 0.4359\n",
            "Epoch 293/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2527 - accuracy: 0.4790 - val_loss: 1.2506 - val_accuracy: 0.4103\n",
            "Epoch 294/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2243 - accuracy: 0.4757 - val_loss: 1.3299 - val_accuracy: 0.3333\n",
            "Epoch 295/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2751 - accuracy: 0.4434 - val_loss: 1.2076 - val_accuracy: 0.4487\n",
            "Epoch 296/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2121 - accuracy: 0.4822 - val_loss: 1.2541 - val_accuracy: 0.3974\n",
            "Epoch 297/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2268 - accuracy: 0.4725 - val_loss: 1.2280 - val_accuracy: 0.4231\n",
            "Epoch 298/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1786 - accuracy: 0.5146 - val_loss: 1.2390 - val_accuracy: 0.3974\n",
            "Epoch 299/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.2555 - accuracy: 0.4790 - val_loss: 1.2313 - val_accuracy: 0.4359\n",
            "Epoch 300/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2753 - accuracy: 0.4272 - val_loss: 1.2337 - val_accuracy: 0.4231\n",
            "Epoch 301/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2616 - accuracy: 0.4563 - val_loss: 1.2965 - val_accuracy: 0.4359\n",
            "Epoch 302/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2283 - accuracy: 0.4693 - val_loss: 1.2333 - val_accuracy: 0.3974\n",
            "Epoch 303/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2623 - accuracy: 0.4660 - val_loss: 1.2085 - val_accuracy: 0.4103\n",
            "Epoch 304/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2347 - accuracy: 0.4790 - val_loss: 1.2804 - val_accuracy: 0.4103\n",
            "Epoch 305/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2968 - accuracy: 0.4337 - val_loss: 1.2410 - val_accuracy: 0.3974\n",
            "Epoch 306/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2269 - accuracy: 0.4693 - val_loss: 1.2652 - val_accuracy: 0.3974\n",
            "Epoch 307/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2915 - accuracy: 0.5016 - val_loss: 1.2775 - val_accuracy: 0.3846\n",
            "Epoch 308/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.2116 - accuracy: 0.4854 - val_loss: 1.3067 - val_accuracy: 0.3846\n",
            "Epoch 309/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2418 - accuracy: 0.4887 - val_loss: 1.2508 - val_accuracy: 0.4103\n",
            "Epoch 310/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2160 - accuracy: 0.5210 - val_loss: 1.3118 - val_accuracy: 0.4103\n",
            "Epoch 311/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2039 - accuracy: 0.4660 - val_loss: 1.2911 - val_accuracy: 0.3846\n",
            "Epoch 312/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 1.2741 - accuracy: 0.4401 - val_loss: 1.2183 - val_accuracy: 0.4103\n",
            "Epoch 313/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2717 - accuracy: 0.4531 - val_loss: 1.2549 - val_accuracy: 0.4231\n",
            "Epoch 314/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 1.2754 - accuracy: 0.4854 - val_loss: 1.3764 - val_accuracy: 0.3718\n",
            "Epoch 315/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3248 - accuracy: 0.4207 - val_loss: 1.2973 - val_accuracy: 0.4103\n",
            "Epoch 316/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2107 - accuracy: 0.4887 - val_loss: 1.2500 - val_accuracy: 0.3974\n",
            "Epoch 317/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2363 - accuracy: 0.4693 - val_loss: 1.3024 - val_accuracy: 0.3974\n",
            "Epoch 318/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2380 - accuracy: 0.4790 - val_loss: 1.2641 - val_accuracy: 0.3974\n",
            "Epoch 319/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2004 - accuracy: 0.5081 - val_loss: 1.2358 - val_accuracy: 0.4231\n",
            "Epoch 320/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2553 - accuracy: 0.4757 - val_loss: 1.2586 - val_accuracy: 0.3974\n",
            "Epoch 321/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2872 - accuracy: 0.4466 - val_loss: 1.2692 - val_accuracy: 0.4231\n",
            "Epoch 322/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2556 - accuracy: 0.4660 - val_loss: 1.2407 - val_accuracy: 0.3974\n",
            "Epoch 323/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2073 - accuracy: 0.5113 - val_loss: 1.3121 - val_accuracy: 0.4615\n",
            "Epoch 324/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2410 - accuracy: 0.4757 - val_loss: 1.2876 - val_accuracy: 0.4103\n",
            "Epoch 325/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2028 - accuracy: 0.4951 - val_loss: 1.2139 - val_accuracy: 0.4615\n",
            "Epoch 326/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.1993 - accuracy: 0.5081 - val_loss: 1.3836 - val_accuracy: 0.3462\n",
            "Epoch 327/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2672 - accuracy: 0.4854 - val_loss: 1.2056 - val_accuracy: 0.4231\n",
            "Epoch 328/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2424 - accuracy: 0.4854 - val_loss: 1.3613 - val_accuracy: 0.3974\n",
            "Epoch 329/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2114 - accuracy: 0.5081 - val_loss: 1.2261 - val_accuracy: 0.3974\n",
            "Epoch 330/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1809 - accuracy: 0.5243 - val_loss: 1.2069 - val_accuracy: 0.4744\n",
            "Epoch 331/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2288 - accuracy: 0.4725 - val_loss: 1.3505 - val_accuracy: 0.3974\n",
            "Epoch 332/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2295 - accuracy: 0.4660 - val_loss: 1.2701 - val_accuracy: 0.4615\n",
            "Epoch 333/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2116 - accuracy: 0.4757 - val_loss: 1.2249 - val_accuracy: 0.4487\n",
            "Epoch 334/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2552 - accuracy: 0.4854 - val_loss: 1.2334 - val_accuracy: 0.4744\n",
            "Epoch 335/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.2072 - accuracy: 0.5016 - val_loss: 1.2580 - val_accuracy: 0.4359\n",
            "Epoch 336/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2334 - accuracy: 0.4919 - val_loss: 1.2166 - val_accuracy: 0.4744\n",
            "Epoch 337/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2059 - accuracy: 0.5113 - val_loss: 1.2353 - val_accuracy: 0.4359\n",
            "Epoch 338/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2006 - accuracy: 0.5146 - val_loss: 1.2269 - val_accuracy: 0.4744\n",
            "Epoch 339/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1843 - accuracy: 0.5016 - val_loss: 1.2371 - val_accuracy: 0.4103\n",
            "Epoch 340/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2866 - accuracy: 0.4693 - val_loss: 1.3968 - val_accuracy: 0.4359\n",
            "Epoch 341/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2959 - accuracy: 0.4919 - val_loss: 1.2087 - val_accuracy: 0.4359\n",
            "Epoch 342/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2193 - accuracy: 0.4984 - val_loss: 1.2292 - val_accuracy: 0.4615\n",
            "Epoch 343/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.2048 - accuracy: 0.5016 - val_loss: 1.2738 - val_accuracy: 0.3974\n",
            "Epoch 344/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2224 - accuracy: 0.4660 - val_loss: 1.2018 - val_accuracy: 0.4231\n",
            "Epoch 345/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2137 - accuracy: 0.4984 - val_loss: 1.2414 - val_accuracy: 0.4359\n",
            "Epoch 346/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1830 - accuracy: 0.5275 - val_loss: 1.1877 - val_accuracy: 0.4487\n",
            "Epoch 347/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2852 - accuracy: 0.4660 - val_loss: 1.2463 - val_accuracy: 0.4359\n",
            "Epoch 348/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3486 - accuracy: 0.4272 - val_loss: 1.3573 - val_accuracy: 0.4359\n",
            "Epoch 349/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.3194 - accuracy: 0.4401 - val_loss: 1.3336 - val_accuracy: 0.4359\n",
            "Epoch 350/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2767 - accuracy: 0.4207 - val_loss: 1.2375 - val_accuracy: 0.5128\n",
            "Epoch 351/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2331 - accuracy: 0.4790 - val_loss: 1.2339 - val_accuracy: 0.4103\n",
            "Epoch 352/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2457 - accuracy: 0.4822 - val_loss: 1.2756 - val_accuracy: 0.3846\n",
            "Epoch 353/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1903 - accuracy: 0.5049 - val_loss: 1.2539 - val_accuracy: 0.3974\n",
            "Epoch 354/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2337 - accuracy: 0.4790 - val_loss: 1.1919 - val_accuracy: 0.4487\n",
            "Epoch 355/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2183 - accuracy: 0.4757 - val_loss: 1.2338 - val_accuracy: 0.4615\n",
            "Epoch 356/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2232 - accuracy: 0.4984 - val_loss: 1.2060 - val_accuracy: 0.4359\n",
            "Epoch 357/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1912 - accuracy: 0.5049 - val_loss: 1.2378 - val_accuracy: 0.3974\n",
            "Epoch 358/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2334 - accuracy: 0.4984 - val_loss: 1.2434 - val_accuracy: 0.4231\n",
            "Epoch 359/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1876 - accuracy: 0.5307 - val_loss: 1.1935 - val_accuracy: 0.4872\n",
            "Epoch 360/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1731 - accuracy: 0.5081 - val_loss: 1.2010 - val_accuracy: 0.4872\n",
            "Epoch 361/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2117 - accuracy: 0.4951 - val_loss: 1.3280 - val_accuracy: 0.4231\n",
            "Epoch 362/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1943 - accuracy: 0.4887 - val_loss: 1.2593 - val_accuracy: 0.4231\n",
            "Epoch 363/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2051 - accuracy: 0.5049 - val_loss: 1.3028 - val_accuracy: 0.4103\n",
            "Epoch 364/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1827 - accuracy: 0.4887 - val_loss: 1.2022 - val_accuracy: 0.4359\n",
            "Epoch 365/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2068 - accuracy: 0.5178 - val_loss: 1.2007 - val_accuracy: 0.4615\n",
            "Epoch 366/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1896 - accuracy: 0.5275 - val_loss: 1.1914 - val_accuracy: 0.4487\n",
            "Epoch 367/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1655 - accuracy: 0.5113 - val_loss: 1.2079 - val_accuracy: 0.4231\n",
            "Epoch 368/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1964 - accuracy: 0.5016 - val_loss: 1.2049 - val_accuracy: 0.5000\n",
            "Epoch 369/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.1860 - accuracy: 0.5146 - val_loss: 1.2032 - val_accuracy: 0.5128\n",
            "Epoch 370/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1656 - accuracy: 0.5307 - val_loss: 1.1852 - val_accuracy: 0.5000\n",
            "Epoch 371/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1803 - accuracy: 0.5146 - val_loss: 1.2676 - val_accuracy: 0.4103\n",
            "Epoch 372/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1640 - accuracy: 0.4919 - val_loss: 1.2134 - val_accuracy: 0.4359\n",
            "Epoch 373/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1867 - accuracy: 0.4854 - val_loss: 1.2065 - val_accuracy: 0.4359\n",
            "Epoch 374/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1844 - accuracy: 0.5210 - val_loss: 1.2230 - val_accuracy: 0.4103\n",
            "Epoch 375/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1706 - accuracy: 0.5307 - val_loss: 1.2298 - val_accuracy: 0.4231\n",
            "Epoch 376/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2012 - accuracy: 0.5081 - val_loss: 1.2083 - val_accuracy: 0.4359\n",
            "Epoch 377/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1524 - accuracy: 0.5372 - val_loss: 1.2395 - val_accuracy: 0.4231\n",
            "Epoch 378/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1400 - accuracy: 0.5049 - val_loss: 1.1797 - val_accuracy: 0.4872\n",
            "Epoch 379/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1857 - accuracy: 0.4854 - val_loss: 1.2106 - val_accuracy: 0.4359\n",
            "Epoch 380/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1796 - accuracy: 0.5113 - val_loss: 1.1842 - val_accuracy: 0.4487\n",
            "Epoch 381/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1873 - accuracy: 0.5049 - val_loss: 1.2171 - val_accuracy: 0.4231\n",
            "Epoch 382/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1476 - accuracy: 0.4822 - val_loss: 1.2121 - val_accuracy: 0.4359\n",
            "Epoch 383/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2244 - accuracy: 0.5049 - val_loss: 1.2287 - val_accuracy: 0.5000\n",
            "Epoch 384/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2629 - accuracy: 0.4822 - val_loss: 1.2533 - val_accuracy: 0.4487\n",
            "Epoch 385/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1509 - accuracy: 0.5502 - val_loss: 1.1821 - val_accuracy: 0.4487\n",
            "Epoch 386/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1618 - accuracy: 0.5243 - val_loss: 1.2210 - val_accuracy: 0.4744\n",
            "Epoch 387/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2255 - accuracy: 0.5178 - val_loss: 1.1913 - val_accuracy: 0.4615\n",
            "Epoch 388/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1577 - accuracy: 0.5340 - val_loss: 1.1942 - val_accuracy: 0.4231\n",
            "Epoch 389/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1813 - accuracy: 0.4984 - val_loss: 1.1684 - val_accuracy: 0.4615\n",
            "Epoch 390/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1229 - accuracy: 0.5243 - val_loss: 1.3311 - val_accuracy: 0.3846\n",
            "Epoch 391/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1651 - accuracy: 0.5081 - val_loss: 1.1995 - val_accuracy: 0.4231\n",
            "Epoch 392/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1299 - accuracy: 0.5696 - val_loss: 1.2031 - val_accuracy: 0.4744\n",
            "Epoch 393/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1487 - accuracy: 0.5178 - val_loss: 1.1910 - val_accuracy: 0.4487\n",
            "Epoch 394/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1367 - accuracy: 0.4984 - val_loss: 1.2383 - val_accuracy: 0.4872\n",
            "Epoch 395/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1993 - accuracy: 0.4951 - val_loss: 1.1685 - val_accuracy: 0.4359\n",
            "Epoch 396/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1397 - accuracy: 0.5307 - val_loss: 1.2547 - val_accuracy: 0.4487\n",
            "Epoch 397/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1665 - accuracy: 0.5372 - val_loss: 1.2560 - val_accuracy: 0.4359\n",
            "Epoch 398/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1152 - accuracy: 0.5631 - val_loss: 1.1927 - val_accuracy: 0.4615\n",
            "Epoch 399/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1685 - accuracy: 0.5275 - val_loss: 1.6029 - val_accuracy: 0.3590\n",
            "Epoch 400/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2685 - accuracy: 0.4693 - val_loss: 1.2455 - val_accuracy: 0.4872\n",
            "Epoch 401/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1337 - accuracy: 0.5243 - val_loss: 1.1884 - val_accuracy: 0.4744\n",
            "Epoch 402/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1894 - accuracy: 0.5049 - val_loss: 1.1448 - val_accuracy: 0.5000\n",
            "Epoch 403/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2228 - accuracy: 0.4822 - val_loss: 1.1881 - val_accuracy: 0.5000\n",
            "Epoch 404/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1949 - accuracy: 0.4854 - val_loss: 1.1548 - val_accuracy: 0.5128\n",
            "Epoch 405/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1804 - accuracy: 0.4822 - val_loss: 1.2017 - val_accuracy: 0.5128\n",
            "Epoch 406/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1469 - accuracy: 0.5372 - val_loss: 1.1403 - val_accuracy: 0.5000\n",
            "Epoch 407/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1722 - accuracy: 0.5210 - val_loss: 1.1518 - val_accuracy: 0.5256\n",
            "Epoch 408/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1527 - accuracy: 0.5307 - val_loss: 1.2305 - val_accuracy: 0.4872\n",
            "Epoch 409/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1973 - accuracy: 0.4984 - val_loss: 1.2320 - val_accuracy: 0.4487\n",
            "Epoch 410/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1216 - accuracy: 0.5307 - val_loss: 1.1600 - val_accuracy: 0.5000\n",
            "Epoch 411/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1529 - accuracy: 0.5210 - val_loss: 1.1851 - val_accuracy: 0.4615\n",
            "Epoch 412/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1604 - accuracy: 0.5081 - val_loss: 1.1826 - val_accuracy: 0.4744\n",
            "Epoch 413/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2107 - accuracy: 0.5113 - val_loss: 1.2327 - val_accuracy: 0.4744\n",
            "Epoch 414/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1999 - accuracy: 0.5178 - val_loss: 1.1626 - val_accuracy: 0.4872\n",
            "Epoch 415/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2424 - accuracy: 0.4693 - val_loss: 1.2466 - val_accuracy: 0.4744\n",
            "Epoch 416/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2168 - accuracy: 0.5146 - val_loss: 1.2701 - val_accuracy: 0.4231\n",
            "Epoch 417/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2363 - accuracy: 0.4919 - val_loss: 1.1831 - val_accuracy: 0.4744\n",
            "Epoch 418/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1523 - accuracy: 0.5146 - val_loss: 1.1620 - val_accuracy: 0.5385\n",
            "Epoch 419/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.2205 - accuracy: 0.4725 - val_loss: 1.1623 - val_accuracy: 0.4872\n",
            "Epoch 420/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1497 - accuracy: 0.5340 - val_loss: 1.1471 - val_accuracy: 0.5513\n",
            "Epoch 421/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 1.1387 - accuracy: 0.5146 - val_loss: 1.1384 - val_accuracy: 0.5385\n",
            "Epoch 422/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1229 - accuracy: 0.5178 - val_loss: 1.1773 - val_accuracy: 0.4487\n",
            "Epoch 423/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1559 - accuracy: 0.5146 - val_loss: 1.1418 - val_accuracy: 0.5000\n",
            "Epoch 424/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1028 - accuracy: 0.5696 - val_loss: 1.1781 - val_accuracy: 0.5385\n",
            "Epoch 425/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1045 - accuracy: 0.5307 - val_loss: 1.1607 - val_accuracy: 0.5000\n",
            "Epoch 426/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0973 - accuracy: 0.5405 - val_loss: 1.1710 - val_accuracy: 0.4231\n",
            "Epoch 427/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1097 - accuracy: 0.5534 - val_loss: 1.1338 - val_accuracy: 0.4872\n",
            "Epoch 428/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1661 - accuracy: 0.5307 - val_loss: 1.1237 - val_accuracy: 0.4744\n",
            "Epoch 429/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0908 - accuracy: 0.5243 - val_loss: 1.1242 - val_accuracy: 0.4872\n",
            "Epoch 430/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1249 - accuracy: 0.5307 - val_loss: 1.1872 - val_accuracy: 0.4359\n",
            "Epoch 431/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1782 - accuracy: 0.5081 - val_loss: 1.3280 - val_accuracy: 0.4231\n",
            "Epoch 432/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1487 - accuracy: 0.5502 - val_loss: 1.1387 - val_accuracy: 0.5256\n",
            "Epoch 433/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1596 - accuracy: 0.5437 - val_loss: 1.1540 - val_accuracy: 0.5128\n",
            "Epoch 434/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2020 - accuracy: 0.4919 - val_loss: 1.2002 - val_accuracy: 0.5513\n",
            "Epoch 435/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1173 - accuracy: 0.5405 - val_loss: 1.2167 - val_accuracy: 0.5000\n",
            "Epoch 436/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1890 - accuracy: 0.5146 - val_loss: 1.1419 - val_accuracy: 0.5385\n",
            "Epoch 437/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1167 - accuracy: 0.5566 - val_loss: 1.1412 - val_accuracy: 0.5513\n",
            "Epoch 438/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1426 - accuracy: 0.5275 - val_loss: 1.1865 - val_accuracy: 0.4744\n",
            "Epoch 439/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1692 - accuracy: 0.5016 - val_loss: 1.1351 - val_accuracy: 0.5128\n",
            "Epoch 440/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1077 - accuracy: 0.5372 - val_loss: 1.1635 - val_accuracy: 0.4615\n",
            "Epoch 441/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1231 - accuracy: 0.5178 - val_loss: 1.1540 - val_accuracy: 0.5128\n",
            "Epoch 442/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1200 - accuracy: 0.5210 - val_loss: 1.1709 - val_accuracy: 0.5128\n",
            "Epoch 443/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1662 - accuracy: 0.4951 - val_loss: 1.1956 - val_accuracy: 0.4231\n",
            "Epoch 444/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0676 - accuracy: 0.5890 - val_loss: 1.0910 - val_accuracy: 0.5513\n",
            "Epoch 445/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1019 - accuracy: 0.5599 - val_loss: 1.1237 - val_accuracy: 0.5385\n",
            "Epoch 446/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0871 - accuracy: 0.5534 - val_loss: 1.1201 - val_accuracy: 0.5385\n",
            "Epoch 447/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2250 - accuracy: 0.4854 - val_loss: 1.2080 - val_accuracy: 0.4744\n",
            "Epoch 448/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.1028 - accuracy: 0.5599 - val_loss: 1.1424 - val_accuracy: 0.5256\n",
            "Epoch 449/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1235 - accuracy: 0.5178 - val_loss: 1.1500 - val_accuracy: 0.4744\n",
            "Epoch 450/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0597 - accuracy: 0.5599 - val_loss: 1.1766 - val_accuracy: 0.4487\n",
            "Epoch 451/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1078 - accuracy: 0.5340 - val_loss: 1.1871 - val_accuracy: 0.4103\n",
            "Epoch 452/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1243 - accuracy: 0.5372 - val_loss: 1.3558 - val_accuracy: 0.3974\n",
            "Epoch 453/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1978 - accuracy: 0.4951 - val_loss: 1.4330 - val_accuracy: 0.4103\n",
            "Epoch 454/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1622 - accuracy: 0.5372 - val_loss: 1.0945 - val_accuracy: 0.5513\n",
            "Epoch 455/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0634 - accuracy: 0.5955 - val_loss: 1.1028 - val_accuracy: 0.5385\n",
            "Epoch 456/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1459 - accuracy: 0.5113 - val_loss: 1.1040 - val_accuracy: 0.5513\n",
            "Epoch 457/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0929 - accuracy: 0.5663 - val_loss: 1.0854 - val_accuracy: 0.5256\n",
            "Epoch 458/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0664 - accuracy: 0.5761 - val_loss: 1.1303 - val_accuracy: 0.5000\n",
            "Epoch 459/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0640 - accuracy: 0.5566 - val_loss: 1.0972 - val_accuracy: 0.5513\n",
            "Epoch 460/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1256 - accuracy: 0.5534 - val_loss: 1.1634 - val_accuracy: 0.5128\n",
            "Epoch 461/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1096 - accuracy: 0.5405 - val_loss: 1.1134 - val_accuracy: 0.5128\n",
            "Epoch 462/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1311 - accuracy: 0.5405 - val_loss: 1.1074 - val_accuracy: 0.5256\n",
            "Epoch 463/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0867 - accuracy: 0.5566 - val_loss: 1.2184 - val_accuracy: 0.4615\n",
            "Epoch 464/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0769 - accuracy: 0.5728 - val_loss: 1.2885 - val_accuracy: 0.4231\n",
            "Epoch 465/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0931 - accuracy: 0.5793 - val_loss: 1.1958 - val_accuracy: 0.4744\n",
            "Epoch 466/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1086 - accuracy: 0.5631 - val_loss: 1.1410 - val_accuracy: 0.5256\n",
            "Epoch 467/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0546 - accuracy: 0.5696 - val_loss: 1.0716 - val_accuracy: 0.5769\n",
            "Epoch 468/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0751 - accuracy: 0.5696 - val_loss: 1.1027 - val_accuracy: 0.5897\n",
            "Epoch 469/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1100 - accuracy: 0.5566 - val_loss: 1.0938 - val_accuracy: 0.5000\n",
            "Epoch 470/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1156 - accuracy: 0.5696 - val_loss: 1.1169 - val_accuracy: 0.5128\n",
            "Epoch 471/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0271 - accuracy: 0.5696 - val_loss: 1.0961 - val_accuracy: 0.5385\n",
            "Epoch 472/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1019 - accuracy: 0.5502 - val_loss: 1.0811 - val_accuracy: 0.5128\n",
            "Epoch 473/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0510 - accuracy: 0.5728 - val_loss: 1.0886 - val_accuracy: 0.5385\n",
            "Epoch 474/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0618 - accuracy: 0.5761 - val_loss: 1.0750 - val_accuracy: 0.5128\n",
            "Epoch 475/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0231 - accuracy: 0.5372 - val_loss: 1.0848 - val_accuracy: 0.5641\n",
            "Epoch 476/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0785 - accuracy: 0.5534 - val_loss: 1.0941 - val_accuracy: 0.5128\n",
            "Epoch 477/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1089 - accuracy: 0.5631 - val_loss: 1.0800 - val_accuracy: 0.5128\n",
            "Epoch 478/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0809 - accuracy: 0.5372 - val_loss: 1.0717 - val_accuracy: 0.5513\n",
            "Epoch 479/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1362 - accuracy: 0.5405 - val_loss: 1.3082 - val_accuracy: 0.4359\n",
            "Epoch 480/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1560 - accuracy: 0.5275 - val_loss: 1.1768 - val_accuracy: 0.5128\n",
            "Epoch 481/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1515 - accuracy: 0.5405 - val_loss: 1.1767 - val_accuracy: 0.4615\n",
            "Epoch 482/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 1.0831 - accuracy: 0.5372 - val_loss: 1.0859 - val_accuracy: 0.5128\n",
            "Epoch 483/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1274 - accuracy: 0.5372 - val_loss: 1.1038 - val_accuracy: 0.5128\n",
            "Epoch 484/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0657 - accuracy: 0.5696 - val_loss: 1.0949 - val_accuracy: 0.5256\n",
            "Epoch 485/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1029 - accuracy: 0.5178 - val_loss: 1.0716 - val_accuracy: 0.5641\n",
            "Epoch 486/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0600 - accuracy: 0.5696 - val_loss: 1.0363 - val_accuracy: 0.5641\n",
            "Epoch 487/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0991 - accuracy: 0.5534 - val_loss: 1.0770 - val_accuracy: 0.5513\n",
            "Epoch 488/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0335 - accuracy: 0.5858 - val_loss: 1.0894 - val_accuracy: 0.5000\n",
            "Epoch 489/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0333 - accuracy: 0.5858 - val_loss: 1.1402 - val_accuracy: 0.4615\n",
            "Epoch 490/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0438 - accuracy: 0.5728 - val_loss: 1.0489 - val_accuracy: 0.5513\n",
            "Epoch 491/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0478 - accuracy: 0.5534 - val_loss: 1.0588 - val_accuracy: 0.5641\n",
            "Epoch 492/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0567 - accuracy: 0.5469 - val_loss: 1.0446 - val_accuracy: 0.5513\n",
            "Epoch 493/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0982 - accuracy: 0.5696 - val_loss: 1.0396 - val_accuracy: 0.5641\n",
            "Epoch 494/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.9912 - accuracy: 0.6149 - val_loss: 1.0558 - val_accuracy: 0.5385\n",
            "Epoch 495/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0297 - accuracy: 0.5728 - val_loss: 1.0898 - val_accuracy: 0.5256\n",
            "Epoch 496/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0583 - accuracy: 0.5890 - val_loss: 1.1834 - val_accuracy: 0.5000\n",
            "Epoch 497/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1012 - accuracy: 0.5340 - val_loss: 1.1013 - val_accuracy: 0.5000\n",
            "Epoch 498/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0261 - accuracy: 0.5761 - val_loss: 1.0650 - val_accuracy: 0.5385\n",
            "Epoch 499/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0519 - accuracy: 0.5825 - val_loss: 1.0497 - val_accuracy: 0.5385\n",
            "Epoch 500/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0694 - accuracy: 0.5275 - val_loss: 1.0415 - val_accuracy: 0.5256\n",
            "Epoch 501/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9841 - accuracy: 0.5825 - val_loss: 1.0841 - val_accuracy: 0.5000\n",
            "Epoch 502/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0763 - accuracy: 0.5728 - val_loss: 1.1963 - val_accuracy: 0.4872\n",
            "Epoch 503/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1816 - accuracy: 0.4984 - val_loss: 1.0816 - val_accuracy: 0.6026\n",
            "Epoch 504/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1073 - accuracy: 0.5534 - val_loss: 1.1047 - val_accuracy: 0.5385\n",
            "Epoch 505/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1642 - accuracy: 0.5275 - val_loss: 1.0944 - val_accuracy: 0.5513\n",
            "Epoch 506/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1693 - accuracy: 0.5243 - val_loss: 1.1484 - val_accuracy: 0.5000\n",
            "Epoch 507/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1670 - accuracy: 0.5016 - val_loss: 1.1849 - val_accuracy: 0.5385\n",
            "Epoch 508/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1286 - accuracy: 0.5307 - val_loss: 1.1157 - val_accuracy: 0.5128\n",
            "Epoch 509/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0883 - accuracy: 0.5340 - val_loss: 1.0767 - val_accuracy: 0.5385\n",
            "Epoch 510/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1037 - accuracy: 0.5372 - val_loss: 1.1012 - val_accuracy: 0.5513\n",
            "Epoch 511/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0368 - accuracy: 0.5793 - val_loss: 1.0967 - val_accuracy: 0.5513\n",
            "Epoch 512/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0468 - accuracy: 0.5631 - val_loss: 1.0836 - val_accuracy: 0.5385\n",
            "Epoch 513/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9929 - accuracy: 0.5987 - val_loss: 1.0402 - val_accuracy: 0.5897\n",
            "Epoch 514/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0315 - accuracy: 0.5599 - val_loss: 1.1788 - val_accuracy: 0.4615\n",
            "Epoch 515/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0405 - accuracy: 0.5663 - val_loss: 1.0518 - val_accuracy: 0.5385\n",
            "Epoch 516/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9543 - accuracy: 0.6181 - val_loss: 1.0383 - val_accuracy: 0.5769\n",
            "Epoch 517/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.9983 - accuracy: 0.5987 - val_loss: 1.1078 - val_accuracy: 0.5513\n",
            "Epoch 518/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0129 - accuracy: 0.6278 - val_loss: 1.0592 - val_accuracy: 0.5769\n",
            "Epoch 519/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0684 - accuracy: 0.5825 - val_loss: 1.0793 - val_accuracy: 0.5128\n",
            "Epoch 520/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0936 - accuracy: 0.5858 - val_loss: 1.0742 - val_accuracy: 0.5256\n",
            "Epoch 521/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9942 - accuracy: 0.6214 - val_loss: 1.1351 - val_accuracy: 0.5128\n",
            "Epoch 522/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0388 - accuracy: 0.5534 - val_loss: 0.9906 - val_accuracy: 0.5641\n",
            "Epoch 523/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0117 - accuracy: 0.5922 - val_loss: 1.0281 - val_accuracy: 0.5385\n",
            "Epoch 524/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0952 - accuracy: 0.5793 - val_loss: 1.0107 - val_accuracy: 0.5641\n",
            "Epoch 525/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0179 - accuracy: 0.6019 - val_loss: 1.0042 - val_accuracy: 0.6282\n",
            "Epoch 526/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0303 - accuracy: 0.5793 - val_loss: 1.0009 - val_accuracy: 0.6154\n",
            "Epoch 527/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0591 - accuracy: 0.5922 - val_loss: 1.0406 - val_accuracy: 0.5256\n",
            "Epoch 528/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0402 - accuracy: 0.5825 - val_loss: 1.0191 - val_accuracy: 0.5385\n",
            "Epoch 529/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0574 - accuracy: 0.5728 - val_loss: 1.0611 - val_accuracy: 0.5256\n",
            "Epoch 530/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0013 - accuracy: 0.5955 - val_loss: 1.0811 - val_accuracy: 0.5385\n",
            "Epoch 531/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0437 - accuracy: 0.5761 - val_loss: 1.0404 - val_accuracy: 0.5769\n",
            "Epoch 532/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9932 - accuracy: 0.6246 - val_loss: 1.0309 - val_accuracy: 0.6026\n",
            "Epoch 533/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0346 - accuracy: 0.5599 - val_loss: 1.1363 - val_accuracy: 0.5128\n",
            "Epoch 534/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0949 - accuracy: 0.5469 - val_loss: 1.0966 - val_accuracy: 0.6026\n",
            "Epoch 535/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0183 - accuracy: 0.5825 - val_loss: 1.0324 - val_accuracy: 0.5897\n",
            "Epoch 536/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0093 - accuracy: 0.5987 - val_loss: 1.0279 - val_accuracy: 0.5769\n",
            "Epoch 537/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0517 - accuracy: 0.5469 - val_loss: 1.0228 - val_accuracy: 0.5513\n",
            "Epoch 538/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9905 - accuracy: 0.6052 - val_loss: 1.0333 - val_accuracy: 0.5385\n",
            "Epoch 539/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0273 - accuracy: 0.5793 - val_loss: 1.0486 - val_accuracy: 0.5000\n",
            "Epoch 540/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0073 - accuracy: 0.5858 - val_loss: 1.0187 - val_accuracy: 0.5641\n",
            "Epoch 541/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9879 - accuracy: 0.6214 - val_loss: 1.0297 - val_accuracy: 0.5513\n",
            "Epoch 542/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0136 - accuracy: 0.5858 - val_loss: 1.0618 - val_accuracy: 0.5897\n",
            "Epoch 543/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9652 - accuracy: 0.6375 - val_loss: 1.0533 - val_accuracy: 0.5385\n",
            "Epoch 544/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9274 - accuracy: 0.6699 - val_loss: 1.0317 - val_accuracy: 0.5256\n",
            "Epoch 545/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9815 - accuracy: 0.6246 - val_loss: 1.0431 - val_accuracy: 0.5513\n",
            "Epoch 546/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.9776 - accuracy: 0.6117 - val_loss: 1.0892 - val_accuracy: 0.5641\n",
            "Epoch 547/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9879 - accuracy: 0.5728 - val_loss: 1.2565 - val_accuracy: 0.5000\n",
            "Epoch 548/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0608 - accuracy: 0.5405 - val_loss: 1.1705 - val_accuracy: 0.4615\n",
            "Epoch 549/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0022 - accuracy: 0.5728 - val_loss: 1.1674 - val_accuracy: 0.4872\n",
            "Epoch 550/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0516 - accuracy: 0.5858 - val_loss: 1.1525 - val_accuracy: 0.5256\n",
            "Epoch 551/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0351 - accuracy: 0.5922 - val_loss: 1.1308 - val_accuracy: 0.5000\n",
            "Epoch 552/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0249 - accuracy: 0.5663 - val_loss: 1.0032 - val_accuracy: 0.5513\n",
            "Epoch 553/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0334 - accuracy: 0.5534 - val_loss: 1.0282 - val_accuracy: 0.5256\n",
            "Epoch 554/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 1.0023 - accuracy: 0.5728 - val_loss: 1.0003 - val_accuracy: 0.5385\n",
            "Epoch 555/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0452 - accuracy: 0.5987 - val_loss: 1.0264 - val_accuracy: 0.4872\n",
            "Epoch 556/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0345 - accuracy: 0.5761 - val_loss: 1.0217 - val_accuracy: 0.5385\n",
            "Epoch 557/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9976 - accuracy: 0.5728 - val_loss: 1.0513 - val_accuracy: 0.5385\n",
            "Epoch 558/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0245 - accuracy: 0.6052 - val_loss: 1.0338 - val_accuracy: 0.5897\n",
            "Epoch 559/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0122 - accuracy: 0.5793 - val_loss: 1.0274 - val_accuracy: 0.5385\n",
            "Epoch 560/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0214 - accuracy: 0.5761 - val_loss: 1.0414 - val_accuracy: 0.6026\n",
            "Epoch 561/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9958 - accuracy: 0.6019 - val_loss: 1.1015 - val_accuracy: 0.5641\n",
            "Epoch 562/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9767 - accuracy: 0.6019 - val_loss: 1.0367 - val_accuracy: 0.5513\n",
            "Epoch 563/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9649 - accuracy: 0.6019 - val_loss: 1.0632 - val_accuracy: 0.5256\n",
            "Epoch 564/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9610 - accuracy: 0.6214 - val_loss: 1.0655 - val_accuracy: 0.5385\n",
            "Epoch 565/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0222 - accuracy: 0.5728 - val_loss: 1.0585 - val_accuracy: 0.5385\n",
            "Epoch 566/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9970 - accuracy: 0.5955 - val_loss: 1.0437 - val_accuracy: 0.5641\n",
            "Epoch 567/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9896 - accuracy: 0.5922 - val_loss: 1.0163 - val_accuracy: 0.5897\n",
            "Epoch 568/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0058 - accuracy: 0.5987 - val_loss: 0.9798 - val_accuracy: 0.6026\n",
            "Epoch 569/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0069 - accuracy: 0.5987 - val_loss: 0.9654 - val_accuracy: 0.5641\n",
            "Epoch 570/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9533 - accuracy: 0.6117 - val_loss: 1.0089 - val_accuracy: 0.5385\n",
            "Epoch 571/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9688 - accuracy: 0.6117 - val_loss: 0.9966 - val_accuracy: 0.5897\n",
            "Epoch 572/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9427 - accuracy: 0.6343 - val_loss: 1.0236 - val_accuracy: 0.6026\n",
            "Epoch 573/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0001 - accuracy: 0.5793 - val_loss: 1.0645 - val_accuracy: 0.5641\n",
            "Epoch 574/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9647 - accuracy: 0.6117 - val_loss: 0.9716 - val_accuracy: 0.5256\n",
            "Epoch 575/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9779 - accuracy: 0.5955 - val_loss: 0.9977 - val_accuracy: 0.5897\n",
            "Epoch 576/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9521 - accuracy: 0.6117 - val_loss: 0.9750 - val_accuracy: 0.6154\n",
            "Epoch 577/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9506 - accuracy: 0.6214 - val_loss: 1.0186 - val_accuracy: 0.5385\n",
            "Epoch 578/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9974 - accuracy: 0.5825 - val_loss: 1.0378 - val_accuracy: 0.5385\n",
            "Epoch 579/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8980 - accuracy: 0.6505 - val_loss: 1.1305 - val_accuracy: 0.5256\n",
            "Epoch 580/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0081 - accuracy: 0.6084 - val_loss: 1.0751 - val_accuracy: 0.5513\n",
            "Epoch 581/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9310 - accuracy: 0.6246 - val_loss: 0.9941 - val_accuracy: 0.5513\n",
            "Epoch 582/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0394 - accuracy: 0.6052 - val_loss: 1.0931 - val_accuracy: 0.5641\n",
            "Epoch 583/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9617 - accuracy: 0.6311 - val_loss: 1.0013 - val_accuracy: 0.5769\n",
            "Epoch 584/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9319 - accuracy: 0.6149 - val_loss: 0.9831 - val_accuracy: 0.5513\n",
            "Epoch 585/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9983 - accuracy: 0.5955 - val_loss: 1.1707 - val_accuracy: 0.5000\n",
            "Epoch 586/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9831 - accuracy: 0.6084 - val_loss: 0.9424 - val_accuracy: 0.6538\n",
            "Epoch 587/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0143 - accuracy: 0.5793 - val_loss: 0.9101 - val_accuracy: 0.6026\n",
            "Epoch 588/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0370 - accuracy: 0.5793 - val_loss: 1.0221 - val_accuracy: 0.6026\n",
            "Epoch 589/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9788 - accuracy: 0.5793 - val_loss: 1.0405 - val_accuracy: 0.5128\n",
            "Epoch 590/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9158 - accuracy: 0.5955 - val_loss: 0.9681 - val_accuracy: 0.5769\n",
            "Epoch 591/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0219 - accuracy: 0.5858 - val_loss: 0.9410 - val_accuracy: 0.6410\n",
            "Epoch 592/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9375 - accuracy: 0.6149 - val_loss: 1.0219 - val_accuracy: 0.5385\n",
            "Epoch 593/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9671 - accuracy: 0.5955 - val_loss: 1.0546 - val_accuracy: 0.5641\n",
            "Epoch 594/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9275 - accuracy: 0.6375 - val_loss: 1.0014 - val_accuracy: 0.5513\n",
            "Epoch 595/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9097 - accuracy: 0.6408 - val_loss: 0.9660 - val_accuracy: 0.6154\n",
            "Epoch 596/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0645 - accuracy: 0.5469 - val_loss: 1.1075 - val_accuracy: 0.5256\n",
            "Epoch 597/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9316 - accuracy: 0.6214 - val_loss: 1.1589 - val_accuracy: 0.5385\n",
            "Epoch 598/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9882 - accuracy: 0.6214 - val_loss: 0.9786 - val_accuracy: 0.5897\n",
            "Epoch 599/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9418 - accuracy: 0.6375 - val_loss: 0.9505 - val_accuracy: 0.5769\n",
            "Epoch 600/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9288 - accuracy: 0.6311 - val_loss: 1.0149 - val_accuracy: 0.5769\n",
            "Epoch 601/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.9366 - accuracy: 0.6214 - val_loss: 0.9863 - val_accuracy: 0.6154\n",
            "Epoch 602/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8823 - accuracy: 0.6537 - val_loss: 0.9675 - val_accuracy: 0.5897\n",
            "Epoch 603/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.9242 - accuracy: 0.6052 - val_loss: 0.9207 - val_accuracy: 0.6282\n",
            "Epoch 604/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8931 - accuracy: 0.6343 - val_loss: 0.9950 - val_accuracy: 0.5513\n",
            "Epoch 605/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9804 - accuracy: 0.6117 - val_loss: 0.9511 - val_accuracy: 0.6410\n",
            "Epoch 606/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9174 - accuracy: 0.6181 - val_loss: 1.0530 - val_accuracy: 0.5128\n",
            "Epoch 607/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9081 - accuracy: 0.6537 - val_loss: 0.9206 - val_accuracy: 0.6154\n",
            "Epoch 608/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9107 - accuracy: 0.6472 - val_loss: 0.9677 - val_accuracy: 0.5897\n",
            "Epoch 609/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8784 - accuracy: 0.6570 - val_loss: 0.9800 - val_accuracy: 0.5513\n",
            "Epoch 610/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9029 - accuracy: 0.6408 - val_loss: 0.9415 - val_accuracy: 0.6026\n",
            "Epoch 611/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8569 - accuracy: 0.6570 - val_loss: 0.9226 - val_accuracy: 0.5641\n",
            "Epoch 612/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9130 - accuracy: 0.6149 - val_loss: 0.9100 - val_accuracy: 0.6154\n",
            "Epoch 613/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9405 - accuracy: 0.6214 - val_loss: 0.8767 - val_accuracy: 0.6410\n",
            "Epoch 614/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9266 - accuracy: 0.6602 - val_loss: 0.9552 - val_accuracy: 0.5897\n",
            "Epoch 615/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9324 - accuracy: 0.6408 - val_loss: 1.0109 - val_accuracy: 0.5641\n",
            "Epoch 616/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9162 - accuracy: 0.6214 - val_loss: 1.0049 - val_accuracy: 0.5897\n",
            "Epoch 617/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9984 - accuracy: 0.5922 - val_loss: 1.0795 - val_accuracy: 0.5385\n",
            "Epoch 618/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0324 - accuracy: 0.5890 - val_loss: 0.9512 - val_accuracy: 0.5128\n",
            "Epoch 619/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9190 - accuracy: 0.6181 - val_loss: 0.9673 - val_accuracy: 0.6026\n",
            "Epoch 620/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9520 - accuracy: 0.6343 - val_loss: 1.0181 - val_accuracy: 0.5256\n",
            "Epoch 621/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9451 - accuracy: 0.6246 - val_loss: 0.9939 - val_accuracy: 0.5641\n",
            "Epoch 622/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9928 - accuracy: 0.6052 - val_loss: 0.9842 - val_accuracy: 0.5769\n",
            "Epoch 623/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9670 - accuracy: 0.6019 - val_loss: 0.9619 - val_accuracy: 0.5897\n",
            "Epoch 624/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0383 - accuracy: 0.6117 - val_loss: 0.9416 - val_accuracy: 0.5385\n",
            "Epoch 625/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0190 - accuracy: 0.5696 - val_loss: 0.9936 - val_accuracy: 0.6410\n",
            "Epoch 626/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9944 - accuracy: 0.6084 - val_loss: 0.9469 - val_accuracy: 0.6026\n",
            "Epoch 627/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9502 - accuracy: 0.6084 - val_loss: 1.0394 - val_accuracy: 0.5000\n",
            "Epoch 628/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9745 - accuracy: 0.6214 - val_loss: 1.0364 - val_accuracy: 0.5128\n",
            "Epoch 629/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9100 - accuracy: 0.6505 - val_loss: 0.9447 - val_accuracy: 0.5641\n",
            "Epoch 630/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9719 - accuracy: 0.5987 - val_loss: 0.9183 - val_accuracy: 0.6026\n",
            "Epoch 631/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9979 - accuracy: 0.5955 - val_loss: 0.9242 - val_accuracy: 0.5641\n",
            "Epoch 632/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0352 - accuracy: 0.5922 - val_loss: 1.0159 - val_accuracy: 0.5641\n",
            "Epoch 633/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0024 - accuracy: 0.6214 - val_loss: 0.9443 - val_accuracy: 0.5897\n",
            "Epoch 634/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9787 - accuracy: 0.6181 - val_loss: 0.9801 - val_accuracy: 0.5769\n",
            "Epoch 635/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9858 - accuracy: 0.5858 - val_loss: 1.0275 - val_accuracy: 0.5769\n",
            "Epoch 636/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0328 - accuracy: 0.5599 - val_loss: 0.9921 - val_accuracy: 0.5769\n",
            "Epoch 637/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9872 - accuracy: 0.6052 - val_loss: 0.9716 - val_accuracy: 0.5641\n",
            "Epoch 638/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9622 - accuracy: 0.6505 - val_loss: 1.1568 - val_accuracy: 0.4872\n",
            "Epoch 639/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0243 - accuracy: 0.6084 - val_loss: 0.9609 - val_accuracy: 0.5897\n",
            "Epoch 640/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9904 - accuracy: 0.6019 - val_loss: 0.9527 - val_accuracy: 0.5897\n",
            "Epoch 641/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9576 - accuracy: 0.6117 - val_loss: 0.9071 - val_accuracy: 0.5769\n",
            "Epoch 642/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1558 - accuracy: 0.5243 - val_loss: 1.0332 - val_accuracy: 0.5641\n",
            "Epoch 643/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0140 - accuracy: 0.5793 - val_loss: 1.0298 - val_accuracy: 0.5641\n",
            "Epoch 644/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9278 - accuracy: 0.6667 - val_loss: 0.9270 - val_accuracy: 0.6154\n",
            "Epoch 645/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0520 - accuracy: 0.5987 - val_loss: 0.9613 - val_accuracy: 0.5513\n",
            "Epoch 646/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0173 - accuracy: 0.5955 - val_loss: 1.0050 - val_accuracy: 0.5641\n",
            "Epoch 647/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0497 - accuracy: 0.5534 - val_loss: 0.9479 - val_accuracy: 0.5769\n",
            "Epoch 648/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0965 - accuracy: 0.5631 - val_loss: 1.0488 - val_accuracy: 0.5385\n",
            "Epoch 649/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0821 - accuracy: 0.5566 - val_loss: 1.0568 - val_accuracy: 0.5385\n",
            "Epoch 650/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9763 - accuracy: 0.6019 - val_loss: 0.9552 - val_accuracy: 0.6282\n",
            "Epoch 651/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0361 - accuracy: 0.6084 - val_loss: 0.9366 - val_accuracy: 0.5769\n",
            "Epoch 652/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9498 - accuracy: 0.6440 - val_loss: 0.9186 - val_accuracy: 0.6026\n",
            "Epoch 653/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0283 - accuracy: 0.6052 - val_loss: 0.9764 - val_accuracy: 0.5000\n",
            "Epoch 654/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0033 - accuracy: 0.6052 - val_loss: 0.9697 - val_accuracy: 0.5641\n",
            "Epoch 655/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9873 - accuracy: 0.6149 - val_loss: 0.9445 - val_accuracy: 0.6154\n",
            "Epoch 656/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9795 - accuracy: 0.6278 - val_loss: 0.9224 - val_accuracy: 0.5513\n",
            "Epoch 657/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9512 - accuracy: 0.6214 - val_loss: 0.9199 - val_accuracy: 0.6154\n",
            "Epoch 658/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9832 - accuracy: 0.6408 - val_loss: 0.9862 - val_accuracy: 0.6154\n",
            "Epoch 659/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0132 - accuracy: 0.5955 - val_loss: 1.0727 - val_accuracy: 0.5128\n",
            "Epoch 660/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0064 - accuracy: 0.5696 - val_loss: 0.8918 - val_accuracy: 0.6154\n",
            "Epoch 661/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.9804 - accuracy: 0.5761 - val_loss: 0.9214 - val_accuracy: 0.6026\n",
            "Epoch 662/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9301 - accuracy: 0.6019 - val_loss: 0.9950 - val_accuracy: 0.5385\n",
            "Epoch 663/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9841 - accuracy: 0.6117 - val_loss: 0.9586 - val_accuracy: 0.5897\n",
            "Epoch 664/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0309 - accuracy: 0.5890 - val_loss: 0.9793 - val_accuracy: 0.5897\n",
            "Epoch 665/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0020 - accuracy: 0.5858 - val_loss: 1.0585 - val_accuracy: 0.5641\n",
            "Epoch 666/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9966 - accuracy: 0.6019 - val_loss: 0.9364 - val_accuracy: 0.5769\n",
            "Epoch 667/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9918 - accuracy: 0.5890 - val_loss: 0.9408 - val_accuracy: 0.6026\n",
            "Epoch 668/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9577 - accuracy: 0.6311 - val_loss: 0.9476 - val_accuracy: 0.5897\n",
            "Epoch 669/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0116 - accuracy: 0.6052 - val_loss: 1.0074 - val_accuracy: 0.6154\n",
            "Epoch 670/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0043 - accuracy: 0.5922 - val_loss: 1.1096 - val_accuracy: 0.5385\n",
            "Epoch 671/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0155 - accuracy: 0.5890 - val_loss: 0.9457 - val_accuracy: 0.5128\n",
            "Epoch 672/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0042 - accuracy: 0.5922 - val_loss: 0.9104 - val_accuracy: 0.6026\n",
            "Epoch 673/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9018 - accuracy: 0.6570 - val_loss: 0.9622 - val_accuracy: 0.5897\n",
            "Epoch 674/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9642 - accuracy: 0.6343 - val_loss: 0.9314 - val_accuracy: 0.5897\n",
            "Epoch 675/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9876 - accuracy: 0.6019 - val_loss: 0.9684 - val_accuracy: 0.5769\n",
            "Epoch 676/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.9043 - accuracy: 0.6440 - val_loss: 1.0100 - val_accuracy: 0.5641\n",
            "Epoch 677/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9917 - accuracy: 0.6019 - val_loss: 1.0467 - val_accuracy: 0.5385\n",
            "Epoch 678/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9411 - accuracy: 0.6472 - val_loss: 0.9500 - val_accuracy: 0.6282\n",
            "Epoch 679/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9227 - accuracy: 0.6537 - val_loss: 0.9457 - val_accuracy: 0.6410\n",
            "Epoch 680/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9608 - accuracy: 0.6505 - val_loss: 0.9670 - val_accuracy: 0.6154\n",
            "Epoch 681/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0262 - accuracy: 0.5663 - val_loss: 1.0069 - val_accuracy: 0.6026\n",
            "Epoch 682/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9188 - accuracy: 0.6926 - val_loss: 0.9914 - val_accuracy: 0.5385\n",
            "Epoch 683/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0621 - accuracy: 0.5696 - val_loss: 0.9251 - val_accuracy: 0.5897\n",
            "Epoch 684/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0382 - accuracy: 0.5922 - val_loss: 1.0359 - val_accuracy: 0.5897\n",
            "Epoch 685/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9983 - accuracy: 0.6343 - val_loss: 0.9278 - val_accuracy: 0.6282\n",
            "Epoch 686/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9560 - accuracy: 0.6278 - val_loss: 1.0003 - val_accuracy: 0.5385\n",
            "Epoch 687/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9864 - accuracy: 0.5922 - val_loss: 0.8907 - val_accuracy: 0.5897\n",
            "Epoch 688/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9094 - accuracy: 0.6472 - val_loss: 0.9263 - val_accuracy: 0.5641\n",
            "Epoch 689/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9251 - accuracy: 0.6570 - val_loss: 0.9083 - val_accuracy: 0.6026\n",
            "Epoch 690/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9406 - accuracy: 0.6537 - val_loss: 0.9760 - val_accuracy: 0.6026\n",
            "Epoch 691/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9033 - accuracy: 0.6408 - val_loss: 0.9429 - val_accuracy: 0.5897\n",
            "Epoch 692/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8951 - accuracy: 0.6505 - val_loss: 0.8642 - val_accuracy: 0.6282\n",
            "Epoch 693/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9575 - accuracy: 0.6117 - val_loss: 0.9717 - val_accuracy: 0.6026\n",
            "Epoch 694/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9476 - accuracy: 0.6052 - val_loss: 0.9262 - val_accuracy: 0.5769\n",
            "Epoch 695/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9779 - accuracy: 0.6052 - val_loss: 0.9392 - val_accuracy: 0.6410\n",
            "Epoch 696/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9072 - accuracy: 0.6505 - val_loss: 0.9060 - val_accuracy: 0.5769\n",
            "Epoch 697/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9550 - accuracy: 0.6181 - val_loss: 0.9162 - val_accuracy: 0.5897\n",
            "Epoch 698/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9300 - accuracy: 0.6214 - val_loss: 0.8890 - val_accuracy: 0.6282\n",
            "Epoch 699/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8832 - accuracy: 0.6634 - val_loss: 0.9039 - val_accuracy: 0.5897\n",
            "Epoch 700/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9378 - accuracy: 0.6375 - val_loss: 0.9574 - val_accuracy: 0.5897\n",
            "Epoch 701/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8699 - accuracy: 0.6472 - val_loss: 0.9104 - val_accuracy: 0.6282\n",
            "Epoch 702/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9597 - accuracy: 0.6181 - val_loss: 0.8648 - val_accuracy: 0.6154\n",
            "Epoch 703/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9573 - accuracy: 0.6311 - val_loss: 0.9442 - val_accuracy: 0.6026\n",
            "Epoch 704/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9059 - accuracy: 0.6408 - val_loss: 0.9894 - val_accuracy: 0.5769\n",
            "Epoch 705/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8944 - accuracy: 0.6570 - val_loss: 0.8767 - val_accuracy: 0.5641\n",
            "Epoch 706/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9744 - accuracy: 0.6343 - val_loss: 0.8732 - val_accuracy: 0.6154\n",
            "Epoch 707/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9214 - accuracy: 0.6408 - val_loss: 0.8714 - val_accuracy: 0.6154\n",
            "Epoch 708/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1714 - accuracy: 0.6278 - val_loss: 1.0513 - val_accuracy: 0.5128\n",
            "Epoch 709/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0246 - accuracy: 0.5566 - val_loss: 1.3685 - val_accuracy: 0.5256\n",
            "Epoch 710/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0194 - accuracy: 0.5922 - val_loss: 0.9342 - val_accuracy: 0.6154\n",
            "Epoch 711/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8718 - accuracy: 0.6311 - val_loss: 0.9932 - val_accuracy: 0.6026\n",
            "Epoch 712/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0016 - accuracy: 0.6246 - val_loss: 1.0990 - val_accuracy: 0.5769\n",
            "Epoch 713/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 1.0481 - accuracy: 0.5696 - val_loss: 0.9527 - val_accuracy: 0.5897\n",
            "Epoch 714/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9969 - accuracy: 0.6117 - val_loss: 0.9862 - val_accuracy: 0.5897\n",
            "Epoch 715/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9898 - accuracy: 0.6375 - val_loss: 1.0550 - val_accuracy: 0.5769\n",
            "Epoch 716/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0704 - accuracy: 0.5599 - val_loss: 1.0472 - val_accuracy: 0.5641\n",
            "Epoch 717/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0586 - accuracy: 0.5631 - val_loss: 0.9969 - val_accuracy: 0.6026\n",
            "Epoch 718/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0367 - accuracy: 0.5987 - val_loss: 0.9694 - val_accuracy: 0.5769\n",
            "Epoch 719/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9299 - accuracy: 0.5955 - val_loss: 0.9836 - val_accuracy: 0.5513\n",
            "Epoch 720/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1117 - accuracy: 0.5696 - val_loss: 1.1296 - val_accuracy: 0.5000\n",
            "Epoch 721/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0678 - accuracy: 0.5566 - val_loss: 1.0941 - val_accuracy: 0.5641\n",
            "Epoch 722/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0098 - accuracy: 0.5987 - val_loss: 0.9887 - val_accuracy: 0.5385\n",
            "Epoch 723/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9212 - accuracy: 0.6311 - val_loss: 0.9763 - val_accuracy: 0.5513\n",
            "Epoch 724/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9657 - accuracy: 0.6149 - val_loss: 0.9730 - val_accuracy: 0.5897\n",
            "Epoch 725/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0095 - accuracy: 0.5955 - val_loss: 0.9638 - val_accuracy: 0.5256\n",
            "Epoch 726/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9132 - accuracy: 0.6311 - val_loss: 0.9735 - val_accuracy: 0.5769\n",
            "Epoch 727/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8751 - accuracy: 0.6667 - val_loss: 0.9299 - val_accuracy: 0.5641\n",
            "Epoch 728/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9648 - accuracy: 0.6214 - val_loss: 1.0332 - val_accuracy: 0.5513\n",
            "Epoch 729/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9387 - accuracy: 0.6181 - val_loss: 0.9037 - val_accuracy: 0.6154\n",
            "Epoch 730/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9406 - accuracy: 0.6019 - val_loss: 0.9524 - val_accuracy: 0.5385\n",
            "Epoch 731/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8818 - accuracy: 0.6602 - val_loss: 0.9244 - val_accuracy: 0.6026\n",
            "Epoch 732/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8559 - accuracy: 0.6731 - val_loss: 0.9164 - val_accuracy: 0.5897\n",
            "Epoch 733/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9124 - accuracy: 0.6343 - val_loss: 0.9412 - val_accuracy: 0.6154\n",
            "Epoch 734/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8753 - accuracy: 0.6634 - val_loss: 0.8985 - val_accuracy: 0.5769\n",
            "Epoch 735/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8728 - accuracy: 0.6602 - val_loss: 0.9621 - val_accuracy: 0.6410\n",
            "Epoch 736/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9517 - accuracy: 0.6375 - val_loss: 0.8907 - val_accuracy: 0.6154\n",
            "Epoch 737/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9344 - accuracy: 0.6084 - val_loss: 0.9415 - val_accuracy: 0.6026\n",
            "Epoch 738/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9010 - accuracy: 0.6375 - val_loss: 0.9314 - val_accuracy: 0.5641\n",
            "Epoch 739/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8353 - accuracy: 0.6505 - val_loss: 0.9348 - val_accuracy: 0.6282\n",
            "Epoch 740/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8380 - accuracy: 0.6731 - val_loss: 0.8801 - val_accuracy: 0.6154\n",
            "Epoch 741/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8981 - accuracy: 0.6634 - val_loss: 0.9109 - val_accuracy: 0.5641\n",
            "Epoch 742/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8491 - accuracy: 0.6893 - val_loss: 0.9575 - val_accuracy: 0.6282\n",
            "Epoch 743/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8469 - accuracy: 0.6796 - val_loss: 0.9164 - val_accuracy: 0.6154\n",
            "Epoch 744/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8340 - accuracy: 0.6537 - val_loss: 0.9835 - val_accuracy: 0.5641\n",
            "Epoch 745/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9110 - accuracy: 0.6343 - val_loss: 0.9167 - val_accuracy: 0.5897\n",
            "Epoch 746/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8860 - accuracy: 0.6408 - val_loss: 0.9971 - val_accuracy: 0.5641\n",
            "Epoch 747/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8671 - accuracy: 0.6537 - val_loss: 0.8982 - val_accuracy: 0.6154\n",
            "Epoch 748/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8712 - accuracy: 0.6408 - val_loss: 0.8728 - val_accuracy: 0.6026\n",
            "Epoch 749/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8724 - accuracy: 0.6408 - val_loss: 0.8924 - val_accuracy: 0.6282\n",
            "Epoch 750/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8769 - accuracy: 0.6796 - val_loss: 0.9463 - val_accuracy: 0.5641\n",
            "Epoch 751/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8455 - accuracy: 0.6731 - val_loss: 0.9268 - val_accuracy: 0.6154\n",
            "Epoch 752/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9002 - accuracy: 0.6311 - val_loss: 0.9600 - val_accuracy: 0.5897\n",
            "Epoch 753/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8858 - accuracy: 0.6246 - val_loss: 0.9112 - val_accuracy: 0.6154\n",
            "Epoch 754/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9038 - accuracy: 0.6699 - val_loss: 0.8794 - val_accuracy: 0.6282\n",
            "Epoch 755/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9566 - accuracy: 0.6408 - val_loss: 0.9008 - val_accuracy: 0.5897\n",
            "Epoch 756/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9078 - accuracy: 0.6408 - val_loss: 0.8694 - val_accuracy: 0.6410\n",
            "Epoch 757/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9243 - accuracy: 0.6311 - val_loss: 0.8835 - val_accuracy: 0.5641\n",
            "Epoch 758/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9456 - accuracy: 0.6246 - val_loss: 0.9725 - val_accuracy: 0.5897\n",
            "Epoch 759/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9343 - accuracy: 0.6084 - val_loss: 0.8168 - val_accuracy: 0.6282\n",
            "Epoch 760/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8618 - accuracy: 0.6537 - val_loss: 0.9456 - val_accuracy: 0.5513\n",
            "Epoch 761/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9212 - accuracy: 0.6472 - val_loss: 0.8552 - val_accuracy: 0.6282\n",
            "Epoch 762/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8426 - accuracy: 0.6634 - val_loss: 0.9204 - val_accuracy: 0.6154\n",
            "Epoch 763/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9006 - accuracy: 0.6149 - val_loss: 0.8623 - val_accuracy: 0.6410\n",
            "Epoch 764/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8236 - accuracy: 0.6570 - val_loss: 0.9772 - val_accuracy: 0.6026\n",
            "Epoch 765/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8379 - accuracy: 0.6828 - val_loss: 0.8740 - val_accuracy: 0.6282\n",
            "Epoch 766/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8284 - accuracy: 0.6861 - val_loss: 0.9266 - val_accuracy: 0.5769\n",
            "Epoch 767/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8842 - accuracy: 0.6214 - val_loss: 0.9054 - val_accuracy: 0.6154\n",
            "Epoch 768/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8588 - accuracy: 0.6699 - val_loss: 0.9151 - val_accuracy: 0.5769\n",
            "Epoch 769/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8635 - accuracy: 0.6246 - val_loss: 0.8816 - val_accuracy: 0.6154\n",
            "Epoch 770/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8994 - accuracy: 0.6505 - val_loss: 1.0040 - val_accuracy: 0.5769\n",
            "Epoch 771/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9030 - accuracy: 0.6472 - val_loss: 0.8615 - val_accuracy: 0.6282\n",
            "Epoch 772/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8063 - accuracy: 0.6958 - val_loss: 0.9373 - val_accuracy: 0.5769\n",
            "Epoch 773/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8456 - accuracy: 0.6667 - val_loss: 0.9472 - val_accuracy: 0.5641\n",
            "Epoch 774/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8213 - accuracy: 0.6731 - val_loss: 0.8405 - val_accuracy: 0.6410\n",
            "Epoch 775/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8644 - accuracy: 0.6667 - val_loss: 0.8948 - val_accuracy: 0.6154\n",
            "Epoch 776/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8702 - accuracy: 0.6634 - val_loss: 0.8794 - val_accuracy: 0.5897\n",
            "Epoch 777/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9303 - accuracy: 0.6084 - val_loss: 0.8745 - val_accuracy: 0.6154\n",
            "Epoch 778/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8292 - accuracy: 0.6990 - val_loss: 0.8919 - val_accuracy: 0.6026\n",
            "Epoch 779/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8116 - accuracy: 0.6602 - val_loss: 0.9247 - val_accuracy: 0.6154\n",
            "Epoch 780/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8790 - accuracy: 0.6634 - val_loss: 0.9007 - val_accuracy: 0.6154\n",
            "Epoch 781/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8965 - accuracy: 0.6408 - val_loss: 0.8781 - val_accuracy: 0.5769\n",
            "Epoch 782/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8647 - accuracy: 0.6861 - val_loss: 0.8452 - val_accuracy: 0.6154\n",
            "Epoch 783/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8268 - accuracy: 0.6828 - val_loss: 0.9790 - val_accuracy: 0.5897\n",
            "Epoch 784/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9067 - accuracy: 0.6181 - val_loss: 0.9098 - val_accuracy: 0.6282\n",
            "Epoch 785/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8457 - accuracy: 0.6699 - val_loss: 0.8758 - val_accuracy: 0.6538\n",
            "Epoch 786/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7960 - accuracy: 0.6699 - val_loss: 0.8927 - val_accuracy: 0.5641\n",
            "Epoch 787/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9524 - accuracy: 0.6343 - val_loss: 0.9064 - val_accuracy: 0.6026\n",
            "Epoch 788/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9032 - accuracy: 0.6440 - val_loss: 0.9616 - val_accuracy: 0.5897\n",
            "Epoch 789/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9307 - accuracy: 0.6149 - val_loss: 0.9883 - val_accuracy: 0.5641\n",
            "Epoch 790/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8812 - accuracy: 0.6667 - val_loss: 0.9061 - val_accuracy: 0.6026\n",
            "Epoch 791/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8917 - accuracy: 0.6278 - val_loss: 0.9893 - val_accuracy: 0.6026\n",
            "Epoch 792/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0077 - accuracy: 0.5987 - val_loss: 0.9188 - val_accuracy: 0.6154\n",
            "Epoch 793/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9825 - accuracy: 0.6181 - val_loss: 0.8959 - val_accuracy: 0.5897\n",
            "Epoch 794/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8757 - accuracy: 0.6052 - val_loss: 0.9013 - val_accuracy: 0.6026\n",
            "Epoch 795/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8716 - accuracy: 0.6861 - val_loss: 0.9503 - val_accuracy: 0.6154\n",
            "Epoch 796/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8750 - accuracy: 0.6343 - val_loss: 0.9011 - val_accuracy: 0.6026\n",
            "Epoch 797/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9114 - accuracy: 0.6149 - val_loss: 0.9633 - val_accuracy: 0.5897\n",
            "Epoch 798/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9195 - accuracy: 0.6440 - val_loss: 0.9737 - val_accuracy: 0.5385\n",
            "Epoch 799/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8791 - accuracy: 0.6311 - val_loss: 0.9256 - val_accuracy: 0.5513\n",
            "Epoch 800/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8547 - accuracy: 0.6246 - val_loss: 0.8631 - val_accuracy: 0.5897\n",
            "Epoch 801/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8867 - accuracy: 0.6634 - val_loss: 0.9218 - val_accuracy: 0.5897\n",
            "Epoch 802/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9133 - accuracy: 0.6117 - val_loss: 0.8457 - val_accuracy: 0.6026\n",
            "Epoch 803/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8813 - accuracy: 0.6537 - val_loss: 0.8594 - val_accuracy: 0.6410\n",
            "Epoch 804/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9548 - accuracy: 0.6019 - val_loss: 0.9724 - val_accuracy: 0.5513\n",
            "Epoch 805/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8989 - accuracy: 0.6570 - val_loss: 0.9612 - val_accuracy: 0.6026\n",
            "Epoch 806/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8661 - accuracy: 0.6699 - val_loss: 0.9199 - val_accuracy: 0.5897\n",
            "Epoch 807/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8811 - accuracy: 0.6472 - val_loss: 0.8159 - val_accuracy: 0.6795\n",
            "Epoch 808/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8672 - accuracy: 0.6667 - val_loss: 0.9183 - val_accuracy: 0.5769\n",
            "Epoch 809/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9418 - accuracy: 0.6343 - val_loss: 1.1257 - val_accuracy: 0.4872\n",
            "Epoch 810/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9817 - accuracy: 0.6117 - val_loss: 1.0118 - val_accuracy: 0.5897\n",
            "Epoch 811/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9243 - accuracy: 0.6343 - val_loss: 1.0541 - val_accuracy: 0.5128\n",
            "Epoch 812/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9128 - accuracy: 0.6472 - val_loss: 0.9763 - val_accuracy: 0.5513\n",
            "Epoch 813/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8842 - accuracy: 0.6278 - val_loss: 0.8952 - val_accuracy: 0.5769\n",
            "Epoch 814/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8603 - accuracy: 0.6699 - val_loss: 0.8161 - val_accuracy: 0.6538\n",
            "Epoch 815/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8669 - accuracy: 0.6731 - val_loss: 0.8765 - val_accuracy: 0.6538\n",
            "Epoch 816/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9989 - accuracy: 0.5793 - val_loss: 0.9126 - val_accuracy: 0.6026\n",
            "Epoch 817/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9163 - accuracy: 0.6311 - val_loss: 0.9617 - val_accuracy: 0.5128\n",
            "Epoch 818/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8758 - accuracy: 0.6375 - val_loss: 0.9467 - val_accuracy: 0.6154\n",
            "Epoch 819/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8403 - accuracy: 0.6893 - val_loss: 0.9125 - val_accuracy: 0.6026\n",
            "Epoch 820/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8869 - accuracy: 0.6408 - val_loss: 0.9107 - val_accuracy: 0.5641\n",
            "Epoch 821/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9065 - accuracy: 0.6634 - val_loss: 0.9273 - val_accuracy: 0.6026\n",
            "Epoch 822/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8806 - accuracy: 0.6408 - val_loss: 0.9389 - val_accuracy: 0.6538\n",
            "Epoch 823/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8742 - accuracy: 0.6570 - val_loss: 0.9126 - val_accuracy: 0.5897\n",
            "Epoch 824/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8527 - accuracy: 0.6537 - val_loss: 0.9192 - val_accuracy: 0.6026\n",
            "Epoch 825/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8332 - accuracy: 0.6731 - val_loss: 0.9104 - val_accuracy: 0.6154\n",
            "Epoch 826/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9401 - accuracy: 0.6019 - val_loss: 0.9661 - val_accuracy: 0.5769\n",
            "Epoch 827/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.9370 - accuracy: 0.6019 - val_loss: 0.9623 - val_accuracy: 0.5769\n",
            "Epoch 828/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9425 - accuracy: 0.6246 - val_loss: 0.9703 - val_accuracy: 0.5385\n",
            "Epoch 829/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0102 - accuracy: 0.5825 - val_loss: 0.9859 - val_accuracy: 0.5897\n",
            "Epoch 830/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9598 - accuracy: 0.6117 - val_loss: 0.9642 - val_accuracy: 0.5897\n",
            "Epoch 831/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9027 - accuracy: 0.6375 - val_loss: 0.8848 - val_accuracy: 0.6154\n",
            "Epoch 832/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8767 - accuracy: 0.6893 - val_loss: 0.8832 - val_accuracy: 0.6026\n",
            "Epoch 833/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8806 - accuracy: 0.6472 - val_loss: 0.9134 - val_accuracy: 0.5513\n",
            "Epoch 834/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9351 - accuracy: 0.6505 - val_loss: 0.8585 - val_accuracy: 0.6410\n",
            "Epoch 835/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9280 - accuracy: 0.6311 - val_loss: 0.8555 - val_accuracy: 0.6154\n",
            "Epoch 836/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8577 - accuracy: 0.6731 - val_loss: 0.9733 - val_accuracy: 0.6026\n",
            "Epoch 837/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8830 - accuracy: 0.6343 - val_loss: 0.9328 - val_accuracy: 0.5897\n",
            "Epoch 838/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8766 - accuracy: 0.6278 - val_loss: 0.8906 - val_accuracy: 0.6282\n",
            "Epoch 839/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9207 - accuracy: 0.6343 - val_loss: 0.8990 - val_accuracy: 0.6026\n",
            "Epoch 840/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9120 - accuracy: 0.6246 - val_loss: 0.9274 - val_accuracy: 0.6026\n",
            "Epoch 841/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8713 - accuracy: 0.6537 - val_loss: 0.8942 - val_accuracy: 0.6282\n",
            "Epoch 842/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8583 - accuracy: 0.6440 - val_loss: 0.9410 - val_accuracy: 0.6282\n",
            "Epoch 843/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9250 - accuracy: 0.6375 - val_loss: 0.9312 - val_accuracy: 0.5769\n",
            "Epoch 844/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8927 - accuracy: 0.6052 - val_loss: 0.9207 - val_accuracy: 0.6026\n",
            "Epoch 845/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9186 - accuracy: 0.6311 - val_loss: 0.9025 - val_accuracy: 0.6282\n",
            "Epoch 846/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9244 - accuracy: 0.6084 - val_loss: 0.9893 - val_accuracy: 0.5385\n",
            "Epoch 847/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9030 - accuracy: 0.6375 - val_loss: 0.9163 - val_accuracy: 0.6410\n",
            "Epoch 848/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9616 - accuracy: 0.6149 - val_loss: 0.9876 - val_accuracy: 0.6282\n",
            "Epoch 849/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9381 - accuracy: 0.6149 - val_loss: 0.9389 - val_accuracy: 0.5897\n",
            "Epoch 850/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9099 - accuracy: 0.6537 - val_loss: 0.9405 - val_accuracy: 0.5897\n",
            "Epoch 851/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9254 - accuracy: 0.6246 - val_loss: 1.0245 - val_accuracy: 0.5513\n",
            "Epoch 852/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9447 - accuracy: 0.6246 - val_loss: 1.0359 - val_accuracy: 0.5897\n",
            "Epoch 853/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 1.0063 - accuracy: 0.5761 - val_loss: 0.8627 - val_accuracy: 0.6410\n",
            "Epoch 854/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9706 - accuracy: 0.6019 - val_loss: 0.9705 - val_accuracy: 0.5897\n",
            "Epoch 855/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9946 - accuracy: 0.6052 - val_loss: 0.9061 - val_accuracy: 0.5769\n",
            "Epoch 856/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9360 - accuracy: 0.6246 - val_loss: 0.8843 - val_accuracy: 0.5769\n",
            "Epoch 857/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9177 - accuracy: 0.5955 - val_loss: 1.0312 - val_accuracy: 0.5000\n",
            "Epoch 858/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9577 - accuracy: 0.6181 - val_loss: 0.9163 - val_accuracy: 0.6154\n",
            "Epoch 859/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9444 - accuracy: 0.6019 - val_loss: 0.9312 - val_accuracy: 0.6282\n",
            "Epoch 860/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9961 - accuracy: 0.5955 - val_loss: 1.0579 - val_accuracy: 0.5256\n",
            "Epoch 861/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 1.0327 - accuracy: 0.5793 - val_loss: 0.8842 - val_accuracy: 0.6282\n",
            "Epoch 862/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9008 - accuracy: 0.6343 - val_loss: 0.8941 - val_accuracy: 0.6026\n",
            "Epoch 863/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8943 - accuracy: 0.6278 - val_loss: 0.9369 - val_accuracy: 0.6026\n",
            "Epoch 864/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8888 - accuracy: 0.6472 - val_loss: 0.9609 - val_accuracy: 0.5641\n",
            "Epoch 865/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8385 - accuracy: 0.6602 - val_loss: 0.9055 - val_accuracy: 0.6026\n",
            "Epoch 866/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8397 - accuracy: 0.6537 - val_loss: 0.9269 - val_accuracy: 0.5769\n",
            "Epoch 867/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9129 - accuracy: 0.6311 - val_loss: 0.9405 - val_accuracy: 0.6538\n",
            "Epoch 868/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8929 - accuracy: 0.6375 - val_loss: 0.8972 - val_accuracy: 0.6282\n",
            "Epoch 869/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9107 - accuracy: 0.6278 - val_loss: 1.0441 - val_accuracy: 0.5256\n",
            "Epoch 870/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8648 - accuracy: 0.6796 - val_loss: 0.8318 - val_accuracy: 0.6667\n",
            "Epoch 871/2000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.9057 - accuracy: 0.6408 - val_loss: 0.9119 - val_accuracy: 0.6282\n",
            "Epoch 872/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9135 - accuracy: 0.6181 - val_loss: 0.8833 - val_accuracy: 0.6282\n",
            "Epoch 873/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9274 - accuracy: 0.6311 - val_loss: 0.9162 - val_accuracy: 0.6026\n",
            "Epoch 874/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9280 - accuracy: 0.6181 - val_loss: 0.9417 - val_accuracy: 0.6026\n",
            "Epoch 875/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9140 - accuracy: 0.5922 - val_loss: 1.0131 - val_accuracy: 0.5256\n",
            "Epoch 876/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9327 - accuracy: 0.6311 - val_loss: 0.9257 - val_accuracy: 0.6026\n",
            "Epoch 877/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9570 - accuracy: 0.5890 - val_loss: 0.8578 - val_accuracy: 0.6410\n",
            "Epoch 878/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8795 - accuracy: 0.6472 - val_loss: 0.9649 - val_accuracy: 0.6282\n",
            "Epoch 879/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8169 - accuracy: 0.6634 - val_loss: 0.9264 - val_accuracy: 0.6154\n",
            "Epoch 880/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8797 - accuracy: 0.6440 - val_loss: 0.9160 - val_accuracy: 0.6026\n",
            "Epoch 881/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8818 - accuracy: 0.6505 - val_loss: 0.9241 - val_accuracy: 0.6026\n",
            "Epoch 882/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8598 - accuracy: 0.6602 - val_loss: 0.9314 - val_accuracy: 0.5641\n",
            "Epoch 883/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8832 - accuracy: 0.6311 - val_loss: 0.8749 - val_accuracy: 0.6282\n",
            "Epoch 884/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8996 - accuracy: 0.6278 - val_loss: 0.9668 - val_accuracy: 0.5897\n",
            "Epoch 885/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8368 - accuracy: 0.6861 - val_loss: 0.8729 - val_accuracy: 0.6410\n",
            "Epoch 886/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8317 - accuracy: 0.6731 - val_loss: 0.9403 - val_accuracy: 0.5641\n",
            "Epoch 887/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8743 - accuracy: 0.6667 - val_loss: 0.8858 - val_accuracy: 0.6410\n",
            "Epoch 888/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8755 - accuracy: 0.6472 - val_loss: 0.9238 - val_accuracy: 0.5641\n",
            "Epoch 889/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8677 - accuracy: 0.6731 - val_loss: 0.8898 - val_accuracy: 0.6282\n",
            "Epoch 890/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8527 - accuracy: 0.6472 - val_loss: 0.8616 - val_accuracy: 0.6410\n",
            "Epoch 891/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8468 - accuracy: 0.6505 - val_loss: 0.8987 - val_accuracy: 0.6026\n",
            "Epoch 892/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8783 - accuracy: 0.6408 - val_loss: 0.8734 - val_accuracy: 0.6154\n",
            "Epoch 893/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8440 - accuracy: 0.6602 - val_loss: 0.9449 - val_accuracy: 0.5769\n",
            "Epoch 894/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9038 - accuracy: 0.6246 - val_loss: 0.8787 - val_accuracy: 0.6410\n",
            "Epoch 895/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8493 - accuracy: 0.6537 - val_loss: 1.2337 - val_accuracy: 0.5000\n",
            "Epoch 896/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9430 - accuracy: 0.6181 - val_loss: 0.9098 - val_accuracy: 0.6154\n",
            "Epoch 897/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9908 - accuracy: 0.6019 - val_loss: 0.9518 - val_accuracy: 0.5513\n",
            "Epoch 898/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9326 - accuracy: 0.6278 - val_loss: 0.9658 - val_accuracy: 0.5385\n",
            "Epoch 899/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.7778 - accuracy: 0.6764 - val_loss: 0.9350 - val_accuracy: 0.6154\n",
            "Epoch 900/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8757 - accuracy: 0.6764 - val_loss: 0.9469 - val_accuracy: 0.5769\n",
            "Epoch 901/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8886 - accuracy: 0.6052 - val_loss: 0.8786 - val_accuracy: 0.6154\n",
            "Epoch 902/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8867 - accuracy: 0.6278 - val_loss: 0.9412 - val_accuracy: 0.5513\n",
            "Epoch 903/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8126 - accuracy: 0.6667 - val_loss: 0.8847 - val_accuracy: 0.6026\n",
            "Epoch 904/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8572 - accuracy: 0.6117 - val_loss: 0.8474 - val_accuracy: 0.6538\n",
            "Epoch 905/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8544 - accuracy: 0.6570 - val_loss: 0.8448 - val_accuracy: 0.6154\n",
            "Epoch 906/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.7903 - accuracy: 0.6893 - val_loss: 0.8857 - val_accuracy: 0.6026\n",
            "Epoch 907/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9421 - accuracy: 0.6343 - val_loss: 0.8812 - val_accuracy: 0.6026\n",
            "Epoch 908/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8529 - accuracy: 0.6828 - val_loss: 0.8418 - val_accuracy: 0.6410\n",
            "Epoch 909/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8056 - accuracy: 0.6602 - val_loss: 0.9067 - val_accuracy: 0.5897\n",
            "Epoch 910/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8464 - accuracy: 0.6667 - val_loss: 0.8972 - val_accuracy: 0.6026\n",
            "Epoch 911/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7903 - accuracy: 0.6926 - val_loss: 0.8973 - val_accuracy: 0.5641\n",
            "Epoch 912/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7979 - accuracy: 0.6667 - val_loss: 0.8315 - val_accuracy: 0.6538\n",
            "Epoch 913/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8000 - accuracy: 0.6731 - val_loss: 0.9639 - val_accuracy: 0.5641\n",
            "Epoch 914/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8344 - accuracy: 0.6505 - val_loss: 0.8852 - val_accuracy: 0.5641\n",
            "Epoch 915/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8324 - accuracy: 0.6667 - val_loss: 0.9646 - val_accuracy: 0.5385\n",
            "Epoch 916/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8236 - accuracy: 0.6570 - val_loss: 0.9213 - val_accuracy: 0.5897\n",
            "Epoch 917/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8826 - accuracy: 0.6375 - val_loss: 1.0464 - val_accuracy: 0.5256\n",
            "Epoch 918/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8522 - accuracy: 0.6117 - val_loss: 0.8982 - val_accuracy: 0.6154\n",
            "Epoch 919/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8193 - accuracy: 0.6537 - val_loss: 0.7995 - val_accuracy: 0.6410\n",
            "Epoch 920/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8510 - accuracy: 0.6343 - val_loss: 0.8473 - val_accuracy: 0.6282\n",
            "Epoch 921/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8457 - accuracy: 0.6537 - val_loss: 0.9449 - val_accuracy: 0.5513\n",
            "Epoch 922/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8702 - accuracy: 0.6440 - val_loss: 0.8270 - val_accuracy: 0.6154\n",
            "Epoch 923/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8435 - accuracy: 0.6440 - val_loss: 0.9368 - val_accuracy: 0.5897\n",
            "Epoch 924/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8503 - accuracy: 0.6537 - val_loss: 0.9079 - val_accuracy: 0.6282\n",
            "Epoch 925/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8158 - accuracy: 0.6570 - val_loss: 1.1112 - val_accuracy: 0.5256\n",
            "Epoch 926/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9205 - accuracy: 0.6246 - val_loss: 0.8469 - val_accuracy: 0.6282\n",
            "Epoch 927/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8348 - accuracy: 0.6699 - val_loss: 0.9114 - val_accuracy: 0.6282\n",
            "Epoch 928/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8396 - accuracy: 0.6570 - val_loss: 0.8494 - val_accuracy: 0.6410\n",
            "Epoch 929/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7719 - accuracy: 0.6731 - val_loss: 0.8688 - val_accuracy: 0.6282\n",
            "Epoch 930/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8470 - accuracy: 0.6537 - val_loss: 0.9094 - val_accuracy: 0.5769\n",
            "Epoch 931/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.7960 - accuracy: 0.6667 - val_loss: 0.8790 - val_accuracy: 0.6026\n",
            "Epoch 932/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.7854 - accuracy: 0.6764 - val_loss: 1.0042 - val_accuracy: 0.5641\n",
            "Epoch 933/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8199 - accuracy: 0.6667 - val_loss: 0.8569 - val_accuracy: 0.6026\n",
            "Epoch 934/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8978 - accuracy: 0.6440 - val_loss: 0.8855 - val_accuracy: 0.6026\n",
            "Epoch 935/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8676 - accuracy: 0.6570 - val_loss: 0.9159 - val_accuracy: 0.6026\n",
            "Epoch 936/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8471 - accuracy: 0.6246 - val_loss: 0.8854 - val_accuracy: 0.6154\n",
            "Epoch 937/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8991 - accuracy: 0.6278 - val_loss: 0.8568 - val_accuracy: 0.6410\n",
            "Epoch 938/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9794 - accuracy: 0.5955 - val_loss: 0.8565 - val_accuracy: 0.6410\n",
            "Epoch 939/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9030 - accuracy: 0.6375 - val_loss: 0.8209 - val_accuracy: 0.6282\n",
            "Epoch 940/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8345 - accuracy: 0.6343 - val_loss: 0.9585 - val_accuracy: 0.5513\n",
            "Epoch 941/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8345 - accuracy: 0.6796 - val_loss: 0.8925 - val_accuracy: 0.5897\n",
            "Epoch 942/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8607 - accuracy: 0.6537 - val_loss: 0.8178 - val_accuracy: 0.6282\n",
            "Epoch 943/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8637 - accuracy: 0.6570 - val_loss: 0.8544 - val_accuracy: 0.6154\n",
            "Epoch 944/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.7978 - accuracy: 0.6667 - val_loss: 0.8719 - val_accuracy: 0.6282\n",
            "Epoch 945/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8794 - accuracy: 0.6764 - val_loss: 0.8888 - val_accuracy: 0.6026\n",
            "Epoch 946/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8097 - accuracy: 0.6861 - val_loss: 0.8480 - val_accuracy: 0.5897\n",
            "Epoch 947/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8834 - accuracy: 0.6537 - val_loss: 0.7994 - val_accuracy: 0.6667\n",
            "Epoch 948/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9602 - accuracy: 0.6181 - val_loss: 0.9861 - val_accuracy: 0.5897\n",
            "Epoch 949/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0006 - accuracy: 0.6019 - val_loss: 0.9392 - val_accuracy: 0.5385\n",
            "Epoch 950/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9628 - accuracy: 0.6084 - val_loss: 0.9356 - val_accuracy: 0.5641\n",
            "Epoch 951/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9392 - accuracy: 0.6311 - val_loss: 0.8561 - val_accuracy: 0.6538\n",
            "Epoch 952/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8844 - accuracy: 0.6537 - val_loss: 0.8642 - val_accuracy: 0.6026\n",
            "Epoch 953/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8480 - accuracy: 0.6570 - val_loss: 0.8661 - val_accuracy: 0.6154\n",
            "Epoch 954/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8791 - accuracy: 0.6408 - val_loss: 0.9311 - val_accuracy: 0.5897\n",
            "Epoch 955/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8928 - accuracy: 0.6278 - val_loss: 1.0786 - val_accuracy: 0.5513\n",
            "Epoch 956/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9302 - accuracy: 0.6440 - val_loss: 0.8597 - val_accuracy: 0.6154\n",
            "Epoch 957/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9093 - accuracy: 0.6375 - val_loss: 0.8934 - val_accuracy: 0.6026\n",
            "Epoch 958/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9669 - accuracy: 0.6019 - val_loss: 0.9566 - val_accuracy: 0.5769\n",
            "Epoch 959/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9286 - accuracy: 0.6408 - val_loss: 0.9258 - val_accuracy: 0.6410\n",
            "Epoch 960/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9802 - accuracy: 0.6181 - val_loss: 0.9319 - val_accuracy: 0.6154\n",
            "Epoch 961/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9514 - accuracy: 0.6181 - val_loss: 0.8982 - val_accuracy: 0.5897\n",
            "Epoch 962/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8832 - accuracy: 0.6246 - val_loss: 0.8485 - val_accuracy: 0.6154\n",
            "Epoch 963/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8869 - accuracy: 0.6667 - val_loss: 0.8650 - val_accuracy: 0.6410\n",
            "Epoch 964/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8169 - accuracy: 0.7087 - val_loss: 0.9204 - val_accuracy: 0.5897\n",
            "Epoch 965/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9554 - accuracy: 0.5922 - val_loss: 0.9306 - val_accuracy: 0.5641\n",
            "Epoch 966/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9964 - accuracy: 0.6052 - val_loss: 0.9396 - val_accuracy: 0.5513\n",
            "Epoch 967/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8902 - accuracy: 0.6278 - val_loss: 0.8493 - val_accuracy: 0.5897\n",
            "Epoch 968/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8844 - accuracy: 0.6667 - val_loss: 0.9716 - val_accuracy: 0.5769\n",
            "Epoch 969/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9021 - accuracy: 0.6505 - val_loss: 0.9704 - val_accuracy: 0.5513\n",
            "Epoch 970/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8683 - accuracy: 0.6667 - val_loss: 0.9282 - val_accuracy: 0.6154\n",
            "Epoch 971/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9201 - accuracy: 0.6214 - val_loss: 0.9195 - val_accuracy: 0.6026\n",
            "Epoch 972/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9287 - accuracy: 0.6343 - val_loss: 0.9349 - val_accuracy: 0.6026\n",
            "Epoch 973/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0235 - accuracy: 0.6311 - val_loss: 0.9124 - val_accuracy: 0.6154\n",
            "Epoch 974/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9594 - accuracy: 0.5890 - val_loss: 1.0851 - val_accuracy: 0.5256\n",
            "Epoch 975/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8426 - accuracy: 0.6634 - val_loss: 0.8356 - val_accuracy: 0.6410\n",
            "Epoch 976/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8762 - accuracy: 0.6343 - val_loss: 0.8685 - val_accuracy: 0.6667\n",
            "Epoch 977/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8718 - accuracy: 0.6764 - val_loss: 0.9705 - val_accuracy: 0.6026\n",
            "Epoch 978/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8740 - accuracy: 0.6408 - val_loss: 0.8268 - val_accuracy: 0.6282\n",
            "Epoch 979/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8863 - accuracy: 0.6505 - val_loss: 0.8481 - val_accuracy: 0.6282\n",
            "Epoch 980/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8681 - accuracy: 0.6634 - val_loss: 0.8652 - val_accuracy: 0.6282\n",
            "Epoch 981/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8845 - accuracy: 0.6214 - val_loss: 0.9114 - val_accuracy: 0.5897\n",
            "Epoch 982/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8716 - accuracy: 0.6505 - val_loss: 0.8665 - val_accuracy: 0.5897\n",
            "Epoch 983/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9428 - accuracy: 0.6181 - val_loss: 1.0171 - val_accuracy: 0.5385\n",
            "Epoch 984/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8688 - accuracy: 0.6375 - val_loss: 0.8970 - val_accuracy: 0.6282\n",
            "Epoch 985/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8689 - accuracy: 0.6570 - val_loss: 0.8273 - val_accuracy: 0.6667\n",
            "Epoch 986/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8477 - accuracy: 0.6796 - val_loss: 0.8393 - val_accuracy: 0.6026\n",
            "Epoch 987/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8906 - accuracy: 0.6278 - val_loss: 0.8832 - val_accuracy: 0.6026\n",
            "Epoch 988/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9059 - accuracy: 0.6472 - val_loss: 0.9796 - val_accuracy: 0.5385\n",
            "Epoch 989/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9249 - accuracy: 0.6084 - val_loss: 1.0973 - val_accuracy: 0.5641\n",
            "Epoch 990/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9166 - accuracy: 0.6214 - val_loss: 1.0155 - val_accuracy: 0.6538\n",
            "Epoch 991/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9850 - accuracy: 0.6181 - val_loss: 0.8514 - val_accuracy: 0.6026\n",
            "Epoch 992/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8873 - accuracy: 0.6440 - val_loss: 0.8911 - val_accuracy: 0.5769\n",
            "Epoch 993/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8689 - accuracy: 0.6796 - val_loss: 0.8315 - val_accuracy: 0.6282\n",
            "Epoch 994/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8570 - accuracy: 0.6634 - val_loss: 0.8213 - val_accuracy: 0.6667\n",
            "Epoch 995/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8466 - accuracy: 0.6893 - val_loss: 0.9323 - val_accuracy: 0.5641\n",
            "Epoch 996/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8942 - accuracy: 0.6440 - val_loss: 0.8862 - val_accuracy: 0.6154\n",
            "Epoch 997/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8222 - accuracy: 0.6667 - val_loss: 0.8292 - val_accuracy: 0.6410\n",
            "Epoch 998/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8165 - accuracy: 0.6990 - val_loss: 0.8501 - val_accuracy: 0.6154\n",
            "Epoch 999/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9196 - accuracy: 0.6375 - val_loss: 0.8573 - val_accuracy: 0.5769\n",
            "Epoch 1000/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9098 - accuracy: 0.6311 - val_loss: 0.8765 - val_accuracy: 0.6154\n",
            "Epoch 1001/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9235 - accuracy: 0.6311 - val_loss: 0.8083 - val_accuracy: 0.5769\n",
            "Epoch 1002/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8585 - accuracy: 0.6634 - val_loss: 0.9989 - val_accuracy: 0.5641\n",
            "Epoch 1003/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8397 - accuracy: 0.6440 - val_loss: 0.8926 - val_accuracy: 0.5769\n",
            "Epoch 1004/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9109 - accuracy: 0.6375 - val_loss: 0.9113 - val_accuracy: 0.6154\n",
            "Epoch 1005/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9126 - accuracy: 0.6019 - val_loss: 0.9043 - val_accuracy: 0.6410\n",
            "Epoch 1006/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9599 - accuracy: 0.5890 - val_loss: 0.8984 - val_accuracy: 0.5769\n",
            "Epoch 1007/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8861 - accuracy: 0.6440 - val_loss: 1.0423 - val_accuracy: 0.5513\n",
            "Epoch 1008/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8225 - accuracy: 0.6796 - val_loss: 0.8413 - val_accuracy: 0.6282\n",
            "Epoch 1009/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8959 - accuracy: 0.6602 - val_loss: 0.8937 - val_accuracy: 0.5641\n",
            "Epoch 1010/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8987 - accuracy: 0.6343 - val_loss: 0.9052 - val_accuracy: 0.5897\n",
            "Epoch 1011/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8006 - accuracy: 0.6699 - val_loss: 0.9456 - val_accuracy: 0.5641\n",
            "Epoch 1012/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9094 - accuracy: 0.6570 - val_loss: 0.9151 - val_accuracy: 0.5897\n",
            "Epoch 1013/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9438 - accuracy: 0.6181 - val_loss: 0.9313 - val_accuracy: 0.6026\n",
            "Epoch 1014/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8688 - accuracy: 0.6440 - val_loss: 0.8952 - val_accuracy: 0.6154\n",
            "Epoch 1015/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8446 - accuracy: 0.6602 - val_loss: 0.8686 - val_accuracy: 0.6667\n",
            "Epoch 1016/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8369 - accuracy: 0.6861 - val_loss: 0.9359 - val_accuracy: 0.5641\n",
            "Epoch 1017/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8933 - accuracy: 0.6764 - val_loss: 0.9371 - val_accuracy: 0.5641\n",
            "Epoch 1018/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8680 - accuracy: 0.6505 - val_loss: 0.8214 - val_accuracy: 0.6282\n",
            "Epoch 1019/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8965 - accuracy: 0.6570 - val_loss: 0.9127 - val_accuracy: 0.5769\n",
            "Epoch 1020/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8602 - accuracy: 0.6537 - val_loss: 0.8547 - val_accuracy: 0.6154\n",
            "Epoch 1021/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8932 - accuracy: 0.6440 - val_loss: 0.9142 - val_accuracy: 0.5769\n",
            "Epoch 1022/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8413 - accuracy: 0.6699 - val_loss: 0.8912 - val_accuracy: 0.6410\n",
            "Epoch 1023/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.7953 - accuracy: 0.6958 - val_loss: 0.9169 - val_accuracy: 0.6026\n",
            "Epoch 1024/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8268 - accuracy: 0.6667 - val_loss: 0.8926 - val_accuracy: 0.6282\n",
            "Epoch 1025/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8045 - accuracy: 0.6602 - val_loss: 0.8662 - val_accuracy: 0.6026\n",
            "Epoch 1026/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8176 - accuracy: 0.6764 - val_loss: 0.8747 - val_accuracy: 0.6282\n",
            "Epoch 1027/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8589 - accuracy: 0.6311 - val_loss: 0.8300 - val_accuracy: 0.6026\n",
            "Epoch 1028/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8849 - accuracy: 0.6278 - val_loss: 0.9173 - val_accuracy: 0.5769\n",
            "Epoch 1029/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8430 - accuracy: 0.6505 - val_loss: 0.8903 - val_accuracy: 0.5769\n",
            "Epoch 1030/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8975 - accuracy: 0.6311 - val_loss: 0.8146 - val_accuracy: 0.6026\n",
            "Epoch 1031/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8593 - accuracy: 0.6375 - val_loss: 0.9383 - val_accuracy: 0.5769\n",
            "Epoch 1032/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8611 - accuracy: 0.6440 - val_loss: 0.9287 - val_accuracy: 0.5769\n",
            "Epoch 1033/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9538 - accuracy: 0.6278 - val_loss: 1.1330 - val_accuracy: 0.5128\n",
            "Epoch 1034/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9425 - accuracy: 0.6375 - val_loss: 0.9161 - val_accuracy: 0.6154\n",
            "Epoch 1035/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9664 - accuracy: 0.6246 - val_loss: 0.9231 - val_accuracy: 0.5385\n",
            "Epoch 1036/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.9522 - accuracy: 0.5955 - val_loss: 0.8569 - val_accuracy: 0.6026\n",
            "Epoch 1037/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9262 - accuracy: 0.5955 - val_loss: 0.9607 - val_accuracy: 0.5513\n",
            "Epoch 1038/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9231 - accuracy: 0.6117 - val_loss: 0.9165 - val_accuracy: 0.6282\n",
            "Epoch 1039/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8338 - accuracy: 0.6570 - val_loss: 0.8443 - val_accuracy: 0.6282\n",
            "Epoch 1040/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8108 - accuracy: 0.7023 - val_loss: 0.8568 - val_accuracy: 0.6026\n",
            "Epoch 1041/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8587 - accuracy: 0.6602 - val_loss: 0.8786 - val_accuracy: 0.5897\n",
            "Epoch 1042/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8375 - accuracy: 0.6731 - val_loss: 0.8565 - val_accuracy: 0.6154\n",
            "Epoch 1043/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8209 - accuracy: 0.6958 - val_loss: 0.8690 - val_accuracy: 0.6282\n",
            "Epoch 1044/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8403 - accuracy: 0.6570 - val_loss: 0.9286 - val_accuracy: 0.5641\n",
            "Epoch 1045/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8241 - accuracy: 0.6731 - val_loss: 0.8095 - val_accuracy: 0.6795\n",
            "Epoch 1046/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8112 - accuracy: 0.6764 - val_loss: 0.8970 - val_accuracy: 0.5897\n",
            "Epoch 1047/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8163 - accuracy: 0.6796 - val_loss: 0.8066 - val_accuracy: 0.6410\n",
            "Epoch 1048/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8545 - accuracy: 0.6634 - val_loss: 0.8329 - val_accuracy: 0.6154\n",
            "Epoch 1049/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8475 - accuracy: 0.6602 - val_loss: 0.9808 - val_accuracy: 0.5641\n",
            "Epoch 1050/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8819 - accuracy: 0.6214 - val_loss: 0.9421 - val_accuracy: 0.5897\n",
            "Epoch 1051/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8220 - accuracy: 0.6861 - val_loss: 0.8577 - val_accuracy: 0.5769\n",
            "Epoch 1052/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8260 - accuracy: 0.6667 - val_loss: 0.8811 - val_accuracy: 0.6410\n",
            "Epoch 1053/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8729 - accuracy: 0.6408 - val_loss: 0.8525 - val_accuracy: 0.5897\n",
            "Epoch 1054/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.7900 - accuracy: 0.6990 - val_loss: 0.8140 - val_accuracy: 0.6410\n",
            "Epoch 1055/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8971 - accuracy: 0.6311 - val_loss: 0.9094 - val_accuracy: 0.5897\n",
            "Epoch 1056/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8732 - accuracy: 0.6731 - val_loss: 0.8793 - val_accuracy: 0.5897\n",
            "Epoch 1057/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9729 - accuracy: 0.5987 - val_loss: 1.0356 - val_accuracy: 0.5385\n",
            "Epoch 1058/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0090 - accuracy: 0.5955 - val_loss: 0.9227 - val_accuracy: 0.6282\n",
            "Epoch 1059/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8967 - accuracy: 0.6278 - val_loss: 0.8799 - val_accuracy: 0.6282\n",
            "Epoch 1060/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8776 - accuracy: 0.6990 - val_loss: 1.0108 - val_accuracy: 0.5769\n",
            "Epoch 1061/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9855 - accuracy: 0.6343 - val_loss: 0.9595 - val_accuracy: 0.5897\n",
            "Epoch 1062/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9730 - accuracy: 0.6181 - val_loss: 0.9376 - val_accuracy: 0.5769\n",
            "Epoch 1063/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9656 - accuracy: 0.6246 - val_loss: 0.9456 - val_accuracy: 0.5769\n",
            "Epoch 1064/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8593 - accuracy: 0.6343 - val_loss: 0.8408 - val_accuracy: 0.6410\n",
            "Epoch 1065/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8639 - accuracy: 0.6570 - val_loss: 0.9540 - val_accuracy: 0.6026\n",
            "Epoch 1066/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8206 - accuracy: 0.6796 - val_loss: 0.8498 - val_accuracy: 0.6282\n",
            "Epoch 1067/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8156 - accuracy: 0.6634 - val_loss: 0.8972 - val_accuracy: 0.6154\n",
            "Epoch 1068/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8371 - accuracy: 0.6699 - val_loss: 0.9872 - val_accuracy: 0.5641\n",
            "Epoch 1069/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8231 - accuracy: 0.6861 - val_loss: 0.9404 - val_accuracy: 0.5897\n",
            "Epoch 1070/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9493 - accuracy: 0.5922 - val_loss: 0.9217 - val_accuracy: 0.6410\n",
            "Epoch 1071/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9002 - accuracy: 0.6440 - val_loss: 0.9114 - val_accuracy: 0.6282\n",
            "Epoch 1072/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8115 - accuracy: 0.6861 - val_loss: 0.8906 - val_accuracy: 0.6410\n",
            "Epoch 1073/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.7797 - accuracy: 0.7055 - val_loss: 0.8614 - val_accuracy: 0.6410\n",
            "Epoch 1074/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8700 - accuracy: 0.6602 - val_loss: 0.9040 - val_accuracy: 0.6154\n",
            "Epoch 1075/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8663 - accuracy: 0.6570 - val_loss: 0.9635 - val_accuracy: 0.5897\n",
            "Epoch 1076/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8320 - accuracy: 0.6602 - val_loss: 0.8127 - val_accuracy: 0.6410\n",
            "Epoch 1077/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8865 - accuracy: 0.6505 - val_loss: 0.8378 - val_accuracy: 0.6410\n",
            "Epoch 1078/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8885 - accuracy: 0.6505 - val_loss: 0.8685 - val_accuracy: 0.6154\n",
            "Epoch 1079/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.7965 - accuracy: 0.7055 - val_loss: 1.1055 - val_accuracy: 0.5385\n",
            "Epoch 1080/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8137 - accuracy: 0.6958 - val_loss: 0.8272 - val_accuracy: 0.6282\n",
            "Epoch 1081/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8293 - accuracy: 0.6893 - val_loss: 0.8965 - val_accuracy: 0.6154\n",
            "Epoch 1082/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8470 - accuracy: 0.6634 - val_loss: 0.9963 - val_accuracy: 0.5641\n",
            "Epoch 1083/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8258 - accuracy: 0.6570 - val_loss: 1.0066 - val_accuracy: 0.5897\n",
            "Epoch 1084/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9301 - accuracy: 0.6117 - val_loss: 0.9548 - val_accuracy: 0.5897\n",
            "Epoch 1085/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9058 - accuracy: 0.6505 - val_loss: 0.9609 - val_accuracy: 0.5897\n",
            "Epoch 1086/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8507 - accuracy: 0.6796 - val_loss: 1.0663 - val_accuracy: 0.5385\n",
            "Epoch 1087/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8918 - accuracy: 0.6472 - val_loss: 0.9763 - val_accuracy: 0.6410\n",
            "Epoch 1088/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8652 - accuracy: 0.6440 - val_loss: 1.0102 - val_accuracy: 0.5769\n",
            "Epoch 1089/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8885 - accuracy: 0.6505 - val_loss: 0.8953 - val_accuracy: 0.6282\n",
            "Epoch 1090/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8799 - accuracy: 0.6505 - val_loss: 0.8712 - val_accuracy: 0.6538\n",
            "Epoch 1091/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8158 - accuracy: 0.6796 - val_loss: 0.9646 - val_accuracy: 0.5769\n",
            "Epoch 1092/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8663 - accuracy: 0.6408 - val_loss: 1.0386 - val_accuracy: 0.5897\n",
            "Epoch 1093/2000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.7756 - accuracy: 0.6861 - val_loss: 0.8208 - val_accuracy: 0.6667\n",
            "Epoch 1094/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8145 - accuracy: 0.6828 - val_loss: 0.8317 - val_accuracy: 0.6538\n",
            "Epoch 1095/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8565 - accuracy: 0.6505 - val_loss: 1.0109 - val_accuracy: 0.5897\n",
            "Epoch 1096/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.7903 - accuracy: 0.6893 - val_loss: 0.9531 - val_accuracy: 0.5769\n",
            "Epoch 1097/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8067 - accuracy: 0.6861 - val_loss: 0.8884 - val_accuracy: 0.6282\n",
            "Epoch 1098/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8560 - accuracy: 0.6731 - val_loss: 0.8314 - val_accuracy: 0.6282\n",
            "Epoch 1099/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8977 - accuracy: 0.6214 - val_loss: 0.8248 - val_accuracy: 0.6538\n",
            "Epoch 1100/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8383 - accuracy: 0.6731 - val_loss: 0.9268 - val_accuracy: 0.6410\n",
            "Epoch 1101/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8308 - accuracy: 0.6796 - val_loss: 0.9197 - val_accuracy: 0.6282\n",
            "Epoch 1102/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8580 - accuracy: 0.6278 - val_loss: 0.9866 - val_accuracy: 0.5897\n",
            "Epoch 1103/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8036 - accuracy: 0.6764 - val_loss: 0.9227 - val_accuracy: 0.6026\n",
            "Epoch 1104/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8543 - accuracy: 0.6570 - val_loss: 0.8732 - val_accuracy: 0.6154\n",
            "Epoch 1105/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8453 - accuracy: 0.6375 - val_loss: 0.9394 - val_accuracy: 0.6026\n",
            "Epoch 1106/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8032 - accuracy: 0.6828 - val_loss: 0.9443 - val_accuracy: 0.5897\n",
            "Epoch 1107/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8593 - accuracy: 0.6570 - val_loss: 0.9470 - val_accuracy: 0.5897\n",
            "Epoch 1108/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8099 - accuracy: 0.6731 - val_loss: 0.9571 - val_accuracy: 0.6026\n",
            "Epoch 1109/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8857 - accuracy: 0.6472 - val_loss: 1.0424 - val_accuracy: 0.5385\n",
            "Epoch 1110/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9202 - accuracy: 0.6537 - val_loss: 1.0022 - val_accuracy: 0.5897\n",
            "Epoch 1111/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8544 - accuracy: 0.6602 - val_loss: 0.9326 - val_accuracy: 0.6154\n",
            "Epoch 1112/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8737 - accuracy: 0.6570 - val_loss: 0.8457 - val_accuracy: 0.6410\n",
            "Epoch 1113/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8562 - accuracy: 0.6472 - val_loss: 1.0292 - val_accuracy: 0.5641\n",
            "Epoch 1114/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8820 - accuracy: 0.6570 - val_loss: 0.8025 - val_accuracy: 0.6667\n",
            "Epoch 1115/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7708 - accuracy: 0.6828 - val_loss: 0.8849 - val_accuracy: 0.6410\n",
            "Epoch 1116/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.9062 - accuracy: 0.6278 - val_loss: 0.9233 - val_accuracy: 0.6026\n",
            "Epoch 1117/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8108 - accuracy: 0.6634 - val_loss: 0.8467 - val_accuracy: 0.6410\n",
            "Epoch 1118/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8043 - accuracy: 0.6537 - val_loss: 0.8182 - val_accuracy: 0.6538\n",
            "Epoch 1119/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8145 - accuracy: 0.6926 - val_loss: 0.8172 - val_accuracy: 0.6154\n",
            "Epoch 1120/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8214 - accuracy: 0.6667 - val_loss: 0.8877 - val_accuracy: 0.6026\n",
            "Epoch 1121/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8389 - accuracy: 0.6699 - val_loss: 0.8742 - val_accuracy: 0.6154\n",
            "Epoch 1122/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8022 - accuracy: 0.6926 - val_loss: 0.9486 - val_accuracy: 0.6282\n",
            "Epoch 1123/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.7900 - accuracy: 0.6699 - val_loss: 0.8827 - val_accuracy: 0.6667\n",
            "Epoch 1124/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8013 - accuracy: 0.6634 - val_loss: 0.8700 - val_accuracy: 0.6410\n",
            "Epoch 1125/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8352 - accuracy: 0.6764 - val_loss: 0.8457 - val_accuracy: 0.6282\n",
            "Epoch 1126/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8466 - accuracy: 0.6570 - val_loss: 0.8384 - val_accuracy: 0.6282\n",
            "Epoch 1127/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8146 - accuracy: 0.6861 - val_loss: 0.9023 - val_accuracy: 0.6282\n",
            "Epoch 1128/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.7601 - accuracy: 0.6958 - val_loss: 0.8645 - val_accuracy: 0.6538\n",
            "Epoch 1129/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.7685 - accuracy: 0.6926 - val_loss: 0.9500 - val_accuracy: 0.6282\n",
            "Epoch 1130/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8091 - accuracy: 0.7120 - val_loss: 0.8246 - val_accuracy: 0.6538\n",
            "Epoch 1131/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8060 - accuracy: 0.6634 - val_loss: 0.8343 - val_accuracy: 0.6026\n",
            "Epoch 1132/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7525 - accuracy: 0.7023 - val_loss: 0.9684 - val_accuracy: 0.5897\n",
            "Epoch 1133/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7919 - accuracy: 0.7152 - val_loss: 0.9044 - val_accuracy: 0.5641\n",
            "Epoch 1134/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8028 - accuracy: 0.6731 - val_loss: 0.8924 - val_accuracy: 0.6026\n",
            "Epoch 1135/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8403 - accuracy: 0.6667 - val_loss: 0.9050 - val_accuracy: 0.6154\n",
            "Epoch 1136/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8267 - accuracy: 0.6602 - val_loss: 0.9175 - val_accuracy: 0.6282\n",
            "Epoch 1137/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8287 - accuracy: 0.6731 - val_loss: 0.8466 - val_accuracy: 0.6154\n",
            "Epoch 1138/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8255 - accuracy: 0.6408 - val_loss: 0.9529 - val_accuracy: 0.5769\n",
            "Epoch 1139/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8057 - accuracy: 0.6602 - val_loss: 0.8799 - val_accuracy: 0.5897\n",
            "Epoch 1140/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8070 - accuracy: 0.6699 - val_loss: 0.9464 - val_accuracy: 0.6154\n",
            "Epoch 1141/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8699 - accuracy: 0.6343 - val_loss: 0.9227 - val_accuracy: 0.6026\n",
            "Epoch 1142/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.7291 - accuracy: 0.7055 - val_loss: 0.8677 - val_accuracy: 0.6667\n",
            "Epoch 1143/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.7851 - accuracy: 0.6667 - val_loss: 0.9139 - val_accuracy: 0.6154\n",
            "Epoch 1144/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7863 - accuracy: 0.7120 - val_loss: 0.8846 - val_accuracy: 0.6538\n",
            "Epoch 1145/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.7932 - accuracy: 0.6667 - val_loss: 0.8643 - val_accuracy: 0.6410\n",
            "Epoch 1146/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7900 - accuracy: 0.6764 - val_loss: 0.9492 - val_accuracy: 0.5769\n",
            "Epoch 1147/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8579 - accuracy: 0.6699 - val_loss: 1.0565 - val_accuracy: 0.5385\n",
            "Epoch 1148/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.7898 - accuracy: 0.6796 - val_loss: 0.8711 - val_accuracy: 0.6026\n",
            "Epoch 1149/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7657 - accuracy: 0.6893 - val_loss: 1.0151 - val_accuracy: 0.5641\n",
            "Epoch 1150/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8367 - accuracy: 0.6667 - val_loss: 0.9119 - val_accuracy: 0.6026\n",
            "Epoch 1151/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8079 - accuracy: 0.6958 - val_loss: 0.8372 - val_accuracy: 0.6282\n",
            "Epoch 1152/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.7766 - accuracy: 0.6990 - val_loss: 0.8245 - val_accuracy: 0.6410\n",
            "Epoch 1153/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7682 - accuracy: 0.6796 - val_loss: 0.9899 - val_accuracy: 0.5769\n",
            "Epoch 1154/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8262 - accuracy: 0.6570 - val_loss: 0.9438 - val_accuracy: 0.5897\n",
            "Epoch 1155/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8057 - accuracy: 0.6796 - val_loss: 0.9525 - val_accuracy: 0.5641\n",
            "Epoch 1156/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7608 - accuracy: 0.7152 - val_loss: 0.8376 - val_accuracy: 0.6026\n",
            "Epoch 1157/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8478 - accuracy: 0.6505 - val_loss: 0.8014 - val_accuracy: 0.6282\n",
            "Epoch 1158/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8245 - accuracy: 0.7023 - val_loss: 0.9294 - val_accuracy: 0.5641\n",
            "Epoch 1159/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8402 - accuracy: 0.6667 - val_loss: 1.0594 - val_accuracy: 0.5513\n",
            "Epoch 1160/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8324 - accuracy: 0.6731 - val_loss: 0.9806 - val_accuracy: 0.5769\n",
            "Epoch 1161/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8562 - accuracy: 0.6375 - val_loss: 0.9145 - val_accuracy: 0.5897\n",
            "Epoch 1162/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7727 - accuracy: 0.6828 - val_loss: 0.8612 - val_accuracy: 0.5897\n",
            "Epoch 1163/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7895 - accuracy: 0.6958 - val_loss: 0.8866 - val_accuracy: 0.5897\n",
            "Epoch 1164/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8911 - accuracy: 0.6796 - val_loss: 0.8729 - val_accuracy: 0.6154\n",
            "Epoch 1165/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9072 - accuracy: 0.6375 - val_loss: 0.8930 - val_accuracy: 0.5897\n",
            "Epoch 1166/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8575 - accuracy: 0.6861 - val_loss: 0.8465 - val_accuracy: 0.6282\n",
            "Epoch 1167/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8264 - accuracy: 0.6796 - val_loss: 1.0361 - val_accuracy: 0.5641\n",
            "Epoch 1168/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7839 - accuracy: 0.6926 - val_loss: 0.8248 - val_accuracy: 0.6538\n",
            "Epoch 1169/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8424 - accuracy: 0.6472 - val_loss: 0.8677 - val_accuracy: 0.5769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJR5pfQ1c9g4"
      },
      "source": [
        "### Evaluation and Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "413JtwURc9g5",
        "outputId": "4725b60f-af5e-4113-9da3-031d483b06ea"
      },
      "source": [
        "# Evaluate our model on the test set\n",
        "loss, accuracy = model_2.evaluate(X_test, y_test)\n",
        "print(f\"Model loss on the test set: {loss}\")\n",
        "print(f\"Model accuracy on the test set: {100*accuracy:.2f}%\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 5ms/step - loss: 0.7995 - accuracy: 0.6410\n",
            "Model loss on the test set: 0.7994661927223206\n",
            "Model accuracy on the test set: 64.10%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "OJB0Jvw9c9g5",
        "outputId": "124252bd-a206-48f1-edaa-5107209b8409"
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history_2.history['loss'])#[5:])\n",
        "plt.plot(history_2.history['val_loss'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "NOjoGnLic9g6",
        "outputId": "671609fd-bb22-48e4-f317-16e0fa7a3e45"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history_2.history['accuracy'])#[5:])\n",
        "plt.plot(history_2.history['val_accuracy'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Binary Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}