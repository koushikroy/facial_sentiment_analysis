{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "00_sentiment_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koushikroy/facial_sentiment_analysis/blob/main/01_sentiment_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCXyx8lD8yuD"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZyNQK_p6gU3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvwNzEk69PpW"
      },
      "source": [
        "# Dateset Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLGsT1ORYjId"
      },
      "source": [
        "## Downloading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvhMNp1L9U-_",
        "outputId": "70f7b497-b524-4fa2-e292-42aa866f0c04"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/koushikroy/facial_sentiment_analysis/main/dataset/imp_fea_dataset.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-04 19:21:10--  https://raw.githubusercontent.com/koushikroy/facial_sentiment_analysis/main/dataset/imp_fea_dataset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 734679 (717K) [text/plain]\n",
            "Saving to: ‘imp_fea_dataset.csv’\n",
            "\n",
            "\rimp_fea_dataset.csv   0%[                    ]       0  --.-KB/s               \rimp_fea_dataset.csv 100%[===================>] 717.46K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-07-04 19:21:10 (22.1 MB/s) - ‘imp_fea_dataset.csv’ saved [734679/734679]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQnuCiaCYs2W"
      },
      "source": [
        "## Exploring and Cleaning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9COVLEMgBPcf"
      },
      "source": [
        "sentiment_data_original = pd.read_csv('/content/imp_fea_dataset.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "YUft2RE7BX-6",
        "outputId": "d203e0e4-538f-4eac-f7f7-1941a157f548"
      },
      "source": [
        "sentiment_data_original.tail(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>11y</th>\n",
              "      <th>339y</th>\n",
              "      <th>110y</th>\n",
              "      <th>17y</th>\n",
              "      <th>18y</th>\n",
              "      <th>68y</th>\n",
              "      <th>16y</th>\n",
              "      <th>67y</th>\n",
              "      <th>298y</th>\n",
              "      <th>316y</th>\n",
              "      <th>86y</th>\n",
              "      <th>315y</th>\n",
              "      <th>106y</th>\n",
              "      <th>297y</th>\n",
              "      <th>85y</th>\n",
              "      <th>317y</th>\n",
              "      <th>87y</th>\n",
              "      <th>15y</th>\n",
              "      <th>108y</th>\n",
              "      <th>66y</th>\n",
              "      <th>335y</th>\n",
              "      <th>318y</th>\n",
              "      <th>337y</th>\n",
              "      <th>53y</th>\n",
              "      <th>88y</th>\n",
              "      <th>70y</th>\n",
              "      <th>296y</th>\n",
              "      <th>300y</th>\n",
              "      <th>10y</th>\n",
              "      <th>283y</th>\n",
              "      <th>405y</th>\n",
              "      <th>109y</th>\n",
              "      <th>181y</th>\n",
              "      <th>338y</th>\n",
              "      <th>404y</th>\n",
              "      <th>64y</th>\n",
              "      <th>152y</th>\n",
              "      <th>406y</th>\n",
              "      <th>180y</th>\n",
              "      <th>...</th>\n",
              "      <th>90y</th>\n",
              "      <th>91y</th>\n",
              "      <th>319y</th>\n",
              "      <th>225y</th>\n",
              "      <th>89y</th>\n",
              "      <th>322y</th>\n",
              "      <th>69y</th>\n",
              "      <th>28y</th>\n",
              "      <th>92y</th>\n",
              "      <th>47y</th>\n",
              "      <th>201y</th>\n",
              "      <th>71y</th>\n",
              "      <th>407y</th>\n",
              "      <th>445y</th>\n",
              "      <th>299y</th>\n",
              "      <th>183y</th>\n",
              "      <th>30y</th>\n",
              "      <th>29y</th>\n",
              "      <th>258y</th>\n",
              "      <th>277y</th>\n",
              "      <th>301y</th>\n",
              "      <th>222y</th>\n",
              "      <th>422y</th>\n",
              "      <th>259y</th>\n",
              "      <th>260y</th>\n",
              "      <th>202y</th>\n",
              "      <th>226y</th>\n",
              "      <th>326y</th>\n",
              "      <th>325y</th>\n",
              "      <th>442y</th>\n",
              "      <th>97y</th>\n",
              "      <th>96y</th>\n",
              "      <th>308y</th>\n",
              "      <th>55y</th>\n",
              "      <th>78y</th>\n",
              "      <th>31y</th>\n",
              "      <th>77x</th>\n",
              "      <th>62x</th>\n",
              "      <th>446y</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>377</td>\n",
              "      <td>0.057580</td>\n",
              "      <td>0.055737</td>\n",
              "      <td>0.065687</td>\n",
              "      <td>0.801167</td>\n",
              "      <td>0.818832</td>\n",
              "      <td>0.083737</td>\n",
              "      <td>0.780952</td>\n",
              "      <td>0.183740</td>\n",
              "      <td>0.065642</td>\n",
              "      <td>0.793096</td>\n",
              "      <td>0.795049</td>\n",
              "      <td>0.809582</td>\n",
              "      <td>0.186704</td>\n",
              "      <td>0.165832</td>\n",
              "      <td>0.811745</td>\n",
              "      <td>0.772483</td>\n",
              "      <td>0.774350</td>\n",
              "      <td>0.762443</td>\n",
              "      <td>0.188844</td>\n",
              "      <td>0.207339</td>\n",
              "      <td>0.162688</td>\n",
              "      <td>0.757256</td>\n",
              "      <td>0.179141</td>\n",
              "      <td>0.209117</td>\n",
              "      <td>0.758892</td>\n",
              "      <td>0.134172</td>\n",
              "      <td>0.190719</td>\n",
              "      <td>0.116605</td>\n",
              "      <td>0.190279</td>\n",
              "      <td>0.186344</td>\n",
              "      <td>0.770469</td>\n",
              "      <td>0.129753</td>\n",
              "      <td>0.774425</td>\n",
              "      <td>0.120699</td>\n",
              "      <td>0.755866</td>\n",
              "      <td>0.207796</td>\n",
              "      <td>0.126575</td>\n",
              "      <td>0.784453</td>\n",
              "      <td>0.759354</td>\n",
              "      <td>...</td>\n",
              "      <td>0.739835</td>\n",
              "      <td>0.748364</td>\n",
              "      <td>0.729835</td>\n",
              "      <td>0.249875</td>\n",
              "      <td>0.734068</td>\n",
              "      <td>0.749575</td>\n",
              "      <td>0.189142</td>\n",
              "      <td>0.255679</td>\n",
              "      <td>0.755268</td>\n",
              "      <td>0.254551</td>\n",
              "      <td>0.837217</td>\n",
              "      <td>0.244238</td>\n",
              "      <td>0.788454</td>\n",
              "      <td>0.227103</td>\n",
              "      <td>0.161308</td>\n",
              "      <td>0.792613</td>\n",
              "      <td>0.264189</td>\n",
              "      <td>0.258699</td>\n",
              "      <td>0.237220</td>\n",
              "      <td>0.226976</td>\n",
              "      <td>0.215179</td>\n",
              "      <td>0.262739</td>\n",
              "      <td>0.826948</td>\n",
              "      <td>0.243718</td>\n",
              "      <td>0.243232</td>\n",
              "      <td>0.829023</td>\n",
              "      <td>0.270396</td>\n",
              "      <td>0.715528</td>\n",
              "      <td>0.713580</td>\n",
              "      <td>0.253272</td>\n",
              "      <td>0.720639</td>\n",
              "      <td>0.718345</td>\n",
              "      <td>0.716413</td>\n",
              "      <td>0.168870</td>\n",
              "      <td>0.722262</td>\n",
              "      <td>0.281437</td>\n",
              "      <td>0.381628</td>\n",
              "      <td>0.372905</td>\n",
              "      <td>0.245757</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>378</td>\n",
              "      <td>0.040592</td>\n",
              "      <td>0.040692</td>\n",
              "      <td>0.047109</td>\n",
              "      <td>0.654993</td>\n",
              "      <td>0.672020</td>\n",
              "      <td>0.065316</td>\n",
              "      <td>0.641142</td>\n",
              "      <td>0.202215</td>\n",
              "      <td>0.053557</td>\n",
              "      <td>0.651571</td>\n",
              "      <td>0.652379</td>\n",
              "      <td>0.669638</td>\n",
              "      <td>0.200389</td>\n",
              "      <td>0.192254</td>\n",
              "      <td>0.670740</td>\n",
              "      <td>0.638445</td>\n",
              "      <td>0.639278</td>\n",
              "      <td>0.631217</td>\n",
              "      <td>0.208053</td>\n",
              "      <td>0.230943</td>\n",
              "      <td>0.186614</td>\n",
              "      <td>0.630313</td>\n",
              "      <td>0.202685</td>\n",
              "      <td>0.228505</td>\n",
              "      <td>0.631049</td>\n",
              "      <td>0.129696</td>\n",
              "      <td>0.221475</td>\n",
              "      <td>0.119150</td>\n",
              "      <td>0.211153</td>\n",
              "      <td>0.215496</td>\n",
              "      <td>0.644172</td>\n",
              "      <td>0.124206</td>\n",
              "      <td>0.646468</td>\n",
              "      <td>0.118786</td>\n",
              "      <td>0.633602</td>\n",
              "      <td>0.217353</td>\n",
              "      <td>0.122361</td>\n",
              "      <td>0.660655</td>\n",
              "      <td>0.635555</td>\n",
              "      <td>...</td>\n",
              "      <td>0.631836</td>\n",
              "      <td>0.639293</td>\n",
              "      <td>0.626436</td>\n",
              "      <td>0.267508</td>\n",
              "      <td>0.629169</td>\n",
              "      <td>0.646994</td>\n",
              "      <td>0.181760</td>\n",
              "      <td>0.281251</td>\n",
              "      <td>0.650276</td>\n",
              "      <td>0.263247</td>\n",
              "      <td>0.751484</td>\n",
              "      <td>0.248831</td>\n",
              "      <td>0.697252</td>\n",
              "      <td>0.254795</td>\n",
              "      <td>0.164786</td>\n",
              "      <td>0.699135</td>\n",
              "      <td>0.285882</td>\n",
              "      <td>0.282808</td>\n",
              "      <td>0.270919</td>\n",
              "      <td>0.247369</td>\n",
              "      <td>0.231996</td>\n",
              "      <td>0.280367</td>\n",
              "      <td>0.751272</td>\n",
              "      <td>0.273957</td>\n",
              "      <td>0.274674</td>\n",
              "      <td>0.752188</td>\n",
              "      <td>0.281065</td>\n",
              "      <td>0.625427</td>\n",
              "      <td>0.625727</td>\n",
              "      <td>0.274864</td>\n",
              "      <td>0.629223</td>\n",
              "      <td>0.629305</td>\n",
              "      <td>0.628706</td>\n",
              "      <td>0.150145</td>\n",
              "      <td>0.632859</td>\n",
              "      <td>0.296373</td>\n",
              "      <td>0.365360</td>\n",
              "      <td>0.358874</td>\n",
              "      <td>0.267231</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>379</td>\n",
              "      <td>0.047037</td>\n",
              "      <td>0.053698</td>\n",
              "      <td>0.046003</td>\n",
              "      <td>0.770048</td>\n",
              "      <td>0.788251</td>\n",
              "      <td>0.056144</td>\n",
              "      <td>0.750620</td>\n",
              "      <td>0.156649</td>\n",
              "      <td>0.070998</td>\n",
              "      <td>0.764836</td>\n",
              "      <td>0.761400</td>\n",
              "      <td>0.782575</td>\n",
              "      <td>0.152988</td>\n",
              "      <td>0.173056</td>\n",
              "      <td>0.779074</td>\n",
              "      <td>0.745185</td>\n",
              "      <td>0.742156</td>\n",
              "      <td>0.733062</td>\n",
              "      <td>0.169833</td>\n",
              "      <td>0.182511</td>\n",
              "      <td>0.176366</td>\n",
              "      <td>0.730659</td>\n",
              "      <td>0.178300</td>\n",
              "      <td>0.177955</td>\n",
              "      <td>0.727808</td>\n",
              "      <td>0.106601</td>\n",
              "      <td>0.199033</td>\n",
              "      <td>0.121661</td>\n",
              "      <td>0.180796</td>\n",
              "      <td>0.200876</td>\n",
              "      <td>0.746139</td>\n",
              "      <td>0.110306</td>\n",
              "      <td>0.740194</td>\n",
              "      <td>0.118150</td>\n",
              "      <td>0.731752</td>\n",
              "      <td>0.170150</td>\n",
              "      <td>0.115850</td>\n",
              "      <td>0.761606</td>\n",
              "      <td>0.726194</td>\n",
              "      <td>...</td>\n",
              "      <td>0.706904</td>\n",
              "      <td>0.714593</td>\n",
              "      <td>0.708938</td>\n",
              "      <td>0.221408</td>\n",
              "      <td>0.701755</td>\n",
              "      <td>0.730570</td>\n",
              "      <td>0.151339</td>\n",
              "      <td>0.235026</td>\n",
              "      <td>0.722049</td>\n",
              "      <td>0.217638</td>\n",
              "      <td>0.822608</td>\n",
              "      <td>0.205933</td>\n",
              "      <td>0.774658</td>\n",
              "      <td>0.245622</td>\n",
              "      <td>0.177707</td>\n",
              "      <td>0.766834</td>\n",
              "      <td>0.240011</td>\n",
              "      <td>0.240398</td>\n",
              "      <td>0.254243</td>\n",
              "      <td>0.246486</td>\n",
              "      <td>0.235120</td>\n",
              "      <td>0.245001</td>\n",
              "      <td>0.817570</td>\n",
              "      <td>0.255411</td>\n",
              "      <td>0.262755</td>\n",
              "      <td>0.811974</td>\n",
              "      <td>0.237825</td>\n",
              "      <td>0.697261</td>\n",
              "      <td>0.695497</td>\n",
              "      <td>0.255156</td>\n",
              "      <td>0.688571</td>\n",
              "      <td>0.687340</td>\n",
              "      <td>0.699216</td>\n",
              "      <td>0.131469</td>\n",
              "      <td>0.689959</td>\n",
              "      <td>0.253661</td>\n",
              "      <td>0.373065</td>\n",
              "      <td>0.364895</td>\n",
              "      <td>0.264379</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>380</td>\n",
              "      <td>0.038742</td>\n",
              "      <td>0.039927</td>\n",
              "      <td>0.044908</td>\n",
              "      <td>0.779642</td>\n",
              "      <td>0.797376</td>\n",
              "      <td>0.062250</td>\n",
              "      <td>0.760387</td>\n",
              "      <td>0.160638</td>\n",
              "      <td>0.053302</td>\n",
              "      <td>0.772826</td>\n",
              "      <td>0.772665</td>\n",
              "      <td>0.788991</td>\n",
              "      <td>0.163712</td>\n",
              "      <td>0.152644</td>\n",
              "      <td>0.788701</td>\n",
              "      <td>0.752912</td>\n",
              "      <td>0.753125</td>\n",
              "      <td>0.742578</td>\n",
              "      <td>0.166608</td>\n",
              "      <td>0.185035</td>\n",
              "      <td>0.153232</td>\n",
              "      <td>0.738023</td>\n",
              "      <td>0.162163</td>\n",
              "      <td>0.186700</td>\n",
              "      <td>0.738493</td>\n",
              "      <td>0.111425</td>\n",
              "      <td>0.177800</td>\n",
              "      <td>0.103095</td>\n",
              "      <td>0.170424</td>\n",
              "      <td>0.176983</td>\n",
              "      <td>0.750672</td>\n",
              "      <td>0.108207</td>\n",
              "      <td>0.751327</td>\n",
              "      <td>0.103806</td>\n",
              "      <td>0.736526</td>\n",
              "      <td>0.185495</td>\n",
              "      <td>0.107094</td>\n",
              "      <td>0.764945</td>\n",
              "      <td>0.737706</td>\n",
              "      <td>...</td>\n",
              "      <td>0.718163</td>\n",
              "      <td>0.725451</td>\n",
              "      <td>0.711383</td>\n",
              "      <td>0.229659</td>\n",
              "      <td>0.713362</td>\n",
              "      <td>0.730885</td>\n",
              "      <td>0.167603</td>\n",
              "      <td>0.237541</td>\n",
              "      <td>0.731675</td>\n",
              "      <td>0.233397</td>\n",
              "      <td>0.821835</td>\n",
              "      <td>0.223394</td>\n",
              "      <td>0.771396</td>\n",
              "      <td>0.219769</td>\n",
              "      <td>0.155336</td>\n",
              "      <td>0.770925</td>\n",
              "      <td>0.245654</td>\n",
              "      <td>0.240755</td>\n",
              "      <td>0.229030</td>\n",
              "      <td>0.221739</td>\n",
              "      <td>0.210895</td>\n",
              "      <td>0.243217</td>\n",
              "      <td>0.811490</td>\n",
              "      <td>0.233206</td>\n",
              "      <td>0.236532</td>\n",
              "      <td>0.811017</td>\n",
              "      <td>0.250121</td>\n",
              "      <td>0.698028</td>\n",
              "      <td>0.695835</td>\n",
              "      <td>0.238348</td>\n",
              "      <td>0.699747</td>\n",
              "      <td>0.698154</td>\n",
              "      <td>0.699124</td>\n",
              "      <td>0.149014</td>\n",
              "      <td>0.700718</td>\n",
              "      <td>0.262499</td>\n",
              "      <td>0.397183</td>\n",
              "      <td>0.388481</td>\n",
              "      <td>0.239594</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>381</td>\n",
              "      <td>0.053937</td>\n",
              "      <td>0.054906</td>\n",
              "      <td>0.059472</td>\n",
              "      <td>0.694596</td>\n",
              "      <td>0.713002</td>\n",
              "      <td>0.075700</td>\n",
              "      <td>0.676611</td>\n",
              "      <td>0.181332</td>\n",
              "      <td>0.067848</td>\n",
              "      <td>0.689126</td>\n",
              "      <td>0.689278</td>\n",
              "      <td>0.706888</td>\n",
              "      <td>0.182350</td>\n",
              "      <td>0.175700</td>\n",
              "      <td>0.707152</td>\n",
              "      <td>0.671113</td>\n",
              "      <td>0.671233</td>\n",
              "      <td>0.661777</td>\n",
              "      <td>0.186636</td>\n",
              "      <td>0.204843</td>\n",
              "      <td>0.174682</td>\n",
              "      <td>0.659092</td>\n",
              "      <td>0.183678</td>\n",
              "      <td>0.204631</td>\n",
              "      <td>0.659164</td>\n",
              "      <td>0.125358</td>\n",
              "      <td>0.199891</td>\n",
              "      <td>0.118878</td>\n",
              "      <td>0.190370</td>\n",
              "      <td>0.197745</td>\n",
              "      <td>0.674233</td>\n",
              "      <td>0.120685</td>\n",
              "      <td>0.674856</td>\n",
              "      <td>0.117358</td>\n",
              "      <td>0.660795</td>\n",
              "      <td>0.199966</td>\n",
              "      <td>0.119472</td>\n",
              "      <td>0.690309</td>\n",
              "      <td>0.661247</td>\n",
              "      <td>...</td>\n",
              "      <td>0.649403</td>\n",
              "      <td>0.657515</td>\n",
              "      <td>0.644188</td>\n",
              "      <td>0.238722</td>\n",
              "      <td>0.644811</td>\n",
              "      <td>0.665620</td>\n",
              "      <td>0.175866</td>\n",
              "      <td>0.247640</td>\n",
              "      <td>0.666517</td>\n",
              "      <td>0.241140</td>\n",
              "      <td>0.767444</td>\n",
              "      <td>0.231280</td>\n",
              "      <td>0.712181</td>\n",
              "      <td>0.231532</td>\n",
              "      <td>0.166143</td>\n",
              "      <td>0.712219</td>\n",
              "      <td>0.253810</td>\n",
              "      <td>0.248616</td>\n",
              "      <td>0.241714</td>\n",
              "      <td>0.232748</td>\n",
              "      <td>0.222143</td>\n",
              "      <td>0.248604</td>\n",
              "      <td>0.759778</td>\n",
              "      <td>0.243649</td>\n",
              "      <td>0.247142</td>\n",
              "      <td>0.759250</td>\n",
              "      <td>0.254537</td>\n",
              "      <td>0.637217</td>\n",
              "      <td>0.635968</td>\n",
              "      <td>0.245965</td>\n",
              "      <td>0.637844</td>\n",
              "      <td>0.636478</td>\n",
              "      <td>0.639595</td>\n",
              "      <td>0.154425</td>\n",
              "      <td>0.640696</td>\n",
              "      <td>0.265902</td>\n",
              "      <td>0.384331</td>\n",
              "      <td>0.376635</td>\n",
              "      <td>0.246866</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>382</td>\n",
              "      <td>0.042583</td>\n",
              "      <td>0.045035</td>\n",
              "      <td>0.047134</td>\n",
              "      <td>0.728669</td>\n",
              "      <td>0.748919</td>\n",
              "      <td>0.062893</td>\n",
              "      <td>0.707321</td>\n",
              "      <td>0.178650</td>\n",
              "      <td>0.058560</td>\n",
              "      <td>0.721632</td>\n",
              "      <td>0.724311</td>\n",
              "      <td>0.740879</td>\n",
              "      <td>0.176057</td>\n",
              "      <td>0.173938</td>\n",
              "      <td>0.743858</td>\n",
              "      <td>0.699588</td>\n",
              "      <td>0.702000</td>\n",
              "      <td>0.688762</td>\n",
              "      <td>0.186769</td>\n",
              "      <td>0.203422</td>\n",
              "      <td>0.168858</td>\n",
              "      <td>0.684601</td>\n",
              "      <td>0.184651</td>\n",
              "      <td>0.200100</td>\n",
              "      <td>0.686834</td>\n",
              "      <td>0.118948</td>\n",
              "      <td>0.198871</td>\n",
              "      <td>0.114615</td>\n",
              "      <td>0.190982</td>\n",
              "      <td>0.193248</td>\n",
              "      <td>0.702782</td>\n",
              "      <td>0.116313</td>\n",
              "      <td>0.707740</td>\n",
              "      <td>0.114175</td>\n",
              "      <td>0.687071</td>\n",
              "      <td>0.192034</td>\n",
              "      <td>0.115768</td>\n",
              "      <td>0.719837</td>\n",
              "      <td>0.691491</td>\n",
              "      <td>...</td>\n",
              "      <td>0.678186</td>\n",
              "      <td>0.687824</td>\n",
              "      <td>0.666948</td>\n",
              "      <td>0.235956</td>\n",
              "      <td>0.672196</td>\n",
              "      <td>0.690822</td>\n",
              "      <td>0.166641</td>\n",
              "      <td>0.246240</td>\n",
              "      <td>0.697651</td>\n",
              "      <td>0.235827</td>\n",
              "      <td>0.787487</td>\n",
              "      <td>0.224265</td>\n",
              "      <td>0.733380</td>\n",
              "      <td>0.227759</td>\n",
              "      <td>0.156860</td>\n",
              "      <td>0.739789</td>\n",
              "      <td>0.251570</td>\n",
              "      <td>0.249302</td>\n",
              "      <td>0.240222</td>\n",
              "      <td>0.224672</td>\n",
              "      <td>0.212296</td>\n",
              "      <td>0.253105</td>\n",
              "      <td>0.777077</td>\n",
              "      <td>0.245095</td>\n",
              "      <td>0.244083</td>\n",
              "      <td>0.781469</td>\n",
              "      <td>0.251451</td>\n",
              "      <td>0.660317</td>\n",
              "      <td>0.657805</td>\n",
              "      <td>0.250418</td>\n",
              "      <td>0.666274</td>\n",
              "      <td>0.663393</td>\n",
              "      <td>0.662893</td>\n",
              "      <td>0.142186</td>\n",
              "      <td>0.669631</td>\n",
              "      <td>0.264282</td>\n",
              "      <td>0.411506</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>0.241827</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>383</td>\n",
              "      <td>0.098089</td>\n",
              "      <td>0.100955</td>\n",
              "      <td>0.099325</td>\n",
              "      <td>0.832645</td>\n",
              "      <td>0.848669</td>\n",
              "      <td>0.109465</td>\n",
              "      <td>0.813827</td>\n",
              "      <td>0.206665</td>\n",
              "      <td>0.113173</td>\n",
              "      <td>0.823182</td>\n",
              "      <td>0.825677</td>\n",
              "      <td>0.837476</td>\n",
              "      <td>0.205407</td>\n",
              "      <td>0.215514</td>\n",
              "      <td>0.840209</td>\n",
              "      <td>0.804069</td>\n",
              "      <td>0.806298</td>\n",
              "      <td>0.795116</td>\n",
              "      <td>0.216277</td>\n",
              "      <td>0.229719</td>\n",
              "      <td>0.216993</td>\n",
              "      <td>0.788585</td>\n",
              "      <td>0.221778</td>\n",
              "      <td>0.228018</td>\n",
              "      <td>0.790531</td>\n",
              "      <td>0.158426</td>\n",
              "      <td>0.238748</td>\n",
              "      <td>0.164363</td>\n",
              "      <td>0.225588</td>\n",
              "      <td>0.239553</td>\n",
              "      <td>0.797080</td>\n",
              "      <td>0.160146</td>\n",
              "      <td>0.801490</td>\n",
              "      <td>0.162956</td>\n",
              "      <td>0.783675</td>\n",
              "      <td>0.221683</td>\n",
              "      <td>0.163352</td>\n",
              "      <td>0.809140</td>\n",
              "      <td>0.787550</td>\n",
              "      <td>...</td>\n",
              "      <td>0.762522</td>\n",
              "      <td>0.770095</td>\n",
              "      <td>0.752246</td>\n",
              "      <td>0.265283</td>\n",
              "      <td>0.756961</td>\n",
              "      <td>0.769037</td>\n",
              "      <td>0.199743</td>\n",
              "      <td>0.273143</td>\n",
              "      <td>0.774898</td>\n",
              "      <td>0.264131</td>\n",
              "      <td>0.858461</td>\n",
              "      <td>0.252524</td>\n",
              "      <td>0.807356</td>\n",
              "      <td>0.273746</td>\n",
              "      <td>0.206976</td>\n",
              "      <td>0.811481</td>\n",
              "      <td>0.279556</td>\n",
              "      <td>0.275489</td>\n",
              "      <td>0.280252</td>\n",
              "      <td>0.273269</td>\n",
              "      <td>0.260509</td>\n",
              "      <td>0.279313</td>\n",
              "      <td>0.845959</td>\n",
              "      <td>0.281529</td>\n",
              "      <td>0.286892</td>\n",
              "      <td>0.847769</td>\n",
              "      <td>0.280159</td>\n",
              "      <td>0.732552</td>\n",
              "      <td>0.730960</td>\n",
              "      <td>0.283917</td>\n",
              "      <td>0.738205</td>\n",
              "      <td>0.736107</td>\n",
              "      <td>0.732715</td>\n",
              "      <td>0.176038</td>\n",
              "      <td>0.738768</td>\n",
              "      <td>0.292135</td>\n",
              "      <td>0.394111</td>\n",
              "      <td>0.386250</td>\n",
              "      <td>0.287928</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>384</td>\n",
              "      <td>0.030021</td>\n",
              "      <td>0.038381</td>\n",
              "      <td>0.029579</td>\n",
              "      <td>0.775125</td>\n",
              "      <td>0.792937</td>\n",
              "      <td>0.042556</td>\n",
              "      <td>0.756839</td>\n",
              "      <td>0.139110</td>\n",
              "      <td>0.059267</td>\n",
              "      <td>0.768600</td>\n",
              "      <td>0.766205</td>\n",
              "      <td>0.784894</td>\n",
              "      <td>0.141035</td>\n",
              "      <td>0.154036</td>\n",
              "      <td>0.782447</td>\n",
              "      <td>0.749900</td>\n",
              "      <td>0.747969</td>\n",
              "      <td>0.740024</td>\n",
              "      <td>0.148157</td>\n",
              "      <td>0.164470</td>\n",
              "      <td>0.161294</td>\n",
              "      <td>0.735523</td>\n",
              "      <td>0.156173</td>\n",
              "      <td>0.164272</td>\n",
              "      <td>0.733820</td>\n",
              "      <td>0.089841</td>\n",
              "      <td>0.179108</td>\n",
              "      <td>0.105251</td>\n",
              "      <td>0.158740</td>\n",
              "      <td>0.183988</td>\n",
              "      <td>0.744956</td>\n",
              "      <td>0.090450</td>\n",
              "      <td>0.741634</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.731926</td>\n",
              "      <td>0.163305</td>\n",
              "      <td>0.096266</td>\n",
              "      <td>0.758921</td>\n",
              "      <td>0.729061</td>\n",
              "      <td>...</td>\n",
              "      <td>0.705510</td>\n",
              "      <td>0.711642</td>\n",
              "      <td>0.704559</td>\n",
              "      <td>0.209858</td>\n",
              "      <td>0.701626</td>\n",
              "      <td>0.721997</td>\n",
              "      <td>0.146862</td>\n",
              "      <td>0.222657</td>\n",
              "      <td>0.717824</td>\n",
              "      <td>0.212812</td>\n",
              "      <td>0.819347</td>\n",
              "      <td>0.203456</td>\n",
              "      <td>0.767552</td>\n",
              "      <td>0.230926</td>\n",
              "      <td>0.171842</td>\n",
              "      <td>0.763855</td>\n",
              "      <td>0.229115</td>\n",
              "      <td>0.227320</td>\n",
              "      <td>0.240029</td>\n",
              "      <td>0.237068</td>\n",
              "      <td>0.228717</td>\n",
              "      <td>0.228086</td>\n",
              "      <td>0.810681</td>\n",
              "      <td>0.241610</td>\n",
              "      <td>0.248977</td>\n",
              "      <td>0.808146</td>\n",
              "      <td>0.230074</td>\n",
              "      <td>0.686705</td>\n",
              "      <td>0.685961</td>\n",
              "      <td>0.237558</td>\n",
              "      <td>0.682670</td>\n",
              "      <td>0.682699</td>\n",
              "      <td>0.686673</td>\n",
              "      <td>0.130370</td>\n",
              "      <td>0.682473</td>\n",
              "      <td>0.244849</td>\n",
              "      <td>0.396086</td>\n",
              "      <td>0.388178</td>\n",
              "      <td>0.252944</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>385</th>\n",
              "      <td>385</td>\n",
              "      <td>0.029790</td>\n",
              "      <td>0.032586</td>\n",
              "      <td>0.032786</td>\n",
              "      <td>0.803435</td>\n",
              "      <td>0.821342</td>\n",
              "      <td>0.046595</td>\n",
              "      <td>0.783120</td>\n",
              "      <td>0.149567</td>\n",
              "      <td>0.046569</td>\n",
              "      <td>0.795293</td>\n",
              "      <td>0.795607</td>\n",
              "      <td>0.811954</td>\n",
              "      <td>0.149780</td>\n",
              "      <td>0.150114</td>\n",
              "      <td>0.812003</td>\n",
              "      <td>0.774113</td>\n",
              "      <td>0.774908</td>\n",
              "      <td>0.763476</td>\n",
              "      <td>0.158602</td>\n",
              "      <td>0.175099</td>\n",
              "      <td>0.150225</td>\n",
              "      <td>0.757582</td>\n",
              "      <td>0.158929</td>\n",
              "      <td>0.174224</td>\n",
              "      <td>0.758704</td>\n",
              "      <td>0.099011</td>\n",
              "      <td>0.175888</td>\n",
              "      <td>0.099284</td>\n",
              "      <td>0.165675</td>\n",
              "      <td>0.174889</td>\n",
              "      <td>0.769847</td>\n",
              "      <td>0.099227</td>\n",
              "      <td>0.771256</td>\n",
              "      <td>0.099572</td>\n",
              "      <td>0.754594</td>\n",
              "      <td>0.169526</td>\n",
              "      <td>0.101058</td>\n",
              "      <td>0.784358</td>\n",
              "      <td>0.756448</td>\n",
              "      <td>...</td>\n",
              "      <td>0.732561</td>\n",
              "      <td>0.740327</td>\n",
              "      <td>0.723830</td>\n",
              "      <td>0.218522</td>\n",
              "      <td>0.727121</td>\n",
              "      <td>0.744616</td>\n",
              "      <td>0.148923</td>\n",
              "      <td>0.227996</td>\n",
              "      <td>0.746451</td>\n",
              "      <td>0.218015</td>\n",
              "      <td>0.836178</td>\n",
              "      <td>0.205789</td>\n",
              "      <td>0.785772</td>\n",
              "      <td>0.219019</td>\n",
              "      <td>0.148878</td>\n",
              "      <td>0.786354</td>\n",
              "      <td>0.235142</td>\n",
              "      <td>0.231854</td>\n",
              "      <td>0.228937</td>\n",
              "      <td>0.217596</td>\n",
              "      <td>0.205009</td>\n",
              "      <td>0.235732</td>\n",
              "      <td>0.825436</td>\n",
              "      <td>0.232628</td>\n",
              "      <td>0.236433</td>\n",
              "      <td>0.825896</td>\n",
              "      <td>0.236950</td>\n",
              "      <td>0.706180</td>\n",
              "      <td>0.704105</td>\n",
              "      <td>0.236436</td>\n",
              "      <td>0.709578</td>\n",
              "      <td>0.707765</td>\n",
              "      <td>0.706934</td>\n",
              "      <td>0.126320</td>\n",
              "      <td>0.710156</td>\n",
              "      <td>0.250745</td>\n",
              "      <td>0.382399</td>\n",
              "      <td>0.373651</td>\n",
              "      <td>0.237434</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>386</td>\n",
              "      <td>0.028294</td>\n",
              "      <td>0.031425</td>\n",
              "      <td>0.032584</td>\n",
              "      <td>0.798233</td>\n",
              "      <td>0.814960</td>\n",
              "      <td>0.048443</td>\n",
              "      <td>0.779954</td>\n",
              "      <td>0.166443</td>\n",
              "      <td>0.046820</td>\n",
              "      <td>0.788627</td>\n",
              "      <td>0.790966</td>\n",
              "      <td>0.803303</td>\n",
              "      <td>0.162677</td>\n",
              "      <td>0.169883</td>\n",
              "      <td>0.805924</td>\n",
              "      <td>0.769750</td>\n",
              "      <td>0.772434</td>\n",
              "      <td>0.762304</td>\n",
              "      <td>0.176322</td>\n",
              "      <td>0.190824</td>\n",
              "      <td>0.166948</td>\n",
              "      <td>0.754930</td>\n",
              "      <td>0.178744</td>\n",
              "      <td>0.185964</td>\n",
              "      <td>0.757427</td>\n",
              "      <td>0.105134</td>\n",
              "      <td>0.194805</td>\n",
              "      <td>0.105626</td>\n",
              "      <td>0.182422</td>\n",
              "      <td>0.190902</td>\n",
              "      <td>0.760143</td>\n",
              "      <td>0.102472</td>\n",
              "      <td>0.765568</td>\n",
              "      <td>0.102679</td>\n",
              "      <td>0.746955</td>\n",
              "      <td>0.178944</td>\n",
              "      <td>0.102618</td>\n",
              "      <td>0.772934</td>\n",
              "      <td>0.752284</td>\n",
              "      <td>...</td>\n",
              "      <td>0.724808</td>\n",
              "      <td>0.731656</td>\n",
              "      <td>0.712595</td>\n",
              "      <td>0.219281</td>\n",
              "      <td>0.720248</td>\n",
              "      <td>0.728908</td>\n",
              "      <td>0.154923</td>\n",
              "      <td>0.225278</td>\n",
              "      <td>0.736722</td>\n",
              "      <td>0.222614</td>\n",
              "      <td>0.831937</td>\n",
              "      <td>0.212774</td>\n",
              "      <td>0.774749</td>\n",
              "      <td>0.221938</td>\n",
              "      <td>0.154258</td>\n",
              "      <td>0.779241</td>\n",
              "      <td>0.231242</td>\n",
              "      <td>0.230126</td>\n",
              "      <td>0.227691</td>\n",
              "      <td>0.224401</td>\n",
              "      <td>0.212821</td>\n",
              "      <td>0.240014</td>\n",
              "      <td>0.818825</td>\n",
              "      <td>0.231867</td>\n",
              "      <td>0.233778</td>\n",
              "      <td>0.820524</td>\n",
              "      <td>0.235848</td>\n",
              "      <td>0.687937</td>\n",
              "      <td>0.687617</td>\n",
              "      <td>0.241956</td>\n",
              "      <td>0.697457</td>\n",
              "      <td>0.696794</td>\n",
              "      <td>0.686967</td>\n",
              "      <td>0.130918</td>\n",
              "      <td>0.697060</td>\n",
              "      <td>0.245452</td>\n",
              "      <td>0.388187</td>\n",
              "      <td>0.379850</td>\n",
              "      <td>0.237805</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 102 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0       11y      339y  ...       62x      446y  output\n",
              "377         377  0.057580  0.055737  ...  0.372905  0.245757       7\n",
              "378         378  0.040592  0.040692  ...  0.358874  0.267231       7\n",
              "379         379  0.047037  0.053698  ...  0.364895  0.264379       7\n",
              "380         380  0.038742  0.039927  ...  0.388481  0.239594       7\n",
              "381         381  0.053937  0.054906  ...  0.376635  0.246866       7\n",
              "382         382  0.042583  0.045035  ...  0.403034  0.241827       7\n",
              "383         383  0.098089  0.100955  ...  0.386250  0.287928       7\n",
              "384         384  0.030021  0.038381  ...  0.388178  0.252944       7\n",
              "385         385  0.029790  0.032586  ...  0.373651  0.237434       7\n",
              "386         386  0.028294  0.031425  ...  0.379850  0.237805       7\n",
              "\n",
              "[10 rows x 102 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7f55_uZCFEG"
      },
      "source": [
        "\n",
        "**From the dataset, we can see that:**\n",
        "*   There are in total 937 Columns excluding the index column \n",
        "*   The first 936 columns represents the landmark points in the face and the 'output' column represnts the emotion\n",
        "*   The face has been cropped and resized thus no need for further normalization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQZ4VOKCBdTM",
        "outputId": "cf45450e-534d-4308-a954-d5534db60232"
      },
      "source": [
        "sentiment_data_original.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 387 entries, 0 to 386\n",
            "Columns: 102 entries, Unnamed: 0 to output\n",
            "dtypes: float64(100), int64(2)\n",
            "memory usage: 308.5 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcv0dQIABi8O",
        "outputId": "df9c80b2-c3f5-42c9-90d6-46fac2ae83e4"
      },
      "source": [
        "#value_count in the output column \n",
        "sentiment_data_original['output'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7    83\n",
              "4    69\n",
              "5    60\n",
              "2    59\n",
              "0    45\n",
              "6    28\n",
              "3    25\n",
              "1    18\n",
              "Name: output, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh4iA1inDAXi"
      },
      "source": [
        "\n",
        "\n",
        "> So you can see that the neutral category has a staggering number of input compared to othet categories. This can be a later as the model might be overflitted. So, we need to take care of this.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "csLqjscvWdWt",
        "outputId": "e53c3369-adea-4a96-c0d8-90b8487b0cbf"
      },
      "source": [
        "sentiment_data_small_version = sentiment_data_original\n",
        "sentiment_data_small_version"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>11y</th>\n",
              "      <th>339y</th>\n",
              "      <th>110y</th>\n",
              "      <th>17y</th>\n",
              "      <th>18y</th>\n",
              "      <th>68y</th>\n",
              "      <th>16y</th>\n",
              "      <th>67y</th>\n",
              "      <th>298y</th>\n",
              "      <th>316y</th>\n",
              "      <th>86y</th>\n",
              "      <th>315y</th>\n",
              "      <th>106y</th>\n",
              "      <th>297y</th>\n",
              "      <th>85y</th>\n",
              "      <th>317y</th>\n",
              "      <th>87y</th>\n",
              "      <th>15y</th>\n",
              "      <th>108y</th>\n",
              "      <th>66y</th>\n",
              "      <th>335y</th>\n",
              "      <th>318y</th>\n",
              "      <th>337y</th>\n",
              "      <th>53y</th>\n",
              "      <th>88y</th>\n",
              "      <th>70y</th>\n",
              "      <th>296y</th>\n",
              "      <th>300y</th>\n",
              "      <th>10y</th>\n",
              "      <th>283y</th>\n",
              "      <th>405y</th>\n",
              "      <th>109y</th>\n",
              "      <th>181y</th>\n",
              "      <th>338y</th>\n",
              "      <th>404y</th>\n",
              "      <th>64y</th>\n",
              "      <th>152y</th>\n",
              "      <th>406y</th>\n",
              "      <th>180y</th>\n",
              "      <th>...</th>\n",
              "      <th>90y</th>\n",
              "      <th>91y</th>\n",
              "      <th>319y</th>\n",
              "      <th>225y</th>\n",
              "      <th>89y</th>\n",
              "      <th>322y</th>\n",
              "      <th>69y</th>\n",
              "      <th>28y</th>\n",
              "      <th>92y</th>\n",
              "      <th>47y</th>\n",
              "      <th>201y</th>\n",
              "      <th>71y</th>\n",
              "      <th>407y</th>\n",
              "      <th>445y</th>\n",
              "      <th>299y</th>\n",
              "      <th>183y</th>\n",
              "      <th>30y</th>\n",
              "      <th>29y</th>\n",
              "      <th>258y</th>\n",
              "      <th>277y</th>\n",
              "      <th>301y</th>\n",
              "      <th>222y</th>\n",
              "      <th>422y</th>\n",
              "      <th>259y</th>\n",
              "      <th>260y</th>\n",
              "      <th>202y</th>\n",
              "      <th>226y</th>\n",
              "      <th>326y</th>\n",
              "      <th>325y</th>\n",
              "      <th>442y</th>\n",
              "      <th>97y</th>\n",
              "      <th>96y</th>\n",
              "      <th>308y</th>\n",
              "      <th>55y</th>\n",
              "      <th>78y</th>\n",
              "      <th>31y</th>\n",
              "      <th>77x</th>\n",
              "      <th>62x</th>\n",
              "      <th>446y</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.087810</td>\n",
              "      <td>0.086514</td>\n",
              "      <td>0.093708</td>\n",
              "      <td>0.701211</td>\n",
              "      <td>0.716253</td>\n",
              "      <td>0.108578</td>\n",
              "      <td>0.686886</td>\n",
              "      <td>0.234690</td>\n",
              "      <td>0.095875</td>\n",
              "      <td>0.696938</td>\n",
              "      <td>0.699335</td>\n",
              "      <td>0.712851</td>\n",
              "      <td>0.234497</td>\n",
              "      <td>0.225658</td>\n",
              "      <td>0.715577</td>\n",
              "      <td>0.683342</td>\n",
              "      <td>0.685688</td>\n",
              "      <td>0.675410</td>\n",
              "      <td>0.238876</td>\n",
              "      <td>0.260274</td>\n",
              "      <td>0.222080</td>\n",
              "      <td>0.673641</td>\n",
              "      <td>0.234514</td>\n",
              "      <td>0.259857</td>\n",
              "      <td>0.675797</td>\n",
              "      <td>0.169770</td>\n",
              "      <td>0.251879</td>\n",
              "      <td>0.159167</td>\n",
              "      <td>0.243084</td>\n",
              "      <td>0.248609</td>\n",
              "      <td>0.687927</td>\n",
              "      <td>0.166242</td>\n",
              "      <td>0.692763</td>\n",
              "      <td>0.160365</td>\n",
              "      <td>0.677250</td>\n",
              "      <td>0.249370</td>\n",
              "      <td>0.165286</td>\n",
              "      <td>0.702218</td>\n",
              "      <td>0.681785</td>\n",
              "      <td>...</td>\n",
              "      <td>0.677961</td>\n",
              "      <td>0.685568</td>\n",
              "      <td>0.668658</td>\n",
              "      <td>0.295010</td>\n",
              "      <td>0.674744</td>\n",
              "      <td>0.688078</td>\n",
              "      <td>0.213322</td>\n",
              "      <td>0.306147</td>\n",
              "      <td>0.695070</td>\n",
              "      <td>0.290614</td>\n",
              "      <td>0.775533</td>\n",
              "      <td>0.275985</td>\n",
              "      <td>0.727246</td>\n",
              "      <td>0.282305</td>\n",
              "      <td>0.196207</td>\n",
              "      <td>0.731739</td>\n",
              "      <td>0.311140</td>\n",
              "      <td>0.306318</td>\n",
              "      <td>0.295218</td>\n",
              "      <td>0.275201</td>\n",
              "      <td>0.259249</td>\n",
              "      <td>0.303790</td>\n",
              "      <td>0.772824</td>\n",
              "      <td>0.297142</td>\n",
              "      <td>0.298986</td>\n",
              "      <td>0.775157</td>\n",
              "      <td>0.306662</td>\n",
              "      <td>0.669025</td>\n",
              "      <td>0.667577</td>\n",
              "      <td>0.297944</td>\n",
              "      <td>0.676777</td>\n",
              "      <td>0.674650</td>\n",
              "      <td>0.672384</td>\n",
              "      <td>0.179662</td>\n",
              "      <td>0.680488</td>\n",
              "      <td>0.320749</td>\n",
              "      <td>0.365988</td>\n",
              "      <td>0.359189</td>\n",
              "      <td>0.292456</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.098683</td>\n",
              "      <td>0.098165</td>\n",
              "      <td>0.104281</td>\n",
              "      <td>0.664070</td>\n",
              "      <td>0.679439</td>\n",
              "      <td>0.119037</td>\n",
              "      <td>0.650274</td>\n",
              "      <td>0.250426</td>\n",
              "      <td>0.107617</td>\n",
              "      <td>0.660159</td>\n",
              "      <td>0.663162</td>\n",
              "      <td>0.676266</td>\n",
              "      <td>0.250525</td>\n",
              "      <td>0.238674</td>\n",
              "      <td>0.679406</td>\n",
              "      <td>0.647318</td>\n",
              "      <td>0.649850</td>\n",
              "      <td>0.639768</td>\n",
              "      <td>0.252469</td>\n",
              "      <td>0.275065</td>\n",
              "      <td>0.233286</td>\n",
              "      <td>0.638513</td>\n",
              "      <td>0.246897</td>\n",
              "      <td>0.275109</td>\n",
              "      <td>0.640868</td>\n",
              "      <td>0.180109</td>\n",
              "      <td>0.263580</td>\n",
              "      <td>0.168977</td>\n",
              "      <td>0.254662</td>\n",
              "      <td>0.258694</td>\n",
              "      <td>0.653565</td>\n",
              "      <td>0.174024</td>\n",
              "      <td>0.659207</td>\n",
              "      <td>0.168450</td>\n",
              "      <td>0.643540</td>\n",
              "      <td>0.264527</td>\n",
              "      <td>0.172342</td>\n",
              "      <td>0.667974</td>\n",
              "      <td>0.648536</td>\n",
              "      <td>...</td>\n",
              "      <td>0.647792</td>\n",
              "      <td>0.655260</td>\n",
              "      <td>0.637938</td>\n",
              "      <td>0.302938</td>\n",
              "      <td>0.644361</td>\n",
              "      <td>0.657061</td>\n",
              "      <td>0.222941</td>\n",
              "      <td>0.311552</td>\n",
              "      <td>0.665310</td>\n",
              "      <td>0.300203</td>\n",
              "      <td>0.746999</td>\n",
              "      <td>0.286466</td>\n",
              "      <td>0.695820</td>\n",
              "      <td>0.284965</td>\n",
              "      <td>0.202315</td>\n",
              "      <td>0.703365</td>\n",
              "      <td>0.316241</td>\n",
              "      <td>0.309106</td>\n",
              "      <td>0.296829</td>\n",
              "      <td>0.277635</td>\n",
              "      <td>0.263057</td>\n",
              "      <td>0.305376</td>\n",
              "      <td>0.742319</td>\n",
              "      <td>0.297439</td>\n",
              "      <td>0.299121</td>\n",
              "      <td>0.747618</td>\n",
              "      <td>0.311871</td>\n",
              "      <td>0.640539</td>\n",
              "      <td>0.638694</td>\n",
              "      <td>0.298007</td>\n",
              "      <td>0.648763</td>\n",
              "      <td>0.646393</td>\n",
              "      <td>0.644356</td>\n",
              "      <td>0.187314</td>\n",
              "      <td>0.653283</td>\n",
              "      <td>0.323162</td>\n",
              "      <td>0.416444</td>\n",
              "      <td>0.409262</td>\n",
              "      <td>0.291724</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.085394</td>\n",
              "      <td>0.084500</td>\n",
              "      <td>0.091048</td>\n",
              "      <td>0.660387</td>\n",
              "      <td>0.674604</td>\n",
              "      <td>0.105700</td>\n",
              "      <td>0.647303</td>\n",
              "      <td>0.229239</td>\n",
              "      <td>0.093703</td>\n",
              "      <td>0.656849</td>\n",
              "      <td>0.658943</td>\n",
              "      <td>0.672119</td>\n",
              "      <td>0.230414</td>\n",
              "      <td>0.219152</td>\n",
              "      <td>0.674397</td>\n",
              "      <td>0.644289</td>\n",
              "      <td>0.646311</td>\n",
              "      <td>0.637065</td>\n",
              "      <td>0.231457</td>\n",
              "      <td>0.253444</td>\n",
              "      <td>0.216089</td>\n",
              "      <td>0.635543</td>\n",
              "      <td>0.226580</td>\n",
              "      <td>0.254535</td>\n",
              "      <td>0.637335</td>\n",
              "      <td>0.164377</td>\n",
              "      <td>0.243990</td>\n",
              "      <td>0.153830</td>\n",
              "      <td>0.234519</td>\n",
              "      <td>0.241096</td>\n",
              "      <td>0.649563</td>\n",
              "      <td>0.159373</td>\n",
              "      <td>0.653839</td>\n",
              "      <td>0.153670</td>\n",
              "      <td>0.639724</td>\n",
              "      <td>0.245381</td>\n",
              "      <td>0.158003</td>\n",
              "      <td>0.662932</td>\n",
              "      <td>0.643669</td>\n",
              "      <td>...</td>\n",
              "      <td>0.641113</td>\n",
              "      <td>0.648317</td>\n",
              "      <td>0.632508</td>\n",
              "      <td>0.285705</td>\n",
              "      <td>0.638079</td>\n",
              "      <td>0.650801</td>\n",
              "      <td>0.207404</td>\n",
              "      <td>0.294994</td>\n",
              "      <td>0.657289</td>\n",
              "      <td>0.282803</td>\n",
              "      <td>0.731376</td>\n",
              "      <td>0.268743</td>\n",
              "      <td>0.687396</td>\n",
              "      <td>0.271849</td>\n",
              "      <td>0.189208</td>\n",
              "      <td>0.692087</td>\n",
              "      <td>0.300169</td>\n",
              "      <td>0.293459</td>\n",
              "      <td>0.283855</td>\n",
              "      <td>0.265146</td>\n",
              "      <td>0.249984</td>\n",
              "      <td>0.289564</td>\n",
              "      <td>0.729418</td>\n",
              "      <td>0.284528</td>\n",
              "      <td>0.287387</td>\n",
              "      <td>0.732354</td>\n",
              "      <td>0.296178</td>\n",
              "      <td>0.633570</td>\n",
              "      <td>0.631925</td>\n",
              "      <td>0.284262</td>\n",
              "      <td>0.640842</td>\n",
              "      <td>0.638711</td>\n",
              "      <td>0.636973</td>\n",
              "      <td>0.173512</td>\n",
              "      <td>0.644635</td>\n",
              "      <td>0.308359</td>\n",
              "      <td>0.387020</td>\n",
              "      <td>0.380484</td>\n",
              "      <td>0.280708</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.075667</td>\n",
              "      <td>0.071821</td>\n",
              "      <td>0.084392</td>\n",
              "      <td>0.665309</td>\n",
              "      <td>0.682307</td>\n",
              "      <td>0.101926</td>\n",
              "      <td>0.649277</td>\n",
              "      <td>0.217908</td>\n",
              "      <td>0.078597</td>\n",
              "      <td>0.659706</td>\n",
              "      <td>0.664673</td>\n",
              "      <td>0.677375</td>\n",
              "      <td>0.219089</td>\n",
              "      <td>0.198675</td>\n",
              "      <td>0.682582</td>\n",
              "      <td>0.644042</td>\n",
              "      <td>0.648405</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.220197</td>\n",
              "      <td>0.242033</td>\n",
              "      <td>0.191865</td>\n",
              "      <td>0.633418</td>\n",
              "      <td>0.210470</td>\n",
              "      <td>0.242735</td>\n",
              "      <td>0.637605</td>\n",
              "      <td>0.156903</td>\n",
              "      <td>0.223781</td>\n",
              "      <td>0.136231</td>\n",
              "      <td>0.220827</td>\n",
              "      <td>0.217122</td>\n",
              "      <td>0.649569</td>\n",
              "      <td>0.150251</td>\n",
              "      <td>0.658837</td>\n",
              "      <td>0.139265</td>\n",
              "      <td>0.637484</td>\n",
              "      <td>0.235818</td>\n",
              "      <td>0.145927</td>\n",
              "      <td>0.665114</td>\n",
              "      <td>0.646164</td>\n",
              "      <td>...</td>\n",
              "      <td>0.643557</td>\n",
              "      <td>0.652164</td>\n",
              "      <td>0.627880</td>\n",
              "      <td>0.276592</td>\n",
              "      <td>0.639275</td>\n",
              "      <td>0.649096</td>\n",
              "      <td>0.204637</td>\n",
              "      <td>0.285989</td>\n",
              "      <td>0.662667</td>\n",
              "      <td>0.275408</td>\n",
              "      <td>0.739109</td>\n",
              "      <td>0.263612</td>\n",
              "      <td>0.689911</td>\n",
              "      <td>0.248962</td>\n",
              "      <td>0.168739</td>\n",
              "      <td>0.700658</td>\n",
              "      <td>0.291710</td>\n",
              "      <td>0.285080</td>\n",
              "      <td>0.263866</td>\n",
              "      <td>0.240913</td>\n",
              "      <td>0.226429</td>\n",
              "      <td>0.281110</td>\n",
              "      <td>0.734375</td>\n",
              "      <td>0.267115</td>\n",
              "      <td>0.266131</td>\n",
              "      <td>0.741187</td>\n",
              "      <td>0.288948</td>\n",
              "      <td>0.628023</td>\n",
              "      <td>0.626254</td>\n",
              "      <td>0.269768</td>\n",
              "      <td>0.642509</td>\n",
              "      <td>0.639889</td>\n",
              "      <td>0.631558</td>\n",
              "      <td>0.176984</td>\n",
              "      <td>0.647038</td>\n",
              "      <td>0.301468</td>\n",
              "      <td>0.420678</td>\n",
              "      <td>0.413922</td>\n",
              "      <td>0.258211</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.113934</td>\n",
              "      <td>0.112442</td>\n",
              "      <td>0.119322</td>\n",
              "      <td>0.645588</td>\n",
              "      <td>0.660449</td>\n",
              "      <td>0.132435</td>\n",
              "      <td>0.632069</td>\n",
              "      <td>0.263147</td>\n",
              "      <td>0.119717</td>\n",
              "      <td>0.641322</td>\n",
              "      <td>0.643500</td>\n",
              "      <td>0.656761</td>\n",
              "      <td>0.258085</td>\n",
              "      <td>0.251820</td>\n",
              "      <td>0.659018</td>\n",
              "      <td>0.628381</td>\n",
              "      <td>0.630256</td>\n",
              "      <td>0.621487</td>\n",
              "      <td>0.269695</td>\n",
              "      <td>0.286610</td>\n",
              "      <td>0.241420</td>\n",
              "      <td>0.619820</td>\n",
              "      <td>0.264192</td>\n",
              "      <td>0.282194</td>\n",
              "      <td>0.621537</td>\n",
              "      <td>0.194297</td>\n",
              "      <td>0.275809</td>\n",
              "      <td>0.182683</td>\n",
              "      <td>0.271582</td>\n",
              "      <td>0.266411</td>\n",
              "      <td>0.633075</td>\n",
              "      <td>0.190689</td>\n",
              "      <td>0.636794</td>\n",
              "      <td>0.184616</td>\n",
              "      <td>0.622806</td>\n",
              "      <td>0.267537</td>\n",
              "      <td>0.188401</td>\n",
              "      <td>0.646956</td>\n",
              "      <td>0.626267</td>\n",
              "      <td>...</td>\n",
              "      <td>0.621448</td>\n",
              "      <td>0.628735</td>\n",
              "      <td>0.613961</td>\n",
              "      <td>0.307392</td>\n",
              "      <td>0.617952</td>\n",
              "      <td>0.632668</td>\n",
              "      <td>0.228110</td>\n",
              "      <td>0.316719</td>\n",
              "      <td>0.638160</td>\n",
              "      <td>0.301570</td>\n",
              "      <td>0.723486</td>\n",
              "      <td>0.286816</td>\n",
              "      <td>0.672381</td>\n",
              "      <td>0.290148</td>\n",
              "      <td>0.206634</td>\n",
              "      <td>0.677821</td>\n",
              "      <td>0.319981</td>\n",
              "      <td>0.316711</td>\n",
              "      <td>0.302736</td>\n",
              "      <td>0.279618</td>\n",
              "      <td>0.263326</td>\n",
              "      <td>0.318060</td>\n",
              "      <td>0.718060</td>\n",
              "      <td>0.305727</td>\n",
              "      <td>0.303800</td>\n",
              "      <td>0.722054</td>\n",
              "      <td>0.315123</td>\n",
              "      <td>0.612670</td>\n",
              "      <td>0.611621</td>\n",
              "      <td>0.311015</td>\n",
              "      <td>0.617605</td>\n",
              "      <td>0.616392</td>\n",
              "      <td>0.615768</td>\n",
              "      <td>0.192330</td>\n",
              "      <td>0.621173</td>\n",
              "      <td>0.326305</td>\n",
              "      <td>0.407039</td>\n",
              "      <td>0.400207</td>\n",
              "      <td>0.295642</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>382</td>\n",
              "      <td>0.042583</td>\n",
              "      <td>0.045035</td>\n",
              "      <td>0.047134</td>\n",
              "      <td>0.728669</td>\n",
              "      <td>0.748919</td>\n",
              "      <td>0.062893</td>\n",
              "      <td>0.707321</td>\n",
              "      <td>0.178650</td>\n",
              "      <td>0.058560</td>\n",
              "      <td>0.721632</td>\n",
              "      <td>0.724311</td>\n",
              "      <td>0.740879</td>\n",
              "      <td>0.176057</td>\n",
              "      <td>0.173938</td>\n",
              "      <td>0.743858</td>\n",
              "      <td>0.699588</td>\n",
              "      <td>0.702000</td>\n",
              "      <td>0.688762</td>\n",
              "      <td>0.186769</td>\n",
              "      <td>0.203422</td>\n",
              "      <td>0.168858</td>\n",
              "      <td>0.684601</td>\n",
              "      <td>0.184651</td>\n",
              "      <td>0.200100</td>\n",
              "      <td>0.686834</td>\n",
              "      <td>0.118948</td>\n",
              "      <td>0.198871</td>\n",
              "      <td>0.114615</td>\n",
              "      <td>0.190982</td>\n",
              "      <td>0.193248</td>\n",
              "      <td>0.702782</td>\n",
              "      <td>0.116313</td>\n",
              "      <td>0.707740</td>\n",
              "      <td>0.114175</td>\n",
              "      <td>0.687071</td>\n",
              "      <td>0.192034</td>\n",
              "      <td>0.115768</td>\n",
              "      <td>0.719837</td>\n",
              "      <td>0.691491</td>\n",
              "      <td>...</td>\n",
              "      <td>0.678186</td>\n",
              "      <td>0.687824</td>\n",
              "      <td>0.666948</td>\n",
              "      <td>0.235956</td>\n",
              "      <td>0.672196</td>\n",
              "      <td>0.690822</td>\n",
              "      <td>0.166641</td>\n",
              "      <td>0.246240</td>\n",
              "      <td>0.697651</td>\n",
              "      <td>0.235827</td>\n",
              "      <td>0.787487</td>\n",
              "      <td>0.224265</td>\n",
              "      <td>0.733380</td>\n",
              "      <td>0.227759</td>\n",
              "      <td>0.156860</td>\n",
              "      <td>0.739789</td>\n",
              "      <td>0.251570</td>\n",
              "      <td>0.249302</td>\n",
              "      <td>0.240222</td>\n",
              "      <td>0.224672</td>\n",
              "      <td>0.212296</td>\n",
              "      <td>0.253105</td>\n",
              "      <td>0.777077</td>\n",
              "      <td>0.245095</td>\n",
              "      <td>0.244083</td>\n",
              "      <td>0.781469</td>\n",
              "      <td>0.251451</td>\n",
              "      <td>0.660317</td>\n",
              "      <td>0.657805</td>\n",
              "      <td>0.250418</td>\n",
              "      <td>0.666274</td>\n",
              "      <td>0.663393</td>\n",
              "      <td>0.662893</td>\n",
              "      <td>0.142186</td>\n",
              "      <td>0.669631</td>\n",
              "      <td>0.264282</td>\n",
              "      <td>0.411506</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>0.241827</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>383</td>\n",
              "      <td>0.098089</td>\n",
              "      <td>0.100955</td>\n",
              "      <td>0.099325</td>\n",
              "      <td>0.832645</td>\n",
              "      <td>0.848669</td>\n",
              "      <td>0.109465</td>\n",
              "      <td>0.813827</td>\n",
              "      <td>0.206665</td>\n",
              "      <td>0.113173</td>\n",
              "      <td>0.823182</td>\n",
              "      <td>0.825677</td>\n",
              "      <td>0.837476</td>\n",
              "      <td>0.205407</td>\n",
              "      <td>0.215514</td>\n",
              "      <td>0.840209</td>\n",
              "      <td>0.804069</td>\n",
              "      <td>0.806298</td>\n",
              "      <td>0.795116</td>\n",
              "      <td>0.216277</td>\n",
              "      <td>0.229719</td>\n",
              "      <td>0.216993</td>\n",
              "      <td>0.788585</td>\n",
              "      <td>0.221778</td>\n",
              "      <td>0.228018</td>\n",
              "      <td>0.790531</td>\n",
              "      <td>0.158426</td>\n",
              "      <td>0.238748</td>\n",
              "      <td>0.164363</td>\n",
              "      <td>0.225588</td>\n",
              "      <td>0.239553</td>\n",
              "      <td>0.797080</td>\n",
              "      <td>0.160146</td>\n",
              "      <td>0.801490</td>\n",
              "      <td>0.162956</td>\n",
              "      <td>0.783675</td>\n",
              "      <td>0.221683</td>\n",
              "      <td>0.163352</td>\n",
              "      <td>0.809140</td>\n",
              "      <td>0.787550</td>\n",
              "      <td>...</td>\n",
              "      <td>0.762522</td>\n",
              "      <td>0.770095</td>\n",
              "      <td>0.752246</td>\n",
              "      <td>0.265283</td>\n",
              "      <td>0.756961</td>\n",
              "      <td>0.769037</td>\n",
              "      <td>0.199743</td>\n",
              "      <td>0.273143</td>\n",
              "      <td>0.774898</td>\n",
              "      <td>0.264131</td>\n",
              "      <td>0.858461</td>\n",
              "      <td>0.252524</td>\n",
              "      <td>0.807356</td>\n",
              "      <td>0.273746</td>\n",
              "      <td>0.206976</td>\n",
              "      <td>0.811481</td>\n",
              "      <td>0.279556</td>\n",
              "      <td>0.275489</td>\n",
              "      <td>0.280252</td>\n",
              "      <td>0.273269</td>\n",
              "      <td>0.260509</td>\n",
              "      <td>0.279313</td>\n",
              "      <td>0.845959</td>\n",
              "      <td>0.281529</td>\n",
              "      <td>0.286892</td>\n",
              "      <td>0.847769</td>\n",
              "      <td>0.280159</td>\n",
              "      <td>0.732552</td>\n",
              "      <td>0.730960</td>\n",
              "      <td>0.283917</td>\n",
              "      <td>0.738205</td>\n",
              "      <td>0.736107</td>\n",
              "      <td>0.732715</td>\n",
              "      <td>0.176038</td>\n",
              "      <td>0.738768</td>\n",
              "      <td>0.292135</td>\n",
              "      <td>0.394111</td>\n",
              "      <td>0.386250</td>\n",
              "      <td>0.287928</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>384</td>\n",
              "      <td>0.030021</td>\n",
              "      <td>0.038381</td>\n",
              "      <td>0.029579</td>\n",
              "      <td>0.775125</td>\n",
              "      <td>0.792937</td>\n",
              "      <td>0.042556</td>\n",
              "      <td>0.756839</td>\n",
              "      <td>0.139110</td>\n",
              "      <td>0.059267</td>\n",
              "      <td>0.768600</td>\n",
              "      <td>0.766205</td>\n",
              "      <td>0.784894</td>\n",
              "      <td>0.141035</td>\n",
              "      <td>0.154036</td>\n",
              "      <td>0.782447</td>\n",
              "      <td>0.749900</td>\n",
              "      <td>0.747969</td>\n",
              "      <td>0.740024</td>\n",
              "      <td>0.148157</td>\n",
              "      <td>0.164470</td>\n",
              "      <td>0.161294</td>\n",
              "      <td>0.735523</td>\n",
              "      <td>0.156173</td>\n",
              "      <td>0.164272</td>\n",
              "      <td>0.733820</td>\n",
              "      <td>0.089841</td>\n",
              "      <td>0.179108</td>\n",
              "      <td>0.105251</td>\n",
              "      <td>0.158740</td>\n",
              "      <td>0.183988</td>\n",
              "      <td>0.744956</td>\n",
              "      <td>0.090450</td>\n",
              "      <td>0.741634</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.731926</td>\n",
              "      <td>0.163305</td>\n",
              "      <td>0.096266</td>\n",
              "      <td>0.758921</td>\n",
              "      <td>0.729061</td>\n",
              "      <td>...</td>\n",
              "      <td>0.705510</td>\n",
              "      <td>0.711642</td>\n",
              "      <td>0.704559</td>\n",
              "      <td>0.209858</td>\n",
              "      <td>0.701626</td>\n",
              "      <td>0.721997</td>\n",
              "      <td>0.146862</td>\n",
              "      <td>0.222657</td>\n",
              "      <td>0.717824</td>\n",
              "      <td>0.212812</td>\n",
              "      <td>0.819347</td>\n",
              "      <td>0.203456</td>\n",
              "      <td>0.767552</td>\n",
              "      <td>0.230926</td>\n",
              "      <td>0.171842</td>\n",
              "      <td>0.763855</td>\n",
              "      <td>0.229115</td>\n",
              "      <td>0.227320</td>\n",
              "      <td>0.240029</td>\n",
              "      <td>0.237068</td>\n",
              "      <td>0.228717</td>\n",
              "      <td>0.228086</td>\n",
              "      <td>0.810681</td>\n",
              "      <td>0.241610</td>\n",
              "      <td>0.248977</td>\n",
              "      <td>0.808146</td>\n",
              "      <td>0.230074</td>\n",
              "      <td>0.686705</td>\n",
              "      <td>0.685961</td>\n",
              "      <td>0.237558</td>\n",
              "      <td>0.682670</td>\n",
              "      <td>0.682699</td>\n",
              "      <td>0.686673</td>\n",
              "      <td>0.130370</td>\n",
              "      <td>0.682473</td>\n",
              "      <td>0.244849</td>\n",
              "      <td>0.396086</td>\n",
              "      <td>0.388178</td>\n",
              "      <td>0.252944</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>385</th>\n",
              "      <td>385</td>\n",
              "      <td>0.029790</td>\n",
              "      <td>0.032586</td>\n",
              "      <td>0.032786</td>\n",
              "      <td>0.803435</td>\n",
              "      <td>0.821342</td>\n",
              "      <td>0.046595</td>\n",
              "      <td>0.783120</td>\n",
              "      <td>0.149567</td>\n",
              "      <td>0.046569</td>\n",
              "      <td>0.795293</td>\n",
              "      <td>0.795607</td>\n",
              "      <td>0.811954</td>\n",
              "      <td>0.149780</td>\n",
              "      <td>0.150114</td>\n",
              "      <td>0.812003</td>\n",
              "      <td>0.774113</td>\n",
              "      <td>0.774908</td>\n",
              "      <td>0.763476</td>\n",
              "      <td>0.158602</td>\n",
              "      <td>0.175099</td>\n",
              "      <td>0.150225</td>\n",
              "      <td>0.757582</td>\n",
              "      <td>0.158929</td>\n",
              "      <td>0.174224</td>\n",
              "      <td>0.758704</td>\n",
              "      <td>0.099011</td>\n",
              "      <td>0.175888</td>\n",
              "      <td>0.099284</td>\n",
              "      <td>0.165675</td>\n",
              "      <td>0.174889</td>\n",
              "      <td>0.769847</td>\n",
              "      <td>0.099227</td>\n",
              "      <td>0.771256</td>\n",
              "      <td>0.099572</td>\n",
              "      <td>0.754594</td>\n",
              "      <td>0.169526</td>\n",
              "      <td>0.101058</td>\n",
              "      <td>0.784358</td>\n",
              "      <td>0.756448</td>\n",
              "      <td>...</td>\n",
              "      <td>0.732561</td>\n",
              "      <td>0.740327</td>\n",
              "      <td>0.723830</td>\n",
              "      <td>0.218522</td>\n",
              "      <td>0.727121</td>\n",
              "      <td>0.744616</td>\n",
              "      <td>0.148923</td>\n",
              "      <td>0.227996</td>\n",
              "      <td>0.746451</td>\n",
              "      <td>0.218015</td>\n",
              "      <td>0.836178</td>\n",
              "      <td>0.205789</td>\n",
              "      <td>0.785772</td>\n",
              "      <td>0.219019</td>\n",
              "      <td>0.148878</td>\n",
              "      <td>0.786354</td>\n",
              "      <td>0.235142</td>\n",
              "      <td>0.231854</td>\n",
              "      <td>0.228937</td>\n",
              "      <td>0.217596</td>\n",
              "      <td>0.205009</td>\n",
              "      <td>0.235732</td>\n",
              "      <td>0.825436</td>\n",
              "      <td>0.232628</td>\n",
              "      <td>0.236433</td>\n",
              "      <td>0.825896</td>\n",
              "      <td>0.236950</td>\n",
              "      <td>0.706180</td>\n",
              "      <td>0.704105</td>\n",
              "      <td>0.236436</td>\n",
              "      <td>0.709578</td>\n",
              "      <td>0.707765</td>\n",
              "      <td>0.706934</td>\n",
              "      <td>0.126320</td>\n",
              "      <td>0.710156</td>\n",
              "      <td>0.250745</td>\n",
              "      <td>0.382399</td>\n",
              "      <td>0.373651</td>\n",
              "      <td>0.237434</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>386</td>\n",
              "      <td>0.028294</td>\n",
              "      <td>0.031425</td>\n",
              "      <td>0.032584</td>\n",
              "      <td>0.798233</td>\n",
              "      <td>0.814960</td>\n",
              "      <td>0.048443</td>\n",
              "      <td>0.779954</td>\n",
              "      <td>0.166443</td>\n",
              "      <td>0.046820</td>\n",
              "      <td>0.788627</td>\n",
              "      <td>0.790966</td>\n",
              "      <td>0.803303</td>\n",
              "      <td>0.162677</td>\n",
              "      <td>0.169883</td>\n",
              "      <td>0.805924</td>\n",
              "      <td>0.769750</td>\n",
              "      <td>0.772434</td>\n",
              "      <td>0.762304</td>\n",
              "      <td>0.176322</td>\n",
              "      <td>0.190824</td>\n",
              "      <td>0.166948</td>\n",
              "      <td>0.754930</td>\n",
              "      <td>0.178744</td>\n",
              "      <td>0.185964</td>\n",
              "      <td>0.757427</td>\n",
              "      <td>0.105134</td>\n",
              "      <td>0.194805</td>\n",
              "      <td>0.105626</td>\n",
              "      <td>0.182422</td>\n",
              "      <td>0.190902</td>\n",
              "      <td>0.760143</td>\n",
              "      <td>0.102472</td>\n",
              "      <td>0.765568</td>\n",
              "      <td>0.102679</td>\n",
              "      <td>0.746955</td>\n",
              "      <td>0.178944</td>\n",
              "      <td>0.102618</td>\n",
              "      <td>0.772934</td>\n",
              "      <td>0.752284</td>\n",
              "      <td>...</td>\n",
              "      <td>0.724808</td>\n",
              "      <td>0.731656</td>\n",
              "      <td>0.712595</td>\n",
              "      <td>0.219281</td>\n",
              "      <td>0.720248</td>\n",
              "      <td>0.728908</td>\n",
              "      <td>0.154923</td>\n",
              "      <td>0.225278</td>\n",
              "      <td>0.736722</td>\n",
              "      <td>0.222614</td>\n",
              "      <td>0.831937</td>\n",
              "      <td>0.212774</td>\n",
              "      <td>0.774749</td>\n",
              "      <td>0.221938</td>\n",
              "      <td>0.154258</td>\n",
              "      <td>0.779241</td>\n",
              "      <td>0.231242</td>\n",
              "      <td>0.230126</td>\n",
              "      <td>0.227691</td>\n",
              "      <td>0.224401</td>\n",
              "      <td>0.212821</td>\n",
              "      <td>0.240014</td>\n",
              "      <td>0.818825</td>\n",
              "      <td>0.231867</td>\n",
              "      <td>0.233778</td>\n",
              "      <td>0.820524</td>\n",
              "      <td>0.235848</td>\n",
              "      <td>0.687937</td>\n",
              "      <td>0.687617</td>\n",
              "      <td>0.241956</td>\n",
              "      <td>0.697457</td>\n",
              "      <td>0.696794</td>\n",
              "      <td>0.686967</td>\n",
              "      <td>0.130918</td>\n",
              "      <td>0.697060</td>\n",
              "      <td>0.245452</td>\n",
              "      <td>0.388187</td>\n",
              "      <td>0.379850</td>\n",
              "      <td>0.237805</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>387 rows × 102 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0       11y      339y  ...       62x      446y  output\n",
              "0             0  0.087810  0.086514  ...  0.359189  0.292456       0\n",
              "1             1  0.098683  0.098165  ...  0.409262  0.291724       0\n",
              "2             2  0.085394  0.084500  ...  0.380484  0.280708       0\n",
              "3             3  0.075667  0.071821  ...  0.413922  0.258211       0\n",
              "4             4  0.113934  0.112442  ...  0.400207  0.295642       0\n",
              "..          ...       ...       ...  ...       ...       ...     ...\n",
              "382         382  0.042583  0.045035  ...  0.403034  0.241827       7\n",
              "383         383  0.098089  0.100955  ...  0.386250  0.287928       7\n",
              "384         384  0.030021  0.038381  ...  0.388178  0.252944       7\n",
              "385         385  0.029790  0.032586  ...  0.373651  0.237434       7\n",
              "386         386  0.028294  0.031425  ...  0.379850  0.237805       7\n",
              "\n",
              "[387 rows x 102 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LojMwG4lWz7K",
        "outputId": "79e93b58-2428-4ed9-8db0-e4ba3771c212"
      },
      "source": [
        "sentiment_data_small_version['output'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7    83\n",
              "4    69\n",
              "5    60\n",
              "2    59\n",
              "0    45\n",
              "6    28\n",
              "3    25\n",
              "1    18\n",
              "Name: output, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvDgkKUsYy2D"
      },
      "source": [
        "## Mapping The Output Column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JmeYUMXY16u"
      },
      "source": [
        "input_df_copy = sentiment_data_small_version"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK1LdxEXZTRI"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wynE83nGZaAN"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvVsxGNI_rzq",
        "outputId": "986b3d98-3d70-4ad6-b3c7-e5cb24544d23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "X = input_df_copy.drop(\"output\", axis=1)\n",
        "X = X.drop(\"Unnamed: 0\", axis=1)\n",
        "X"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>11y</th>\n",
              "      <th>339y</th>\n",
              "      <th>110y</th>\n",
              "      <th>17y</th>\n",
              "      <th>18y</th>\n",
              "      <th>68y</th>\n",
              "      <th>16y</th>\n",
              "      <th>67y</th>\n",
              "      <th>298y</th>\n",
              "      <th>316y</th>\n",
              "      <th>86y</th>\n",
              "      <th>315y</th>\n",
              "      <th>106y</th>\n",
              "      <th>297y</th>\n",
              "      <th>85y</th>\n",
              "      <th>317y</th>\n",
              "      <th>87y</th>\n",
              "      <th>15y</th>\n",
              "      <th>108y</th>\n",
              "      <th>66y</th>\n",
              "      <th>335y</th>\n",
              "      <th>318y</th>\n",
              "      <th>337y</th>\n",
              "      <th>53y</th>\n",
              "      <th>88y</th>\n",
              "      <th>70y</th>\n",
              "      <th>296y</th>\n",
              "      <th>300y</th>\n",
              "      <th>10y</th>\n",
              "      <th>283y</th>\n",
              "      <th>405y</th>\n",
              "      <th>109y</th>\n",
              "      <th>181y</th>\n",
              "      <th>338y</th>\n",
              "      <th>404y</th>\n",
              "      <th>64y</th>\n",
              "      <th>152y</th>\n",
              "      <th>406y</th>\n",
              "      <th>180y</th>\n",
              "      <th>105y</th>\n",
              "      <th>...</th>\n",
              "      <th>443y</th>\n",
              "      <th>90y</th>\n",
              "      <th>91y</th>\n",
              "      <th>319y</th>\n",
              "      <th>225y</th>\n",
              "      <th>89y</th>\n",
              "      <th>322y</th>\n",
              "      <th>69y</th>\n",
              "      <th>28y</th>\n",
              "      <th>92y</th>\n",
              "      <th>47y</th>\n",
              "      <th>201y</th>\n",
              "      <th>71y</th>\n",
              "      <th>407y</th>\n",
              "      <th>445y</th>\n",
              "      <th>299y</th>\n",
              "      <th>183y</th>\n",
              "      <th>30y</th>\n",
              "      <th>29y</th>\n",
              "      <th>258y</th>\n",
              "      <th>277y</th>\n",
              "      <th>301y</th>\n",
              "      <th>222y</th>\n",
              "      <th>422y</th>\n",
              "      <th>259y</th>\n",
              "      <th>260y</th>\n",
              "      <th>202y</th>\n",
              "      <th>226y</th>\n",
              "      <th>326y</th>\n",
              "      <th>325y</th>\n",
              "      <th>442y</th>\n",
              "      <th>97y</th>\n",
              "      <th>96y</th>\n",
              "      <th>308y</th>\n",
              "      <th>55y</th>\n",
              "      <th>78y</th>\n",
              "      <th>31y</th>\n",
              "      <th>77x</th>\n",
              "      <th>62x</th>\n",
              "      <th>446y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.087810</td>\n",
              "      <td>0.086514</td>\n",
              "      <td>0.093708</td>\n",
              "      <td>0.701211</td>\n",
              "      <td>0.716253</td>\n",
              "      <td>0.108578</td>\n",
              "      <td>0.686886</td>\n",
              "      <td>0.234690</td>\n",
              "      <td>0.095875</td>\n",
              "      <td>0.696938</td>\n",
              "      <td>0.699335</td>\n",
              "      <td>0.712851</td>\n",
              "      <td>0.234497</td>\n",
              "      <td>0.225658</td>\n",
              "      <td>0.715577</td>\n",
              "      <td>0.683342</td>\n",
              "      <td>0.685688</td>\n",
              "      <td>0.675410</td>\n",
              "      <td>0.238876</td>\n",
              "      <td>0.260274</td>\n",
              "      <td>0.222080</td>\n",
              "      <td>0.673641</td>\n",
              "      <td>0.234514</td>\n",
              "      <td>0.259857</td>\n",
              "      <td>0.675797</td>\n",
              "      <td>0.169770</td>\n",
              "      <td>0.251879</td>\n",
              "      <td>0.159167</td>\n",
              "      <td>0.243084</td>\n",
              "      <td>0.248609</td>\n",
              "      <td>0.687927</td>\n",
              "      <td>0.166242</td>\n",
              "      <td>0.692763</td>\n",
              "      <td>0.160365</td>\n",
              "      <td>0.677250</td>\n",
              "      <td>0.249370</td>\n",
              "      <td>0.165286</td>\n",
              "      <td>0.702218</td>\n",
              "      <td>0.681785</td>\n",
              "      <td>0.183595</td>\n",
              "      <td>...</td>\n",
              "      <td>0.282703</td>\n",
              "      <td>0.677961</td>\n",
              "      <td>0.685568</td>\n",
              "      <td>0.668658</td>\n",
              "      <td>0.295010</td>\n",
              "      <td>0.674744</td>\n",
              "      <td>0.688078</td>\n",
              "      <td>0.213322</td>\n",
              "      <td>0.306147</td>\n",
              "      <td>0.695070</td>\n",
              "      <td>0.290614</td>\n",
              "      <td>0.775533</td>\n",
              "      <td>0.275985</td>\n",
              "      <td>0.727246</td>\n",
              "      <td>0.282305</td>\n",
              "      <td>0.196207</td>\n",
              "      <td>0.731739</td>\n",
              "      <td>0.311140</td>\n",
              "      <td>0.306318</td>\n",
              "      <td>0.295218</td>\n",
              "      <td>0.275201</td>\n",
              "      <td>0.259249</td>\n",
              "      <td>0.303790</td>\n",
              "      <td>0.772824</td>\n",
              "      <td>0.297142</td>\n",
              "      <td>0.298986</td>\n",
              "      <td>0.775157</td>\n",
              "      <td>0.306662</td>\n",
              "      <td>0.669025</td>\n",
              "      <td>0.667577</td>\n",
              "      <td>0.297944</td>\n",
              "      <td>0.676777</td>\n",
              "      <td>0.674650</td>\n",
              "      <td>0.672384</td>\n",
              "      <td>0.179662</td>\n",
              "      <td>0.680488</td>\n",
              "      <td>0.320749</td>\n",
              "      <td>0.365988</td>\n",
              "      <td>0.359189</td>\n",
              "      <td>0.292456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.098683</td>\n",
              "      <td>0.098165</td>\n",
              "      <td>0.104281</td>\n",
              "      <td>0.664070</td>\n",
              "      <td>0.679439</td>\n",
              "      <td>0.119037</td>\n",
              "      <td>0.650274</td>\n",
              "      <td>0.250426</td>\n",
              "      <td>0.107617</td>\n",
              "      <td>0.660159</td>\n",
              "      <td>0.663162</td>\n",
              "      <td>0.676266</td>\n",
              "      <td>0.250525</td>\n",
              "      <td>0.238674</td>\n",
              "      <td>0.679406</td>\n",
              "      <td>0.647318</td>\n",
              "      <td>0.649850</td>\n",
              "      <td>0.639768</td>\n",
              "      <td>0.252469</td>\n",
              "      <td>0.275065</td>\n",
              "      <td>0.233286</td>\n",
              "      <td>0.638513</td>\n",
              "      <td>0.246897</td>\n",
              "      <td>0.275109</td>\n",
              "      <td>0.640868</td>\n",
              "      <td>0.180109</td>\n",
              "      <td>0.263580</td>\n",
              "      <td>0.168977</td>\n",
              "      <td>0.254662</td>\n",
              "      <td>0.258694</td>\n",
              "      <td>0.653565</td>\n",
              "      <td>0.174024</td>\n",
              "      <td>0.659207</td>\n",
              "      <td>0.168450</td>\n",
              "      <td>0.643540</td>\n",
              "      <td>0.264527</td>\n",
              "      <td>0.172342</td>\n",
              "      <td>0.667974</td>\n",
              "      <td>0.648536</td>\n",
              "      <td>0.194566</td>\n",
              "      <td>...</td>\n",
              "      <td>0.287110</td>\n",
              "      <td>0.647792</td>\n",
              "      <td>0.655260</td>\n",
              "      <td>0.637938</td>\n",
              "      <td>0.302938</td>\n",
              "      <td>0.644361</td>\n",
              "      <td>0.657061</td>\n",
              "      <td>0.222941</td>\n",
              "      <td>0.311552</td>\n",
              "      <td>0.665310</td>\n",
              "      <td>0.300203</td>\n",
              "      <td>0.746999</td>\n",
              "      <td>0.286466</td>\n",
              "      <td>0.695820</td>\n",
              "      <td>0.284965</td>\n",
              "      <td>0.202315</td>\n",
              "      <td>0.703365</td>\n",
              "      <td>0.316241</td>\n",
              "      <td>0.309106</td>\n",
              "      <td>0.296829</td>\n",
              "      <td>0.277635</td>\n",
              "      <td>0.263057</td>\n",
              "      <td>0.305376</td>\n",
              "      <td>0.742319</td>\n",
              "      <td>0.297439</td>\n",
              "      <td>0.299121</td>\n",
              "      <td>0.747618</td>\n",
              "      <td>0.311871</td>\n",
              "      <td>0.640539</td>\n",
              "      <td>0.638694</td>\n",
              "      <td>0.298007</td>\n",
              "      <td>0.648763</td>\n",
              "      <td>0.646393</td>\n",
              "      <td>0.644356</td>\n",
              "      <td>0.187314</td>\n",
              "      <td>0.653283</td>\n",
              "      <td>0.323162</td>\n",
              "      <td>0.416444</td>\n",
              "      <td>0.409262</td>\n",
              "      <td>0.291724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.085394</td>\n",
              "      <td>0.084500</td>\n",
              "      <td>0.091048</td>\n",
              "      <td>0.660387</td>\n",
              "      <td>0.674604</td>\n",
              "      <td>0.105700</td>\n",
              "      <td>0.647303</td>\n",
              "      <td>0.229239</td>\n",
              "      <td>0.093703</td>\n",
              "      <td>0.656849</td>\n",
              "      <td>0.658943</td>\n",
              "      <td>0.672119</td>\n",
              "      <td>0.230414</td>\n",
              "      <td>0.219152</td>\n",
              "      <td>0.674397</td>\n",
              "      <td>0.644289</td>\n",
              "      <td>0.646311</td>\n",
              "      <td>0.637065</td>\n",
              "      <td>0.231457</td>\n",
              "      <td>0.253444</td>\n",
              "      <td>0.216089</td>\n",
              "      <td>0.635543</td>\n",
              "      <td>0.226580</td>\n",
              "      <td>0.254535</td>\n",
              "      <td>0.637335</td>\n",
              "      <td>0.164377</td>\n",
              "      <td>0.243990</td>\n",
              "      <td>0.153830</td>\n",
              "      <td>0.234519</td>\n",
              "      <td>0.241096</td>\n",
              "      <td>0.649563</td>\n",
              "      <td>0.159373</td>\n",
              "      <td>0.653839</td>\n",
              "      <td>0.153670</td>\n",
              "      <td>0.639724</td>\n",
              "      <td>0.245381</td>\n",
              "      <td>0.158003</td>\n",
              "      <td>0.662932</td>\n",
              "      <td>0.643669</td>\n",
              "      <td>0.179022</td>\n",
              "      <td>...</td>\n",
              "      <td>0.271447</td>\n",
              "      <td>0.641113</td>\n",
              "      <td>0.648317</td>\n",
              "      <td>0.632508</td>\n",
              "      <td>0.285705</td>\n",
              "      <td>0.638079</td>\n",
              "      <td>0.650801</td>\n",
              "      <td>0.207404</td>\n",
              "      <td>0.294994</td>\n",
              "      <td>0.657289</td>\n",
              "      <td>0.282803</td>\n",
              "      <td>0.731376</td>\n",
              "      <td>0.268743</td>\n",
              "      <td>0.687396</td>\n",
              "      <td>0.271849</td>\n",
              "      <td>0.189208</td>\n",
              "      <td>0.692087</td>\n",
              "      <td>0.300169</td>\n",
              "      <td>0.293459</td>\n",
              "      <td>0.283855</td>\n",
              "      <td>0.265146</td>\n",
              "      <td>0.249984</td>\n",
              "      <td>0.289564</td>\n",
              "      <td>0.729418</td>\n",
              "      <td>0.284528</td>\n",
              "      <td>0.287387</td>\n",
              "      <td>0.732354</td>\n",
              "      <td>0.296178</td>\n",
              "      <td>0.633570</td>\n",
              "      <td>0.631925</td>\n",
              "      <td>0.284262</td>\n",
              "      <td>0.640842</td>\n",
              "      <td>0.638711</td>\n",
              "      <td>0.636973</td>\n",
              "      <td>0.173512</td>\n",
              "      <td>0.644635</td>\n",
              "      <td>0.308359</td>\n",
              "      <td>0.387020</td>\n",
              "      <td>0.380484</td>\n",
              "      <td>0.280708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.075667</td>\n",
              "      <td>0.071821</td>\n",
              "      <td>0.084392</td>\n",
              "      <td>0.665309</td>\n",
              "      <td>0.682307</td>\n",
              "      <td>0.101926</td>\n",
              "      <td>0.649277</td>\n",
              "      <td>0.217908</td>\n",
              "      <td>0.078597</td>\n",
              "      <td>0.659706</td>\n",
              "      <td>0.664673</td>\n",
              "      <td>0.677375</td>\n",
              "      <td>0.219089</td>\n",
              "      <td>0.198675</td>\n",
              "      <td>0.682582</td>\n",
              "      <td>0.644042</td>\n",
              "      <td>0.648405</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.220197</td>\n",
              "      <td>0.242033</td>\n",
              "      <td>0.191865</td>\n",
              "      <td>0.633418</td>\n",
              "      <td>0.210470</td>\n",
              "      <td>0.242735</td>\n",
              "      <td>0.637605</td>\n",
              "      <td>0.156903</td>\n",
              "      <td>0.223781</td>\n",
              "      <td>0.136231</td>\n",
              "      <td>0.220827</td>\n",
              "      <td>0.217122</td>\n",
              "      <td>0.649569</td>\n",
              "      <td>0.150251</td>\n",
              "      <td>0.658837</td>\n",
              "      <td>0.139265</td>\n",
              "      <td>0.637484</td>\n",
              "      <td>0.235818</td>\n",
              "      <td>0.145927</td>\n",
              "      <td>0.665114</td>\n",
              "      <td>0.646164</td>\n",
              "      <td>0.173008</td>\n",
              "      <td>...</td>\n",
              "      <td>0.252855</td>\n",
              "      <td>0.643557</td>\n",
              "      <td>0.652164</td>\n",
              "      <td>0.627880</td>\n",
              "      <td>0.276592</td>\n",
              "      <td>0.639275</td>\n",
              "      <td>0.649096</td>\n",
              "      <td>0.204637</td>\n",
              "      <td>0.285989</td>\n",
              "      <td>0.662667</td>\n",
              "      <td>0.275408</td>\n",
              "      <td>0.739109</td>\n",
              "      <td>0.263612</td>\n",
              "      <td>0.689911</td>\n",
              "      <td>0.248962</td>\n",
              "      <td>0.168739</td>\n",
              "      <td>0.700658</td>\n",
              "      <td>0.291710</td>\n",
              "      <td>0.285080</td>\n",
              "      <td>0.263866</td>\n",
              "      <td>0.240913</td>\n",
              "      <td>0.226429</td>\n",
              "      <td>0.281110</td>\n",
              "      <td>0.734375</td>\n",
              "      <td>0.267115</td>\n",
              "      <td>0.266131</td>\n",
              "      <td>0.741187</td>\n",
              "      <td>0.288948</td>\n",
              "      <td>0.628023</td>\n",
              "      <td>0.626254</td>\n",
              "      <td>0.269768</td>\n",
              "      <td>0.642509</td>\n",
              "      <td>0.639889</td>\n",
              "      <td>0.631558</td>\n",
              "      <td>0.176984</td>\n",
              "      <td>0.647038</td>\n",
              "      <td>0.301468</td>\n",
              "      <td>0.420678</td>\n",
              "      <td>0.413922</td>\n",
              "      <td>0.258211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.113934</td>\n",
              "      <td>0.112442</td>\n",
              "      <td>0.119322</td>\n",
              "      <td>0.645588</td>\n",
              "      <td>0.660449</td>\n",
              "      <td>0.132435</td>\n",
              "      <td>0.632069</td>\n",
              "      <td>0.263147</td>\n",
              "      <td>0.119717</td>\n",
              "      <td>0.641322</td>\n",
              "      <td>0.643500</td>\n",
              "      <td>0.656761</td>\n",
              "      <td>0.258085</td>\n",
              "      <td>0.251820</td>\n",
              "      <td>0.659018</td>\n",
              "      <td>0.628381</td>\n",
              "      <td>0.630256</td>\n",
              "      <td>0.621487</td>\n",
              "      <td>0.269695</td>\n",
              "      <td>0.286610</td>\n",
              "      <td>0.241420</td>\n",
              "      <td>0.619820</td>\n",
              "      <td>0.264192</td>\n",
              "      <td>0.282194</td>\n",
              "      <td>0.621537</td>\n",
              "      <td>0.194297</td>\n",
              "      <td>0.275809</td>\n",
              "      <td>0.182683</td>\n",
              "      <td>0.271582</td>\n",
              "      <td>0.266411</td>\n",
              "      <td>0.633075</td>\n",
              "      <td>0.190689</td>\n",
              "      <td>0.636794</td>\n",
              "      <td>0.184616</td>\n",
              "      <td>0.622806</td>\n",
              "      <td>0.267537</td>\n",
              "      <td>0.188401</td>\n",
              "      <td>0.646956</td>\n",
              "      <td>0.626267</td>\n",
              "      <td>0.203949</td>\n",
              "      <td>...</td>\n",
              "      <td>0.296709</td>\n",
              "      <td>0.621448</td>\n",
              "      <td>0.628735</td>\n",
              "      <td>0.613961</td>\n",
              "      <td>0.307392</td>\n",
              "      <td>0.617952</td>\n",
              "      <td>0.632668</td>\n",
              "      <td>0.228110</td>\n",
              "      <td>0.316719</td>\n",
              "      <td>0.638160</td>\n",
              "      <td>0.301570</td>\n",
              "      <td>0.723486</td>\n",
              "      <td>0.286816</td>\n",
              "      <td>0.672381</td>\n",
              "      <td>0.290148</td>\n",
              "      <td>0.206634</td>\n",
              "      <td>0.677821</td>\n",
              "      <td>0.319981</td>\n",
              "      <td>0.316711</td>\n",
              "      <td>0.302736</td>\n",
              "      <td>0.279618</td>\n",
              "      <td>0.263326</td>\n",
              "      <td>0.318060</td>\n",
              "      <td>0.718060</td>\n",
              "      <td>0.305727</td>\n",
              "      <td>0.303800</td>\n",
              "      <td>0.722054</td>\n",
              "      <td>0.315123</td>\n",
              "      <td>0.612670</td>\n",
              "      <td>0.611621</td>\n",
              "      <td>0.311015</td>\n",
              "      <td>0.617605</td>\n",
              "      <td>0.616392</td>\n",
              "      <td>0.615768</td>\n",
              "      <td>0.192330</td>\n",
              "      <td>0.621173</td>\n",
              "      <td>0.326305</td>\n",
              "      <td>0.407039</td>\n",
              "      <td>0.400207</td>\n",
              "      <td>0.295642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>0.042583</td>\n",
              "      <td>0.045035</td>\n",
              "      <td>0.047134</td>\n",
              "      <td>0.728669</td>\n",
              "      <td>0.748919</td>\n",
              "      <td>0.062893</td>\n",
              "      <td>0.707321</td>\n",
              "      <td>0.178650</td>\n",
              "      <td>0.058560</td>\n",
              "      <td>0.721632</td>\n",
              "      <td>0.724311</td>\n",
              "      <td>0.740879</td>\n",
              "      <td>0.176057</td>\n",
              "      <td>0.173938</td>\n",
              "      <td>0.743858</td>\n",
              "      <td>0.699588</td>\n",
              "      <td>0.702000</td>\n",
              "      <td>0.688762</td>\n",
              "      <td>0.186769</td>\n",
              "      <td>0.203422</td>\n",
              "      <td>0.168858</td>\n",
              "      <td>0.684601</td>\n",
              "      <td>0.184651</td>\n",
              "      <td>0.200100</td>\n",
              "      <td>0.686834</td>\n",
              "      <td>0.118948</td>\n",
              "      <td>0.198871</td>\n",
              "      <td>0.114615</td>\n",
              "      <td>0.190982</td>\n",
              "      <td>0.193248</td>\n",
              "      <td>0.702782</td>\n",
              "      <td>0.116313</td>\n",
              "      <td>0.707740</td>\n",
              "      <td>0.114175</td>\n",
              "      <td>0.687071</td>\n",
              "      <td>0.192034</td>\n",
              "      <td>0.115768</td>\n",
              "      <td>0.719837</td>\n",
              "      <td>0.691491</td>\n",
              "      <td>0.133331</td>\n",
              "      <td>...</td>\n",
              "      <td>0.229436</td>\n",
              "      <td>0.678186</td>\n",
              "      <td>0.687824</td>\n",
              "      <td>0.666948</td>\n",
              "      <td>0.235956</td>\n",
              "      <td>0.672196</td>\n",
              "      <td>0.690822</td>\n",
              "      <td>0.166641</td>\n",
              "      <td>0.246240</td>\n",
              "      <td>0.697651</td>\n",
              "      <td>0.235827</td>\n",
              "      <td>0.787487</td>\n",
              "      <td>0.224265</td>\n",
              "      <td>0.733380</td>\n",
              "      <td>0.227759</td>\n",
              "      <td>0.156860</td>\n",
              "      <td>0.739789</td>\n",
              "      <td>0.251570</td>\n",
              "      <td>0.249302</td>\n",
              "      <td>0.240222</td>\n",
              "      <td>0.224672</td>\n",
              "      <td>0.212296</td>\n",
              "      <td>0.253105</td>\n",
              "      <td>0.777077</td>\n",
              "      <td>0.245095</td>\n",
              "      <td>0.244083</td>\n",
              "      <td>0.781469</td>\n",
              "      <td>0.251451</td>\n",
              "      <td>0.660317</td>\n",
              "      <td>0.657805</td>\n",
              "      <td>0.250418</td>\n",
              "      <td>0.666274</td>\n",
              "      <td>0.663393</td>\n",
              "      <td>0.662893</td>\n",
              "      <td>0.142186</td>\n",
              "      <td>0.669631</td>\n",
              "      <td>0.264282</td>\n",
              "      <td>0.411506</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>0.241827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>0.098089</td>\n",
              "      <td>0.100955</td>\n",
              "      <td>0.099325</td>\n",
              "      <td>0.832645</td>\n",
              "      <td>0.848669</td>\n",
              "      <td>0.109465</td>\n",
              "      <td>0.813827</td>\n",
              "      <td>0.206665</td>\n",
              "      <td>0.113173</td>\n",
              "      <td>0.823182</td>\n",
              "      <td>0.825677</td>\n",
              "      <td>0.837476</td>\n",
              "      <td>0.205407</td>\n",
              "      <td>0.215514</td>\n",
              "      <td>0.840209</td>\n",
              "      <td>0.804069</td>\n",
              "      <td>0.806298</td>\n",
              "      <td>0.795116</td>\n",
              "      <td>0.216277</td>\n",
              "      <td>0.229719</td>\n",
              "      <td>0.216993</td>\n",
              "      <td>0.788585</td>\n",
              "      <td>0.221778</td>\n",
              "      <td>0.228018</td>\n",
              "      <td>0.790531</td>\n",
              "      <td>0.158426</td>\n",
              "      <td>0.238748</td>\n",
              "      <td>0.164363</td>\n",
              "      <td>0.225588</td>\n",
              "      <td>0.239553</td>\n",
              "      <td>0.797080</td>\n",
              "      <td>0.160146</td>\n",
              "      <td>0.801490</td>\n",
              "      <td>0.162956</td>\n",
              "      <td>0.783675</td>\n",
              "      <td>0.221683</td>\n",
              "      <td>0.163352</td>\n",
              "      <td>0.809140</td>\n",
              "      <td>0.787550</td>\n",
              "      <td>0.169676</td>\n",
              "      <td>...</td>\n",
              "      <td>0.267666</td>\n",
              "      <td>0.762522</td>\n",
              "      <td>0.770095</td>\n",
              "      <td>0.752246</td>\n",
              "      <td>0.265283</td>\n",
              "      <td>0.756961</td>\n",
              "      <td>0.769037</td>\n",
              "      <td>0.199743</td>\n",
              "      <td>0.273143</td>\n",
              "      <td>0.774898</td>\n",
              "      <td>0.264131</td>\n",
              "      <td>0.858461</td>\n",
              "      <td>0.252524</td>\n",
              "      <td>0.807356</td>\n",
              "      <td>0.273746</td>\n",
              "      <td>0.206976</td>\n",
              "      <td>0.811481</td>\n",
              "      <td>0.279556</td>\n",
              "      <td>0.275489</td>\n",
              "      <td>0.280252</td>\n",
              "      <td>0.273269</td>\n",
              "      <td>0.260509</td>\n",
              "      <td>0.279313</td>\n",
              "      <td>0.845959</td>\n",
              "      <td>0.281529</td>\n",
              "      <td>0.286892</td>\n",
              "      <td>0.847769</td>\n",
              "      <td>0.280159</td>\n",
              "      <td>0.732552</td>\n",
              "      <td>0.730960</td>\n",
              "      <td>0.283917</td>\n",
              "      <td>0.738205</td>\n",
              "      <td>0.736107</td>\n",
              "      <td>0.732715</td>\n",
              "      <td>0.176038</td>\n",
              "      <td>0.738768</td>\n",
              "      <td>0.292135</td>\n",
              "      <td>0.394111</td>\n",
              "      <td>0.386250</td>\n",
              "      <td>0.287928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>0.030021</td>\n",
              "      <td>0.038381</td>\n",
              "      <td>0.029579</td>\n",
              "      <td>0.775125</td>\n",
              "      <td>0.792937</td>\n",
              "      <td>0.042556</td>\n",
              "      <td>0.756839</td>\n",
              "      <td>0.139110</td>\n",
              "      <td>0.059267</td>\n",
              "      <td>0.768600</td>\n",
              "      <td>0.766205</td>\n",
              "      <td>0.784894</td>\n",
              "      <td>0.141035</td>\n",
              "      <td>0.154036</td>\n",
              "      <td>0.782447</td>\n",
              "      <td>0.749900</td>\n",
              "      <td>0.747969</td>\n",
              "      <td>0.740024</td>\n",
              "      <td>0.148157</td>\n",
              "      <td>0.164470</td>\n",
              "      <td>0.161294</td>\n",
              "      <td>0.735523</td>\n",
              "      <td>0.156173</td>\n",
              "      <td>0.164272</td>\n",
              "      <td>0.733820</td>\n",
              "      <td>0.089841</td>\n",
              "      <td>0.179108</td>\n",
              "      <td>0.105251</td>\n",
              "      <td>0.158740</td>\n",
              "      <td>0.183988</td>\n",
              "      <td>0.744956</td>\n",
              "      <td>0.090450</td>\n",
              "      <td>0.741634</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.731926</td>\n",
              "      <td>0.163305</td>\n",
              "      <td>0.096266</td>\n",
              "      <td>0.758921</td>\n",
              "      <td>0.729061</td>\n",
              "      <td>0.107759</td>\n",
              "      <td>...</td>\n",
              "      <td>0.218759</td>\n",
              "      <td>0.705510</td>\n",
              "      <td>0.711642</td>\n",
              "      <td>0.704559</td>\n",
              "      <td>0.209858</td>\n",
              "      <td>0.701626</td>\n",
              "      <td>0.721997</td>\n",
              "      <td>0.146862</td>\n",
              "      <td>0.222657</td>\n",
              "      <td>0.717824</td>\n",
              "      <td>0.212812</td>\n",
              "      <td>0.819347</td>\n",
              "      <td>0.203456</td>\n",
              "      <td>0.767552</td>\n",
              "      <td>0.230926</td>\n",
              "      <td>0.171842</td>\n",
              "      <td>0.763855</td>\n",
              "      <td>0.229115</td>\n",
              "      <td>0.227320</td>\n",
              "      <td>0.240029</td>\n",
              "      <td>0.237068</td>\n",
              "      <td>0.228717</td>\n",
              "      <td>0.228086</td>\n",
              "      <td>0.810681</td>\n",
              "      <td>0.241610</td>\n",
              "      <td>0.248977</td>\n",
              "      <td>0.808146</td>\n",
              "      <td>0.230074</td>\n",
              "      <td>0.686705</td>\n",
              "      <td>0.685961</td>\n",
              "      <td>0.237558</td>\n",
              "      <td>0.682670</td>\n",
              "      <td>0.682699</td>\n",
              "      <td>0.686673</td>\n",
              "      <td>0.130370</td>\n",
              "      <td>0.682473</td>\n",
              "      <td>0.244849</td>\n",
              "      <td>0.396086</td>\n",
              "      <td>0.388178</td>\n",
              "      <td>0.252944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>385</th>\n",
              "      <td>0.029790</td>\n",
              "      <td>0.032586</td>\n",
              "      <td>0.032786</td>\n",
              "      <td>0.803435</td>\n",
              "      <td>0.821342</td>\n",
              "      <td>0.046595</td>\n",
              "      <td>0.783120</td>\n",
              "      <td>0.149567</td>\n",
              "      <td>0.046569</td>\n",
              "      <td>0.795293</td>\n",
              "      <td>0.795607</td>\n",
              "      <td>0.811954</td>\n",
              "      <td>0.149780</td>\n",
              "      <td>0.150114</td>\n",
              "      <td>0.812003</td>\n",
              "      <td>0.774113</td>\n",
              "      <td>0.774908</td>\n",
              "      <td>0.763476</td>\n",
              "      <td>0.158602</td>\n",
              "      <td>0.175099</td>\n",
              "      <td>0.150225</td>\n",
              "      <td>0.757582</td>\n",
              "      <td>0.158929</td>\n",
              "      <td>0.174224</td>\n",
              "      <td>0.758704</td>\n",
              "      <td>0.099011</td>\n",
              "      <td>0.175888</td>\n",
              "      <td>0.099284</td>\n",
              "      <td>0.165675</td>\n",
              "      <td>0.174889</td>\n",
              "      <td>0.769847</td>\n",
              "      <td>0.099227</td>\n",
              "      <td>0.771256</td>\n",
              "      <td>0.099572</td>\n",
              "      <td>0.754594</td>\n",
              "      <td>0.169526</td>\n",
              "      <td>0.101058</td>\n",
              "      <td>0.784358</td>\n",
              "      <td>0.756448</td>\n",
              "      <td>0.113617</td>\n",
              "      <td>...</td>\n",
              "      <td>0.213546</td>\n",
              "      <td>0.732561</td>\n",
              "      <td>0.740327</td>\n",
              "      <td>0.723830</td>\n",
              "      <td>0.218522</td>\n",
              "      <td>0.727121</td>\n",
              "      <td>0.744616</td>\n",
              "      <td>0.148923</td>\n",
              "      <td>0.227996</td>\n",
              "      <td>0.746451</td>\n",
              "      <td>0.218015</td>\n",
              "      <td>0.836178</td>\n",
              "      <td>0.205789</td>\n",
              "      <td>0.785772</td>\n",
              "      <td>0.219019</td>\n",
              "      <td>0.148878</td>\n",
              "      <td>0.786354</td>\n",
              "      <td>0.235142</td>\n",
              "      <td>0.231854</td>\n",
              "      <td>0.228937</td>\n",
              "      <td>0.217596</td>\n",
              "      <td>0.205009</td>\n",
              "      <td>0.235732</td>\n",
              "      <td>0.825436</td>\n",
              "      <td>0.232628</td>\n",
              "      <td>0.236433</td>\n",
              "      <td>0.825896</td>\n",
              "      <td>0.236950</td>\n",
              "      <td>0.706180</td>\n",
              "      <td>0.704105</td>\n",
              "      <td>0.236436</td>\n",
              "      <td>0.709578</td>\n",
              "      <td>0.707765</td>\n",
              "      <td>0.706934</td>\n",
              "      <td>0.126320</td>\n",
              "      <td>0.710156</td>\n",
              "      <td>0.250745</td>\n",
              "      <td>0.382399</td>\n",
              "      <td>0.373651</td>\n",
              "      <td>0.237434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>0.028294</td>\n",
              "      <td>0.031425</td>\n",
              "      <td>0.032584</td>\n",
              "      <td>0.798233</td>\n",
              "      <td>0.814960</td>\n",
              "      <td>0.048443</td>\n",
              "      <td>0.779954</td>\n",
              "      <td>0.166443</td>\n",
              "      <td>0.046820</td>\n",
              "      <td>0.788627</td>\n",
              "      <td>0.790966</td>\n",
              "      <td>0.803303</td>\n",
              "      <td>0.162677</td>\n",
              "      <td>0.169883</td>\n",
              "      <td>0.805924</td>\n",
              "      <td>0.769750</td>\n",
              "      <td>0.772434</td>\n",
              "      <td>0.762304</td>\n",
              "      <td>0.176322</td>\n",
              "      <td>0.190824</td>\n",
              "      <td>0.166948</td>\n",
              "      <td>0.754930</td>\n",
              "      <td>0.178744</td>\n",
              "      <td>0.185964</td>\n",
              "      <td>0.757427</td>\n",
              "      <td>0.105134</td>\n",
              "      <td>0.194805</td>\n",
              "      <td>0.105626</td>\n",
              "      <td>0.182422</td>\n",
              "      <td>0.190902</td>\n",
              "      <td>0.760143</td>\n",
              "      <td>0.102472</td>\n",
              "      <td>0.765568</td>\n",
              "      <td>0.102679</td>\n",
              "      <td>0.746955</td>\n",
              "      <td>0.178944</td>\n",
              "      <td>0.102618</td>\n",
              "      <td>0.772934</td>\n",
              "      <td>0.752284</td>\n",
              "      <td>0.120295</td>\n",
              "      <td>...</td>\n",
              "      <td>0.220696</td>\n",
              "      <td>0.724808</td>\n",
              "      <td>0.731656</td>\n",
              "      <td>0.712595</td>\n",
              "      <td>0.219281</td>\n",
              "      <td>0.720248</td>\n",
              "      <td>0.728908</td>\n",
              "      <td>0.154923</td>\n",
              "      <td>0.225278</td>\n",
              "      <td>0.736722</td>\n",
              "      <td>0.222614</td>\n",
              "      <td>0.831937</td>\n",
              "      <td>0.212774</td>\n",
              "      <td>0.774749</td>\n",
              "      <td>0.221938</td>\n",
              "      <td>0.154258</td>\n",
              "      <td>0.779241</td>\n",
              "      <td>0.231242</td>\n",
              "      <td>0.230126</td>\n",
              "      <td>0.227691</td>\n",
              "      <td>0.224401</td>\n",
              "      <td>0.212821</td>\n",
              "      <td>0.240014</td>\n",
              "      <td>0.818825</td>\n",
              "      <td>0.231867</td>\n",
              "      <td>0.233778</td>\n",
              "      <td>0.820524</td>\n",
              "      <td>0.235848</td>\n",
              "      <td>0.687937</td>\n",
              "      <td>0.687617</td>\n",
              "      <td>0.241956</td>\n",
              "      <td>0.697457</td>\n",
              "      <td>0.696794</td>\n",
              "      <td>0.686967</td>\n",
              "      <td>0.130918</td>\n",
              "      <td>0.697060</td>\n",
              "      <td>0.245452</td>\n",
              "      <td>0.388187</td>\n",
              "      <td>0.379850</td>\n",
              "      <td>0.237805</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>387 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          11y      339y      110y  ...       77x       62x      446y\n",
              "0    0.087810  0.086514  0.093708  ...  0.365988  0.359189  0.292456\n",
              "1    0.098683  0.098165  0.104281  ...  0.416444  0.409262  0.291724\n",
              "2    0.085394  0.084500  0.091048  ...  0.387020  0.380484  0.280708\n",
              "3    0.075667  0.071821  0.084392  ...  0.420678  0.413922  0.258211\n",
              "4    0.113934  0.112442  0.119322  ...  0.407039  0.400207  0.295642\n",
              "..        ...       ...       ...  ...       ...       ...       ...\n",
              "382  0.042583  0.045035  0.047134  ...  0.411506  0.403034  0.241827\n",
              "383  0.098089  0.100955  0.099325  ...  0.394111  0.386250  0.287928\n",
              "384  0.030021  0.038381  0.029579  ...  0.396086  0.388178  0.252944\n",
              "385  0.029790  0.032586  0.032786  ...  0.382399  0.373651  0.237434\n",
              "386  0.028294  0.031425  0.032584  ...  0.388187  0.379850  0.237805\n",
              "\n",
              "[387 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56PAsc3mZbhG"
      },
      "source": [
        "# Create X & y\n",
        "\n",
        "y = input_df_copy[\"output\"]\n",
        "\n",
        "# Build our train and test sets (use random state to ensure same split as before)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKTrYiSkZfwM"
      },
      "source": [
        "# Model Declaration and Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GeMq8iWZjza"
      },
      "source": [
        "## Model 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrAdvUFIcsuY"
      },
      "source": [
        "### Declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLDNxnFAZhXs"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(256, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(128, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(8, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate = .0003),\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    patience=250,\n",
        "    min_delta=0.0001,\n",
        "    restore_best_weights=True,\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt7Sb_fNcvWu"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGPlkzWGZpww",
        "outputId": "45bb5e0d-8a57-440d-cfbd-23cf738f6144"
      },
      "source": [
        "history_1 = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=2000,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1, \n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "10/10 [==============================] - 1s 38ms/step - loss: 2.0615 - accuracy: 0.1942 - val_loss: 2.0430 - val_accuracy: 0.1026\n",
            "Epoch 2/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0162 - accuracy: 0.2136 - val_loss: 2.0253 - val_accuracy: 0.1026\n",
            "Epoch 3/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9825 - accuracy: 0.2136 - val_loss: 2.0141 - val_accuracy: 0.2179\n",
            "Epoch 4/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9797 - accuracy: 0.2298 - val_loss: 2.0276 - val_accuracy: 0.2179\n",
            "Epoch 5/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9448 - accuracy: 0.2589 - val_loss: 2.0239 - val_accuracy: 0.2179\n",
            "Epoch 6/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9595 - accuracy: 0.2395 - val_loss: 2.0198 - val_accuracy: 0.2179\n",
            "Epoch 7/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9436 - accuracy: 0.2718 - val_loss: 2.0057 - val_accuracy: 0.2821\n",
            "Epoch 8/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.9503 - accuracy: 0.2557 - val_loss: 1.9894 - val_accuracy: 0.2179\n",
            "Epoch 9/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.9547 - accuracy: 0.2589 - val_loss: 1.9860 - val_accuracy: 0.2308\n",
            "Epoch 10/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.9196 - accuracy: 0.2751 - val_loss: 1.9765 - val_accuracy: 0.2564\n",
            "Epoch 11/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.9283 - accuracy: 0.2783 - val_loss: 1.9703 - val_accuracy: 0.2821\n",
            "Epoch 12/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.9221 - accuracy: 0.2751 - val_loss: 1.9639 - val_accuracy: 0.2821\n",
            "Epoch 13/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8915 - accuracy: 0.2945 - val_loss: 1.9495 - val_accuracy: 0.2949\n",
            "Epoch 14/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.8941 - accuracy: 0.3236 - val_loss: 1.9314 - val_accuracy: 0.3077\n",
            "Epoch 15/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.8738 - accuracy: 0.3172 - val_loss: 1.9148 - val_accuracy: 0.2821\n",
            "Epoch 16/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.8577 - accuracy: 0.3010 - val_loss: 1.8993 - val_accuracy: 0.3205\n",
            "Epoch 17/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8557 - accuracy: 0.3786 - val_loss: 1.8737 - val_accuracy: 0.2949\n",
            "Epoch 18/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.8155 - accuracy: 0.3333 - val_loss: 1.8481 - val_accuracy: 0.3077\n",
            "Epoch 19/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.7856 - accuracy: 0.3625 - val_loss: 1.8255 - val_accuracy: 0.2949\n",
            "Epoch 20/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.7632 - accuracy: 0.3883 - val_loss: 1.8000 - val_accuracy: 0.3077\n",
            "Epoch 21/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.7371 - accuracy: 0.3883 - val_loss: 1.7671 - val_accuracy: 0.3077\n",
            "Epoch 22/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.7233 - accuracy: 0.3625 - val_loss: 1.7424 - val_accuracy: 0.3077\n",
            "Epoch 23/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.6821 - accuracy: 0.3916 - val_loss: 1.7164 - val_accuracy: 0.2949\n",
            "Epoch 24/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.6663 - accuracy: 0.3528 - val_loss: 1.6898 - val_accuracy: 0.3077\n",
            "Epoch 25/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.6312 - accuracy: 0.3916 - val_loss: 1.6615 - val_accuracy: 0.3077\n",
            "Epoch 26/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.6237 - accuracy: 0.3689 - val_loss: 1.6509 - val_accuracy: 0.3205\n",
            "Epoch 27/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.6190 - accuracy: 0.3948 - val_loss: 1.6256 - val_accuracy: 0.3333\n",
            "Epoch 28/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5745 - accuracy: 0.4142 - val_loss: 1.6035 - val_accuracy: 0.3077\n",
            "Epoch 29/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.5870 - accuracy: 0.3948 - val_loss: 1.6075 - val_accuracy: 0.3205\n",
            "Epoch 30/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.5849 - accuracy: 0.3657 - val_loss: 1.5982 - val_accuracy: 0.3077\n",
            "Epoch 31/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.5419 - accuracy: 0.3851 - val_loss: 1.5948 - val_accuracy: 0.3077\n",
            "Epoch 32/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.5467 - accuracy: 0.4142 - val_loss: 1.5635 - val_accuracy: 0.3077\n",
            "Epoch 33/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.5188 - accuracy: 0.4013 - val_loss: 1.5660 - val_accuracy: 0.3077\n",
            "Epoch 34/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5288 - accuracy: 0.3916 - val_loss: 1.5557 - val_accuracy: 0.3077\n",
            "Epoch 35/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.5154 - accuracy: 0.4110 - val_loss: 1.5531 - val_accuracy: 0.3077\n",
            "Epoch 36/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4914 - accuracy: 0.4110 - val_loss: 1.5495 - val_accuracy: 0.3077\n",
            "Epoch 37/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.5317 - accuracy: 0.3981 - val_loss: 1.5479 - val_accuracy: 0.3205\n",
            "Epoch 38/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.5335 - accuracy: 0.3916 - val_loss: 1.5301 - val_accuracy: 0.3333\n",
            "Epoch 39/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.4980 - accuracy: 0.3819 - val_loss: 1.5652 - val_accuracy: 0.3077\n",
            "Epoch 40/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.5208 - accuracy: 0.3981 - val_loss: 1.5423 - val_accuracy: 0.3462\n",
            "Epoch 41/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4959 - accuracy: 0.4078 - val_loss: 1.5338 - val_accuracy: 0.3077\n",
            "Epoch 42/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4826 - accuracy: 0.4239 - val_loss: 1.5196 - val_accuracy: 0.3205\n",
            "Epoch 43/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4788 - accuracy: 0.4110 - val_loss: 1.5143 - val_accuracy: 0.3205\n",
            "Epoch 44/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4784 - accuracy: 0.4078 - val_loss: 1.5186 - val_accuracy: 0.3205\n",
            "Epoch 45/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.4809 - accuracy: 0.4142 - val_loss: 1.5137 - val_accuracy: 0.3205\n",
            "Epoch 46/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4611 - accuracy: 0.4304 - val_loss: 1.5172 - val_accuracy: 0.3205\n",
            "Epoch 47/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4773 - accuracy: 0.4110 - val_loss: 1.5135 - val_accuracy: 0.3333\n",
            "Epoch 48/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4717 - accuracy: 0.4045 - val_loss: 1.5096 - val_accuracy: 0.3205\n",
            "Epoch 49/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4776 - accuracy: 0.4013 - val_loss: 1.5244 - val_accuracy: 0.3077\n",
            "Epoch 50/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4771 - accuracy: 0.4337 - val_loss: 1.5049 - val_accuracy: 0.3205\n",
            "Epoch 51/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4754 - accuracy: 0.4207 - val_loss: 1.4970 - val_accuracy: 0.3077\n",
            "Epoch 52/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4675 - accuracy: 0.4078 - val_loss: 1.5183 - val_accuracy: 0.3077\n",
            "Epoch 53/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4632 - accuracy: 0.4207 - val_loss: 1.5040 - val_accuracy: 0.3205\n",
            "Epoch 54/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.4911 - accuracy: 0.4110 - val_loss: 1.4942 - val_accuracy: 0.3205\n",
            "Epoch 55/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.4645 - accuracy: 0.4175 - val_loss: 1.4922 - val_accuracy: 0.3333\n",
            "Epoch 56/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4592 - accuracy: 0.4304 - val_loss: 1.4903 - val_accuracy: 0.3205\n",
            "Epoch 57/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4467 - accuracy: 0.4304 - val_loss: 1.4972 - val_accuracy: 0.3333\n",
            "Epoch 58/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4440 - accuracy: 0.4272 - val_loss: 1.5014 - val_accuracy: 0.3333\n",
            "Epoch 59/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4470 - accuracy: 0.4272 - val_loss: 1.4895 - val_accuracy: 0.3333\n",
            "Epoch 60/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4561 - accuracy: 0.4078 - val_loss: 1.4823 - val_accuracy: 0.3333\n",
            "Epoch 61/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4437 - accuracy: 0.4142 - val_loss: 1.4969 - val_accuracy: 0.3205\n",
            "Epoch 62/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4660 - accuracy: 0.4013 - val_loss: 1.4859 - val_accuracy: 0.3205\n",
            "Epoch 63/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4256 - accuracy: 0.4466 - val_loss: 1.4965 - val_accuracy: 0.3333\n",
            "Epoch 64/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4511 - accuracy: 0.4142 - val_loss: 1.4918 - val_accuracy: 0.3333\n",
            "Epoch 65/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4336 - accuracy: 0.4498 - val_loss: 1.4836 - val_accuracy: 0.3333\n",
            "Epoch 66/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.4385 - accuracy: 0.4401 - val_loss: 1.4854 - val_accuracy: 0.3205\n",
            "Epoch 67/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4275 - accuracy: 0.4142 - val_loss: 1.4655 - val_accuracy: 0.3333\n",
            "Epoch 68/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.4481 - accuracy: 0.4434 - val_loss: 1.4694 - val_accuracy: 0.3333\n",
            "Epoch 69/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4453 - accuracy: 0.4239 - val_loss: 1.4776 - val_accuracy: 0.3333\n",
            "Epoch 70/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4261 - accuracy: 0.4401 - val_loss: 1.4791 - val_accuracy: 0.3462\n",
            "Epoch 71/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4421 - accuracy: 0.4272 - val_loss: 1.4838 - val_accuracy: 0.3333\n",
            "Epoch 72/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4244 - accuracy: 0.4175 - val_loss: 1.4671 - val_accuracy: 0.3333\n",
            "Epoch 73/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4369 - accuracy: 0.4175 - val_loss: 1.4669 - val_accuracy: 0.3462\n",
            "Epoch 74/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4523 - accuracy: 0.4239 - val_loss: 1.4607 - val_accuracy: 0.3333\n",
            "Epoch 75/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4341 - accuracy: 0.4175 - val_loss: 1.4626 - val_accuracy: 0.3462\n",
            "Epoch 76/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4380 - accuracy: 0.4563 - val_loss: 1.4798 - val_accuracy: 0.3333\n",
            "Epoch 77/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4415 - accuracy: 0.4337 - val_loss: 1.4819 - val_accuracy: 0.3333\n",
            "Epoch 78/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4401 - accuracy: 0.4239 - val_loss: 1.4650 - val_accuracy: 0.3333\n",
            "Epoch 79/2000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.4402 - accuracy: 0.4239 - val_loss: 1.4657 - val_accuracy: 0.3333\n",
            "Epoch 80/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4285 - accuracy: 0.4434 - val_loss: 1.4843 - val_accuracy: 0.3462\n",
            "Epoch 81/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4228 - accuracy: 0.4531 - val_loss: 1.4899 - val_accuracy: 0.3462\n",
            "Epoch 82/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4361 - accuracy: 0.4628 - val_loss: 1.4802 - val_accuracy: 0.3462\n",
            "Epoch 83/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4606 - accuracy: 0.4207 - val_loss: 1.4928 - val_accuracy: 0.3462\n",
            "Epoch 84/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4408 - accuracy: 0.4272 - val_loss: 1.4749 - val_accuracy: 0.3462\n",
            "Epoch 85/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4331 - accuracy: 0.4272 - val_loss: 1.4547 - val_accuracy: 0.3462\n",
            "Epoch 86/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4336 - accuracy: 0.4207 - val_loss: 1.4704 - val_accuracy: 0.3333\n",
            "Epoch 87/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4192 - accuracy: 0.4337 - val_loss: 1.4648 - val_accuracy: 0.3462\n",
            "Epoch 88/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4034 - accuracy: 0.4693 - val_loss: 1.4560 - val_accuracy: 0.3590\n",
            "Epoch 89/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.4167 - accuracy: 0.4401 - val_loss: 1.4591 - val_accuracy: 0.3590\n",
            "Epoch 90/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4037 - accuracy: 0.4304 - val_loss: 1.4438 - val_accuracy: 0.3718\n",
            "Epoch 91/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4242 - accuracy: 0.4466 - val_loss: 1.4556 - val_accuracy: 0.3974\n",
            "Epoch 92/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4155 - accuracy: 0.4595 - val_loss: 1.4480 - val_accuracy: 0.3974\n",
            "Epoch 93/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.4241 - accuracy: 0.4563 - val_loss: 1.4339 - val_accuracy: 0.3846\n",
            "Epoch 94/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4115 - accuracy: 0.4498 - val_loss: 1.4401 - val_accuracy: 0.3974\n",
            "Epoch 95/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4070 - accuracy: 0.4757 - val_loss: 1.4455 - val_accuracy: 0.3718\n",
            "Epoch 96/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3905 - accuracy: 0.4725 - val_loss: 1.4533 - val_accuracy: 0.3718\n",
            "Epoch 97/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4065 - accuracy: 0.4595 - val_loss: 1.4385 - val_accuracy: 0.3974\n",
            "Epoch 98/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4030 - accuracy: 0.4531 - val_loss: 1.4517 - val_accuracy: 0.3974\n",
            "Epoch 99/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3868 - accuracy: 0.4757 - val_loss: 1.4505 - val_accuracy: 0.3718\n",
            "Epoch 100/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3900 - accuracy: 0.4563 - val_loss: 1.4383 - val_accuracy: 0.4103\n",
            "Epoch 101/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4042 - accuracy: 0.4078 - val_loss: 1.4361 - val_accuracy: 0.3590\n",
            "Epoch 102/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3852 - accuracy: 0.4725 - val_loss: 1.4256 - val_accuracy: 0.4103\n",
            "Epoch 103/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3988 - accuracy: 0.4595 - val_loss: 1.4136 - val_accuracy: 0.4615\n",
            "Epoch 104/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3844 - accuracy: 0.4854 - val_loss: 1.4582 - val_accuracy: 0.3462\n",
            "Epoch 105/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3888 - accuracy: 0.4595 - val_loss: 1.4080 - val_accuracy: 0.4615\n",
            "Epoch 106/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3822 - accuracy: 0.4725 - val_loss: 1.4189 - val_accuracy: 0.4359\n",
            "Epoch 107/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3740 - accuracy: 0.4757 - val_loss: 1.4342 - val_accuracy: 0.4231\n",
            "Epoch 108/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3945 - accuracy: 0.4693 - val_loss: 1.4155 - val_accuracy: 0.3846\n",
            "Epoch 109/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3925 - accuracy: 0.4466 - val_loss: 1.4111 - val_accuracy: 0.4615\n",
            "Epoch 110/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3648 - accuracy: 0.4531 - val_loss: 1.4163 - val_accuracy: 0.3974\n",
            "Epoch 111/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3897 - accuracy: 0.4984 - val_loss: 1.3973 - val_accuracy: 0.4487\n",
            "Epoch 112/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3703 - accuracy: 0.5049 - val_loss: 1.4269 - val_accuracy: 0.4231\n",
            "Epoch 113/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3836 - accuracy: 0.4531 - val_loss: 1.4032 - val_accuracy: 0.4872\n",
            "Epoch 114/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3884 - accuracy: 0.4854 - val_loss: 1.4222 - val_accuracy: 0.4103\n",
            "Epoch 115/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3627 - accuracy: 0.4498 - val_loss: 1.4121 - val_accuracy: 0.4744\n",
            "Epoch 116/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3709 - accuracy: 0.5113 - val_loss: 1.4308 - val_accuracy: 0.3846\n",
            "Epoch 117/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3614 - accuracy: 0.4563 - val_loss: 1.3965 - val_accuracy: 0.4744\n",
            "Epoch 118/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3651 - accuracy: 0.5016 - val_loss: 1.3962 - val_accuracy: 0.4359\n",
            "Epoch 119/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3474 - accuracy: 0.5016 - val_loss: 1.4299 - val_accuracy: 0.3974\n",
            "Epoch 120/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3335 - accuracy: 0.4693 - val_loss: 1.4026 - val_accuracy: 0.5000\n",
            "Epoch 121/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3592 - accuracy: 0.4984 - val_loss: 1.4688 - val_accuracy: 0.3590\n",
            "Epoch 122/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3481 - accuracy: 0.4660 - val_loss: 1.3770 - val_accuracy: 0.4744\n",
            "Epoch 123/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3824 - accuracy: 0.4919 - val_loss: 1.4036 - val_accuracy: 0.3974\n",
            "Epoch 124/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.3453 - accuracy: 0.5016 - val_loss: 1.3817 - val_accuracy: 0.4615\n",
            "Epoch 125/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3286 - accuracy: 0.5178 - val_loss: 1.4031 - val_accuracy: 0.4231\n",
            "Epoch 126/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3293 - accuracy: 0.4757 - val_loss: 1.3572 - val_accuracy: 0.5513\n",
            "Epoch 127/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.3204 - accuracy: 0.5307 - val_loss: 1.4500 - val_accuracy: 0.3590\n",
            "Epoch 128/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3402 - accuracy: 0.4822 - val_loss: 1.3937 - val_accuracy: 0.4231\n",
            "Epoch 129/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3175 - accuracy: 0.5146 - val_loss: 1.3532 - val_accuracy: 0.5000\n",
            "Epoch 130/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3166 - accuracy: 0.5340 - val_loss: 1.3899 - val_accuracy: 0.4231\n",
            "Epoch 131/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3083 - accuracy: 0.5146 - val_loss: 1.3560 - val_accuracy: 0.4615\n",
            "Epoch 132/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2999 - accuracy: 0.5307 - val_loss: 1.3481 - val_accuracy: 0.5385\n",
            "Epoch 133/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.3073 - accuracy: 0.5210 - val_loss: 1.3541 - val_accuracy: 0.4744\n",
            "Epoch 134/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3152 - accuracy: 0.5243 - val_loss: 1.3468 - val_accuracy: 0.5000\n",
            "Epoch 135/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2964 - accuracy: 0.5405 - val_loss: 1.4198 - val_accuracy: 0.4231\n",
            "Epoch 136/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2806 - accuracy: 0.5437 - val_loss: 1.3656 - val_accuracy: 0.4615\n",
            "Epoch 137/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3014 - accuracy: 0.5016 - val_loss: 1.3263 - val_accuracy: 0.5128\n",
            "Epoch 138/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.3088 - accuracy: 0.5275 - val_loss: 1.3400 - val_accuracy: 0.4744\n",
            "Epoch 139/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2865 - accuracy: 0.5307 - val_loss: 1.3322 - val_accuracy: 0.5513\n",
            "Epoch 140/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3030 - accuracy: 0.5405 - val_loss: 1.3814 - val_accuracy: 0.4231\n",
            "Epoch 141/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.3171 - accuracy: 0.5275 - val_loss: 1.4186 - val_accuracy: 0.3846\n",
            "Epoch 142/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2858 - accuracy: 0.5210 - val_loss: 1.3850 - val_accuracy: 0.4231\n",
            "Epoch 143/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2658 - accuracy: 0.5340 - val_loss: 1.3130 - val_accuracy: 0.5513\n",
            "Epoch 144/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2820 - accuracy: 0.5405 - val_loss: 1.3019 - val_accuracy: 0.5385\n",
            "Epoch 145/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3143 - accuracy: 0.5016 - val_loss: 1.3023 - val_accuracy: 0.5641\n",
            "Epoch 146/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3129 - accuracy: 0.4790 - val_loss: 1.5280 - val_accuracy: 0.3205\n",
            "Epoch 147/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2649 - accuracy: 0.5210 - val_loss: 1.3336 - val_accuracy: 0.4615\n",
            "Epoch 148/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2656 - accuracy: 0.5340 - val_loss: 1.3050 - val_accuracy: 0.5256\n",
            "Epoch 149/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2390 - accuracy: 0.5663 - val_loss: 1.4418 - val_accuracy: 0.3846\n",
            "Epoch 150/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2738 - accuracy: 0.5178 - val_loss: 1.3023 - val_accuracy: 0.4744\n",
            "Epoch 151/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2176 - accuracy: 0.5469 - val_loss: 1.2797 - val_accuracy: 0.5641\n",
            "Epoch 152/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2687 - accuracy: 0.5307 - val_loss: 1.2952 - val_accuracy: 0.5000\n",
            "Epoch 153/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2359 - accuracy: 0.5663 - val_loss: 1.3998 - val_accuracy: 0.4103\n",
            "Epoch 154/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2451 - accuracy: 0.5502 - val_loss: 1.3188 - val_accuracy: 0.4615\n",
            "Epoch 155/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1957 - accuracy: 0.5890 - val_loss: 1.2841 - val_accuracy: 0.5000\n",
            "Epoch 156/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2155 - accuracy: 0.5502 - val_loss: 1.2736 - val_accuracy: 0.5256\n",
            "Epoch 157/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2605 - accuracy: 0.5437 - val_loss: 1.2633 - val_accuracy: 0.5769\n",
            "Epoch 158/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2204 - accuracy: 0.5696 - val_loss: 1.2714 - val_accuracy: 0.5641\n",
            "Epoch 159/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2139 - accuracy: 0.5761 - val_loss: 1.2711 - val_accuracy: 0.5385\n",
            "Epoch 160/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2256 - accuracy: 0.5599 - val_loss: 1.3703 - val_accuracy: 0.4487\n",
            "Epoch 161/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2067 - accuracy: 0.5728 - val_loss: 1.2624 - val_accuracy: 0.5385\n",
            "Epoch 162/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2025 - accuracy: 0.5437 - val_loss: 1.2957 - val_accuracy: 0.4615\n",
            "Epoch 163/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1895 - accuracy: 0.5696 - val_loss: 1.5532 - val_accuracy: 0.3462\n",
            "Epoch 164/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2950 - accuracy: 0.4854 - val_loss: 1.4174 - val_accuracy: 0.4103\n",
            "Epoch 165/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2881 - accuracy: 0.5016 - val_loss: 1.2505 - val_accuracy: 0.5769\n",
            "Epoch 166/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2452 - accuracy: 0.5405 - val_loss: 1.2672 - val_accuracy: 0.5000\n",
            "Epoch 167/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1866 - accuracy: 0.5566 - val_loss: 1.2686 - val_accuracy: 0.4872\n",
            "Epoch 168/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1686 - accuracy: 0.5793 - val_loss: 1.2624 - val_accuracy: 0.5385\n",
            "Epoch 169/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1651 - accuracy: 0.5858 - val_loss: 1.2600 - val_accuracy: 0.5385\n",
            "Epoch 170/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1735 - accuracy: 0.5631 - val_loss: 1.3098 - val_accuracy: 0.4487\n",
            "Epoch 171/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1794 - accuracy: 0.5566 - val_loss: 1.2415 - val_accuracy: 0.5641\n",
            "Epoch 172/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2222 - accuracy: 0.5502 - val_loss: 1.2366 - val_accuracy: 0.5641\n",
            "Epoch 173/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1916 - accuracy: 0.5825 - val_loss: 1.3547 - val_accuracy: 0.4487\n",
            "Epoch 174/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1867 - accuracy: 0.5631 - val_loss: 1.2909 - val_accuracy: 0.4615\n",
            "Epoch 175/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1623 - accuracy: 0.5761 - val_loss: 1.2233 - val_accuracy: 0.5641\n",
            "Epoch 176/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1944 - accuracy: 0.5631 - val_loss: 1.2273 - val_accuracy: 0.5641\n",
            "Epoch 177/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1665 - accuracy: 0.5825 - val_loss: 1.2400 - val_accuracy: 0.5385\n",
            "Epoch 178/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1337 - accuracy: 0.5761 - val_loss: 1.2814 - val_accuracy: 0.4615\n",
            "Epoch 179/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.1620 - accuracy: 0.5825 - val_loss: 1.2858 - val_accuracy: 0.4744\n",
            "Epoch 180/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1376 - accuracy: 0.5825 - val_loss: 1.3584 - val_accuracy: 0.4487\n",
            "Epoch 181/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1353 - accuracy: 0.5793 - val_loss: 1.2714 - val_accuracy: 0.4744\n",
            "Epoch 182/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1628 - accuracy: 0.5566 - val_loss: 1.2125 - val_accuracy: 0.5897\n",
            "Epoch 183/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1446 - accuracy: 0.5955 - val_loss: 1.2275 - val_accuracy: 0.5000\n",
            "Epoch 184/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1655 - accuracy: 0.5631 - val_loss: 1.2470 - val_accuracy: 0.4872\n",
            "Epoch 185/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1516 - accuracy: 0.5922 - val_loss: 1.2303 - val_accuracy: 0.5000\n",
            "Epoch 186/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1641 - accuracy: 0.5858 - val_loss: 1.2399 - val_accuracy: 0.5000\n",
            "Epoch 187/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1683 - accuracy: 0.5728 - val_loss: 1.2133 - val_accuracy: 0.5641\n",
            "Epoch 188/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1500 - accuracy: 0.5696 - val_loss: 1.2202 - val_accuracy: 0.5256\n",
            "Epoch 189/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1417 - accuracy: 0.5922 - val_loss: 1.2932 - val_accuracy: 0.4744\n",
            "Epoch 190/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1392 - accuracy: 0.5793 - val_loss: 1.2328 - val_accuracy: 0.5000\n",
            "Epoch 191/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1402 - accuracy: 0.5922 - val_loss: 1.1984 - val_accuracy: 0.5641\n",
            "Epoch 192/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1527 - accuracy: 0.5761 - val_loss: 1.3376 - val_accuracy: 0.4487\n",
            "Epoch 193/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1374 - accuracy: 0.5696 - val_loss: 1.2134 - val_accuracy: 0.5513\n",
            "Epoch 194/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1307 - accuracy: 0.5793 - val_loss: 1.2682 - val_accuracy: 0.4744\n",
            "Epoch 195/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1375 - accuracy: 0.5987 - val_loss: 1.2884 - val_accuracy: 0.4744\n",
            "Epoch 196/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1243 - accuracy: 0.5922 - val_loss: 1.2010 - val_accuracy: 0.5641\n",
            "Epoch 197/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1364 - accuracy: 0.5922 - val_loss: 1.2744 - val_accuracy: 0.4744\n",
            "Epoch 198/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1329 - accuracy: 0.5955 - val_loss: 1.2447 - val_accuracy: 0.4872\n",
            "Epoch 199/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1307 - accuracy: 0.5793 - val_loss: 1.2162 - val_accuracy: 0.5000\n",
            "Epoch 200/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1253 - accuracy: 0.5890 - val_loss: 1.2333 - val_accuracy: 0.5000\n",
            "Epoch 201/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1086 - accuracy: 0.6084 - val_loss: 1.2112 - val_accuracy: 0.5513\n",
            "Epoch 202/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1371 - accuracy: 0.5955 - val_loss: 1.2012 - val_accuracy: 0.5513\n",
            "Epoch 203/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1373 - accuracy: 0.5793 - val_loss: 1.2025 - val_accuracy: 0.5385\n",
            "Epoch 204/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1664 - accuracy: 0.5825 - val_loss: 1.2031 - val_accuracy: 0.5513\n",
            "Epoch 205/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1034 - accuracy: 0.6052 - val_loss: 1.2843 - val_accuracy: 0.4744\n",
            "Epoch 206/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1399 - accuracy: 0.5890 - val_loss: 1.2984 - val_accuracy: 0.4615\n",
            "Epoch 207/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1255 - accuracy: 0.5858 - val_loss: 1.2220 - val_accuracy: 0.5000\n",
            "Epoch 208/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1371 - accuracy: 0.5825 - val_loss: 1.1811 - val_accuracy: 0.5641\n",
            "Epoch 209/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1000 - accuracy: 0.6214 - val_loss: 1.2801 - val_accuracy: 0.4744\n",
            "Epoch 210/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1265 - accuracy: 0.6019 - val_loss: 1.2278 - val_accuracy: 0.4872\n",
            "Epoch 211/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1280 - accuracy: 0.5663 - val_loss: 1.2632 - val_accuracy: 0.4744\n",
            "Epoch 212/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.1291 - accuracy: 0.6019 - val_loss: 1.3537 - val_accuracy: 0.4615\n",
            "Epoch 213/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1308 - accuracy: 0.5858 - val_loss: 1.2712 - val_accuracy: 0.4615\n",
            "Epoch 214/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1244 - accuracy: 0.5987 - val_loss: 1.2424 - val_accuracy: 0.4872\n",
            "Epoch 215/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1210 - accuracy: 0.5922 - val_loss: 1.2050 - val_accuracy: 0.5385\n",
            "Epoch 216/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0886 - accuracy: 0.5825 - val_loss: 1.2905 - val_accuracy: 0.4615\n",
            "Epoch 217/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1114 - accuracy: 0.5890 - val_loss: 1.4154 - val_accuracy: 0.4487\n",
            "Epoch 218/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1227 - accuracy: 0.5761 - val_loss: 1.3061 - val_accuracy: 0.4615\n",
            "Epoch 219/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0904 - accuracy: 0.6052 - val_loss: 1.2180 - val_accuracy: 0.5000\n",
            "Epoch 220/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1008 - accuracy: 0.5955 - val_loss: 1.2110 - val_accuracy: 0.5000\n",
            "Epoch 221/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1088 - accuracy: 0.5793 - val_loss: 1.1649 - val_accuracy: 0.5641\n",
            "Epoch 222/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1282 - accuracy: 0.5825 - val_loss: 1.1664 - val_accuracy: 0.5641\n",
            "Epoch 223/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1215 - accuracy: 0.6084 - val_loss: 1.2030 - val_accuracy: 0.5256\n",
            "Epoch 224/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0936 - accuracy: 0.6117 - val_loss: 1.2597 - val_accuracy: 0.4744\n",
            "Epoch 225/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1276 - accuracy: 0.5761 - val_loss: 1.3348 - val_accuracy: 0.4615\n",
            "Epoch 226/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1039 - accuracy: 0.5955 - val_loss: 1.3591 - val_accuracy: 0.4615\n",
            "Epoch 227/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1147 - accuracy: 0.5858 - val_loss: 1.1938 - val_accuracy: 0.5128\n",
            "Epoch 228/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0942 - accuracy: 0.5922 - val_loss: 1.1716 - val_accuracy: 0.5641\n",
            "Epoch 229/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1081 - accuracy: 0.6149 - val_loss: 1.1898 - val_accuracy: 0.5769\n",
            "Epoch 230/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1268 - accuracy: 0.5793 - val_loss: 1.1748 - val_accuracy: 0.5641\n",
            "Epoch 231/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1011 - accuracy: 0.6084 - val_loss: 1.3033 - val_accuracy: 0.4615\n",
            "Epoch 232/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1004 - accuracy: 0.6149 - val_loss: 1.3196 - val_accuracy: 0.4615\n",
            "Epoch 233/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1178 - accuracy: 0.5566 - val_loss: 1.1710 - val_accuracy: 0.5641\n",
            "Epoch 234/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.1093 - accuracy: 0.5793 - val_loss: 1.1719 - val_accuracy: 0.5641\n",
            "Epoch 235/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0905 - accuracy: 0.5890 - val_loss: 1.1782 - val_accuracy: 0.5641\n",
            "Epoch 236/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1163 - accuracy: 0.5890 - val_loss: 1.1531 - val_accuracy: 0.5769\n",
            "Epoch 237/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0965 - accuracy: 0.6149 - val_loss: 1.2996 - val_accuracy: 0.4744\n",
            "Epoch 238/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1046 - accuracy: 0.5987 - val_loss: 1.1677 - val_accuracy: 0.5385\n",
            "Epoch 239/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1034 - accuracy: 0.5922 - val_loss: 1.1626 - val_accuracy: 0.5385\n",
            "Epoch 240/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0918 - accuracy: 0.5890 - val_loss: 1.1812 - val_accuracy: 0.5256\n",
            "Epoch 241/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0805 - accuracy: 0.6084 - val_loss: 1.2020 - val_accuracy: 0.5256\n",
            "Epoch 242/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0532 - accuracy: 0.6214 - val_loss: 1.2515 - val_accuracy: 0.4872\n",
            "Epoch 243/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0799 - accuracy: 0.6084 - val_loss: 1.2021 - val_accuracy: 0.5128\n",
            "Epoch 244/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0877 - accuracy: 0.5890 - val_loss: 1.1684 - val_accuracy: 0.5641\n",
            "Epoch 245/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0594 - accuracy: 0.6117 - val_loss: 1.2095 - val_accuracy: 0.5256\n",
            "Epoch 246/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0752 - accuracy: 0.5858 - val_loss: 1.1746 - val_accuracy: 0.5769\n",
            "Epoch 247/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1060 - accuracy: 0.6052 - val_loss: 1.1637 - val_accuracy: 0.5769\n",
            "Epoch 248/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0959 - accuracy: 0.5922 - val_loss: 1.1877 - val_accuracy: 0.5256\n",
            "Epoch 249/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0658 - accuracy: 0.5825 - val_loss: 1.2185 - val_accuracy: 0.4872\n",
            "Epoch 250/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1108 - accuracy: 0.5987 - val_loss: 1.2600 - val_accuracy: 0.4744\n",
            "Epoch 251/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1138 - accuracy: 0.6052 - val_loss: 1.2095 - val_accuracy: 0.5000\n",
            "Epoch 252/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1431 - accuracy: 0.6084 - val_loss: 1.1685 - val_accuracy: 0.5641\n",
            "Epoch 253/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0842 - accuracy: 0.6084 - val_loss: 1.1572 - val_accuracy: 0.5769\n",
            "Epoch 254/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1307 - accuracy: 0.5761 - val_loss: 1.1706 - val_accuracy: 0.5769\n",
            "Epoch 255/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1069 - accuracy: 0.6214 - val_loss: 1.1537 - val_accuracy: 0.5769\n",
            "Epoch 256/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0856 - accuracy: 0.6214 - val_loss: 1.2278 - val_accuracy: 0.4872\n",
            "Epoch 257/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1114 - accuracy: 0.5696 - val_loss: 1.2959 - val_accuracy: 0.4744\n",
            "Epoch 258/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0677 - accuracy: 0.6149 - val_loss: 1.1937 - val_accuracy: 0.5256\n",
            "Epoch 259/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0856 - accuracy: 0.6019 - val_loss: 1.1974 - val_accuracy: 0.5128\n",
            "Epoch 260/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1118 - accuracy: 0.6019 - val_loss: 1.3593 - val_accuracy: 0.4615\n",
            "Epoch 261/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0970 - accuracy: 0.5955 - val_loss: 1.3430 - val_accuracy: 0.4744\n",
            "Epoch 262/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1288 - accuracy: 0.5566 - val_loss: 1.3179 - val_accuracy: 0.4872\n",
            "Epoch 263/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0688 - accuracy: 0.6084 - val_loss: 1.1905 - val_accuracy: 0.5128\n",
            "Epoch 264/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0778 - accuracy: 0.6019 - val_loss: 1.2023 - val_accuracy: 0.5000\n",
            "Epoch 265/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0716 - accuracy: 0.6343 - val_loss: 1.1818 - val_accuracy: 0.5385\n",
            "Epoch 266/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0819 - accuracy: 0.6052 - val_loss: 1.2613 - val_accuracy: 0.4744\n",
            "Epoch 267/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1579 - accuracy: 0.5663 - val_loss: 1.2103 - val_accuracy: 0.5000\n",
            "Epoch 268/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1651 - accuracy: 0.5858 - val_loss: 1.1544 - val_accuracy: 0.5769\n",
            "Epoch 269/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1083 - accuracy: 0.5955 - val_loss: 1.1537 - val_accuracy: 0.5641\n",
            "Epoch 270/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0789 - accuracy: 0.6052 - val_loss: 1.1715 - val_accuracy: 0.5513\n",
            "Epoch 271/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0748 - accuracy: 0.5890 - val_loss: 1.1748 - val_accuracy: 0.5385\n",
            "Epoch 272/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0720 - accuracy: 0.5955 - val_loss: 1.1822 - val_accuracy: 0.5385\n",
            "Epoch 273/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1009 - accuracy: 0.5825 - val_loss: 1.1871 - val_accuracy: 0.5256\n",
            "Epoch 274/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1283 - accuracy: 0.5890 - val_loss: 1.1707 - val_accuracy: 0.5513\n",
            "Epoch 275/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0619 - accuracy: 0.6052 - val_loss: 1.1446 - val_accuracy: 0.5641\n",
            "Epoch 276/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0501 - accuracy: 0.6311 - val_loss: 1.1777 - val_accuracy: 0.5513\n",
            "Epoch 277/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0378 - accuracy: 0.6375 - val_loss: 1.2407 - val_accuracy: 0.5128\n",
            "Epoch 278/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0810 - accuracy: 0.6278 - val_loss: 1.3300 - val_accuracy: 0.4615\n",
            "Epoch 279/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0741 - accuracy: 0.6149 - val_loss: 1.1642 - val_accuracy: 0.5513\n",
            "Epoch 280/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0839 - accuracy: 0.6246 - val_loss: 1.1346 - val_accuracy: 0.5641\n",
            "Epoch 281/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0607 - accuracy: 0.6117 - val_loss: 1.3178 - val_accuracy: 0.5128\n",
            "Epoch 282/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0791 - accuracy: 0.6084 - val_loss: 1.2255 - val_accuracy: 0.5000\n",
            "Epoch 283/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0398 - accuracy: 0.6019 - val_loss: 1.1760 - val_accuracy: 0.5256\n",
            "Epoch 284/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0442 - accuracy: 0.6019 - val_loss: 1.2482 - val_accuracy: 0.5000\n",
            "Epoch 285/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0438 - accuracy: 0.6149 - val_loss: 1.2119 - val_accuracy: 0.5000\n",
            "Epoch 286/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0753 - accuracy: 0.6052 - val_loss: 1.2224 - val_accuracy: 0.5000\n",
            "Epoch 287/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0759 - accuracy: 0.5793 - val_loss: 1.1379 - val_accuracy: 0.5513\n",
            "Epoch 288/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1135 - accuracy: 0.5825 - val_loss: 1.1367 - val_accuracy: 0.5769\n",
            "Epoch 289/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0750 - accuracy: 0.6278 - val_loss: 1.1364 - val_accuracy: 0.5385\n",
            "Epoch 290/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0921 - accuracy: 0.5987 - val_loss: 1.2802 - val_accuracy: 0.4744\n",
            "Epoch 291/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0810 - accuracy: 0.6278 - val_loss: 1.1638 - val_accuracy: 0.5641\n",
            "Epoch 292/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0469 - accuracy: 0.6019 - val_loss: 1.1885 - val_accuracy: 0.5385\n",
            "Epoch 293/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1161 - accuracy: 0.5825 - val_loss: 1.1232 - val_accuracy: 0.5769\n",
            "Epoch 294/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0524 - accuracy: 0.5858 - val_loss: 1.1919 - val_accuracy: 0.5256\n",
            "Epoch 295/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0427 - accuracy: 0.6246 - val_loss: 1.1458 - val_accuracy: 0.5769\n",
            "Epoch 296/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0379 - accuracy: 0.6246 - val_loss: 1.1403 - val_accuracy: 0.5769\n",
            "Epoch 297/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0936 - accuracy: 0.5825 - val_loss: 1.2677 - val_accuracy: 0.4872\n",
            "Epoch 298/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0334 - accuracy: 0.5987 - val_loss: 1.1356 - val_accuracy: 0.5769\n",
            "Epoch 299/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0682 - accuracy: 0.6084 - val_loss: 1.1341 - val_accuracy: 0.5769\n",
            "Epoch 300/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0923 - accuracy: 0.6019 - val_loss: 1.1602 - val_accuracy: 0.5641\n",
            "Epoch 301/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1035 - accuracy: 0.6117 - val_loss: 1.2152 - val_accuracy: 0.4872\n",
            "Epoch 302/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0487 - accuracy: 0.6117 - val_loss: 1.2367 - val_accuracy: 0.4872\n",
            "Epoch 303/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0831 - accuracy: 0.6149 - val_loss: 1.1305 - val_accuracy: 0.5897\n",
            "Epoch 304/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0803 - accuracy: 0.5955 - val_loss: 1.1308 - val_accuracy: 0.5897\n",
            "Epoch 305/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0631 - accuracy: 0.6052 - val_loss: 1.3033 - val_accuracy: 0.4615\n",
            "Epoch 306/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1290 - accuracy: 0.5922 - val_loss: 1.4641 - val_accuracy: 0.4359\n",
            "Epoch 307/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1176 - accuracy: 0.5793 - val_loss: 1.3890 - val_accuracy: 0.4615\n",
            "Epoch 308/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0983 - accuracy: 0.6019 - val_loss: 1.1709 - val_accuracy: 0.5641\n",
            "Epoch 309/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0572 - accuracy: 0.6052 - val_loss: 1.1342 - val_accuracy: 0.5897\n",
            "Epoch 310/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0684 - accuracy: 0.5922 - val_loss: 1.2274 - val_accuracy: 0.5000\n",
            "Epoch 311/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0400 - accuracy: 0.6084 - val_loss: 1.1705 - val_accuracy: 0.5641\n",
            "Epoch 312/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0589 - accuracy: 0.6343 - val_loss: 1.1365 - val_accuracy: 0.5769\n",
            "Epoch 313/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0410 - accuracy: 0.6278 - val_loss: 1.1801 - val_accuracy: 0.5385\n",
            "Epoch 314/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0382 - accuracy: 0.6375 - val_loss: 1.2219 - val_accuracy: 0.5128\n",
            "Epoch 315/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0250 - accuracy: 0.6117 - val_loss: 1.2668 - val_accuracy: 0.4872\n",
            "Epoch 316/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0311 - accuracy: 0.6375 - val_loss: 1.1668 - val_accuracy: 0.5513\n",
            "Epoch 317/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0580 - accuracy: 0.5987 - val_loss: 1.1294 - val_accuracy: 0.6026\n",
            "Epoch 318/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0298 - accuracy: 0.6278 - val_loss: 1.2661 - val_accuracy: 0.4872\n",
            "Epoch 319/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0469 - accuracy: 0.6440 - val_loss: 1.1910 - val_accuracy: 0.5000\n",
            "Epoch 320/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0380 - accuracy: 0.6246 - val_loss: 1.1220 - val_accuracy: 0.5641\n",
            "Epoch 321/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0409 - accuracy: 0.6149 - val_loss: 1.1540 - val_accuracy: 0.5641\n",
            "Epoch 322/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0710 - accuracy: 0.6181 - val_loss: 1.3417 - val_accuracy: 0.4615\n",
            "Epoch 323/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0934 - accuracy: 0.6019 - val_loss: 1.2741 - val_accuracy: 0.4744\n",
            "Epoch 324/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0689 - accuracy: 0.6084 - val_loss: 1.1491 - val_accuracy: 0.5641\n",
            "Epoch 325/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0386 - accuracy: 0.6440 - val_loss: 1.1530 - val_accuracy: 0.5641\n",
            "Epoch 326/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0327 - accuracy: 0.6052 - val_loss: 1.2269 - val_accuracy: 0.5000\n",
            "Epoch 327/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0663 - accuracy: 0.6246 - val_loss: 1.1196 - val_accuracy: 0.5897\n",
            "Epoch 328/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0369 - accuracy: 0.6181 - val_loss: 1.2100 - val_accuracy: 0.5128\n",
            "Epoch 329/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0388 - accuracy: 0.6117 - val_loss: 1.2433 - val_accuracy: 0.5256\n",
            "Epoch 330/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0654 - accuracy: 0.6117 - val_loss: 1.1708 - val_accuracy: 0.5641\n",
            "Epoch 331/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0496 - accuracy: 0.6052 - val_loss: 1.1122 - val_accuracy: 0.5897\n",
            "Epoch 332/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0245 - accuracy: 0.6246 - val_loss: 1.1628 - val_accuracy: 0.5513\n",
            "Epoch 333/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0449 - accuracy: 0.6214 - val_loss: 1.1694 - val_accuracy: 0.5513\n",
            "Epoch 334/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0427 - accuracy: 0.6278 - val_loss: 1.3099 - val_accuracy: 0.4744\n",
            "Epoch 335/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0329 - accuracy: 0.6343 - val_loss: 1.2173 - val_accuracy: 0.5256\n",
            "Epoch 336/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0296 - accuracy: 0.6214 - val_loss: 1.2906 - val_accuracy: 0.4744\n",
            "Epoch 337/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0363 - accuracy: 0.6278 - val_loss: 1.2545 - val_accuracy: 0.5256\n",
            "Epoch 338/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0368 - accuracy: 0.6278 - val_loss: 1.1291 - val_accuracy: 0.5897\n",
            "Epoch 339/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0724 - accuracy: 0.5987 - val_loss: 1.1369 - val_accuracy: 0.5769\n",
            "Epoch 340/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0355 - accuracy: 0.6117 - val_loss: 1.1783 - val_accuracy: 0.5513\n",
            "Epoch 341/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0373 - accuracy: 0.6149 - val_loss: 1.3063 - val_accuracy: 0.4615\n",
            "Epoch 342/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0561 - accuracy: 0.6181 - val_loss: 1.1592 - val_accuracy: 0.5769\n",
            "Epoch 343/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0465 - accuracy: 0.6505 - val_loss: 1.2287 - val_accuracy: 0.5128\n",
            "Epoch 344/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0978 - accuracy: 0.5890 - val_loss: 1.1213 - val_accuracy: 0.5769\n",
            "Epoch 345/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0700 - accuracy: 0.5922 - val_loss: 1.1274 - val_accuracy: 0.5897\n",
            "Epoch 346/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0610 - accuracy: 0.6181 - val_loss: 1.1506 - val_accuracy: 0.5641\n",
            "Epoch 347/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0616 - accuracy: 0.6214 - val_loss: 1.1297 - val_accuracy: 0.5769\n",
            "Epoch 348/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0620 - accuracy: 0.6117 - val_loss: 1.1467 - val_accuracy: 0.5769\n",
            "Epoch 349/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0158 - accuracy: 0.6472 - val_loss: 1.1393 - val_accuracy: 0.5641\n",
            "Epoch 350/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0356 - accuracy: 0.6375 - val_loss: 1.1801 - val_accuracy: 0.5513\n",
            "Epoch 351/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0480 - accuracy: 0.6375 - val_loss: 1.1379 - val_accuracy: 0.5769\n",
            "Epoch 352/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0078 - accuracy: 0.6343 - val_loss: 1.3318 - val_accuracy: 0.4872\n",
            "Epoch 353/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0255 - accuracy: 0.6246 - val_loss: 1.1244 - val_accuracy: 0.5769\n",
            "Epoch 354/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0359 - accuracy: 0.6537 - val_loss: 1.1077 - val_accuracy: 0.5897\n",
            "Epoch 355/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0646 - accuracy: 0.5858 - val_loss: 1.1794 - val_accuracy: 0.5256\n",
            "Epoch 356/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0170 - accuracy: 0.6375 - val_loss: 1.1618 - val_accuracy: 0.5641\n",
            "Epoch 357/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0272 - accuracy: 0.6246 - val_loss: 1.1270 - val_accuracy: 0.5769\n",
            "Epoch 358/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0122 - accuracy: 0.6181 - val_loss: 1.1060 - val_accuracy: 0.5897\n",
            "Epoch 359/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0344 - accuracy: 0.6311 - val_loss: 1.1259 - val_accuracy: 0.5641\n",
            "Epoch 360/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0116 - accuracy: 0.6408 - val_loss: 1.1503 - val_accuracy: 0.5513\n",
            "Epoch 361/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0127 - accuracy: 0.6505 - val_loss: 1.1686 - val_accuracy: 0.5513\n",
            "Epoch 362/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0112 - accuracy: 0.6311 - val_loss: 1.1212 - val_accuracy: 0.5897\n",
            "Epoch 363/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0044 - accuracy: 0.6375 - val_loss: 1.1249 - val_accuracy: 0.5641\n",
            "Epoch 364/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0514 - accuracy: 0.6149 - val_loss: 1.1276 - val_accuracy: 0.5641\n",
            "Epoch 365/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0143 - accuracy: 0.6343 - val_loss: 1.1984 - val_accuracy: 0.5256\n",
            "Epoch 366/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0091 - accuracy: 0.6246 - val_loss: 1.2617 - val_accuracy: 0.5128\n",
            "Epoch 367/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0155 - accuracy: 0.6343 - val_loss: 1.1055 - val_accuracy: 0.5897\n",
            "Epoch 368/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0322 - accuracy: 0.6343 - val_loss: 1.1107 - val_accuracy: 0.5897\n",
            "Epoch 369/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0599 - accuracy: 0.5987 - val_loss: 1.2421 - val_accuracy: 0.5128\n",
            "Epoch 370/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9987 - accuracy: 0.6214 - val_loss: 1.2157 - val_accuracy: 0.5128\n",
            "Epoch 371/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0040 - accuracy: 0.6343 - val_loss: 1.1415 - val_accuracy: 0.5769\n",
            "Epoch 372/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0482 - accuracy: 0.6181 - val_loss: 1.1961 - val_accuracy: 0.5256\n",
            "Epoch 373/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0251 - accuracy: 0.6408 - val_loss: 1.1077 - val_accuracy: 0.5897\n",
            "Epoch 374/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0632 - accuracy: 0.6343 - val_loss: 1.1585 - val_accuracy: 0.5641\n",
            "Epoch 375/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9971 - accuracy: 0.6246 - val_loss: 1.1190 - val_accuracy: 0.5897\n",
            "Epoch 376/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0465 - accuracy: 0.6117 - val_loss: 1.1256 - val_accuracy: 0.5769\n",
            "Epoch 377/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0341 - accuracy: 0.6117 - val_loss: 1.1128 - val_accuracy: 0.5769\n",
            "Epoch 378/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0217 - accuracy: 0.6408 - val_loss: 1.1354 - val_accuracy: 0.5641\n",
            "Epoch 379/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0021 - accuracy: 0.6505 - val_loss: 1.1123 - val_accuracy: 0.5769\n",
            "Epoch 380/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0065 - accuracy: 0.6311 - val_loss: 1.1170 - val_accuracy: 0.5641\n",
            "Epoch 381/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0323 - accuracy: 0.6246 - val_loss: 1.4749 - val_accuracy: 0.4359\n",
            "Epoch 382/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0734 - accuracy: 0.6472 - val_loss: 1.1528 - val_accuracy: 0.5769\n",
            "Epoch 383/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0340 - accuracy: 0.5987 - val_loss: 1.1197 - val_accuracy: 0.5769\n",
            "Epoch 384/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0204 - accuracy: 0.6084 - val_loss: 1.1239 - val_accuracy: 0.5641\n",
            "Epoch 385/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0100 - accuracy: 0.6408 - val_loss: 1.1302 - val_accuracy: 0.5769\n",
            "Epoch 386/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0287 - accuracy: 0.6214 - val_loss: 1.1701 - val_accuracy: 0.5128\n",
            "Epoch 387/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0223 - accuracy: 0.6246 - val_loss: 1.2789 - val_accuracy: 0.4872\n",
            "Epoch 388/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0060 - accuracy: 0.6117 - val_loss: 1.2222 - val_accuracy: 0.5128\n",
            "Epoch 389/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0053 - accuracy: 0.6537 - val_loss: 1.1105 - val_accuracy: 0.5897\n",
            "Epoch 390/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0265 - accuracy: 0.6278 - val_loss: 1.1629 - val_accuracy: 0.5641\n",
            "Epoch 391/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0053 - accuracy: 0.6408 - val_loss: 1.1523 - val_accuracy: 0.5513\n",
            "Epoch 392/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0015 - accuracy: 0.6408 - val_loss: 1.1543 - val_accuracy: 0.5769\n",
            "Epoch 393/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0057 - accuracy: 0.6667 - val_loss: 1.1086 - val_accuracy: 0.5897\n",
            "Epoch 394/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0082 - accuracy: 0.6472 - val_loss: 1.1323 - val_accuracy: 0.5641\n",
            "Epoch 395/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9952 - accuracy: 0.6602 - val_loss: 1.1498 - val_accuracy: 0.5641\n",
            "Epoch 396/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9914 - accuracy: 0.6408 - val_loss: 1.1443 - val_accuracy: 0.5641\n",
            "Epoch 397/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0135 - accuracy: 0.6181 - val_loss: 1.1129 - val_accuracy: 0.5641\n",
            "Epoch 398/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.9697 - accuracy: 0.6602 - val_loss: 1.3671 - val_accuracy: 0.4615\n",
            "Epoch 399/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0073 - accuracy: 0.6311 - val_loss: 1.1177 - val_accuracy: 0.5897\n",
            "Epoch 400/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9769 - accuracy: 0.6570 - val_loss: 1.1844 - val_accuracy: 0.5256\n",
            "Epoch 401/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9858 - accuracy: 0.6472 - val_loss: 1.2669 - val_accuracy: 0.5000\n",
            "Epoch 402/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0040 - accuracy: 0.6440 - val_loss: 1.1107 - val_accuracy: 0.5769\n",
            "Epoch 403/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0038 - accuracy: 0.6570 - val_loss: 1.1808 - val_accuracy: 0.5385\n",
            "Epoch 404/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0087 - accuracy: 0.6440 - val_loss: 1.1227 - val_accuracy: 0.5641\n",
            "Epoch 405/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0189 - accuracy: 0.6408 - val_loss: 1.1089 - val_accuracy: 0.5897\n",
            "Epoch 406/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0251 - accuracy: 0.6214 - val_loss: 1.1190 - val_accuracy: 0.5641\n",
            "Epoch 407/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0262 - accuracy: 0.6440 - val_loss: 1.1586 - val_accuracy: 0.5256\n",
            "Epoch 408/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.0043 - accuracy: 0.6602 - val_loss: 1.2042 - val_accuracy: 0.5128\n",
            "Epoch 409/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.9914 - accuracy: 0.6440 - val_loss: 1.2186 - val_accuracy: 0.5385\n",
            "Epoch 410/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.0844 - accuracy: 0.6019 - val_loss: 1.1045 - val_accuracy: 0.5897\n",
            "Epoch 411/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0149 - accuracy: 0.6570 - val_loss: 1.1285 - val_accuracy: 0.5641\n",
            "Epoch 412/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0175 - accuracy: 0.6408 - val_loss: 1.0911 - val_accuracy: 0.5897\n",
            "Epoch 413/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0290 - accuracy: 0.6440 - val_loss: 1.1871 - val_accuracy: 0.5256\n",
            "Epoch 414/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0347 - accuracy: 0.6149 - val_loss: 1.1320 - val_accuracy: 0.5769\n",
            "Epoch 415/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0003 - accuracy: 0.6537 - val_loss: 1.2002 - val_accuracy: 0.5128\n",
            "Epoch 416/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9919 - accuracy: 0.6343 - val_loss: 1.1450 - val_accuracy: 0.5769\n",
            "Epoch 417/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0121 - accuracy: 0.6440 - val_loss: 1.1369 - val_accuracy: 0.5769\n",
            "Epoch 418/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9994 - accuracy: 0.6311 - val_loss: 1.1657 - val_accuracy: 0.5641\n",
            "Epoch 419/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9738 - accuracy: 0.6537 - val_loss: 1.1803 - val_accuracy: 0.5256\n",
            "Epoch 420/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0020 - accuracy: 0.6278 - val_loss: 1.1018 - val_accuracy: 0.5897\n",
            "Epoch 421/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9844 - accuracy: 0.6440 - val_loss: 1.2253 - val_accuracy: 0.5128\n",
            "Epoch 422/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0523 - accuracy: 0.6472 - val_loss: 1.2373 - val_accuracy: 0.5128\n",
            "Epoch 423/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.0220 - accuracy: 0.6343 - val_loss: 1.2279 - val_accuracy: 0.5000\n",
            "Epoch 424/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9695 - accuracy: 0.6537 - val_loss: 1.1241 - val_accuracy: 0.5769\n",
            "Epoch 425/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9883 - accuracy: 0.6408 - val_loss: 1.1228 - val_accuracy: 0.5769\n",
            "Epoch 426/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9777 - accuracy: 0.6472 - val_loss: 1.1820 - val_accuracy: 0.5385\n",
            "Epoch 427/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9869 - accuracy: 0.6505 - val_loss: 1.0924 - val_accuracy: 0.5769\n",
            "Epoch 428/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9882 - accuracy: 0.6602 - val_loss: 1.1676 - val_accuracy: 0.5641\n",
            "Epoch 429/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9613 - accuracy: 0.6699 - val_loss: 1.0918 - val_accuracy: 0.5897\n",
            "Epoch 430/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9876 - accuracy: 0.6343 - val_loss: 1.1602 - val_accuracy: 0.5513\n",
            "Epoch 431/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9974 - accuracy: 0.6343 - val_loss: 1.2443 - val_accuracy: 0.4872\n",
            "Epoch 432/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.9978 - accuracy: 0.6375 - val_loss: 1.1394 - val_accuracy: 0.5641\n",
            "Epoch 433/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0082 - accuracy: 0.6505 - val_loss: 1.1598 - val_accuracy: 0.5385\n",
            "Epoch 434/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9759 - accuracy: 0.6505 - val_loss: 1.1211 - val_accuracy: 0.5769\n",
            "Epoch 435/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9705 - accuracy: 0.6505 - val_loss: 1.1504 - val_accuracy: 0.5641\n",
            "Epoch 436/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9680 - accuracy: 0.6440 - val_loss: 1.1180 - val_accuracy: 0.5769\n",
            "Epoch 437/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9979 - accuracy: 0.6570 - val_loss: 1.1289 - val_accuracy: 0.5256\n",
            "Epoch 438/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0143 - accuracy: 0.6537 - val_loss: 1.1175 - val_accuracy: 0.5897\n",
            "Epoch 439/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0194 - accuracy: 0.6537 - val_loss: 1.0937 - val_accuracy: 0.6026\n",
            "Epoch 440/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9694 - accuracy: 0.6634 - val_loss: 1.1425 - val_accuracy: 0.5641\n",
            "Epoch 441/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0296 - accuracy: 0.6181 - val_loss: 1.3449 - val_accuracy: 0.4744\n",
            "Epoch 442/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0056 - accuracy: 0.6667 - val_loss: 1.1320 - val_accuracy: 0.5769\n",
            "Epoch 443/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9957 - accuracy: 0.6311 - val_loss: 1.1182 - val_accuracy: 0.6026\n",
            "Epoch 444/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9894 - accuracy: 0.6570 - val_loss: 1.1285 - val_accuracy: 0.5641\n",
            "Epoch 445/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9520 - accuracy: 0.6602 - val_loss: 1.0968 - val_accuracy: 0.6026\n",
            "Epoch 446/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9683 - accuracy: 0.6278 - val_loss: 1.1729 - val_accuracy: 0.5256\n",
            "Epoch 447/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0143 - accuracy: 0.6375 - val_loss: 1.0935 - val_accuracy: 0.5897\n",
            "Epoch 448/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9963 - accuracy: 0.6343 - val_loss: 1.2044 - val_accuracy: 0.5128\n",
            "Epoch 449/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9782 - accuracy: 0.6505 - val_loss: 1.0960 - val_accuracy: 0.5897\n",
            "Epoch 450/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9958 - accuracy: 0.6440 - val_loss: 1.1805 - val_accuracy: 0.5513\n",
            "Epoch 451/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9714 - accuracy: 0.6537 - val_loss: 1.0994 - val_accuracy: 0.5897\n",
            "Epoch 452/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9949 - accuracy: 0.6537 - val_loss: 1.0857 - val_accuracy: 0.6026\n",
            "Epoch 453/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0250 - accuracy: 0.6311 - val_loss: 1.1430 - val_accuracy: 0.5513\n",
            "Epoch 454/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0183 - accuracy: 0.6667 - val_loss: 1.1119 - val_accuracy: 0.5897\n",
            "Epoch 455/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9532 - accuracy: 0.6537 - val_loss: 1.2239 - val_accuracy: 0.5128\n",
            "Epoch 456/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9952 - accuracy: 0.6408 - val_loss: 1.1744 - val_accuracy: 0.5513\n",
            "Epoch 457/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0011 - accuracy: 0.6246 - val_loss: 1.1562 - val_accuracy: 0.5385\n",
            "Epoch 458/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9695 - accuracy: 0.6570 - val_loss: 1.1142 - val_accuracy: 0.5897\n",
            "Epoch 459/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9980 - accuracy: 0.6343 - val_loss: 1.1167 - val_accuracy: 0.5769\n",
            "Epoch 460/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9844 - accuracy: 0.6602 - val_loss: 1.1296 - val_accuracy: 0.6026\n",
            "Epoch 461/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9799 - accuracy: 0.6472 - val_loss: 1.2942 - val_accuracy: 0.4872\n",
            "Epoch 462/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9991 - accuracy: 0.6408 - val_loss: 1.2715 - val_accuracy: 0.4744\n",
            "Epoch 463/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9737 - accuracy: 0.6570 - val_loss: 1.0877 - val_accuracy: 0.6026\n",
            "Epoch 464/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9993 - accuracy: 0.6343 - val_loss: 1.1030 - val_accuracy: 0.5897\n",
            "Epoch 465/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9630 - accuracy: 0.6667 - val_loss: 1.2577 - val_accuracy: 0.4872\n",
            "Epoch 466/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9740 - accuracy: 0.6472 - val_loss: 1.2148 - val_accuracy: 0.5128\n",
            "Epoch 467/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9837 - accuracy: 0.6634 - val_loss: 1.2082 - val_accuracy: 0.4872\n",
            "Epoch 468/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9737 - accuracy: 0.6634 - val_loss: 1.1610 - val_accuracy: 0.5641\n",
            "Epoch 469/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9431 - accuracy: 0.6764 - val_loss: 1.1135 - val_accuracy: 0.5513\n",
            "Epoch 470/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9623 - accuracy: 0.6634 - val_loss: 1.1626 - val_accuracy: 0.5513\n",
            "Epoch 471/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9442 - accuracy: 0.6602 - val_loss: 1.2264 - val_accuracy: 0.4872\n",
            "Epoch 472/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.0097 - accuracy: 0.6246 - val_loss: 1.1077 - val_accuracy: 0.5897\n",
            "Epoch 473/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9523 - accuracy: 0.6537 - val_loss: 1.1245 - val_accuracy: 0.5385\n",
            "Epoch 474/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9781 - accuracy: 0.6570 - val_loss: 1.1490 - val_accuracy: 0.5513\n",
            "Epoch 475/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9390 - accuracy: 0.6537 - val_loss: 1.1013 - val_accuracy: 0.5897\n",
            "Epoch 476/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.9503 - accuracy: 0.6699 - val_loss: 1.1766 - val_accuracy: 0.5385\n",
            "Epoch 477/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.9691 - accuracy: 0.6408 - val_loss: 1.2001 - val_accuracy: 0.5385\n",
            "Epoch 478/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9589 - accuracy: 0.6440 - val_loss: 1.0826 - val_accuracy: 0.6026\n",
            "Epoch 479/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.9820 - accuracy: 0.6602 - val_loss: 1.1433 - val_accuracy: 0.5641\n",
            "Epoch 480/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9549 - accuracy: 0.6570 - val_loss: 1.1149 - val_accuracy: 0.5897\n",
            "Epoch 481/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9598 - accuracy: 0.6602 - val_loss: 1.0949 - val_accuracy: 0.6154\n",
            "Epoch 482/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.9200 - accuracy: 0.6828 - val_loss: 1.2070 - val_accuracy: 0.5000\n",
            "Epoch 483/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.9652 - accuracy: 0.6602 - val_loss: 1.1504 - val_accuracy: 0.5769\n",
            "Epoch 484/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9598 - accuracy: 0.6537 - val_loss: 1.1130 - val_accuracy: 0.5641\n",
            "Epoch 485/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9467 - accuracy: 0.6667 - val_loss: 1.2245 - val_accuracy: 0.4872\n",
            "Epoch 486/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9640 - accuracy: 0.6440 - val_loss: 1.1416 - val_accuracy: 0.5769\n",
            "Epoch 487/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.9392 - accuracy: 0.6731 - val_loss: 1.1060 - val_accuracy: 0.6026\n",
            "Epoch 488/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9293 - accuracy: 0.6764 - val_loss: 1.1140 - val_accuracy: 0.5513\n",
            "Epoch 489/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9853 - accuracy: 0.6505 - val_loss: 1.0718 - val_accuracy: 0.6154\n",
            "Epoch 490/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0149 - accuracy: 0.6084 - val_loss: 1.1733 - val_accuracy: 0.5385\n",
            "Epoch 491/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9752 - accuracy: 0.6440 - val_loss: 1.1414 - val_accuracy: 0.5641\n",
            "Epoch 492/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9635 - accuracy: 0.6699 - val_loss: 1.1960 - val_accuracy: 0.5256\n",
            "Epoch 493/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9772 - accuracy: 0.6408 - val_loss: 1.1457 - val_accuracy: 0.5256\n",
            "Epoch 494/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9780 - accuracy: 0.6440 - val_loss: 1.0873 - val_accuracy: 0.6026\n",
            "Epoch 495/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9395 - accuracy: 0.6796 - val_loss: 1.1338 - val_accuracy: 0.5256\n",
            "Epoch 496/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9786 - accuracy: 0.6505 - val_loss: 1.1034 - val_accuracy: 0.5897\n",
            "Epoch 497/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9638 - accuracy: 0.6699 - val_loss: 1.1423 - val_accuracy: 0.5256\n",
            "Epoch 498/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9572 - accuracy: 0.6408 - val_loss: 1.1684 - val_accuracy: 0.5128\n",
            "Epoch 499/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9444 - accuracy: 0.6634 - val_loss: 1.1182 - val_accuracy: 0.5897\n",
            "Epoch 500/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9597 - accuracy: 0.6958 - val_loss: 1.1958 - val_accuracy: 0.5128\n",
            "Epoch 501/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9814 - accuracy: 0.6634 - val_loss: 1.1477 - val_accuracy: 0.5513\n",
            "Epoch 502/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9533 - accuracy: 0.6570 - val_loss: 1.1801 - val_accuracy: 0.5256\n",
            "Epoch 503/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9465 - accuracy: 0.6537 - val_loss: 1.1443 - val_accuracy: 0.5513\n",
            "Epoch 504/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9593 - accuracy: 0.6537 - val_loss: 1.0948 - val_accuracy: 0.5897\n",
            "Epoch 505/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9814 - accuracy: 0.6408 - val_loss: 1.1468 - val_accuracy: 0.5641\n",
            "Epoch 506/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9505 - accuracy: 0.6537 - val_loss: 1.2353 - val_accuracy: 0.5000\n",
            "Epoch 507/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9435 - accuracy: 0.6440 - val_loss: 1.0954 - val_accuracy: 0.5769\n",
            "Epoch 508/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9595 - accuracy: 0.6505 - val_loss: 1.1625 - val_accuracy: 0.5385\n",
            "Epoch 509/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9294 - accuracy: 0.6764 - val_loss: 1.0910 - val_accuracy: 0.6026\n",
            "Epoch 510/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9702 - accuracy: 0.6796 - val_loss: 1.0827 - val_accuracy: 0.5897\n",
            "Epoch 511/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9651 - accuracy: 0.6602 - val_loss: 1.2811 - val_accuracy: 0.5000\n",
            "Epoch 512/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.9532 - accuracy: 0.6505 - val_loss: 1.1001 - val_accuracy: 0.6026\n",
            "Epoch 513/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9398 - accuracy: 0.6537 - val_loss: 1.1062 - val_accuracy: 0.5513\n",
            "Epoch 514/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9575 - accuracy: 0.6893 - val_loss: 1.1020 - val_accuracy: 0.6026\n",
            "Epoch 515/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9036 - accuracy: 0.6699 - val_loss: 1.1053 - val_accuracy: 0.6026\n",
            "Epoch 516/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9452 - accuracy: 0.6537 - val_loss: 1.0887 - val_accuracy: 0.6026\n",
            "Epoch 517/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9655 - accuracy: 0.6375 - val_loss: 1.1358 - val_accuracy: 0.5513\n",
            "Epoch 518/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9178 - accuracy: 0.6505 - val_loss: 1.1652 - val_accuracy: 0.5513\n",
            "Epoch 519/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9437 - accuracy: 0.6667 - val_loss: 1.1325 - val_accuracy: 0.5897\n",
            "Epoch 520/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9413 - accuracy: 0.6764 - val_loss: 1.1633 - val_accuracy: 0.5641\n",
            "Epoch 521/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9501 - accuracy: 0.6764 - val_loss: 1.1239 - val_accuracy: 0.5385\n",
            "Epoch 522/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9716 - accuracy: 0.6602 - val_loss: 1.1361 - val_accuracy: 0.5769\n",
            "Epoch 523/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9479 - accuracy: 0.6828 - val_loss: 1.0906 - val_accuracy: 0.6026\n",
            "Epoch 524/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9521 - accuracy: 0.6570 - val_loss: 1.0753 - val_accuracy: 0.5769\n",
            "Epoch 525/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9541 - accuracy: 0.6408 - val_loss: 1.1108 - val_accuracy: 0.5641\n",
            "Epoch 526/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9273 - accuracy: 0.6731 - val_loss: 1.1099 - val_accuracy: 0.5897\n",
            "Epoch 527/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9428 - accuracy: 0.6667 - val_loss: 1.1045 - val_accuracy: 0.5897\n",
            "Epoch 528/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9594 - accuracy: 0.6505 - val_loss: 1.1944 - val_accuracy: 0.5513\n",
            "Epoch 529/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9209 - accuracy: 0.6796 - val_loss: 1.1509 - val_accuracy: 0.5385\n",
            "Epoch 530/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9297 - accuracy: 0.6699 - val_loss: 1.1558 - val_accuracy: 0.5513\n",
            "Epoch 531/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9370 - accuracy: 0.6699 - val_loss: 1.1293 - val_accuracy: 0.5641\n",
            "Epoch 532/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9489 - accuracy: 0.6699 - val_loss: 1.1424 - val_accuracy: 0.5769\n",
            "Epoch 533/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9540 - accuracy: 0.6699 - val_loss: 1.1379 - val_accuracy: 0.5769\n",
            "Epoch 534/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9232 - accuracy: 0.6602 - val_loss: 1.1222 - val_accuracy: 0.5769\n",
            "Epoch 535/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9455 - accuracy: 0.6375 - val_loss: 1.2075 - val_accuracy: 0.5513\n",
            "Epoch 536/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9376 - accuracy: 0.6699 - val_loss: 1.0921 - val_accuracy: 0.5897\n",
            "Epoch 537/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9375 - accuracy: 0.6667 - val_loss: 1.0976 - val_accuracy: 0.5769\n",
            "Epoch 538/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9696 - accuracy: 0.6667 - val_loss: 1.0828 - val_accuracy: 0.6026\n",
            "Epoch 539/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9379 - accuracy: 0.6731 - val_loss: 1.0931 - val_accuracy: 0.5897\n",
            "Epoch 540/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9257 - accuracy: 0.6667 - val_loss: 1.1624 - val_accuracy: 0.5385\n",
            "Epoch 541/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9369 - accuracy: 0.6602 - val_loss: 1.1029 - val_accuracy: 0.5769\n",
            "Epoch 542/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9841 - accuracy: 0.6440 - val_loss: 1.0623 - val_accuracy: 0.6026\n",
            "Epoch 543/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9864 - accuracy: 0.6408 - val_loss: 1.2190 - val_accuracy: 0.5000\n",
            "Epoch 544/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9404 - accuracy: 0.6731 - val_loss: 1.0939 - val_accuracy: 0.5897\n",
            "Epoch 545/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9568 - accuracy: 0.6472 - val_loss: 1.1058 - val_accuracy: 0.5513\n",
            "Epoch 546/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9139 - accuracy: 0.6699 - val_loss: 1.1095 - val_accuracy: 0.5897\n",
            "Epoch 547/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9583 - accuracy: 0.6375 - val_loss: 1.1110 - val_accuracy: 0.5641\n",
            "Epoch 548/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9976 - accuracy: 0.6440 - val_loss: 1.2345 - val_accuracy: 0.5128\n",
            "Epoch 549/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9280 - accuracy: 0.6861 - val_loss: 1.1316 - val_accuracy: 0.5641\n",
            "Epoch 550/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9451 - accuracy: 0.6505 - val_loss: 1.1783 - val_accuracy: 0.5641\n",
            "Epoch 551/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9236 - accuracy: 0.6731 - val_loss: 1.1277 - val_accuracy: 0.5641\n",
            "Epoch 552/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9228 - accuracy: 0.6796 - val_loss: 1.1514 - val_accuracy: 0.5641\n",
            "Epoch 553/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9415 - accuracy: 0.6699 - val_loss: 1.1342 - val_accuracy: 0.5513\n",
            "Epoch 554/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9454 - accuracy: 0.6472 - val_loss: 1.0841 - val_accuracy: 0.5897\n",
            "Epoch 555/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9672 - accuracy: 0.6537 - val_loss: 1.0973 - val_accuracy: 0.5897\n",
            "Epoch 556/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9484 - accuracy: 0.6472 - val_loss: 1.1048 - val_accuracy: 0.6026\n",
            "Epoch 557/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9433 - accuracy: 0.6570 - val_loss: 1.0826 - val_accuracy: 0.6026\n",
            "Epoch 558/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9366 - accuracy: 0.6440 - val_loss: 1.1525 - val_accuracy: 0.5513\n",
            "Epoch 559/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9776 - accuracy: 0.6343 - val_loss: 1.1152 - val_accuracy: 0.5513\n",
            "Epoch 560/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9255 - accuracy: 0.6570 - val_loss: 1.0845 - val_accuracy: 0.6026\n",
            "Epoch 561/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9597 - accuracy: 0.6505 - val_loss: 1.1471 - val_accuracy: 0.5256\n",
            "Epoch 562/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9297 - accuracy: 0.6537 - val_loss: 1.1082 - val_accuracy: 0.5769\n",
            "Epoch 563/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9059 - accuracy: 0.6926 - val_loss: 1.0931 - val_accuracy: 0.5897\n",
            "Epoch 564/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9064 - accuracy: 0.6537 - val_loss: 1.1825 - val_accuracy: 0.5513\n",
            "Epoch 565/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9359 - accuracy: 0.6667 - val_loss: 1.0750 - val_accuracy: 0.6154\n",
            "Epoch 566/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9362 - accuracy: 0.6634 - val_loss: 1.1352 - val_accuracy: 0.5641\n",
            "Epoch 567/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9487 - accuracy: 0.6472 - val_loss: 1.1173 - val_accuracy: 0.5641\n",
            "Epoch 568/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9730 - accuracy: 0.6634 - val_loss: 1.1452 - val_accuracy: 0.5513\n",
            "Epoch 569/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9084 - accuracy: 0.6796 - val_loss: 1.0856 - val_accuracy: 0.5769\n",
            "Epoch 570/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8911 - accuracy: 0.6731 - val_loss: 1.1889 - val_accuracy: 0.5128\n",
            "Epoch 571/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9275 - accuracy: 0.6731 - val_loss: 1.1873 - val_accuracy: 0.5385\n",
            "Epoch 572/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9723 - accuracy: 0.6375 - val_loss: 1.1211 - val_accuracy: 0.5385\n",
            "Epoch 573/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9765 - accuracy: 0.6343 - val_loss: 1.1113 - val_accuracy: 0.5641\n",
            "Epoch 574/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9190 - accuracy: 0.6731 - val_loss: 1.0887 - val_accuracy: 0.5897\n",
            "Epoch 575/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9433 - accuracy: 0.6602 - val_loss: 1.1049 - val_accuracy: 0.5769\n",
            "Epoch 576/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9382 - accuracy: 0.6667 - val_loss: 1.1407 - val_accuracy: 0.5513\n",
            "Epoch 577/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9076 - accuracy: 0.6796 - val_loss: 1.0979 - val_accuracy: 0.5769\n",
            "Epoch 578/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9141 - accuracy: 0.6861 - val_loss: 1.1975 - val_accuracy: 0.5513\n",
            "Epoch 579/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9134 - accuracy: 0.6570 - val_loss: 1.0836 - val_accuracy: 0.5897\n",
            "Epoch 580/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9326 - accuracy: 0.6537 - val_loss: 1.0757 - val_accuracy: 0.6026\n",
            "Epoch 581/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9338 - accuracy: 0.6602 - val_loss: 1.2026 - val_accuracy: 0.5513\n",
            "Epoch 582/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9737 - accuracy: 0.6634 - val_loss: 1.1915 - val_accuracy: 0.5385\n",
            "Epoch 583/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9336 - accuracy: 0.6570 - val_loss: 1.1404 - val_accuracy: 0.5769\n",
            "Epoch 584/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8982 - accuracy: 0.6764 - val_loss: 1.0852 - val_accuracy: 0.5897\n",
            "Epoch 585/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9203 - accuracy: 0.6602 - val_loss: 1.1062 - val_accuracy: 0.5641\n",
            "Epoch 586/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9046 - accuracy: 0.6828 - val_loss: 1.1307 - val_accuracy: 0.5385\n",
            "Epoch 587/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9500 - accuracy: 0.6570 - val_loss: 1.1083 - val_accuracy: 0.5769\n",
            "Epoch 588/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9143 - accuracy: 0.6764 - val_loss: 1.1111 - val_accuracy: 0.5769\n",
            "Epoch 589/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8894 - accuracy: 0.6796 - val_loss: 1.0855 - val_accuracy: 0.5769\n",
            "Epoch 590/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8943 - accuracy: 0.6796 - val_loss: 1.1382 - val_accuracy: 0.5385\n",
            "Epoch 591/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9227 - accuracy: 0.6699 - val_loss: 1.0810 - val_accuracy: 0.5897\n",
            "Epoch 592/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9481 - accuracy: 0.6764 - val_loss: 1.2191 - val_accuracy: 0.5256\n",
            "Epoch 593/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9962 - accuracy: 0.6505 - val_loss: 1.4598 - val_accuracy: 0.5128\n",
            "Epoch 594/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9950 - accuracy: 0.6246 - val_loss: 1.1436 - val_accuracy: 0.5769\n",
            "Epoch 595/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9080 - accuracy: 0.6861 - val_loss: 1.1089 - val_accuracy: 0.5513\n",
            "Epoch 596/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9191 - accuracy: 0.6699 - val_loss: 1.0685 - val_accuracy: 0.6154\n",
            "Epoch 597/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9090 - accuracy: 0.6828 - val_loss: 1.0995 - val_accuracy: 0.5897\n",
            "Epoch 598/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9311 - accuracy: 0.6408 - val_loss: 1.1444 - val_accuracy: 0.5641\n",
            "Epoch 599/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9325 - accuracy: 0.6699 - val_loss: 1.1553 - val_accuracy: 0.5385\n",
            "Epoch 600/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9337 - accuracy: 0.6764 - val_loss: 1.0721 - val_accuracy: 0.5897\n",
            "Epoch 601/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9389 - accuracy: 0.6731 - val_loss: 1.1555 - val_accuracy: 0.5641\n",
            "Epoch 602/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9363 - accuracy: 0.6570 - val_loss: 1.0736 - val_accuracy: 0.5897\n",
            "Epoch 603/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9501 - accuracy: 0.6472 - val_loss: 1.0981 - val_accuracy: 0.5897\n",
            "Epoch 604/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9572 - accuracy: 0.6311 - val_loss: 1.2265 - val_accuracy: 0.5385\n",
            "Epoch 605/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9296 - accuracy: 0.6440 - val_loss: 1.1401 - val_accuracy: 0.5385\n",
            "Epoch 606/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9205 - accuracy: 0.6731 - val_loss: 1.0820 - val_accuracy: 0.5769\n",
            "Epoch 607/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9270 - accuracy: 0.6505 - val_loss: 1.1065 - val_accuracy: 0.5513\n",
            "Epoch 608/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9208 - accuracy: 0.6796 - val_loss: 1.1126 - val_accuracy: 0.5641\n",
            "Epoch 609/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8920 - accuracy: 0.6861 - val_loss: 1.0755 - val_accuracy: 0.6026\n",
            "Epoch 610/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9077 - accuracy: 0.6861 - val_loss: 1.1055 - val_accuracy: 0.5641\n",
            "Epoch 611/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9120 - accuracy: 0.6505 - val_loss: 1.1967 - val_accuracy: 0.5256\n",
            "Epoch 612/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9380 - accuracy: 0.6634 - val_loss: 1.1154 - val_accuracy: 0.5769\n",
            "Epoch 613/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9763 - accuracy: 0.6214 - val_loss: 1.1927 - val_accuracy: 0.5000\n",
            "Epoch 614/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9336 - accuracy: 0.6537 - val_loss: 1.0818 - val_accuracy: 0.5769\n",
            "Epoch 615/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9064 - accuracy: 0.6570 - val_loss: 1.0818 - val_accuracy: 0.5897\n",
            "Epoch 616/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9085 - accuracy: 0.6570 - val_loss: 1.2048 - val_accuracy: 0.5128\n",
            "Epoch 617/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9360 - accuracy: 0.6472 - val_loss: 1.0753 - val_accuracy: 0.5641\n",
            "Epoch 618/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9395 - accuracy: 0.6311 - val_loss: 1.1444 - val_accuracy: 0.5513\n",
            "Epoch 619/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9249 - accuracy: 0.6505 - val_loss: 1.1206 - val_accuracy: 0.5641\n",
            "Epoch 620/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9320 - accuracy: 0.6570 - val_loss: 1.0869 - val_accuracy: 0.5769\n",
            "Epoch 621/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9128 - accuracy: 0.6602 - val_loss: 1.1676 - val_accuracy: 0.5513\n",
            "Epoch 622/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8948 - accuracy: 0.6699 - val_loss: 1.0861 - val_accuracy: 0.5769\n",
            "Epoch 623/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8983 - accuracy: 0.6828 - val_loss: 1.0942 - val_accuracy: 0.5513\n",
            "Epoch 624/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8917 - accuracy: 0.6634 - val_loss: 1.0892 - val_accuracy: 0.5769\n",
            "Epoch 625/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9242 - accuracy: 0.6861 - val_loss: 1.0953 - val_accuracy: 0.5769\n",
            "Epoch 626/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9295 - accuracy: 0.6537 - val_loss: 1.1024 - val_accuracy: 0.5641\n",
            "Epoch 627/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9171 - accuracy: 0.6828 - val_loss: 1.0886 - val_accuracy: 0.5769\n",
            "Epoch 628/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8824 - accuracy: 0.6667 - val_loss: 1.1001 - val_accuracy: 0.5513\n",
            "Epoch 629/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8872 - accuracy: 0.6634 - val_loss: 1.1097 - val_accuracy: 0.5641\n",
            "Epoch 630/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9041 - accuracy: 0.6796 - val_loss: 1.1707 - val_accuracy: 0.5769\n",
            "Epoch 631/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9052 - accuracy: 0.6764 - val_loss: 1.0975 - val_accuracy: 0.5897\n",
            "Epoch 632/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8780 - accuracy: 0.7023 - val_loss: 1.0873 - val_accuracy: 0.5769\n",
            "Epoch 633/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8898 - accuracy: 0.6731 - val_loss: 1.0984 - val_accuracy: 0.5641\n",
            "Epoch 634/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8872 - accuracy: 0.6796 - val_loss: 1.1173 - val_accuracy: 0.5513\n",
            "Epoch 635/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9311 - accuracy: 0.6570 - val_loss: 1.1261 - val_accuracy: 0.5128\n",
            "Epoch 636/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8857 - accuracy: 0.6408 - val_loss: 1.0967 - val_accuracy: 0.5897\n",
            "Epoch 637/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8869 - accuracy: 0.6861 - val_loss: 1.1371 - val_accuracy: 0.5385\n",
            "Epoch 638/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9202 - accuracy: 0.6537 - val_loss: 1.2333 - val_accuracy: 0.4872\n",
            "Epoch 639/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9910 - accuracy: 0.6408 - val_loss: 1.0924 - val_accuracy: 0.5769\n",
            "Epoch 640/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9290 - accuracy: 0.6861 - val_loss: 1.0765 - val_accuracy: 0.5897\n",
            "Epoch 641/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8925 - accuracy: 0.6699 - val_loss: 1.0666 - val_accuracy: 0.5897\n",
            "Epoch 642/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8567 - accuracy: 0.6861 - val_loss: 1.1079 - val_accuracy: 0.5769\n",
            "Epoch 643/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9255 - accuracy: 0.6731 - val_loss: 1.1542 - val_accuracy: 0.5513\n",
            "Epoch 644/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9246 - accuracy: 0.6699 - val_loss: 1.1083 - val_accuracy: 0.5769\n",
            "Epoch 645/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8983 - accuracy: 0.6796 - val_loss: 1.1234 - val_accuracy: 0.5513\n",
            "Epoch 646/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9022 - accuracy: 0.6731 - val_loss: 1.1946 - val_accuracy: 0.5513\n",
            "Epoch 647/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9082 - accuracy: 0.6699 - val_loss: 1.1315 - val_accuracy: 0.5897\n",
            "Epoch 648/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8713 - accuracy: 0.6893 - val_loss: 1.1170 - val_accuracy: 0.5513\n",
            "Epoch 649/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8843 - accuracy: 0.6699 - val_loss: 1.0656 - val_accuracy: 0.6026\n",
            "Epoch 650/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8903 - accuracy: 0.6699 - val_loss: 1.1486 - val_accuracy: 0.5769\n",
            "Epoch 651/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9704 - accuracy: 0.6214 - val_loss: 1.1293 - val_accuracy: 0.5641\n",
            "Epoch 652/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9340 - accuracy: 0.6537 - val_loss: 1.2647 - val_accuracy: 0.5256\n",
            "Epoch 653/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9555 - accuracy: 0.6699 - val_loss: 1.0695 - val_accuracy: 0.5769\n",
            "Epoch 654/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8490 - accuracy: 0.7120 - val_loss: 1.1120 - val_accuracy: 0.5897\n",
            "Epoch 655/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8744 - accuracy: 0.6926 - val_loss: 1.0806 - val_accuracy: 0.5897\n",
            "Epoch 656/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9016 - accuracy: 0.6667 - val_loss: 1.1293 - val_accuracy: 0.5385\n",
            "Epoch 657/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8935 - accuracy: 0.6602 - val_loss: 1.1420 - val_accuracy: 0.5513\n",
            "Epoch 658/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9217 - accuracy: 0.6796 - val_loss: 1.0580 - val_accuracy: 0.5769\n",
            "Epoch 659/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9129 - accuracy: 0.6537 - val_loss: 1.2081 - val_accuracy: 0.5513\n",
            "Epoch 660/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8746 - accuracy: 0.6926 - val_loss: 1.0579 - val_accuracy: 0.6154\n",
            "Epoch 661/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8949 - accuracy: 0.6958 - val_loss: 1.1198 - val_accuracy: 0.5256\n",
            "Epoch 662/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8944 - accuracy: 0.6731 - val_loss: 1.0731 - val_accuracy: 0.5769\n",
            "Epoch 663/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8914 - accuracy: 0.6667 - val_loss: 1.0768 - val_accuracy: 0.5769\n",
            "Epoch 664/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8660 - accuracy: 0.6731 - val_loss: 1.1045 - val_accuracy: 0.5897\n",
            "Epoch 665/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8932 - accuracy: 0.6537 - val_loss: 1.0711 - val_accuracy: 0.5641\n",
            "Epoch 666/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8722 - accuracy: 0.6796 - val_loss: 1.1545 - val_accuracy: 0.6026\n",
            "Epoch 667/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8977 - accuracy: 0.6828 - val_loss: 1.0584 - val_accuracy: 0.5897\n",
            "Epoch 668/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9092 - accuracy: 0.6634 - val_loss: 1.0966 - val_accuracy: 0.5513\n",
            "Epoch 669/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8941 - accuracy: 0.6699 - val_loss: 1.1382 - val_accuracy: 0.5897\n",
            "Epoch 670/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8990 - accuracy: 0.6667 - val_loss: 1.1371 - val_accuracy: 0.5513\n",
            "Epoch 671/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8846 - accuracy: 0.6796 - val_loss: 1.0519 - val_accuracy: 0.6282\n",
            "Epoch 672/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9227 - accuracy: 0.6440 - val_loss: 1.1217 - val_accuracy: 0.5641\n",
            "Epoch 673/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9054 - accuracy: 0.6570 - val_loss: 1.1726 - val_accuracy: 0.5385\n",
            "Epoch 674/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9279 - accuracy: 0.6343 - val_loss: 1.0704 - val_accuracy: 0.5897\n",
            "Epoch 675/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8939 - accuracy: 0.6731 - val_loss: 1.1036 - val_accuracy: 0.5897\n",
            "Epoch 676/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.8885 - accuracy: 0.6828 - val_loss: 1.1020 - val_accuracy: 0.5513\n",
            "Epoch 677/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8951 - accuracy: 0.6699 - val_loss: 1.0568 - val_accuracy: 0.5897\n",
            "Epoch 678/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9069 - accuracy: 0.6537 - val_loss: 1.1282 - val_accuracy: 0.6026\n",
            "Epoch 679/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8526 - accuracy: 0.6926 - val_loss: 1.0808 - val_accuracy: 0.5641\n",
            "Epoch 680/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8858 - accuracy: 0.6796 - val_loss: 1.0692 - val_accuracy: 0.5769\n",
            "Epoch 681/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8532 - accuracy: 0.6893 - val_loss: 1.0751 - val_accuracy: 0.5769\n",
            "Epoch 682/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8960 - accuracy: 0.6699 - val_loss: 1.2310 - val_accuracy: 0.5256\n",
            "Epoch 683/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8931 - accuracy: 0.6958 - val_loss: 1.0991 - val_accuracy: 0.5513\n",
            "Epoch 684/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8854 - accuracy: 0.6926 - val_loss: 1.0748 - val_accuracy: 0.5897\n",
            "Epoch 685/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8757 - accuracy: 0.6731 - val_loss: 1.0982 - val_accuracy: 0.5385\n",
            "Epoch 686/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8662 - accuracy: 0.6764 - val_loss: 1.1337 - val_accuracy: 0.5769\n",
            "Epoch 687/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8964 - accuracy: 0.6731 - val_loss: 1.0732 - val_accuracy: 0.6026\n",
            "Epoch 688/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9200 - accuracy: 0.6602 - val_loss: 1.1218 - val_accuracy: 0.5769\n",
            "Epoch 689/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8745 - accuracy: 0.6796 - val_loss: 1.0750 - val_accuracy: 0.6026\n",
            "Epoch 690/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8681 - accuracy: 0.6634 - val_loss: 1.0554 - val_accuracy: 0.5897\n",
            "Epoch 691/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8798 - accuracy: 0.6828 - val_loss: 1.1392 - val_accuracy: 0.5769\n",
            "Epoch 692/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8590 - accuracy: 0.6796 - val_loss: 1.1087 - val_accuracy: 0.5769\n",
            "Epoch 693/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8670 - accuracy: 0.6699 - val_loss: 1.0725 - val_accuracy: 0.5769\n",
            "Epoch 694/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8729 - accuracy: 0.6699 - val_loss: 1.1351 - val_accuracy: 0.5641\n",
            "Epoch 695/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8544 - accuracy: 0.6926 - val_loss: 1.0741 - val_accuracy: 0.5897\n",
            "Epoch 696/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8427 - accuracy: 0.7055 - val_loss: 1.0788 - val_accuracy: 0.5769\n",
            "Epoch 697/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8699 - accuracy: 0.6990 - val_loss: 1.1165 - val_accuracy: 0.5769\n",
            "Epoch 698/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8604 - accuracy: 0.6926 - val_loss: 1.0733 - val_accuracy: 0.5769\n",
            "Epoch 699/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8504 - accuracy: 0.7023 - val_loss: 1.0849 - val_accuracy: 0.5897\n",
            "Epoch 700/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8584 - accuracy: 0.6958 - val_loss: 1.0689 - val_accuracy: 0.5897\n",
            "Epoch 701/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8716 - accuracy: 0.6990 - val_loss: 1.1203 - val_accuracy: 0.5897\n",
            "Epoch 702/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8682 - accuracy: 0.6764 - val_loss: 1.0424 - val_accuracy: 0.5897\n",
            "Epoch 703/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8546 - accuracy: 0.6764 - val_loss: 1.0848 - val_accuracy: 0.5513\n",
            "Epoch 704/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8595 - accuracy: 0.6861 - val_loss: 1.1551 - val_accuracy: 0.5385\n",
            "Epoch 705/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8555 - accuracy: 0.6764 - val_loss: 1.0506 - val_accuracy: 0.5897\n",
            "Epoch 706/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8669 - accuracy: 0.6699 - val_loss: 1.1122 - val_accuracy: 0.5897\n",
            "Epoch 707/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0075 - accuracy: 0.6278 - val_loss: 1.0707 - val_accuracy: 0.6026\n",
            "Epoch 708/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9670 - accuracy: 0.6408 - val_loss: 1.1632 - val_accuracy: 0.5897\n",
            "Epoch 709/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9194 - accuracy: 0.6440 - val_loss: 1.0629 - val_accuracy: 0.6026\n",
            "Epoch 710/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8969 - accuracy: 0.6699 - val_loss: 1.1662 - val_accuracy: 0.5000\n",
            "Epoch 711/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8845 - accuracy: 0.6667 - val_loss: 1.0673 - val_accuracy: 0.5641\n",
            "Epoch 712/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9231 - accuracy: 0.6634 - val_loss: 1.0772 - val_accuracy: 0.6026\n",
            "Epoch 713/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8851 - accuracy: 0.6472 - val_loss: 1.1198 - val_accuracy: 0.5513\n",
            "Epoch 714/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8838 - accuracy: 0.6731 - val_loss: 1.0453 - val_accuracy: 0.5897\n",
            "Epoch 715/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8898 - accuracy: 0.6602 - val_loss: 1.1593 - val_accuracy: 0.5513\n",
            "Epoch 716/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9252 - accuracy: 0.6602 - val_loss: 1.0571 - val_accuracy: 0.6026\n",
            "Epoch 717/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9839 - accuracy: 0.6375 - val_loss: 1.2266 - val_accuracy: 0.5385\n",
            "Epoch 718/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9106 - accuracy: 0.6602 - val_loss: 1.0947 - val_accuracy: 0.5769\n",
            "Epoch 719/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8971 - accuracy: 0.6699 - val_loss: 1.0374 - val_accuracy: 0.6026\n",
            "Epoch 720/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8726 - accuracy: 0.6861 - val_loss: 1.1407 - val_accuracy: 0.6282\n",
            "Epoch 721/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8703 - accuracy: 0.6667 - val_loss: 1.1355 - val_accuracy: 0.6026\n",
            "Epoch 722/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8810 - accuracy: 0.6828 - val_loss: 1.0506 - val_accuracy: 0.5897\n",
            "Epoch 723/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8766 - accuracy: 0.6699 - val_loss: 1.1509 - val_accuracy: 0.5641\n",
            "Epoch 724/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8202 - accuracy: 0.7023 - val_loss: 1.0436 - val_accuracy: 0.6026\n",
            "Epoch 725/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8714 - accuracy: 0.6602 - val_loss: 1.1384 - val_accuracy: 0.5256\n",
            "Epoch 726/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8994 - accuracy: 0.6764 - val_loss: 1.1520 - val_accuracy: 0.5641\n",
            "Epoch 727/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8429 - accuracy: 0.7055 - val_loss: 1.0763 - val_accuracy: 0.5769\n",
            "Epoch 728/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8554 - accuracy: 0.6861 - val_loss: 1.0597 - val_accuracy: 0.5641\n",
            "Epoch 729/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8556 - accuracy: 0.6861 - val_loss: 1.0822 - val_accuracy: 0.5769\n",
            "Epoch 730/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8586 - accuracy: 0.7023 - val_loss: 1.0767 - val_accuracy: 0.6154\n",
            "Epoch 731/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8700 - accuracy: 0.6699 - val_loss: 1.1065 - val_accuracy: 0.5641\n",
            "Epoch 732/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8890 - accuracy: 0.6828 - val_loss: 1.0447 - val_accuracy: 0.6154\n",
            "Epoch 733/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8710 - accuracy: 0.6861 - val_loss: 1.1061 - val_accuracy: 0.5769\n",
            "Epoch 734/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8844 - accuracy: 0.6602 - val_loss: 1.0682 - val_accuracy: 0.5769\n",
            "Epoch 735/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8286 - accuracy: 0.7023 - val_loss: 1.0717 - val_accuracy: 0.5769\n",
            "Epoch 736/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8622 - accuracy: 0.7023 - val_loss: 1.0663 - val_accuracy: 0.5769\n",
            "Epoch 737/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9010 - accuracy: 0.6828 - val_loss: 1.1289 - val_accuracy: 0.5769\n",
            "Epoch 738/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8657 - accuracy: 0.6958 - val_loss: 1.0479 - val_accuracy: 0.5897\n",
            "Epoch 739/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8593 - accuracy: 0.7120 - val_loss: 1.0498 - val_accuracy: 0.5769\n",
            "Epoch 740/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8515 - accuracy: 0.6667 - val_loss: 1.0788 - val_accuracy: 0.5641\n",
            "Epoch 741/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8599 - accuracy: 0.6958 - val_loss: 1.0767 - val_accuracy: 0.6154\n",
            "Epoch 742/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8479 - accuracy: 0.6893 - val_loss: 1.0645 - val_accuracy: 0.5769\n",
            "Epoch 743/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8815 - accuracy: 0.6893 - val_loss: 1.1125 - val_accuracy: 0.5897\n",
            "Epoch 744/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8917 - accuracy: 0.6634 - val_loss: 1.2242 - val_accuracy: 0.6154\n",
            "Epoch 745/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9250 - accuracy: 0.6602 - val_loss: 1.1046 - val_accuracy: 0.5897\n",
            "Epoch 746/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8831 - accuracy: 0.6796 - val_loss: 1.0427 - val_accuracy: 0.6026\n",
            "Epoch 747/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8372 - accuracy: 0.6990 - val_loss: 1.0561 - val_accuracy: 0.6026\n",
            "Epoch 748/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8296 - accuracy: 0.6926 - val_loss: 1.0427 - val_accuracy: 0.5897\n",
            "Epoch 749/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8448 - accuracy: 0.6926 - val_loss: 1.0487 - val_accuracy: 0.6154\n",
            "Epoch 750/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8235 - accuracy: 0.6893 - val_loss: 1.0751 - val_accuracy: 0.5641\n",
            "Epoch 751/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8779 - accuracy: 0.6893 - val_loss: 1.0722 - val_accuracy: 0.6154\n",
            "Epoch 752/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8450 - accuracy: 0.7087 - val_loss: 1.1521 - val_accuracy: 0.5128\n",
            "Epoch 753/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8459 - accuracy: 0.6796 - val_loss: 1.0584 - val_accuracy: 0.5897\n",
            "Epoch 754/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8567 - accuracy: 0.6893 - val_loss: 1.1502 - val_accuracy: 0.5897\n",
            "Epoch 755/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.8978 - accuracy: 0.6764 - val_loss: 1.0773 - val_accuracy: 0.5641\n",
            "Epoch 756/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8320 - accuracy: 0.6828 - val_loss: 1.0715 - val_accuracy: 0.5897\n",
            "Epoch 757/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8339 - accuracy: 0.6990 - val_loss: 1.1307 - val_accuracy: 0.5769\n",
            "Epoch 758/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8496 - accuracy: 0.6861 - val_loss: 1.0512 - val_accuracy: 0.5769\n",
            "Epoch 759/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8419 - accuracy: 0.6828 - val_loss: 1.0930 - val_accuracy: 0.5769\n",
            "Epoch 760/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8606 - accuracy: 0.6926 - val_loss: 1.0391 - val_accuracy: 0.5897\n",
            "Epoch 761/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8410 - accuracy: 0.6731 - val_loss: 1.2371 - val_accuracy: 0.5128\n",
            "Epoch 762/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8710 - accuracy: 0.6893 - val_loss: 1.0601 - val_accuracy: 0.6154\n",
            "Epoch 763/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.9113 - accuracy: 0.6602 - val_loss: 1.1794 - val_accuracy: 0.5513\n",
            "Epoch 764/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8431 - accuracy: 0.6828 - val_loss: 1.0317 - val_accuracy: 0.6026\n",
            "Epoch 765/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8685 - accuracy: 0.6861 - val_loss: 1.1027 - val_accuracy: 0.6026\n",
            "Epoch 766/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8808 - accuracy: 0.6731 - val_loss: 1.1732 - val_accuracy: 0.5641\n",
            "Epoch 767/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8700 - accuracy: 0.6796 - val_loss: 1.0278 - val_accuracy: 0.6026\n",
            "Epoch 768/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8135 - accuracy: 0.7023 - val_loss: 1.0580 - val_accuracy: 0.5897\n",
            "Epoch 769/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8224 - accuracy: 0.6796 - val_loss: 1.0385 - val_accuracy: 0.6154\n",
            "Epoch 770/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8727 - accuracy: 0.6570 - val_loss: 1.0851 - val_accuracy: 0.6154\n",
            "Epoch 771/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8508 - accuracy: 0.6796 - val_loss: 1.1266 - val_accuracy: 0.6026\n",
            "Epoch 772/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8634 - accuracy: 0.6893 - val_loss: 1.0781 - val_accuracy: 0.5897\n",
            "Epoch 773/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8180 - accuracy: 0.7120 - val_loss: 1.0545 - val_accuracy: 0.5897\n",
            "Epoch 774/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8207 - accuracy: 0.7055 - val_loss: 1.0992 - val_accuracy: 0.6026\n",
            "Epoch 775/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8652 - accuracy: 0.6893 - val_loss: 1.0369 - val_accuracy: 0.5897\n",
            "Epoch 776/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8576 - accuracy: 0.6699 - val_loss: 1.0459 - val_accuracy: 0.5769\n",
            "Epoch 777/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8711 - accuracy: 0.6828 - val_loss: 1.0807 - val_accuracy: 0.5769\n",
            "Epoch 778/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8391 - accuracy: 0.6861 - val_loss: 1.0284 - val_accuracy: 0.5769\n",
            "Epoch 779/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8406 - accuracy: 0.6828 - val_loss: 1.1144 - val_accuracy: 0.6154\n",
            "Epoch 780/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8560 - accuracy: 0.6796 - val_loss: 1.0337 - val_accuracy: 0.5897\n",
            "Epoch 781/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8114 - accuracy: 0.7055 - val_loss: 1.0449 - val_accuracy: 0.5897\n",
            "Epoch 782/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8350 - accuracy: 0.6764 - val_loss: 1.0976 - val_accuracy: 0.5513\n",
            "Epoch 783/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8082 - accuracy: 0.7023 - val_loss: 1.1191 - val_accuracy: 0.5513\n",
            "Epoch 784/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8811 - accuracy: 0.6990 - val_loss: 1.0397 - val_accuracy: 0.6282\n",
            "Epoch 785/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8580 - accuracy: 0.6667 - val_loss: 1.0804 - val_accuracy: 0.5897\n",
            "Epoch 786/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8805 - accuracy: 0.6667 - val_loss: 1.0914 - val_accuracy: 0.5897\n",
            "Epoch 787/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8433 - accuracy: 0.6926 - val_loss: 1.1107 - val_accuracy: 0.5897\n",
            "Epoch 788/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8323 - accuracy: 0.7120 - val_loss: 1.0757 - val_accuracy: 0.5897\n",
            "Epoch 789/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8540 - accuracy: 0.6731 - val_loss: 1.0920 - val_accuracy: 0.5769\n",
            "Epoch 790/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8159 - accuracy: 0.6990 - val_loss: 1.0901 - val_accuracy: 0.5641\n",
            "Epoch 791/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8343 - accuracy: 0.6796 - val_loss: 1.0855 - val_accuracy: 0.6026\n",
            "Epoch 792/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8284 - accuracy: 0.7152 - val_loss: 1.0528 - val_accuracy: 0.5897\n",
            "Epoch 793/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8465 - accuracy: 0.7055 - val_loss: 1.0703 - val_accuracy: 0.6154\n",
            "Epoch 794/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8560 - accuracy: 0.6926 - val_loss: 1.1556 - val_accuracy: 0.5641\n",
            "Epoch 795/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8385 - accuracy: 0.6926 - val_loss: 1.0755 - val_accuracy: 0.5769\n",
            "Epoch 796/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8374 - accuracy: 0.6926 - val_loss: 1.0681 - val_accuracy: 0.5769\n",
            "Epoch 797/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8341 - accuracy: 0.6958 - val_loss: 1.1356 - val_accuracy: 0.5513\n",
            "Epoch 798/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8459 - accuracy: 0.6828 - val_loss: 1.0709 - val_accuracy: 0.5641\n",
            "Epoch 799/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8608 - accuracy: 0.6828 - val_loss: 1.0754 - val_accuracy: 0.6026\n",
            "Epoch 800/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8521 - accuracy: 0.6699 - val_loss: 1.1567 - val_accuracy: 0.5641\n",
            "Epoch 801/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8326 - accuracy: 0.7379 - val_loss: 1.0635 - val_accuracy: 0.6026\n",
            "Epoch 802/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8460 - accuracy: 0.6861 - val_loss: 1.0640 - val_accuracy: 0.5897\n",
            "Epoch 803/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8347 - accuracy: 0.6958 - val_loss: 1.1094 - val_accuracy: 0.5897\n",
            "Epoch 804/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8198 - accuracy: 0.6828 - val_loss: 1.0530 - val_accuracy: 0.6154\n",
            "Epoch 805/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8468 - accuracy: 0.6796 - val_loss: 1.0346 - val_accuracy: 0.5769\n",
            "Epoch 806/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8328 - accuracy: 0.6796 - val_loss: 1.0928 - val_accuracy: 0.5897\n",
            "Epoch 807/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8487 - accuracy: 0.6893 - val_loss: 1.0232 - val_accuracy: 0.5769\n",
            "Epoch 808/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8136 - accuracy: 0.6926 - val_loss: 1.1257 - val_accuracy: 0.6154\n",
            "Epoch 809/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8344 - accuracy: 0.6893 - val_loss: 1.0283 - val_accuracy: 0.6026\n",
            "Epoch 810/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.8202 - accuracy: 0.6926 - val_loss: 1.0830 - val_accuracy: 0.5385\n",
            "Epoch 811/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8203 - accuracy: 0.7055 - val_loss: 1.0779 - val_accuracy: 0.5641\n",
            "Epoch 812/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8234 - accuracy: 0.6990 - val_loss: 1.0232 - val_accuracy: 0.6282\n",
            "Epoch 813/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8312 - accuracy: 0.6926 - val_loss: 1.0773 - val_accuracy: 0.5641\n",
            "Epoch 814/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8203 - accuracy: 0.7087 - val_loss: 1.1003 - val_accuracy: 0.5769\n",
            "Epoch 815/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8045 - accuracy: 0.6893 - val_loss: 1.0619 - val_accuracy: 0.5897\n",
            "Epoch 816/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8102 - accuracy: 0.6990 - val_loss: 1.0618 - val_accuracy: 0.5641\n",
            "Epoch 817/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8350 - accuracy: 0.7023 - val_loss: 1.0284 - val_accuracy: 0.5897\n",
            "Epoch 818/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8138 - accuracy: 0.7055 - val_loss: 1.1267 - val_accuracy: 0.6026\n",
            "Epoch 819/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7914 - accuracy: 0.7120 - val_loss: 1.0395 - val_accuracy: 0.6154\n",
            "Epoch 820/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8182 - accuracy: 0.6990 - val_loss: 1.0793 - val_accuracy: 0.6026\n",
            "Epoch 821/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8475 - accuracy: 0.7087 - val_loss: 1.0920 - val_accuracy: 0.6026\n",
            "Epoch 822/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8096 - accuracy: 0.6796 - val_loss: 1.1227 - val_accuracy: 0.6026\n",
            "Epoch 823/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8142 - accuracy: 0.7023 - val_loss: 1.2322 - val_accuracy: 0.5641\n",
            "Epoch 824/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8812 - accuracy: 0.6570 - val_loss: 1.0569 - val_accuracy: 0.6026\n",
            "Epoch 825/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8667 - accuracy: 0.6634 - val_loss: 1.0468 - val_accuracy: 0.5897\n",
            "Epoch 826/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8149 - accuracy: 0.7023 - val_loss: 1.1025 - val_accuracy: 0.6026\n",
            "Epoch 827/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8348 - accuracy: 0.6990 - val_loss: 1.1128 - val_accuracy: 0.6410\n",
            "Epoch 828/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8701 - accuracy: 0.6602 - val_loss: 1.0524 - val_accuracy: 0.6026\n",
            "Epoch 829/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9070 - accuracy: 0.6990 - val_loss: 1.0531 - val_accuracy: 0.5769\n",
            "Epoch 830/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8193 - accuracy: 0.6731 - val_loss: 1.0384 - val_accuracy: 0.6154\n",
            "Epoch 831/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8092 - accuracy: 0.7023 - val_loss: 1.0487 - val_accuracy: 0.6026\n",
            "Epoch 832/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8305 - accuracy: 0.7184 - val_loss: 1.1298 - val_accuracy: 0.6538\n",
            "Epoch 833/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8197 - accuracy: 0.6861 - val_loss: 1.0796 - val_accuracy: 0.5641\n",
            "Epoch 834/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7942 - accuracy: 0.7249 - val_loss: 1.0870 - val_accuracy: 0.6154\n",
            "Epoch 835/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8145 - accuracy: 0.6796 - val_loss: 1.0708 - val_accuracy: 0.6154\n",
            "Epoch 836/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8180 - accuracy: 0.6958 - val_loss: 1.0164 - val_accuracy: 0.5897\n",
            "Epoch 837/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7882 - accuracy: 0.7120 - val_loss: 1.0793 - val_accuracy: 0.6154\n",
            "Epoch 838/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8108 - accuracy: 0.7087 - val_loss: 1.0337 - val_accuracy: 0.6154\n",
            "Epoch 839/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8001 - accuracy: 0.7120 - val_loss: 1.0802 - val_accuracy: 0.6026\n",
            "Epoch 840/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8236 - accuracy: 0.6828 - val_loss: 1.0167 - val_accuracy: 0.6282\n",
            "Epoch 841/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8033 - accuracy: 0.6958 - val_loss: 1.1199 - val_accuracy: 0.5128\n",
            "Epoch 842/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8245 - accuracy: 0.7055 - val_loss: 1.0204 - val_accuracy: 0.6026\n",
            "Epoch 843/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8070 - accuracy: 0.7152 - val_loss: 1.0853 - val_accuracy: 0.5897\n",
            "Epoch 844/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8179 - accuracy: 0.6828 - val_loss: 1.1119 - val_accuracy: 0.6282\n",
            "Epoch 845/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8574 - accuracy: 0.6958 - val_loss: 1.0983 - val_accuracy: 0.6154\n",
            "Epoch 846/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8128 - accuracy: 0.6926 - val_loss: 1.1261 - val_accuracy: 0.6154\n",
            "Epoch 847/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8146 - accuracy: 0.7023 - val_loss: 1.0205 - val_accuracy: 0.6154\n",
            "Epoch 848/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7772 - accuracy: 0.7055 - val_loss: 1.0932 - val_accuracy: 0.5641\n",
            "Epoch 849/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8526 - accuracy: 0.6602 - val_loss: 1.0591 - val_accuracy: 0.6026\n",
            "Epoch 850/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8357 - accuracy: 0.6958 - val_loss: 1.0598 - val_accuracy: 0.6410\n",
            "Epoch 851/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8671 - accuracy: 0.6764 - val_loss: 1.0839 - val_accuracy: 0.5513\n",
            "Epoch 852/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8119 - accuracy: 0.6893 - val_loss: 1.0271 - val_accuracy: 0.5897\n",
            "Epoch 853/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8224 - accuracy: 0.6958 - val_loss: 1.0614 - val_accuracy: 0.5769\n",
            "Epoch 854/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8086 - accuracy: 0.6861 - val_loss: 1.0670 - val_accuracy: 0.6154\n",
            "Epoch 855/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8398 - accuracy: 0.6926 - val_loss: 1.0573 - val_accuracy: 0.6282\n",
            "Epoch 856/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8224 - accuracy: 0.7023 - val_loss: 1.0488 - val_accuracy: 0.6154\n",
            "Epoch 857/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7731 - accuracy: 0.7152 - val_loss: 1.1066 - val_accuracy: 0.6282\n",
            "Epoch 858/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8126 - accuracy: 0.6958 - val_loss: 1.1161 - val_accuracy: 0.6026\n",
            "Epoch 859/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7828 - accuracy: 0.7314 - val_loss: 1.0530 - val_accuracy: 0.5897\n",
            "Epoch 860/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7915 - accuracy: 0.7055 - val_loss: 1.0250 - val_accuracy: 0.5897\n",
            "Epoch 861/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7807 - accuracy: 0.7152 - val_loss: 1.0801 - val_accuracy: 0.6026\n",
            "Epoch 862/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8205 - accuracy: 0.6828 - val_loss: 1.0356 - val_accuracy: 0.6026\n",
            "Epoch 863/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8324 - accuracy: 0.6926 - val_loss: 0.9938 - val_accuracy: 0.6282\n",
            "Epoch 864/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8030 - accuracy: 0.6990 - val_loss: 1.0257 - val_accuracy: 0.5769\n",
            "Epoch 865/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8038 - accuracy: 0.6893 - val_loss: 1.0066 - val_accuracy: 0.6026\n",
            "Epoch 866/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8136 - accuracy: 0.6926 - val_loss: 1.0620 - val_accuracy: 0.5641\n",
            "Epoch 867/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8080 - accuracy: 0.6990 - val_loss: 1.0213 - val_accuracy: 0.6154\n",
            "Epoch 868/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7894 - accuracy: 0.7087 - val_loss: 1.0606 - val_accuracy: 0.6538\n",
            "Epoch 869/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8126 - accuracy: 0.6990 - val_loss: 1.0635 - val_accuracy: 0.6282\n",
            "Epoch 870/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8165 - accuracy: 0.7249 - val_loss: 1.0893 - val_accuracy: 0.5897\n",
            "Epoch 871/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8952 - accuracy: 0.6764 - val_loss: 1.0121 - val_accuracy: 0.6282\n",
            "Epoch 872/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7937 - accuracy: 0.7152 - val_loss: 1.0594 - val_accuracy: 0.5769\n",
            "Epoch 873/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7832 - accuracy: 0.7217 - val_loss: 1.0891 - val_accuracy: 0.6026\n",
            "Epoch 874/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8003 - accuracy: 0.6861 - val_loss: 1.0151 - val_accuracy: 0.5897\n",
            "Epoch 875/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7702 - accuracy: 0.7152 - val_loss: 1.0459 - val_accuracy: 0.6026\n",
            "Epoch 876/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8063 - accuracy: 0.6828 - val_loss: 1.0250 - val_accuracy: 0.6026\n",
            "Epoch 877/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8168 - accuracy: 0.7217 - val_loss: 1.0721 - val_accuracy: 0.5769\n",
            "Epoch 878/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8021 - accuracy: 0.7282 - val_loss: 1.0187 - val_accuracy: 0.5897\n",
            "Epoch 879/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7601 - accuracy: 0.7087 - val_loss: 1.1210 - val_accuracy: 0.5897\n",
            "Epoch 880/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7873 - accuracy: 0.7184 - val_loss: 1.0517 - val_accuracy: 0.6154\n",
            "Epoch 881/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7970 - accuracy: 0.7055 - val_loss: 1.0728 - val_accuracy: 0.6026\n",
            "Epoch 882/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7916 - accuracy: 0.6861 - val_loss: 1.1774 - val_accuracy: 0.5769\n",
            "Epoch 883/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8671 - accuracy: 0.6764 - val_loss: 1.2611 - val_accuracy: 0.5769\n",
            "Epoch 884/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8699 - accuracy: 0.6699 - val_loss: 1.1806 - val_accuracy: 0.5897\n",
            "Epoch 885/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.8813 - accuracy: 0.6958 - val_loss: 1.0995 - val_accuracy: 0.6026\n",
            "Epoch 886/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8072 - accuracy: 0.7087 - val_loss: 1.0125 - val_accuracy: 0.6026\n",
            "Epoch 887/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7832 - accuracy: 0.7249 - val_loss: 1.0437 - val_accuracy: 0.6154\n",
            "Epoch 888/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8130 - accuracy: 0.6926 - val_loss: 1.1135 - val_accuracy: 0.6154\n",
            "Epoch 889/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8638 - accuracy: 0.6796 - val_loss: 1.1579 - val_accuracy: 0.5769\n",
            "Epoch 890/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8616 - accuracy: 0.6667 - val_loss: 1.0181 - val_accuracy: 0.6410\n",
            "Epoch 891/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8356 - accuracy: 0.7055 - val_loss: 1.0172 - val_accuracy: 0.5897\n",
            "Epoch 892/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8161 - accuracy: 0.7087 - val_loss: 0.9998 - val_accuracy: 0.6026\n",
            "Epoch 893/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7636 - accuracy: 0.7120 - val_loss: 1.0370 - val_accuracy: 0.6282\n",
            "Epoch 894/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7660 - accuracy: 0.7217 - val_loss: 0.9978 - val_accuracy: 0.6538\n",
            "Epoch 895/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8394 - accuracy: 0.6796 - val_loss: 1.0592 - val_accuracy: 0.6026\n",
            "Epoch 896/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8047 - accuracy: 0.7055 - val_loss: 1.0242 - val_accuracy: 0.6667\n",
            "Epoch 897/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7920 - accuracy: 0.7023 - val_loss: 1.0579 - val_accuracy: 0.6154\n",
            "Epoch 898/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7840 - accuracy: 0.7087 - val_loss: 1.0986 - val_accuracy: 0.6154\n",
            "Epoch 899/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8526 - accuracy: 0.6958 - val_loss: 1.0812 - val_accuracy: 0.6282\n",
            "Epoch 900/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8363 - accuracy: 0.6764 - val_loss: 1.0891 - val_accuracy: 0.5769\n",
            "Epoch 901/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8161 - accuracy: 0.6926 - val_loss: 1.0235 - val_accuracy: 0.5769\n",
            "Epoch 902/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7920 - accuracy: 0.6990 - val_loss: 1.0370 - val_accuracy: 0.6026\n",
            "Epoch 903/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7718 - accuracy: 0.7249 - val_loss: 1.1533 - val_accuracy: 0.5769\n",
            "Epoch 904/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8341 - accuracy: 0.6796 - val_loss: 1.0313 - val_accuracy: 0.5897\n",
            "Epoch 905/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7852 - accuracy: 0.7120 - val_loss: 1.0761 - val_accuracy: 0.6154\n",
            "Epoch 906/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7555 - accuracy: 0.7282 - val_loss: 1.0471 - val_accuracy: 0.5897\n",
            "Epoch 907/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7732 - accuracy: 0.7314 - val_loss: 1.0337 - val_accuracy: 0.6282\n",
            "Epoch 908/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8499 - accuracy: 0.6764 - val_loss: 1.0650 - val_accuracy: 0.5897\n",
            "Epoch 909/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8053 - accuracy: 0.6861 - val_loss: 1.0168 - val_accuracy: 0.6026\n",
            "Epoch 910/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8010 - accuracy: 0.7152 - val_loss: 1.0148 - val_accuracy: 0.6026\n",
            "Epoch 911/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7603 - accuracy: 0.7282 - val_loss: 1.0016 - val_accuracy: 0.6282\n",
            "Epoch 912/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8066 - accuracy: 0.6990 - val_loss: 1.0247 - val_accuracy: 0.6154\n",
            "Epoch 913/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8077 - accuracy: 0.7087 - val_loss: 1.0897 - val_accuracy: 0.6026\n",
            "Epoch 914/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8079 - accuracy: 0.7120 - val_loss: 1.0166 - val_accuracy: 0.5897\n",
            "Epoch 915/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7808 - accuracy: 0.7023 - val_loss: 1.1120 - val_accuracy: 0.5897\n",
            "Epoch 916/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7763 - accuracy: 0.6796 - val_loss: 1.0767 - val_accuracy: 0.6026\n",
            "Epoch 917/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8274 - accuracy: 0.6926 - val_loss: 1.1292 - val_accuracy: 0.6154\n",
            "Epoch 918/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9202 - accuracy: 0.6440 - val_loss: 1.2420 - val_accuracy: 0.5385\n",
            "Epoch 919/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9163 - accuracy: 0.6764 - val_loss: 1.3043 - val_accuracy: 0.5513\n",
            "Epoch 920/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9037 - accuracy: 0.6828 - val_loss: 1.1434 - val_accuracy: 0.6026\n",
            "Epoch 921/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9216 - accuracy: 0.6893 - val_loss: 1.1221 - val_accuracy: 0.6026\n",
            "Epoch 922/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8855 - accuracy: 0.6634 - val_loss: 1.1023 - val_accuracy: 0.6026\n",
            "Epoch 923/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8699 - accuracy: 0.6958 - val_loss: 0.9975 - val_accuracy: 0.6026\n",
            "Epoch 924/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8145 - accuracy: 0.6990 - val_loss: 1.0349 - val_accuracy: 0.5769\n",
            "Epoch 925/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7797 - accuracy: 0.6926 - val_loss: 1.0668 - val_accuracy: 0.5897\n",
            "Epoch 926/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7635 - accuracy: 0.7184 - val_loss: 1.0474 - val_accuracy: 0.6410\n",
            "Epoch 927/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7855 - accuracy: 0.7055 - val_loss: 1.0530 - val_accuracy: 0.5897\n",
            "Epoch 928/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7179 - accuracy: 0.7346 - val_loss: 0.9978 - val_accuracy: 0.6154\n",
            "Epoch 929/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7628 - accuracy: 0.7217 - val_loss: 1.0507 - val_accuracy: 0.6026\n",
            "Epoch 930/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7885 - accuracy: 0.7023 - val_loss: 1.0388 - val_accuracy: 0.6282\n",
            "Epoch 931/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7951 - accuracy: 0.7152 - val_loss: 1.0123 - val_accuracy: 0.6154\n",
            "Epoch 932/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7729 - accuracy: 0.7152 - val_loss: 1.0214 - val_accuracy: 0.5641\n",
            "Epoch 933/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7690 - accuracy: 0.7087 - val_loss: 1.0357 - val_accuracy: 0.6154\n",
            "Epoch 934/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7977 - accuracy: 0.7217 - val_loss: 1.0781 - val_accuracy: 0.6154\n",
            "Epoch 935/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7619 - accuracy: 0.7120 - val_loss: 1.0666 - val_accuracy: 0.6026\n",
            "Epoch 936/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7667 - accuracy: 0.7055 - val_loss: 1.0748 - val_accuracy: 0.6410\n",
            "Epoch 937/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8183 - accuracy: 0.7023 - val_loss: 1.0775 - val_accuracy: 0.5897\n",
            "Epoch 938/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7684 - accuracy: 0.7055 - val_loss: 1.0581 - val_accuracy: 0.6026\n",
            "Epoch 939/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8031 - accuracy: 0.6958 - val_loss: 1.0497 - val_accuracy: 0.5769\n",
            "Epoch 940/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7418 - accuracy: 0.7184 - val_loss: 1.0533 - val_accuracy: 0.6154\n",
            "Epoch 941/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7702 - accuracy: 0.7087 - val_loss: 1.0062 - val_accuracy: 0.6026\n",
            "Epoch 942/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7767 - accuracy: 0.7249 - val_loss: 1.0223 - val_accuracy: 0.6026\n",
            "Epoch 943/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7584 - accuracy: 0.7152 - val_loss: 1.0369 - val_accuracy: 0.6154\n",
            "Epoch 944/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8101 - accuracy: 0.6861 - val_loss: 1.0522 - val_accuracy: 0.5897\n",
            "Epoch 945/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7989 - accuracy: 0.7055 - val_loss: 1.0104 - val_accuracy: 0.6154\n",
            "Epoch 946/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7723 - accuracy: 0.7120 - val_loss: 1.0203 - val_accuracy: 0.6154\n",
            "Epoch 947/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7684 - accuracy: 0.7152 - val_loss: 1.0488 - val_accuracy: 0.6282\n",
            "Epoch 948/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7614 - accuracy: 0.7314 - val_loss: 1.0171 - val_accuracy: 0.6282\n",
            "Epoch 949/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7559 - accuracy: 0.7282 - val_loss: 1.0784 - val_accuracy: 0.6026\n",
            "Epoch 950/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7473 - accuracy: 0.7184 - val_loss: 1.0057 - val_accuracy: 0.6538\n",
            "Epoch 951/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7304 - accuracy: 0.7055 - val_loss: 1.0830 - val_accuracy: 0.5769\n",
            "Epoch 952/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7778 - accuracy: 0.7120 - val_loss: 1.0129 - val_accuracy: 0.5897\n",
            "Epoch 953/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7684 - accuracy: 0.7120 - val_loss: 1.0043 - val_accuracy: 0.5897\n",
            "Epoch 954/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7674 - accuracy: 0.6990 - val_loss: 1.0183 - val_accuracy: 0.6026\n",
            "Epoch 955/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7859 - accuracy: 0.7217 - val_loss: 1.0343 - val_accuracy: 0.6026\n",
            "Epoch 956/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8081 - accuracy: 0.6893 - val_loss: 1.0027 - val_accuracy: 0.6026\n",
            "Epoch 957/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7647 - accuracy: 0.7055 - val_loss: 1.0153 - val_accuracy: 0.6282\n",
            "Epoch 958/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7753 - accuracy: 0.6926 - val_loss: 1.1825 - val_accuracy: 0.5256\n",
            "Epoch 959/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8340 - accuracy: 0.7055 - val_loss: 1.0329 - val_accuracy: 0.6410\n",
            "Epoch 960/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8245 - accuracy: 0.6893 - val_loss: 1.0859 - val_accuracy: 0.6282\n",
            "Epoch 961/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8250 - accuracy: 0.7023 - val_loss: 1.1234 - val_accuracy: 0.5897\n",
            "Epoch 962/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7491 - accuracy: 0.7249 - val_loss: 1.0020 - val_accuracy: 0.6410\n",
            "Epoch 963/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7982 - accuracy: 0.6990 - val_loss: 1.0607 - val_accuracy: 0.6154\n",
            "Epoch 964/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8480 - accuracy: 0.6796 - val_loss: 1.0411 - val_accuracy: 0.6154\n",
            "Epoch 965/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8906 - accuracy: 0.6634 - val_loss: 1.1990 - val_accuracy: 0.5897\n",
            "Epoch 966/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7848 - accuracy: 0.6893 - val_loss: 1.0371 - val_accuracy: 0.6026\n",
            "Epoch 967/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7740 - accuracy: 0.7282 - val_loss: 1.1725 - val_accuracy: 0.6026\n",
            "Epoch 968/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8290 - accuracy: 0.7023 - val_loss: 1.0856 - val_accuracy: 0.6154\n",
            "Epoch 969/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8549 - accuracy: 0.6699 - val_loss: 1.0458 - val_accuracy: 0.6154\n",
            "Epoch 970/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7820 - accuracy: 0.7282 - val_loss: 1.0895 - val_accuracy: 0.6282\n",
            "Epoch 971/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7977 - accuracy: 0.6893 - val_loss: 1.0105 - val_accuracy: 0.6410\n",
            "Epoch 972/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7476 - accuracy: 0.7282 - val_loss: 1.0347 - val_accuracy: 0.6154\n",
            "Epoch 973/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7905 - accuracy: 0.7023 - val_loss: 0.9979 - val_accuracy: 0.6410\n",
            "Epoch 974/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7624 - accuracy: 0.7023 - val_loss: 1.0171 - val_accuracy: 0.6410\n",
            "Epoch 975/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7713 - accuracy: 0.6926 - val_loss: 1.0156 - val_accuracy: 0.6410\n",
            "Epoch 976/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7447 - accuracy: 0.7217 - val_loss: 1.0453 - val_accuracy: 0.5897\n",
            "Epoch 977/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7904 - accuracy: 0.7055 - val_loss: 1.0624 - val_accuracy: 0.6282\n",
            "Epoch 978/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7782 - accuracy: 0.6926 - val_loss: 1.0010 - val_accuracy: 0.6026\n",
            "Epoch 979/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7482 - accuracy: 0.7120 - val_loss: 0.9855 - val_accuracy: 0.6282\n",
            "Epoch 980/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.7837 - accuracy: 0.7282 - val_loss: 1.1873 - val_accuracy: 0.5256\n",
            "Epoch 981/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7889 - accuracy: 0.6990 - val_loss: 0.9925 - val_accuracy: 0.6154\n",
            "Epoch 982/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7759 - accuracy: 0.6893 - val_loss: 0.9974 - val_accuracy: 0.6154\n",
            "Epoch 983/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7392 - accuracy: 0.7152 - val_loss: 1.1497 - val_accuracy: 0.5897\n",
            "Epoch 984/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7443 - accuracy: 0.7508 - val_loss: 1.0111 - val_accuracy: 0.6026\n",
            "Epoch 985/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7661 - accuracy: 0.7217 - val_loss: 1.1175 - val_accuracy: 0.5897\n",
            "Epoch 986/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7570 - accuracy: 0.7152 - val_loss: 1.0333 - val_accuracy: 0.6538\n",
            "Epoch 987/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7764 - accuracy: 0.7055 - val_loss: 1.0083 - val_accuracy: 0.6538\n",
            "Epoch 988/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7791 - accuracy: 0.7120 - val_loss: 1.0111 - val_accuracy: 0.5769\n",
            "Epoch 989/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7646 - accuracy: 0.7282 - val_loss: 1.0291 - val_accuracy: 0.6282\n",
            "Epoch 990/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7684 - accuracy: 0.7282 - val_loss: 1.0390 - val_accuracy: 0.6154\n",
            "Epoch 991/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7617 - accuracy: 0.7152 - val_loss: 1.0586 - val_accuracy: 0.5897\n",
            "Epoch 992/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7491 - accuracy: 0.7184 - val_loss: 0.9986 - val_accuracy: 0.6538\n",
            "Epoch 993/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7673 - accuracy: 0.7184 - val_loss: 0.9971 - val_accuracy: 0.6410\n",
            "Epoch 994/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7390 - accuracy: 0.7217 - val_loss: 1.0056 - val_accuracy: 0.6538\n",
            "Epoch 995/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7339 - accuracy: 0.7282 - val_loss: 1.0788 - val_accuracy: 0.6154\n",
            "Epoch 996/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7263 - accuracy: 0.7443 - val_loss: 1.1763 - val_accuracy: 0.6026\n",
            "Epoch 997/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7964 - accuracy: 0.6990 - val_loss: 1.2572 - val_accuracy: 0.5769\n",
            "Epoch 998/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8722 - accuracy: 0.6893 - val_loss: 1.0541 - val_accuracy: 0.6154\n",
            "Epoch 999/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7624 - accuracy: 0.7282 - val_loss: 1.0531 - val_accuracy: 0.6154\n",
            "Epoch 1000/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7652 - accuracy: 0.7087 - val_loss: 1.1801 - val_accuracy: 0.5769\n",
            "Epoch 1001/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7617 - accuracy: 0.7249 - val_loss: 1.0148 - val_accuracy: 0.6410\n",
            "Epoch 1002/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7275 - accuracy: 0.7314 - val_loss: 1.1133 - val_accuracy: 0.6026\n",
            "Epoch 1003/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7286 - accuracy: 0.7282 - val_loss: 1.0015 - val_accuracy: 0.6282\n",
            "Epoch 1004/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7694 - accuracy: 0.7055 - val_loss: 1.0226 - val_accuracy: 0.6538\n",
            "Epoch 1005/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8817 - accuracy: 0.6537 - val_loss: 1.0533 - val_accuracy: 0.6026\n",
            "Epoch 1006/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7738 - accuracy: 0.7120 - val_loss: 1.1121 - val_accuracy: 0.6154\n",
            "Epoch 1007/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7610 - accuracy: 0.6990 - val_loss: 1.0200 - val_accuracy: 0.6410\n",
            "Epoch 1008/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7420 - accuracy: 0.7217 - val_loss: 1.0470 - val_accuracy: 0.6154\n",
            "Epoch 1009/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7967 - accuracy: 0.7249 - val_loss: 0.9820 - val_accuracy: 0.6410\n",
            "Epoch 1010/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7377 - accuracy: 0.7249 - val_loss: 1.0149 - val_accuracy: 0.6026\n",
            "Epoch 1011/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8026 - accuracy: 0.7023 - val_loss: 0.9999 - val_accuracy: 0.6154\n",
            "Epoch 1012/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7428 - accuracy: 0.7314 - val_loss: 1.0081 - val_accuracy: 0.6795\n",
            "Epoch 1013/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7514 - accuracy: 0.6990 - val_loss: 1.0247 - val_accuracy: 0.6795\n",
            "Epoch 1014/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7495 - accuracy: 0.7249 - val_loss: 1.0038 - val_accuracy: 0.6538\n",
            "Epoch 1015/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7466 - accuracy: 0.7120 - val_loss: 0.9952 - val_accuracy: 0.6154\n",
            "Epoch 1016/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7220 - accuracy: 0.7314 - val_loss: 0.9868 - val_accuracy: 0.6282\n",
            "Epoch 1017/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7639 - accuracy: 0.7184 - val_loss: 1.0676 - val_accuracy: 0.5769\n",
            "Epoch 1018/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7530 - accuracy: 0.7055 - val_loss: 1.0146 - val_accuracy: 0.6667\n",
            "Epoch 1019/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7231 - accuracy: 0.7055 - val_loss: 1.0300 - val_accuracy: 0.6667\n",
            "Epoch 1020/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7117 - accuracy: 0.7476 - val_loss: 1.0439 - val_accuracy: 0.6410\n",
            "Epoch 1021/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7305 - accuracy: 0.7314 - val_loss: 1.0648 - val_accuracy: 0.6154\n",
            "Epoch 1022/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7963 - accuracy: 0.6926 - val_loss: 1.2277 - val_accuracy: 0.5769\n",
            "Epoch 1023/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7853 - accuracy: 0.6926 - val_loss: 1.0555 - val_accuracy: 0.6154\n",
            "Epoch 1024/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7553 - accuracy: 0.6926 - val_loss: 1.1001 - val_accuracy: 0.5769\n",
            "Epoch 1025/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7492 - accuracy: 0.7152 - val_loss: 1.0600 - val_accuracy: 0.6154\n",
            "Epoch 1026/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7094 - accuracy: 0.7379 - val_loss: 1.0621 - val_accuracy: 0.6154\n",
            "Epoch 1027/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7338 - accuracy: 0.7346 - val_loss: 1.0628 - val_accuracy: 0.6282\n",
            "Epoch 1028/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7328 - accuracy: 0.7411 - val_loss: 1.0319 - val_accuracy: 0.6795\n",
            "Epoch 1029/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7354 - accuracy: 0.7217 - val_loss: 1.0526 - val_accuracy: 0.6154\n",
            "Epoch 1030/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7384 - accuracy: 0.7152 - val_loss: 0.9957 - val_accuracy: 0.6410\n",
            "Epoch 1031/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7674 - accuracy: 0.7055 - val_loss: 1.1188 - val_accuracy: 0.6154\n",
            "Epoch 1032/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8614 - accuracy: 0.6796 - val_loss: 1.0136 - val_accuracy: 0.6410\n",
            "Epoch 1033/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8709 - accuracy: 0.6570 - val_loss: 1.0111 - val_accuracy: 0.6154\n",
            "Epoch 1034/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7637 - accuracy: 0.7120 - val_loss: 0.9954 - val_accuracy: 0.6026\n",
            "Epoch 1035/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7296 - accuracy: 0.7152 - val_loss: 1.0134 - val_accuracy: 0.6154\n",
            "Epoch 1036/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7363 - accuracy: 0.7152 - val_loss: 1.0221 - val_accuracy: 0.6538\n",
            "Epoch 1037/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7537 - accuracy: 0.7314 - val_loss: 1.0403 - val_accuracy: 0.6282\n",
            "Epoch 1038/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7454 - accuracy: 0.7120 - val_loss: 0.9740 - val_accuracy: 0.6538\n",
            "Epoch 1039/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7340 - accuracy: 0.7282 - val_loss: 0.9899 - val_accuracy: 0.6026\n",
            "Epoch 1040/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7569 - accuracy: 0.6990 - val_loss: 0.9827 - val_accuracy: 0.6026\n",
            "Epoch 1041/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7458 - accuracy: 0.7314 - val_loss: 1.0032 - val_accuracy: 0.5897\n",
            "Epoch 1042/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7349 - accuracy: 0.7282 - val_loss: 1.0459 - val_accuracy: 0.6410\n",
            "Epoch 1043/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7598 - accuracy: 0.7379 - val_loss: 1.1239 - val_accuracy: 0.6026\n",
            "Epoch 1044/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7856 - accuracy: 0.7120 - val_loss: 1.0838 - val_accuracy: 0.6538\n",
            "Epoch 1045/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7904 - accuracy: 0.6958 - val_loss: 1.0332 - val_accuracy: 0.6410\n",
            "Epoch 1046/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8014 - accuracy: 0.7087 - val_loss: 1.0820 - val_accuracy: 0.6026\n",
            "Epoch 1047/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8025 - accuracy: 0.6926 - val_loss: 1.0015 - val_accuracy: 0.6282\n",
            "Epoch 1048/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7592 - accuracy: 0.7411 - val_loss: 1.0141 - val_accuracy: 0.5897\n",
            "Epoch 1049/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7913 - accuracy: 0.6796 - val_loss: 1.0125 - val_accuracy: 0.6282\n",
            "Epoch 1050/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7949 - accuracy: 0.7152 - val_loss: 0.9685 - val_accuracy: 0.6410\n",
            "Epoch 1051/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7533 - accuracy: 0.7152 - val_loss: 1.0425 - val_accuracy: 0.5897\n",
            "Epoch 1052/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7443 - accuracy: 0.7217 - val_loss: 1.0595 - val_accuracy: 0.6410\n",
            "Epoch 1053/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7573 - accuracy: 0.7184 - val_loss: 1.2090 - val_accuracy: 0.5897\n",
            "Epoch 1054/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8356 - accuracy: 0.7087 - val_loss: 1.0502 - val_accuracy: 0.6154\n",
            "Epoch 1055/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7792 - accuracy: 0.6990 - val_loss: 1.0768 - val_accuracy: 0.6026\n",
            "Epoch 1056/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7999 - accuracy: 0.7055 - val_loss: 1.0864 - val_accuracy: 0.5769\n",
            "Epoch 1057/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7526 - accuracy: 0.7282 - val_loss: 0.9904 - val_accuracy: 0.6410\n",
            "Epoch 1058/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7423 - accuracy: 0.7346 - val_loss: 1.1004 - val_accuracy: 0.6026\n",
            "Epoch 1059/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7622 - accuracy: 0.7217 - val_loss: 1.0511 - val_accuracy: 0.6410\n",
            "Epoch 1060/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7586 - accuracy: 0.7120 - val_loss: 1.2345 - val_accuracy: 0.5385\n",
            "Epoch 1061/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7472 - accuracy: 0.7184 - val_loss: 1.0521 - val_accuracy: 0.6282\n",
            "Epoch 1062/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8035 - accuracy: 0.6926 - val_loss: 0.9907 - val_accuracy: 0.6410\n",
            "Epoch 1063/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7529 - accuracy: 0.7120 - val_loss: 1.0423 - val_accuracy: 0.6154\n",
            "Epoch 1064/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7671 - accuracy: 0.7282 - val_loss: 0.9838 - val_accuracy: 0.6282\n",
            "Epoch 1065/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7634 - accuracy: 0.6828 - val_loss: 1.0436 - val_accuracy: 0.6410\n",
            "Epoch 1066/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7678 - accuracy: 0.7249 - val_loss: 1.0085 - val_accuracy: 0.6154\n",
            "Epoch 1067/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7556 - accuracy: 0.7120 - val_loss: 1.1346 - val_accuracy: 0.6026\n",
            "Epoch 1068/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7881 - accuracy: 0.6958 - val_loss: 1.0285 - val_accuracy: 0.6410\n",
            "Epoch 1069/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7486 - accuracy: 0.7120 - val_loss: 1.0059 - val_accuracy: 0.6410\n",
            "Epoch 1070/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7478 - accuracy: 0.7282 - val_loss: 1.0322 - val_accuracy: 0.6410\n",
            "Epoch 1071/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7068 - accuracy: 0.7540 - val_loss: 1.0016 - val_accuracy: 0.6538\n",
            "Epoch 1072/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7321 - accuracy: 0.7152 - val_loss: 1.0465 - val_accuracy: 0.5641\n",
            "Epoch 1073/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7618 - accuracy: 0.7249 - val_loss: 0.9996 - val_accuracy: 0.5769\n",
            "Epoch 1074/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7524 - accuracy: 0.7346 - val_loss: 1.0054 - val_accuracy: 0.6410\n",
            "Epoch 1075/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7620 - accuracy: 0.7023 - val_loss: 1.0695 - val_accuracy: 0.6154\n",
            "Epoch 1076/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.8141 - accuracy: 0.6926 - val_loss: 1.2299 - val_accuracy: 0.5769\n",
            "Epoch 1077/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7894 - accuracy: 0.6796 - val_loss: 1.1490 - val_accuracy: 0.6154\n",
            "Epoch 1078/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7568 - accuracy: 0.7087 - val_loss: 1.1967 - val_accuracy: 0.6154\n",
            "Epoch 1079/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.7494 - accuracy: 0.7055 - val_loss: 1.0602 - val_accuracy: 0.6154\n",
            "Epoch 1080/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7585 - accuracy: 0.7379 - val_loss: 1.0005 - val_accuracy: 0.6026\n",
            "Epoch 1081/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7802 - accuracy: 0.7023 - val_loss: 1.0211 - val_accuracy: 0.6154\n",
            "Epoch 1082/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7110 - accuracy: 0.7249 - val_loss: 1.0124 - val_accuracy: 0.6667\n",
            "Epoch 1083/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7146 - accuracy: 0.7411 - val_loss: 1.0834 - val_accuracy: 0.5897\n",
            "Epoch 1084/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7224 - accuracy: 0.7411 - val_loss: 0.9875 - val_accuracy: 0.6282\n",
            "Epoch 1085/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7138 - accuracy: 0.7184 - val_loss: 0.9776 - val_accuracy: 0.6154\n",
            "Epoch 1086/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7442 - accuracy: 0.7249 - val_loss: 1.0203 - val_accuracy: 0.6282\n",
            "Epoch 1087/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7377 - accuracy: 0.7087 - val_loss: 0.9961 - val_accuracy: 0.6538\n",
            "Epoch 1088/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7304 - accuracy: 0.7152 - val_loss: 1.0327 - val_accuracy: 0.6154\n",
            "Epoch 1089/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7169 - accuracy: 0.7476 - val_loss: 1.0214 - val_accuracy: 0.6154\n",
            "Epoch 1090/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7456 - accuracy: 0.7346 - val_loss: 1.1849 - val_accuracy: 0.6154\n",
            "Epoch 1091/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7069 - accuracy: 0.7476 - val_loss: 1.0468 - val_accuracy: 0.6026\n",
            "Epoch 1092/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7501 - accuracy: 0.7055 - val_loss: 1.0763 - val_accuracy: 0.6282\n",
            "Epoch 1093/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7359 - accuracy: 0.7055 - val_loss: 0.9813 - val_accuracy: 0.6410\n",
            "Epoch 1094/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7090 - accuracy: 0.7508 - val_loss: 0.9760 - val_accuracy: 0.6282\n",
            "Epoch 1095/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7130 - accuracy: 0.7540 - val_loss: 0.9944 - val_accuracy: 0.6154\n",
            "Epoch 1096/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7386 - accuracy: 0.7346 - val_loss: 1.0398 - val_accuracy: 0.6154\n",
            "Epoch 1097/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7195 - accuracy: 0.7346 - val_loss: 0.9857 - val_accuracy: 0.6538\n",
            "Epoch 1098/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7374 - accuracy: 0.7249 - val_loss: 1.0293 - val_accuracy: 0.6154\n",
            "Epoch 1099/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7329 - accuracy: 0.7411 - val_loss: 1.0300 - val_accuracy: 0.6026\n",
            "Epoch 1100/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7161 - accuracy: 0.7379 - val_loss: 0.9832 - val_accuracy: 0.6410\n",
            "Epoch 1101/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7700 - accuracy: 0.6990 - val_loss: 1.0504 - val_accuracy: 0.5897\n",
            "Epoch 1102/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7546 - accuracy: 0.7152 - val_loss: 0.9930 - val_accuracy: 0.6154\n",
            "Epoch 1103/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7335 - accuracy: 0.7379 - val_loss: 0.9690 - val_accuracy: 0.6667\n",
            "Epoch 1104/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7257 - accuracy: 0.7249 - val_loss: 0.9981 - val_accuracy: 0.6154\n",
            "Epoch 1105/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6967 - accuracy: 0.7476 - val_loss: 1.0328 - val_accuracy: 0.6410\n",
            "Epoch 1106/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7505 - accuracy: 0.7346 - val_loss: 0.9919 - val_accuracy: 0.6026\n",
            "Epoch 1107/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.7309 - accuracy: 0.7249 - val_loss: 0.9846 - val_accuracy: 0.6282\n",
            "Epoch 1108/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7226 - accuracy: 0.7508 - val_loss: 0.9966 - val_accuracy: 0.6538\n",
            "Epoch 1109/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7027 - accuracy: 0.7184 - val_loss: 1.0888 - val_accuracy: 0.6154\n",
            "Epoch 1110/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.7675 - accuracy: 0.7087 - val_loss: 1.0142 - val_accuracy: 0.6795\n",
            "Epoch 1111/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6957 - accuracy: 0.7508 - val_loss: 1.0416 - val_accuracy: 0.6410\n",
            "Epoch 1112/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.7365 - accuracy: 0.7217 - val_loss: 0.9894 - val_accuracy: 0.6026\n",
            "Epoch 1113/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6991 - accuracy: 0.7346 - val_loss: 0.9648 - val_accuracy: 0.6667\n",
            "Epoch 1114/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7363 - accuracy: 0.7314 - val_loss: 1.0727 - val_accuracy: 0.5897\n",
            "Epoch 1115/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7162 - accuracy: 0.7217 - val_loss: 0.9831 - val_accuracy: 0.6538\n",
            "Epoch 1116/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7398 - accuracy: 0.7217 - val_loss: 0.9921 - val_accuracy: 0.6410\n",
            "Epoch 1117/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7046 - accuracy: 0.7249 - val_loss: 1.0668 - val_accuracy: 0.6282\n",
            "Epoch 1118/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7002 - accuracy: 0.7314 - val_loss: 0.9641 - val_accuracy: 0.6538\n",
            "Epoch 1119/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7499 - accuracy: 0.7379 - val_loss: 0.9650 - val_accuracy: 0.6410\n",
            "Epoch 1120/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7135 - accuracy: 0.7411 - val_loss: 1.0440 - val_accuracy: 0.5897\n",
            "Epoch 1121/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7327 - accuracy: 0.7184 - val_loss: 0.9994 - val_accuracy: 0.6410\n",
            "Epoch 1122/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7593 - accuracy: 0.7152 - val_loss: 0.9708 - val_accuracy: 0.6795\n",
            "Epoch 1123/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7159 - accuracy: 0.7249 - val_loss: 1.0286 - val_accuracy: 0.6026\n",
            "Epoch 1124/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7195 - accuracy: 0.7282 - val_loss: 1.0297 - val_accuracy: 0.6410\n",
            "Epoch 1125/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7218 - accuracy: 0.7282 - val_loss: 1.0694 - val_accuracy: 0.5897\n",
            "Epoch 1126/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7318 - accuracy: 0.7249 - val_loss: 1.0052 - val_accuracy: 0.6154\n",
            "Epoch 1127/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7139 - accuracy: 0.7152 - val_loss: 1.1201 - val_accuracy: 0.6026\n",
            "Epoch 1128/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7496 - accuracy: 0.7217 - val_loss: 0.9746 - val_accuracy: 0.6667\n",
            "Epoch 1129/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7276 - accuracy: 0.7282 - val_loss: 1.0182 - val_accuracy: 0.6154\n",
            "Epoch 1130/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7513 - accuracy: 0.7282 - val_loss: 1.0108 - val_accuracy: 0.6410\n",
            "Epoch 1131/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7731 - accuracy: 0.6990 - val_loss: 1.0338 - val_accuracy: 0.6410\n",
            "Epoch 1132/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8479 - accuracy: 0.7023 - val_loss: 0.9694 - val_accuracy: 0.6410\n",
            "Epoch 1133/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7767 - accuracy: 0.7023 - val_loss: 1.0211 - val_accuracy: 0.6282\n",
            "Epoch 1134/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7659 - accuracy: 0.7282 - val_loss: 1.0028 - val_accuracy: 0.5897\n",
            "Epoch 1135/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.7217 - accuracy: 0.6990 - val_loss: 1.0115 - val_accuracy: 0.6282\n",
            "Epoch 1136/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.7329 - accuracy: 0.7249 - val_loss: 0.9927 - val_accuracy: 0.6538\n",
            "Epoch 1137/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7088 - accuracy: 0.7346 - val_loss: 1.0317 - val_accuracy: 0.6538\n",
            "Epoch 1138/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7380 - accuracy: 0.7120 - val_loss: 1.0346 - val_accuracy: 0.6154\n",
            "Epoch 1139/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6936 - accuracy: 0.7314 - val_loss: 0.9572 - val_accuracy: 0.6795\n",
            "Epoch 1140/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7135 - accuracy: 0.7282 - val_loss: 0.9896 - val_accuracy: 0.6538\n",
            "Epoch 1141/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7310 - accuracy: 0.7152 - val_loss: 1.0544 - val_accuracy: 0.6154\n",
            "Epoch 1142/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6853 - accuracy: 0.7346 - val_loss: 0.9649 - val_accuracy: 0.6538\n",
            "Epoch 1143/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7093 - accuracy: 0.7411 - val_loss: 1.0237 - val_accuracy: 0.5897\n",
            "Epoch 1144/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7749 - accuracy: 0.7249 - val_loss: 0.9904 - val_accuracy: 0.6538\n",
            "Epoch 1145/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7106 - accuracy: 0.7411 - val_loss: 1.0029 - val_accuracy: 0.6538\n",
            "Epoch 1146/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7116 - accuracy: 0.7443 - val_loss: 0.9978 - val_accuracy: 0.6410\n",
            "Epoch 1147/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7269 - accuracy: 0.7184 - val_loss: 1.0038 - val_accuracy: 0.6538\n",
            "Epoch 1148/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.7438 - accuracy: 0.7120 - val_loss: 0.9756 - val_accuracy: 0.6667\n",
            "Epoch 1149/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6945 - accuracy: 0.7540 - val_loss: 0.9991 - val_accuracy: 0.6410\n",
            "Epoch 1150/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6904 - accuracy: 0.7476 - val_loss: 0.9922 - val_accuracy: 0.6410\n",
            "Epoch 1151/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7333 - accuracy: 0.7120 - val_loss: 1.0260 - val_accuracy: 0.6154\n",
            "Epoch 1152/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.7315 - accuracy: 0.7411 - val_loss: 1.0094 - val_accuracy: 0.6538\n",
            "Epoch 1153/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7403 - accuracy: 0.7087 - val_loss: 0.9860 - val_accuracy: 0.6538\n",
            "Epoch 1154/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7976 - accuracy: 0.6926 - val_loss: 0.9825 - val_accuracy: 0.6282\n",
            "Epoch 1155/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7010 - accuracy: 0.7443 - val_loss: 0.9821 - val_accuracy: 0.6410\n",
            "Epoch 1156/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7073 - accuracy: 0.7346 - val_loss: 0.9607 - val_accuracy: 0.6795\n",
            "Epoch 1157/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7363 - accuracy: 0.6990 - val_loss: 1.0507 - val_accuracy: 0.6154\n",
            "Epoch 1158/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.7411 - val_loss: 1.0628 - val_accuracy: 0.6154\n",
            "Epoch 1159/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7569 - accuracy: 0.7087 - val_loss: 1.1796 - val_accuracy: 0.6026\n",
            "Epoch 1160/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7196 - accuracy: 0.7249 - val_loss: 1.0702 - val_accuracy: 0.5897\n",
            "Epoch 1161/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6794 - accuracy: 0.7282 - val_loss: 0.9647 - val_accuracy: 0.6667\n",
            "Epoch 1162/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6872 - accuracy: 0.7411 - val_loss: 1.0324 - val_accuracy: 0.6154\n",
            "Epoch 1163/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.7435 - accuracy: 0.7443 - val_loss: 0.9562 - val_accuracy: 0.6410\n",
            "Epoch 1164/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6974 - accuracy: 0.7249 - val_loss: 1.0059 - val_accuracy: 0.6410\n",
            "Epoch 1165/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.6987 - accuracy: 0.7184 - val_loss: 1.0576 - val_accuracy: 0.6154\n",
            "Epoch 1166/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7104 - accuracy: 0.7379 - val_loss: 0.9638 - val_accuracy: 0.7051\n",
            "Epoch 1167/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8108 - accuracy: 0.7023 - val_loss: 1.0351 - val_accuracy: 0.6154\n",
            "Epoch 1168/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.8262 - accuracy: 0.7087 - val_loss: 1.0132 - val_accuracy: 0.6667\n",
            "Epoch 1169/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7496 - accuracy: 0.6990 - val_loss: 1.0413 - val_accuracy: 0.6795\n",
            "Epoch 1170/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7434 - accuracy: 0.7249 - val_loss: 1.0079 - val_accuracy: 0.6410\n",
            "Epoch 1171/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7060 - accuracy: 0.7605 - val_loss: 1.0082 - val_accuracy: 0.6410\n",
            "Epoch 1172/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6889 - accuracy: 0.7443 - val_loss: 0.9804 - val_accuracy: 0.6282\n",
            "Epoch 1173/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6998 - accuracy: 0.7346 - val_loss: 0.9918 - val_accuracy: 0.6410\n",
            "Epoch 1174/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6747 - accuracy: 0.7540 - val_loss: 0.9856 - val_accuracy: 0.6538\n",
            "Epoch 1175/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7092 - accuracy: 0.7411 - val_loss: 1.0194 - val_accuracy: 0.6282\n",
            "Epoch 1176/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6956 - accuracy: 0.7346 - val_loss: 1.0569 - val_accuracy: 0.6282\n",
            "Epoch 1177/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7125 - accuracy: 0.7379 - val_loss: 1.0278 - val_accuracy: 0.6410\n",
            "Epoch 1178/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6935 - accuracy: 0.7379 - val_loss: 1.1065 - val_accuracy: 0.5769\n",
            "Epoch 1179/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7244 - accuracy: 0.7120 - val_loss: 1.0342 - val_accuracy: 0.6410\n",
            "Epoch 1180/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7436 - accuracy: 0.7184 - val_loss: 1.0858 - val_accuracy: 0.5897\n",
            "Epoch 1181/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6846 - accuracy: 0.7184 - val_loss: 1.1840 - val_accuracy: 0.6026\n",
            "Epoch 1182/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6910 - accuracy: 0.7443 - val_loss: 1.0046 - val_accuracy: 0.6667\n",
            "Epoch 1183/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7120 - accuracy: 0.7314 - val_loss: 1.0279 - val_accuracy: 0.6282\n",
            "Epoch 1184/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7186 - accuracy: 0.7282 - val_loss: 0.9865 - val_accuracy: 0.6282\n",
            "Epoch 1185/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7104 - accuracy: 0.7508 - val_loss: 1.0038 - val_accuracy: 0.6538\n",
            "Epoch 1186/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7360 - accuracy: 0.7249 - val_loss: 1.0532 - val_accuracy: 0.6538\n",
            "Epoch 1187/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7586 - accuracy: 0.7023 - val_loss: 1.1814 - val_accuracy: 0.5897\n",
            "Epoch 1188/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6927 - accuracy: 0.7411 - val_loss: 1.0421 - val_accuracy: 0.6282\n",
            "Epoch 1189/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6783 - accuracy: 0.7379 - val_loss: 1.1107 - val_accuracy: 0.5897\n",
            "Epoch 1190/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7212 - accuracy: 0.7411 - val_loss: 0.9809 - val_accuracy: 0.6667\n",
            "Epoch 1191/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6854 - accuracy: 0.7443 - val_loss: 0.9816 - val_accuracy: 0.6667\n",
            "Epoch 1192/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6945 - accuracy: 0.7314 - val_loss: 0.9781 - val_accuracy: 0.6667\n",
            "Epoch 1193/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6661 - accuracy: 0.7411 - val_loss: 1.0080 - val_accuracy: 0.6026\n",
            "Epoch 1194/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.7379 - val_loss: 0.9777 - val_accuracy: 0.6538\n",
            "Epoch 1195/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6747 - accuracy: 0.7540 - val_loss: 0.9785 - val_accuracy: 0.6410\n",
            "Epoch 1196/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6622 - accuracy: 0.7540 - val_loss: 0.9686 - val_accuracy: 0.6667\n",
            "Epoch 1197/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6869 - accuracy: 0.7443 - val_loss: 1.0548 - val_accuracy: 0.6410\n",
            "Epoch 1198/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6871 - accuracy: 0.7346 - val_loss: 1.0548 - val_accuracy: 0.6154\n",
            "Epoch 1199/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.7508 - val_loss: 0.9635 - val_accuracy: 0.6667\n",
            "Epoch 1200/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6819 - accuracy: 0.7573 - val_loss: 0.9700 - val_accuracy: 0.6538\n",
            "Epoch 1201/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6770 - accuracy: 0.7249 - val_loss: 1.0022 - val_accuracy: 0.6410\n",
            "Epoch 1202/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7018 - accuracy: 0.7540 - val_loss: 1.0140 - val_accuracy: 0.6667\n",
            "Epoch 1203/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7203 - accuracy: 0.7249 - val_loss: 0.9730 - val_accuracy: 0.6410\n",
            "Epoch 1204/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6914 - accuracy: 0.7540 - val_loss: 0.9741 - val_accuracy: 0.6538\n",
            "Epoch 1205/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6954 - accuracy: 0.7508 - val_loss: 0.9923 - val_accuracy: 0.6667\n",
            "Epoch 1206/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.6775 - accuracy: 0.7670 - val_loss: 1.2017 - val_accuracy: 0.5897\n",
            "Epoch 1207/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6910 - accuracy: 0.7508 - val_loss: 1.0151 - val_accuracy: 0.6667\n",
            "Epoch 1208/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6612 - accuracy: 0.7605 - val_loss: 1.0251 - val_accuracy: 0.6282\n",
            "Epoch 1209/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7566 - accuracy: 0.7055 - val_loss: 0.9812 - val_accuracy: 0.6923\n",
            "Epoch 1210/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7215 - accuracy: 0.7379 - val_loss: 1.0256 - val_accuracy: 0.5897\n",
            "Epoch 1211/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7024 - accuracy: 0.7120 - val_loss: 0.9869 - val_accuracy: 0.6410\n",
            "Epoch 1212/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7104 - accuracy: 0.7314 - val_loss: 0.9775 - val_accuracy: 0.6667\n",
            "Epoch 1213/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7210 - accuracy: 0.7249 - val_loss: 1.0174 - val_accuracy: 0.6154\n",
            "Epoch 1214/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7399 - accuracy: 0.7217 - val_loss: 0.9717 - val_accuracy: 0.6538\n",
            "Epoch 1215/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6687 - accuracy: 0.7476 - val_loss: 1.0331 - val_accuracy: 0.6282\n",
            "Epoch 1216/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6648 - accuracy: 0.7282 - val_loss: 0.9820 - val_accuracy: 0.6667\n",
            "Epoch 1217/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7019 - accuracy: 0.7184 - val_loss: 0.9774 - val_accuracy: 0.6538\n",
            "Epoch 1218/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6760 - accuracy: 0.7346 - val_loss: 1.0598 - val_accuracy: 0.6282\n",
            "Epoch 1219/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7306 - accuracy: 0.7411 - val_loss: 0.9943 - val_accuracy: 0.6538\n",
            "Epoch 1220/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6699 - accuracy: 0.7638 - val_loss: 1.0007 - val_accuracy: 0.6538\n",
            "Epoch 1221/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7370 - accuracy: 0.7540 - val_loss: 1.0623 - val_accuracy: 0.6282\n",
            "Epoch 1222/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8272 - accuracy: 0.6828 - val_loss: 1.0232 - val_accuracy: 0.6410\n",
            "Epoch 1223/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7704 - accuracy: 0.7120 - val_loss: 0.9753 - val_accuracy: 0.6667\n",
            "Epoch 1224/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7738 - accuracy: 0.7055 - val_loss: 0.9777 - val_accuracy: 0.6667\n",
            "Epoch 1225/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7725 - accuracy: 0.6893 - val_loss: 1.0650 - val_accuracy: 0.6154\n",
            "Epoch 1226/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7588 - accuracy: 0.7152 - val_loss: 1.0737 - val_accuracy: 0.6410\n",
            "Epoch 1227/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7193 - accuracy: 0.7217 - val_loss: 0.9656 - val_accuracy: 0.6538\n",
            "Epoch 1228/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6928 - accuracy: 0.7508 - val_loss: 1.0210 - val_accuracy: 0.5897\n",
            "Epoch 1229/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6705 - accuracy: 0.7476 - val_loss: 1.0456 - val_accuracy: 0.6154\n",
            "Epoch 1230/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7019 - accuracy: 0.7508 - val_loss: 1.0203 - val_accuracy: 0.6538\n",
            "Epoch 1231/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6975 - accuracy: 0.7346 - val_loss: 1.0745 - val_accuracy: 0.5897\n",
            "Epoch 1232/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6650 - accuracy: 0.7573 - val_loss: 0.9814 - val_accuracy: 0.6667\n",
            "Epoch 1233/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7197 - accuracy: 0.7346 - val_loss: 1.0054 - val_accuracy: 0.6282\n",
            "Epoch 1234/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6951 - accuracy: 0.7476 - val_loss: 0.9669 - val_accuracy: 0.6667\n",
            "Epoch 1235/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6963 - accuracy: 0.7314 - val_loss: 0.9574 - val_accuracy: 0.6795\n",
            "Epoch 1236/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6857 - accuracy: 0.7573 - val_loss: 1.0007 - val_accuracy: 0.6410\n",
            "Epoch 1237/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6840 - accuracy: 0.7346 - val_loss: 0.9429 - val_accuracy: 0.6795\n",
            "Epoch 1238/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6856 - accuracy: 0.7476 - val_loss: 0.9737 - val_accuracy: 0.6154\n",
            "Epoch 1239/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7189 - accuracy: 0.7476 - val_loss: 0.9555 - val_accuracy: 0.6667\n",
            "Epoch 1240/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7104 - accuracy: 0.7120 - val_loss: 1.0876 - val_accuracy: 0.6282\n",
            "Epoch 1241/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7576 - accuracy: 0.6958 - val_loss: 1.2837 - val_accuracy: 0.5769\n",
            "Epoch 1242/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7131 - accuracy: 0.7346 - val_loss: 0.9852 - val_accuracy: 0.6795\n",
            "Epoch 1243/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7139 - accuracy: 0.7476 - val_loss: 1.1316 - val_accuracy: 0.6026\n",
            "Epoch 1244/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7089 - accuracy: 0.7217 - val_loss: 1.1165 - val_accuracy: 0.5769\n",
            "Epoch 1245/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6990 - accuracy: 0.7411 - val_loss: 1.0014 - val_accuracy: 0.6410\n",
            "Epoch 1246/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6816 - accuracy: 0.7411 - val_loss: 1.0150 - val_accuracy: 0.6538\n",
            "Epoch 1247/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6609 - accuracy: 0.7573 - val_loss: 0.9982 - val_accuracy: 0.6667\n",
            "Epoch 1248/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6765 - accuracy: 0.7217 - val_loss: 1.1023 - val_accuracy: 0.5897\n",
            "Epoch 1249/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7227 - accuracy: 0.7346 - val_loss: 1.0307 - val_accuracy: 0.6923\n",
            "Epoch 1250/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6963 - accuracy: 0.7443 - val_loss: 1.0666 - val_accuracy: 0.6154\n",
            "Epoch 1251/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7698 - accuracy: 0.6990 - val_loss: 0.9894 - val_accuracy: 0.6795\n",
            "Epoch 1252/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7101 - accuracy: 0.7314 - val_loss: 0.9558 - val_accuracy: 0.6795\n",
            "Epoch 1253/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6940 - accuracy: 0.7573 - val_loss: 0.9991 - val_accuracy: 0.6154\n",
            "Epoch 1254/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6838 - accuracy: 0.7573 - val_loss: 1.0832 - val_accuracy: 0.6154\n",
            "Epoch 1255/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6913 - accuracy: 0.7476 - val_loss: 1.0057 - val_accuracy: 0.6795\n",
            "Epoch 1256/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6935 - accuracy: 0.7443 - val_loss: 0.9996 - val_accuracy: 0.6410\n",
            "Epoch 1257/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6919 - accuracy: 0.7702 - val_loss: 0.9718 - val_accuracy: 0.6538\n",
            "Epoch 1258/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7066 - accuracy: 0.7120 - val_loss: 0.9579 - val_accuracy: 0.6667\n",
            "Epoch 1259/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6553 - accuracy: 0.7702 - val_loss: 0.9741 - val_accuracy: 0.6538\n",
            "Epoch 1260/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6556 - accuracy: 0.7638 - val_loss: 1.0549 - val_accuracy: 0.6154\n",
            "Epoch 1261/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6682 - accuracy: 0.7573 - val_loss: 1.0445 - val_accuracy: 0.6538\n",
            "Epoch 1262/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6822 - accuracy: 0.7379 - val_loss: 1.1344 - val_accuracy: 0.6026\n",
            "Epoch 1263/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6950 - accuracy: 0.7411 - val_loss: 1.0463 - val_accuracy: 0.6026\n",
            "Epoch 1264/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6575 - accuracy: 0.7573 - val_loss: 1.0248 - val_accuracy: 0.6538\n",
            "Epoch 1265/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7005 - accuracy: 0.7476 - val_loss: 0.9810 - val_accuracy: 0.6667\n",
            "Epoch 1266/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7031 - accuracy: 0.7379 - val_loss: 0.9721 - val_accuracy: 0.6538\n",
            "Epoch 1267/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6821 - accuracy: 0.7605 - val_loss: 0.9827 - val_accuracy: 0.6667\n",
            "Epoch 1268/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6427 - accuracy: 0.7508 - val_loss: 0.9656 - val_accuracy: 0.6667\n",
            "Epoch 1269/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6564 - accuracy: 0.7638 - val_loss: 1.1739 - val_accuracy: 0.6154\n",
            "Epoch 1270/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7541 - accuracy: 0.7152 - val_loss: 1.1671 - val_accuracy: 0.6026\n",
            "Epoch 1271/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7224 - accuracy: 0.7314 - val_loss: 1.3063 - val_accuracy: 0.5769\n",
            "Epoch 1272/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.7512 - accuracy: 0.7087 - val_loss: 1.0796 - val_accuracy: 0.6282\n",
            "Epoch 1273/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7860 - accuracy: 0.6926 - val_loss: 1.1691 - val_accuracy: 0.5769\n",
            "Epoch 1274/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7213 - accuracy: 0.7249 - val_loss: 1.1585 - val_accuracy: 0.5769\n",
            "Epoch 1275/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6732 - accuracy: 0.7346 - val_loss: 1.0237 - val_accuracy: 0.6538\n",
            "Epoch 1276/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7024 - accuracy: 0.7249 - val_loss: 1.0179 - val_accuracy: 0.6282\n",
            "Epoch 1277/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6521 - accuracy: 0.7638 - val_loss: 0.9776 - val_accuracy: 0.6538\n",
            "Epoch 1278/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6869 - accuracy: 0.7476 - val_loss: 0.9865 - val_accuracy: 0.6538\n",
            "Epoch 1279/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6806 - accuracy: 0.7573 - val_loss: 0.9730 - val_accuracy: 0.6538\n",
            "Epoch 1280/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6632 - accuracy: 0.7605 - val_loss: 0.9991 - val_accuracy: 0.5641\n",
            "Epoch 1281/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6447 - accuracy: 0.7670 - val_loss: 0.9875 - val_accuracy: 0.6795\n",
            "Epoch 1282/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7002 - accuracy: 0.7508 - val_loss: 1.0584 - val_accuracy: 0.6410\n",
            "Epoch 1283/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6746 - accuracy: 0.7443 - val_loss: 1.0547 - val_accuracy: 0.6410\n",
            "Epoch 1284/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6505 - accuracy: 0.7314 - val_loss: 1.0768 - val_accuracy: 0.6282\n",
            "Epoch 1285/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6980 - accuracy: 0.7346 - val_loss: 1.0965 - val_accuracy: 0.5769\n",
            "Epoch 1286/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6681 - accuracy: 0.7314 - val_loss: 0.9815 - val_accuracy: 0.6923\n",
            "Epoch 1287/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6514 - accuracy: 0.7670 - val_loss: 0.9594 - val_accuracy: 0.6795\n",
            "Epoch 1288/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6769 - accuracy: 0.7735 - val_loss: 0.9451 - val_accuracy: 0.7051\n",
            "Epoch 1289/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7038 - accuracy: 0.7443 - val_loss: 1.0221 - val_accuracy: 0.6538\n",
            "Epoch 1290/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6786 - accuracy: 0.7443 - val_loss: 0.9830 - val_accuracy: 0.6667\n",
            "Epoch 1291/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6905 - accuracy: 0.7314 - val_loss: 0.9591 - val_accuracy: 0.6667\n",
            "Epoch 1292/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6501 - accuracy: 0.7670 - val_loss: 0.9465 - val_accuracy: 0.7179\n",
            "Epoch 1293/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6364 - accuracy: 0.7864 - val_loss: 0.9901 - val_accuracy: 0.6410\n",
            "Epoch 1294/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6514 - accuracy: 0.7767 - val_loss: 1.0060 - val_accuracy: 0.6538\n",
            "Epoch 1295/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6993 - accuracy: 0.7379 - val_loss: 1.0747 - val_accuracy: 0.6282\n",
            "Epoch 1296/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6844 - accuracy: 0.7573 - val_loss: 0.9929 - val_accuracy: 0.6667\n",
            "Epoch 1297/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7050 - accuracy: 0.7314 - val_loss: 1.0460 - val_accuracy: 0.6154\n",
            "Epoch 1298/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6558 - accuracy: 0.7702 - val_loss: 1.0734 - val_accuracy: 0.6538\n",
            "Epoch 1299/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6219 - accuracy: 0.7605 - val_loss: 1.0075 - val_accuracy: 0.6410\n",
            "Epoch 1300/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6702 - accuracy: 0.7799 - val_loss: 0.9747 - val_accuracy: 0.6795\n",
            "Epoch 1301/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6192 - accuracy: 0.7767 - val_loss: 0.9771 - val_accuracy: 0.6282\n",
            "Epoch 1302/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6830 - accuracy: 0.7379 - val_loss: 0.9354 - val_accuracy: 0.6667\n",
            "Epoch 1303/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6581 - accuracy: 0.7638 - val_loss: 0.9636 - val_accuracy: 0.6538\n",
            "Epoch 1304/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7043 - accuracy: 0.7605 - val_loss: 0.9370 - val_accuracy: 0.7051\n",
            "Epoch 1305/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6692 - accuracy: 0.7638 - val_loss: 0.9635 - val_accuracy: 0.6410\n",
            "Epoch 1306/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6759 - accuracy: 0.7379 - val_loss: 0.9864 - val_accuracy: 0.6667\n",
            "Epoch 1307/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6697 - accuracy: 0.7605 - val_loss: 0.9714 - val_accuracy: 0.6795\n",
            "Epoch 1308/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6462 - accuracy: 0.7702 - val_loss: 0.9967 - val_accuracy: 0.6410\n",
            "Epoch 1309/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7020 - accuracy: 0.7573 - val_loss: 0.9574 - val_accuracy: 0.6667\n",
            "Epoch 1310/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6221 - accuracy: 0.7573 - val_loss: 1.0062 - val_accuracy: 0.6410\n",
            "Epoch 1311/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6749 - accuracy: 0.7476 - val_loss: 0.9506 - val_accuracy: 0.7051\n",
            "Epoch 1312/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7187 - accuracy: 0.7217 - val_loss: 0.9881 - val_accuracy: 0.6410\n",
            "Epoch 1313/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6619 - accuracy: 0.7314 - val_loss: 0.9689 - val_accuracy: 0.6667\n",
            "Epoch 1314/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6808 - accuracy: 0.7314 - val_loss: 0.9701 - val_accuracy: 0.6410\n",
            "Epoch 1315/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6889 - accuracy: 0.7540 - val_loss: 0.9619 - val_accuracy: 0.6795\n",
            "Epoch 1316/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6630 - accuracy: 0.7508 - val_loss: 0.9758 - val_accuracy: 0.6923\n",
            "Epoch 1317/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6999 - accuracy: 0.7346 - val_loss: 0.9676 - val_accuracy: 0.7051\n",
            "Epoch 1318/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7088 - accuracy: 0.7314 - val_loss: 1.1684 - val_accuracy: 0.5897\n",
            "Epoch 1319/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7251 - accuracy: 0.7314 - val_loss: 1.1063 - val_accuracy: 0.6026\n",
            "Epoch 1320/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6665 - accuracy: 0.7443 - val_loss: 0.9536 - val_accuracy: 0.7179\n",
            "Epoch 1321/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6487 - accuracy: 0.7443 - val_loss: 1.0559 - val_accuracy: 0.6154\n",
            "Epoch 1322/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6681 - accuracy: 0.7476 - val_loss: 1.2123 - val_accuracy: 0.5897\n",
            "Epoch 1323/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7637 - accuracy: 0.7055 - val_loss: 1.1498 - val_accuracy: 0.6282\n",
            "Epoch 1324/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7393 - accuracy: 0.7152 - val_loss: 1.1997 - val_accuracy: 0.5897\n",
            "Epoch 1325/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7363 - accuracy: 0.7379 - val_loss: 1.0096 - val_accuracy: 0.6538\n",
            "Epoch 1326/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6585 - accuracy: 0.7864 - val_loss: 0.9507 - val_accuracy: 0.6282\n",
            "Epoch 1327/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6435 - accuracy: 0.7799 - val_loss: 1.0128 - val_accuracy: 0.6538\n",
            "Epoch 1328/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6825 - accuracy: 0.7508 - val_loss: 1.0110 - val_accuracy: 0.6667\n",
            "Epoch 1329/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7006 - accuracy: 0.7346 - val_loss: 1.0804 - val_accuracy: 0.6410\n",
            "Epoch 1330/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6846 - accuracy: 0.7184 - val_loss: 1.0055 - val_accuracy: 0.6538\n",
            "Epoch 1331/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7000 - accuracy: 0.7314 - val_loss: 1.1545 - val_accuracy: 0.6026\n",
            "Epoch 1332/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6486 - accuracy: 0.7508 - val_loss: 1.0570 - val_accuracy: 0.6410\n",
            "Epoch 1333/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6873 - accuracy: 0.7346 - val_loss: 1.0539 - val_accuracy: 0.6282\n",
            "Epoch 1334/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7033 - accuracy: 0.7476 - val_loss: 1.0425 - val_accuracy: 0.6538\n",
            "Epoch 1335/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6536 - accuracy: 0.7476 - val_loss: 1.0674 - val_accuracy: 0.6026\n",
            "Epoch 1336/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6897 - accuracy: 0.7476 - val_loss: 1.0359 - val_accuracy: 0.6538\n",
            "Epoch 1337/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6571 - accuracy: 0.7540 - val_loss: 0.9915 - val_accuracy: 0.6410\n",
            "Epoch 1338/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6738 - accuracy: 0.7573 - val_loss: 0.9865 - val_accuracy: 0.6667\n",
            "Epoch 1339/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6715 - accuracy: 0.7702 - val_loss: 0.9581 - val_accuracy: 0.6923\n",
            "Epoch 1340/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6517 - accuracy: 0.7282 - val_loss: 0.9477 - val_accuracy: 0.6923\n",
            "Epoch 1341/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6253 - accuracy: 0.7411 - val_loss: 0.9698 - val_accuracy: 0.6667\n",
            "Epoch 1342/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6800 - accuracy: 0.7605 - val_loss: 0.9720 - val_accuracy: 0.6795\n",
            "Epoch 1343/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6664 - accuracy: 0.7638 - val_loss: 0.9796 - val_accuracy: 0.6795\n",
            "Epoch 1344/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6329 - accuracy: 0.7735 - val_loss: 0.9906 - val_accuracy: 0.6538\n",
            "Epoch 1345/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6078 - accuracy: 0.7573 - val_loss: 0.9659 - val_accuracy: 0.6795\n",
            "Epoch 1346/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7031 - accuracy: 0.7314 - val_loss: 1.0370 - val_accuracy: 0.6026\n",
            "Epoch 1347/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7160 - accuracy: 0.7120 - val_loss: 1.0532 - val_accuracy: 0.6154\n",
            "Epoch 1348/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7093 - accuracy: 0.7282 - val_loss: 0.9642 - val_accuracy: 0.6667\n",
            "Epoch 1349/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7608 - accuracy: 0.7120 - val_loss: 0.9867 - val_accuracy: 0.6538\n",
            "Epoch 1350/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7091 - accuracy: 0.7411 - val_loss: 1.0787 - val_accuracy: 0.6795\n",
            "Epoch 1351/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6972 - accuracy: 0.7282 - val_loss: 1.0696 - val_accuracy: 0.6026\n",
            "Epoch 1352/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6867 - accuracy: 0.7346 - val_loss: 0.9817 - val_accuracy: 0.6410\n",
            "Epoch 1353/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6627 - accuracy: 0.7573 - val_loss: 1.0551 - val_accuracy: 0.6154\n",
            "Epoch 1354/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6952 - accuracy: 0.7443 - val_loss: 0.9637 - val_accuracy: 0.6667\n",
            "Epoch 1355/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6674 - accuracy: 0.7605 - val_loss: 0.9577 - val_accuracy: 0.6538\n",
            "Epoch 1356/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6980 - accuracy: 0.7184 - val_loss: 0.9766 - val_accuracy: 0.6538\n",
            "Epoch 1357/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7343 - accuracy: 0.7249 - val_loss: 0.9617 - val_accuracy: 0.6923\n",
            "Epoch 1358/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7145 - accuracy: 0.7346 - val_loss: 1.0088 - val_accuracy: 0.6282\n",
            "Epoch 1359/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6996 - accuracy: 0.7443 - val_loss: 1.0734 - val_accuracy: 0.6154\n",
            "Epoch 1360/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6999 - accuracy: 0.7314 - val_loss: 1.0622 - val_accuracy: 0.6282\n",
            "Epoch 1361/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6785 - accuracy: 0.7638 - val_loss: 1.0009 - val_accuracy: 0.6667\n",
            "Epoch 1362/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6189 - accuracy: 0.7573 - val_loss: 0.9940 - val_accuracy: 0.6410\n",
            "Epoch 1363/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6276 - accuracy: 0.7508 - val_loss: 1.1748 - val_accuracy: 0.6026\n",
            "Epoch 1364/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6753 - accuracy: 0.7346 - val_loss: 0.9929 - val_accuracy: 0.6410\n",
            "Epoch 1365/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6221 - accuracy: 0.7605 - val_loss: 1.0117 - val_accuracy: 0.6538\n",
            "Epoch 1366/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6736 - accuracy: 0.7152 - val_loss: 1.0866 - val_accuracy: 0.5897\n",
            "Epoch 1367/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6563 - accuracy: 0.7314 - val_loss: 0.9572 - val_accuracy: 0.7051\n",
            "Epoch 1368/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6699 - accuracy: 0.7670 - val_loss: 1.0167 - val_accuracy: 0.6282\n",
            "Epoch 1369/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6911 - accuracy: 0.7249 - val_loss: 0.9951 - val_accuracy: 0.6538\n",
            "Epoch 1370/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6228 - accuracy: 0.7702 - val_loss: 0.9558 - val_accuracy: 0.6795\n",
            "Epoch 1371/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6047 - accuracy: 0.7508 - val_loss: 0.9872 - val_accuracy: 0.6410\n",
            "Epoch 1372/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6641 - accuracy: 0.7443 - val_loss: 0.9666 - val_accuracy: 0.6923\n",
            "Epoch 1373/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6318 - accuracy: 0.7573 - val_loss: 0.9924 - val_accuracy: 0.6410\n",
            "Epoch 1374/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6274 - accuracy: 0.7799 - val_loss: 0.9537 - val_accuracy: 0.6667\n",
            "Epoch 1375/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6121 - accuracy: 0.7767 - val_loss: 0.9333 - val_accuracy: 0.7179\n",
            "Epoch 1376/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6364 - accuracy: 0.7702 - val_loss: 0.9880 - val_accuracy: 0.6923\n",
            "Epoch 1377/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6475 - accuracy: 0.7379 - val_loss: 0.9624 - val_accuracy: 0.6795\n",
            "Epoch 1378/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6578 - accuracy: 0.7573 - val_loss: 0.9478 - val_accuracy: 0.6795\n",
            "Epoch 1379/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6270 - accuracy: 0.7573 - val_loss: 1.0983 - val_accuracy: 0.5769\n",
            "Epoch 1380/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6208 - accuracy: 0.7735 - val_loss: 0.9328 - val_accuracy: 0.6923\n",
            "Epoch 1381/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6551 - accuracy: 0.7540 - val_loss: 0.9882 - val_accuracy: 0.6282\n",
            "Epoch 1382/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6219 - accuracy: 0.7799 - val_loss: 0.9686 - val_accuracy: 0.6923\n",
            "Epoch 1383/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7163 - accuracy: 0.7411 - val_loss: 1.0161 - val_accuracy: 0.6667\n",
            "Epoch 1384/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6564 - accuracy: 0.7638 - val_loss: 1.0597 - val_accuracy: 0.6410\n",
            "Epoch 1385/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6489 - accuracy: 0.7476 - val_loss: 1.0650 - val_accuracy: 0.6410\n",
            "Epoch 1386/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6718 - accuracy: 0.7379 - val_loss: 0.9633 - val_accuracy: 0.6795\n",
            "Epoch 1387/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6427 - accuracy: 0.7896 - val_loss: 1.0243 - val_accuracy: 0.6538\n",
            "Epoch 1388/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6387 - accuracy: 0.7573 - val_loss: 1.0031 - val_accuracy: 0.6538\n",
            "Epoch 1389/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6177 - accuracy: 0.7702 - val_loss: 1.1686 - val_accuracy: 0.5769\n",
            "Epoch 1390/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6314 - accuracy: 0.7508 - val_loss: 1.0088 - val_accuracy: 0.6667\n",
            "Epoch 1391/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6369 - accuracy: 0.7540 - val_loss: 0.9781 - val_accuracy: 0.6538\n",
            "Epoch 1392/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6712 - accuracy: 0.7379 - val_loss: 0.9997 - val_accuracy: 0.6923\n",
            "Epoch 1393/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6322 - accuracy: 0.7702 - val_loss: 1.0509 - val_accuracy: 0.6538\n",
            "Epoch 1394/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6549 - accuracy: 0.7314 - val_loss: 1.0737 - val_accuracy: 0.5641\n",
            "Epoch 1395/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6693 - accuracy: 0.7638 - val_loss: 0.9896 - val_accuracy: 0.6923\n",
            "Epoch 1396/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6097 - accuracy: 0.7832 - val_loss: 1.1398 - val_accuracy: 0.6026\n",
            "Epoch 1397/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6453 - accuracy: 0.7735 - val_loss: 1.0416 - val_accuracy: 0.6667\n",
            "Epoch 1398/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6432 - accuracy: 0.7605 - val_loss: 1.2383 - val_accuracy: 0.6154\n",
            "Epoch 1399/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6814 - accuracy: 0.7379 - val_loss: 1.0723 - val_accuracy: 0.6154\n",
            "Epoch 1400/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6928 - accuracy: 0.7638 - val_loss: 1.0082 - val_accuracy: 0.6538\n",
            "Epoch 1401/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6354 - accuracy: 0.7767 - val_loss: 1.0702 - val_accuracy: 0.5897\n",
            "Epoch 1402/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6623 - accuracy: 0.7476 - val_loss: 1.0656 - val_accuracy: 0.6667\n",
            "Epoch 1403/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6817 - accuracy: 0.7184 - val_loss: 1.0370 - val_accuracy: 0.6410\n",
            "Epoch 1404/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6117 - accuracy: 0.7702 - val_loss: 0.9805 - val_accuracy: 0.6410\n",
            "Epoch 1405/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6612 - accuracy: 0.7282 - val_loss: 0.9611 - val_accuracy: 0.6538\n",
            "Epoch 1406/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6379 - accuracy: 0.7702 - val_loss: 0.9584 - val_accuracy: 0.6795\n",
            "Epoch 1407/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6945 - accuracy: 0.7638 - val_loss: 0.9658 - val_accuracy: 0.6923\n",
            "Epoch 1408/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7079 - accuracy: 0.7411 - val_loss: 1.1889 - val_accuracy: 0.6026\n",
            "Epoch 1409/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7320 - accuracy: 0.7249 - val_loss: 1.0204 - val_accuracy: 0.6538\n",
            "Epoch 1410/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6669 - accuracy: 0.7379 - val_loss: 1.0974 - val_accuracy: 0.6154\n",
            "Epoch 1411/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6628 - accuracy: 0.7702 - val_loss: 1.0727 - val_accuracy: 0.6410\n",
            "Epoch 1412/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6214 - accuracy: 0.7735 - val_loss: 1.2359 - val_accuracy: 0.6154\n",
            "Epoch 1413/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6712 - accuracy: 0.7443 - val_loss: 1.0219 - val_accuracy: 0.6795\n",
            "Epoch 1414/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6408 - accuracy: 0.7508 - val_loss: 1.0863 - val_accuracy: 0.6282\n",
            "Epoch 1415/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6347 - accuracy: 0.7540 - val_loss: 0.9723 - val_accuracy: 0.6667\n",
            "Epoch 1416/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6520 - accuracy: 0.7735 - val_loss: 0.9736 - val_accuracy: 0.6923\n",
            "Epoch 1417/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6940 - accuracy: 0.7314 - val_loss: 1.0458 - val_accuracy: 0.6026\n",
            "Epoch 1418/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7056 - accuracy: 0.7314 - val_loss: 0.9720 - val_accuracy: 0.6667\n",
            "Epoch 1419/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6662 - accuracy: 0.7476 - val_loss: 1.0353 - val_accuracy: 0.6410\n",
            "Epoch 1420/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6717 - accuracy: 0.7508 - val_loss: 0.9685 - val_accuracy: 0.6538\n",
            "Epoch 1421/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6440 - accuracy: 0.7605 - val_loss: 0.9965 - val_accuracy: 0.6410\n",
            "Epoch 1422/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6468 - accuracy: 0.7443 - val_loss: 0.9763 - val_accuracy: 0.6410\n",
            "Epoch 1423/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6448 - accuracy: 0.7411 - val_loss: 1.0240 - val_accuracy: 0.6154\n",
            "Epoch 1424/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6629 - accuracy: 0.7508 - val_loss: 1.0058 - val_accuracy: 0.6410\n",
            "Epoch 1425/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6870 - accuracy: 0.7540 - val_loss: 1.1089 - val_accuracy: 0.6282\n",
            "Epoch 1426/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6542 - accuracy: 0.7573 - val_loss: 1.0830 - val_accuracy: 0.6410\n",
            "Epoch 1427/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6434 - accuracy: 0.7508 - val_loss: 1.0687 - val_accuracy: 0.6154\n",
            "Epoch 1428/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6371 - accuracy: 0.7573 - val_loss: 1.0051 - val_accuracy: 0.6538\n",
            "Epoch 1429/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6450 - accuracy: 0.7411 - val_loss: 0.9545 - val_accuracy: 0.6795\n",
            "Epoch 1430/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6608 - accuracy: 0.7282 - val_loss: 1.0358 - val_accuracy: 0.6026\n",
            "Epoch 1431/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6419 - accuracy: 0.7411 - val_loss: 0.9533 - val_accuracy: 0.6667\n",
            "Epoch 1432/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6567 - accuracy: 0.7702 - val_loss: 1.0000 - val_accuracy: 0.6795\n",
            "Epoch 1433/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6496 - accuracy: 0.7605 - val_loss: 0.9446 - val_accuracy: 0.6795\n",
            "Epoch 1434/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6149 - accuracy: 0.7896 - val_loss: 0.9955 - val_accuracy: 0.6282\n",
            "Epoch 1435/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6242 - accuracy: 0.7670 - val_loss: 0.9877 - val_accuracy: 0.6667\n",
            "Epoch 1436/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6695 - accuracy: 0.7670 - val_loss: 1.0311 - val_accuracy: 0.6154\n",
            "Epoch 1437/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6649 - accuracy: 0.7573 - val_loss: 0.9845 - val_accuracy: 0.6667\n",
            "Epoch 1438/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5977 - accuracy: 0.7994 - val_loss: 0.9664 - val_accuracy: 0.7051\n",
            "Epoch 1439/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6325 - accuracy: 0.7508 - val_loss: 1.0008 - val_accuracy: 0.6410\n",
            "Epoch 1440/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6130 - accuracy: 0.7638 - val_loss: 1.1998 - val_accuracy: 0.5769\n",
            "Epoch 1441/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.6213 - accuracy: 0.7735 - val_loss: 1.0354 - val_accuracy: 0.6410\n",
            "Epoch 1442/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6814 - accuracy: 0.7476 - val_loss: 1.2823 - val_accuracy: 0.5897\n",
            "Epoch 1443/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6872 - accuracy: 0.7346 - val_loss: 1.0599 - val_accuracy: 0.6667\n",
            "Epoch 1444/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6357 - accuracy: 0.7605 - val_loss: 1.0536 - val_accuracy: 0.6282\n",
            "Epoch 1445/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7154 - accuracy: 0.7379 - val_loss: 1.0748 - val_accuracy: 0.5897\n",
            "Epoch 1446/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6242 - accuracy: 0.7702 - val_loss: 0.9566 - val_accuracy: 0.6923\n",
            "Epoch 1447/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6382 - accuracy: 0.7670 - val_loss: 1.0844 - val_accuracy: 0.6282\n",
            "Epoch 1448/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7051 - accuracy: 0.7508 - val_loss: 0.9883 - val_accuracy: 0.6410\n",
            "Epoch 1449/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7086 - accuracy: 0.7184 - val_loss: 0.9565 - val_accuracy: 0.6410\n",
            "Epoch 1450/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6815 - accuracy: 0.7184 - val_loss: 0.9714 - val_accuracy: 0.6538\n",
            "Epoch 1451/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6333 - accuracy: 0.7540 - val_loss: 0.9459 - val_accuracy: 0.6795\n",
            "Epoch 1452/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6551 - accuracy: 0.7540 - val_loss: 1.1105 - val_accuracy: 0.5641\n",
            "Epoch 1453/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6815 - accuracy: 0.7217 - val_loss: 1.0029 - val_accuracy: 0.6410\n",
            "Epoch 1454/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6997 - accuracy: 0.7249 - val_loss: 0.9832 - val_accuracy: 0.6795\n",
            "Epoch 1455/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6824 - accuracy: 0.7379 - val_loss: 0.9763 - val_accuracy: 0.6538\n",
            "Epoch 1456/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6079 - accuracy: 0.8026 - val_loss: 0.9641 - val_accuracy: 0.6667\n",
            "Epoch 1457/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6035 - accuracy: 0.7961 - val_loss: 0.9766 - val_accuracy: 0.6667\n",
            "Epoch 1458/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6711 - accuracy: 0.7443 - val_loss: 1.0105 - val_accuracy: 0.6154\n",
            "Epoch 1459/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6148 - accuracy: 0.7670 - val_loss: 1.1206 - val_accuracy: 0.6410\n",
            "Epoch 1460/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6686 - accuracy: 0.7443 - val_loss: 1.1405 - val_accuracy: 0.6154\n",
            "Epoch 1461/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6687 - accuracy: 0.7605 - val_loss: 1.2154 - val_accuracy: 0.6154\n",
            "Epoch 1462/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6456 - accuracy: 0.7476 - val_loss: 1.1510 - val_accuracy: 0.6026\n",
            "Epoch 1463/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6296 - accuracy: 0.7799 - val_loss: 1.0352 - val_accuracy: 0.6538\n",
            "Epoch 1464/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6181 - accuracy: 0.7864 - val_loss: 0.9566 - val_accuracy: 0.6923\n",
            "Epoch 1465/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5786 - accuracy: 0.7896 - val_loss: 0.9950 - val_accuracy: 0.6154\n",
            "Epoch 1466/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6505 - accuracy: 0.7508 - val_loss: 0.9983 - val_accuracy: 0.6410\n",
            "Epoch 1467/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6434 - accuracy: 0.7638 - val_loss: 1.0242 - val_accuracy: 0.6795\n",
            "Epoch 1468/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6706 - accuracy: 0.7346 - val_loss: 0.9819 - val_accuracy: 0.6410\n",
            "Epoch 1469/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6627 - accuracy: 0.7443 - val_loss: 0.9652 - val_accuracy: 0.6923\n",
            "Epoch 1470/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6519 - accuracy: 0.7443 - val_loss: 1.1376 - val_accuracy: 0.5769\n",
            "Epoch 1471/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6829 - accuracy: 0.7314 - val_loss: 0.9760 - val_accuracy: 0.6795\n",
            "Epoch 1472/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6067 - accuracy: 0.7767 - val_loss: 0.9898 - val_accuracy: 0.6667\n",
            "Epoch 1473/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6186 - accuracy: 0.7508 - val_loss: 0.9898 - val_accuracy: 0.6667\n",
            "Epoch 1474/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6193 - accuracy: 0.7476 - val_loss: 0.9889 - val_accuracy: 0.6923\n",
            "Epoch 1475/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6002 - accuracy: 0.7702 - val_loss: 1.1478 - val_accuracy: 0.5897\n",
            "Epoch 1476/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6620 - accuracy: 0.7540 - val_loss: 1.0480 - val_accuracy: 0.6410\n",
            "Epoch 1477/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6096 - accuracy: 0.7702 - val_loss: 0.9836 - val_accuracy: 0.6667\n",
            "Epoch 1478/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6226 - accuracy: 0.7702 - val_loss: 0.9794 - val_accuracy: 0.7051\n",
            "Epoch 1479/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6036 - accuracy: 0.7735 - val_loss: 0.9590 - val_accuracy: 0.6795\n",
            "Epoch 1480/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6016 - accuracy: 0.7832 - val_loss: 1.0038 - val_accuracy: 0.6538\n",
            "Epoch 1481/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6393 - accuracy: 0.7443 - val_loss: 0.9855 - val_accuracy: 0.6795\n",
            "Epoch 1482/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6312 - accuracy: 0.7605 - val_loss: 1.0105 - val_accuracy: 0.6410\n",
            "Epoch 1483/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6194 - accuracy: 0.7702 - val_loss: 0.9616 - val_accuracy: 0.6923\n",
            "Epoch 1484/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6064 - accuracy: 0.7767 - val_loss: 1.0699 - val_accuracy: 0.6154\n",
            "Epoch 1485/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6192 - accuracy: 0.7573 - val_loss: 1.2040 - val_accuracy: 0.5769\n",
            "Epoch 1486/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6045 - accuracy: 0.7799 - val_loss: 1.0675 - val_accuracy: 0.6538\n",
            "Epoch 1487/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7431 - accuracy: 0.7217 - val_loss: 1.1961 - val_accuracy: 0.5769\n",
            "Epoch 1488/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6969 - accuracy: 0.7282 - val_loss: 0.9538 - val_accuracy: 0.7179\n",
            "Epoch 1489/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7298 - accuracy: 0.7282 - val_loss: 1.0634 - val_accuracy: 0.6154\n",
            "Epoch 1490/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7453 - accuracy: 0.7087 - val_loss: 0.9958 - val_accuracy: 0.6538\n",
            "Epoch 1491/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7235 - accuracy: 0.7249 - val_loss: 0.9612 - val_accuracy: 0.6667\n",
            "Epoch 1492/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6686 - accuracy: 0.7573 - val_loss: 0.9827 - val_accuracy: 0.6667\n",
            "Epoch 1493/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6568 - accuracy: 0.7670 - val_loss: 0.9631 - val_accuracy: 0.7051\n",
            "Epoch 1494/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6551 - accuracy: 0.7638 - val_loss: 0.9727 - val_accuracy: 0.6538\n",
            "Epoch 1495/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6061 - accuracy: 0.7767 - val_loss: 0.9517 - val_accuracy: 0.6667\n",
            "Epoch 1496/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6405 - accuracy: 0.7605 - val_loss: 1.0109 - val_accuracy: 0.6410\n",
            "Epoch 1497/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6702 - accuracy: 0.7573 - val_loss: 0.9822 - val_accuracy: 0.6923\n",
            "Epoch 1498/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6081 - accuracy: 0.7832 - val_loss: 0.9737 - val_accuracy: 0.6410\n",
            "Epoch 1499/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6124 - accuracy: 0.7929 - val_loss: 1.0036 - val_accuracy: 0.6667\n",
            "Epoch 1500/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5997 - accuracy: 0.7799 - val_loss: 0.9888 - val_accuracy: 0.6538\n",
            "Epoch 1501/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6263 - accuracy: 0.7573 - val_loss: 1.0588 - val_accuracy: 0.6410\n",
            "Epoch 1502/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5729 - accuracy: 0.7799 - val_loss: 1.0275 - val_accuracy: 0.6667\n",
            "Epoch 1503/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6198 - accuracy: 0.7832 - val_loss: 1.0108 - val_accuracy: 0.6410\n",
            "Epoch 1504/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6126 - accuracy: 0.7799 - val_loss: 0.9699 - val_accuracy: 0.6667\n",
            "Epoch 1505/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6347 - accuracy: 0.7573 - val_loss: 0.9502 - val_accuracy: 0.6923\n",
            "Epoch 1506/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6443 - accuracy: 0.7508 - val_loss: 0.9526 - val_accuracy: 0.6538\n",
            "Epoch 1507/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6611 - accuracy: 0.7573 - val_loss: 0.9749 - val_accuracy: 0.6923\n",
            "Epoch 1508/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6582 - accuracy: 0.7573 - val_loss: 1.0542 - val_accuracy: 0.6410\n",
            "Epoch 1509/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6708 - accuracy: 0.7508 - val_loss: 1.2014 - val_accuracy: 0.5897\n",
            "Epoch 1510/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6869 - accuracy: 0.7508 - val_loss: 1.3034 - val_accuracy: 0.5897\n",
            "Epoch 1511/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7562 - accuracy: 0.7087 - val_loss: 1.2624 - val_accuracy: 0.5897\n",
            "Epoch 1512/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8270 - accuracy: 0.6828 - val_loss: 0.9447 - val_accuracy: 0.7179\n",
            "Epoch 1513/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7391 - accuracy: 0.7314 - val_loss: 1.0050 - val_accuracy: 0.6410\n",
            "Epoch 1514/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6961 - accuracy: 0.7379 - val_loss: 1.0097 - val_accuracy: 0.6282\n",
            "Epoch 1515/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6491 - accuracy: 0.7605 - val_loss: 1.0068 - val_accuracy: 0.6410\n",
            "Epoch 1516/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6427 - accuracy: 0.7476 - val_loss: 0.9758 - val_accuracy: 0.6538\n",
            "Epoch 1517/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6220 - accuracy: 0.7670 - val_loss: 1.0471 - val_accuracy: 0.6282\n",
            "Epoch 1518/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6242 - accuracy: 0.7605 - val_loss: 1.0048 - val_accuracy: 0.6667\n",
            "Epoch 1519/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5947 - accuracy: 0.7961 - val_loss: 1.0561 - val_accuracy: 0.6410\n",
            "Epoch 1520/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6064 - accuracy: 0.7799 - val_loss: 1.0532 - val_accuracy: 0.6154\n",
            "Epoch 1521/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.6103 - accuracy: 0.7735 - val_loss: 0.9800 - val_accuracy: 0.6795\n",
            "Epoch 1522/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5915 - accuracy: 0.7929 - val_loss: 0.9677 - val_accuracy: 0.6667\n",
            "Epoch 1523/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6795 - accuracy: 0.7379 - val_loss: 0.9762 - val_accuracy: 0.6538\n",
            "Epoch 1524/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6354 - accuracy: 0.7832 - val_loss: 0.9726 - val_accuracy: 0.7051\n",
            "Epoch 1525/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6106 - accuracy: 0.7702 - val_loss: 0.9879 - val_accuracy: 0.6282\n",
            "Epoch 1526/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6552 - accuracy: 0.7282 - val_loss: 1.0062 - val_accuracy: 0.6282\n",
            "Epoch 1527/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6735 - accuracy: 0.7411 - val_loss: 0.9360 - val_accuracy: 0.6795\n",
            "Epoch 1528/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6666 - accuracy: 0.7540 - val_loss: 0.9945 - val_accuracy: 0.6667\n",
            "Epoch 1529/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6071 - accuracy: 0.7670 - val_loss: 0.9543 - val_accuracy: 0.6795\n",
            "Epoch 1530/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6082 - accuracy: 0.7605 - val_loss: 1.0417 - val_accuracy: 0.6154\n",
            "Epoch 1531/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6007 - accuracy: 0.7638 - val_loss: 1.0992 - val_accuracy: 0.6154\n",
            "Epoch 1532/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6150 - accuracy: 0.7832 - val_loss: 0.9769 - val_accuracy: 0.6667\n",
            "Epoch 1533/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6028 - accuracy: 0.7799 - val_loss: 0.9652 - val_accuracy: 0.6923\n",
            "Epoch 1534/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6119 - accuracy: 0.7540 - val_loss: 0.9761 - val_accuracy: 0.6667\n",
            "Epoch 1535/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6274 - accuracy: 0.7702 - val_loss: 0.9749 - val_accuracy: 0.6667\n",
            "Epoch 1536/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5923 - accuracy: 0.7929 - val_loss: 0.9729 - val_accuracy: 0.6667\n",
            "Epoch 1537/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5750 - accuracy: 0.7799 - val_loss: 0.9825 - val_accuracy: 0.6667\n",
            "Epoch 1538/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6122 - accuracy: 0.7735 - val_loss: 0.9544 - val_accuracy: 0.6923\n",
            "Epoch 1539/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6128 - accuracy: 0.7443 - val_loss: 0.9770 - val_accuracy: 0.7051\n",
            "Epoch 1540/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6067 - accuracy: 0.7573 - val_loss: 1.0406 - val_accuracy: 0.6667\n",
            "Epoch 1541/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5985 - accuracy: 0.7767 - val_loss: 1.0956 - val_accuracy: 0.6538\n",
            "Epoch 1542/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6579 - accuracy: 0.7670 - val_loss: 1.3444 - val_accuracy: 0.6026\n",
            "Epoch 1543/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7079 - accuracy: 0.7346 - val_loss: 1.0243 - val_accuracy: 0.6538\n",
            "Epoch 1544/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6125 - accuracy: 0.7638 - val_loss: 1.0888 - val_accuracy: 0.6282\n",
            "Epoch 1545/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6067 - accuracy: 0.7443 - val_loss: 1.0996 - val_accuracy: 0.6026\n",
            "Epoch 1546/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6344 - accuracy: 0.7605 - val_loss: 0.9390 - val_accuracy: 0.6923\n",
            "Epoch 1547/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6133 - accuracy: 0.7573 - val_loss: 1.0579 - val_accuracy: 0.6154\n",
            "Epoch 1548/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6176 - accuracy: 0.7735 - val_loss: 0.9779 - val_accuracy: 0.6538\n",
            "Epoch 1549/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6171 - accuracy: 0.7702 - val_loss: 0.9847 - val_accuracy: 0.6667\n",
            "Epoch 1550/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6023 - accuracy: 0.7605 - val_loss: 0.9538 - val_accuracy: 0.7308\n",
            "Epoch 1551/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6007 - accuracy: 0.7864 - val_loss: 0.9994 - val_accuracy: 0.6410\n",
            "Epoch 1552/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6623 - accuracy: 0.7476 - val_loss: 1.0304 - val_accuracy: 0.6667\n",
            "Epoch 1553/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6063 - accuracy: 0.7896 - val_loss: 1.0699 - val_accuracy: 0.6795\n",
            "Epoch 1554/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6161 - accuracy: 0.7605 - val_loss: 1.0559 - val_accuracy: 0.6026\n",
            "Epoch 1555/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6362 - accuracy: 0.7508 - val_loss: 1.0083 - val_accuracy: 0.6667\n",
            "Epoch 1556/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5807 - accuracy: 0.7670 - val_loss: 1.1163 - val_accuracy: 0.6026\n",
            "Epoch 1557/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6280 - accuracy: 0.7605 - val_loss: 1.1081 - val_accuracy: 0.6154\n",
            "Epoch 1558/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6274 - accuracy: 0.7735 - val_loss: 1.0319 - val_accuracy: 0.6538\n",
            "Epoch 1559/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5680 - accuracy: 0.7832 - val_loss: 1.0021 - val_accuracy: 0.6410\n",
            "Epoch 1560/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5864 - accuracy: 0.7832 - val_loss: 0.9625 - val_accuracy: 0.7179\n",
            "Epoch 1561/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6036 - accuracy: 0.7864 - val_loss: 1.1143 - val_accuracy: 0.5769\n",
            "Epoch 1562/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6193 - accuracy: 0.7540 - val_loss: 0.9638 - val_accuracy: 0.7179\n",
            "Epoch 1563/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6462 - accuracy: 0.7508 - val_loss: 0.9955 - val_accuracy: 0.6667\n",
            "Epoch 1564/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6262 - accuracy: 0.7540 - val_loss: 1.0714 - val_accuracy: 0.5897\n",
            "Epoch 1565/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5927 - accuracy: 0.7702 - val_loss: 0.9637 - val_accuracy: 0.6795\n",
            "Epoch 1566/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5975 - accuracy: 0.7702 - val_loss: 0.9953 - val_accuracy: 0.6282\n",
            "Epoch 1567/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5740 - accuracy: 0.7864 - val_loss: 0.9748 - val_accuracy: 0.6795\n",
            "Epoch 1568/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6004 - accuracy: 0.7864 - val_loss: 1.0039 - val_accuracy: 0.6410\n",
            "Epoch 1569/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6124 - accuracy: 0.7670 - val_loss: 0.9956 - val_accuracy: 0.7051\n",
            "Epoch 1570/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5863 - accuracy: 0.7767 - val_loss: 1.1162 - val_accuracy: 0.6410\n",
            "Epoch 1571/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6251 - accuracy: 0.7832 - val_loss: 1.0436 - val_accuracy: 0.6538\n",
            "Epoch 1572/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6333 - accuracy: 0.7605 - val_loss: 0.9532 - val_accuracy: 0.6667\n",
            "Epoch 1573/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5798 - accuracy: 0.7767 - val_loss: 1.0262 - val_accuracy: 0.6026\n",
            "Epoch 1574/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6110 - accuracy: 0.7540 - val_loss: 1.0144 - val_accuracy: 0.6667\n",
            "Epoch 1575/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6197 - accuracy: 0.7540 - val_loss: 0.9948 - val_accuracy: 0.6667\n",
            "Epoch 1576/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6162 - accuracy: 0.7864 - val_loss: 1.1249 - val_accuracy: 0.6154\n",
            "Epoch 1577/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6830 - accuracy: 0.7346 - val_loss: 0.9560 - val_accuracy: 0.6795\n",
            "Epoch 1578/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6777 - accuracy: 0.7249 - val_loss: 1.0128 - val_accuracy: 0.6795\n",
            "Epoch 1579/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6722 - accuracy: 0.7282 - val_loss: 1.0022 - val_accuracy: 0.6795\n",
            "Epoch 1580/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6179 - accuracy: 0.7735 - val_loss: 0.9606 - val_accuracy: 0.6923\n",
            "Epoch 1581/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5936 - accuracy: 0.7832 - val_loss: 0.9881 - val_accuracy: 0.6795\n",
            "Epoch 1582/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6118 - accuracy: 0.7670 - val_loss: 0.9693 - val_accuracy: 0.6667\n",
            "Epoch 1583/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5879 - accuracy: 0.7508 - val_loss: 1.0878 - val_accuracy: 0.6538\n",
            "Epoch 1584/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5591 - accuracy: 0.8058 - val_loss: 1.0004 - val_accuracy: 0.6795\n",
            "Epoch 1585/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6042 - accuracy: 0.7735 - val_loss: 0.9719 - val_accuracy: 0.6667\n",
            "Epoch 1586/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6536 - accuracy: 0.7346 - val_loss: 0.9481 - val_accuracy: 0.6667\n",
            "Epoch 1587/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6631 - accuracy: 0.7799 - val_loss: 1.0577 - val_accuracy: 0.6282\n",
            "Epoch 1588/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6520 - accuracy: 0.7670 - val_loss: 1.0531 - val_accuracy: 0.6538\n",
            "Epoch 1589/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6997 - accuracy: 0.7411 - val_loss: 0.9945 - val_accuracy: 0.6923\n",
            "Epoch 1590/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6349 - accuracy: 0.7670 - val_loss: 1.0396 - val_accuracy: 0.6538\n",
            "Epoch 1591/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6358 - accuracy: 0.7573 - val_loss: 1.2429 - val_accuracy: 0.6026\n",
            "Epoch 1592/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7227 - accuracy: 0.7379 - val_loss: 1.0777 - val_accuracy: 0.6795\n",
            "Epoch 1593/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6548 - accuracy: 0.7476 - val_loss: 1.7198 - val_accuracy: 0.4744\n",
            "Epoch 1594/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7701 - accuracy: 0.7217 - val_loss: 1.1538 - val_accuracy: 0.6282\n",
            "Epoch 1595/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6469 - accuracy: 0.7443 - val_loss: 1.0732 - val_accuracy: 0.6154\n",
            "Epoch 1596/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6151 - accuracy: 0.7540 - val_loss: 0.9753 - val_accuracy: 0.6795\n",
            "Epoch 1597/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5742 - accuracy: 0.7864 - val_loss: 1.0051 - val_accuracy: 0.6282\n",
            "Epoch 1598/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6291 - accuracy: 0.7638 - val_loss: 0.9657 - val_accuracy: 0.6538\n",
            "Epoch 1599/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6106 - accuracy: 0.7799 - val_loss: 0.9739 - val_accuracy: 0.6923\n",
            "Epoch 1600/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6082 - accuracy: 0.7832 - val_loss: 0.9729 - val_accuracy: 0.6667\n",
            "Epoch 1601/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5587 - accuracy: 0.7961 - val_loss: 1.1089 - val_accuracy: 0.6154\n",
            "Epoch 1602/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5978 - accuracy: 0.7540 - val_loss: 1.0720 - val_accuracy: 0.6154\n",
            "Epoch 1603/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6054 - accuracy: 0.7702 - val_loss: 1.0503 - val_accuracy: 0.6282\n",
            "Epoch 1604/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6194 - accuracy: 0.7735 - val_loss: 1.0607 - val_accuracy: 0.6410\n",
            "Epoch 1605/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5704 - accuracy: 0.7702 - val_loss: 1.0837 - val_accuracy: 0.6282\n",
            "Epoch 1606/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5896 - accuracy: 0.7638 - val_loss: 0.9801 - val_accuracy: 0.6795\n",
            "Epoch 1607/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6001 - accuracy: 0.7767 - val_loss: 0.9434 - val_accuracy: 0.6667\n",
            "Epoch 1608/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6091 - accuracy: 0.7832 - val_loss: 0.9552 - val_accuracy: 0.6795\n",
            "Epoch 1609/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5803 - accuracy: 0.7767 - val_loss: 1.0041 - val_accuracy: 0.6923\n",
            "Epoch 1610/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5945 - accuracy: 0.7799 - val_loss: 0.9598 - val_accuracy: 0.6923\n",
            "Epoch 1611/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6139 - accuracy: 0.7670 - val_loss: 0.9561 - val_accuracy: 0.7051\n",
            "Epoch 1612/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5866 - accuracy: 0.7864 - val_loss: 1.1745 - val_accuracy: 0.6282\n",
            "Epoch 1613/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6210 - accuracy: 0.7605 - val_loss: 0.9685 - val_accuracy: 0.6667\n",
            "Epoch 1614/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5959 - accuracy: 0.7540 - val_loss: 0.9708 - val_accuracy: 0.6923\n",
            "Epoch 1615/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5528 - accuracy: 0.7864 - val_loss: 0.9913 - val_accuracy: 0.6538\n",
            "Epoch 1616/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6105 - accuracy: 0.7702 - val_loss: 1.0692 - val_accuracy: 0.6282\n",
            "Epoch 1617/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5635 - accuracy: 0.7864 - val_loss: 0.9929 - val_accuracy: 0.6538\n",
            "Epoch 1618/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5790 - accuracy: 0.7864 - val_loss: 0.9568 - val_accuracy: 0.7051\n",
            "Epoch 1619/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6168 - accuracy: 0.7540 - val_loss: 0.9636 - val_accuracy: 0.7051\n",
            "Epoch 1620/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5784 - accuracy: 0.8091 - val_loss: 0.9571 - val_accuracy: 0.7051\n",
            "Epoch 1621/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5635 - accuracy: 0.7994 - val_loss: 1.0495 - val_accuracy: 0.6410\n",
            "Epoch 1622/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6975 - accuracy: 0.7314 - val_loss: 0.9811 - val_accuracy: 0.6154\n",
            "Epoch 1623/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6154 - accuracy: 0.7540 - val_loss: 1.0413 - val_accuracy: 0.6538\n",
            "Epoch 1624/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6410 - accuracy: 0.7702 - val_loss: 0.9569 - val_accuracy: 0.6923\n",
            "Epoch 1625/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6078 - accuracy: 0.7605 - val_loss: 0.9824 - val_accuracy: 0.6923\n",
            "Epoch 1626/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5974 - accuracy: 0.7832 - val_loss: 0.9743 - val_accuracy: 0.6667\n",
            "Epoch 1627/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6213 - accuracy: 0.7735 - val_loss: 0.9450 - val_accuracy: 0.6667\n",
            "Epoch 1628/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5698 - accuracy: 0.7799 - val_loss: 1.0588 - val_accuracy: 0.6154\n",
            "Epoch 1629/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6546 - accuracy: 0.7411 - val_loss: 1.0412 - val_accuracy: 0.6282\n",
            "Epoch 1630/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6715 - accuracy: 0.7411 - val_loss: 0.9648 - val_accuracy: 0.6923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hdE6EQfZ6tU"
      },
      "source": [
        "### Evaluation and Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gLH2mdEZ74z",
        "outputId": "de95efac-5fc7-484d-868d-47cffbff7ff1"
      },
      "source": [
        "# Evaluate our model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Model loss on the test set: {loss}\")\n",
        "print(f\"Model accuracy on the test set: {100*accuracy:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 5ms/step - loss: 0.7197 - accuracy: 0.6795\n",
            "Model loss on the test set: 0.719667375087738\n",
            "Model accuracy on the test set: 67.95%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Zr5zUN7waFYr",
        "outputId": "50263b10-b21f-4e76-f8d8-5d918364ec37"
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history_1.history['loss'])#[5:])\n",
        "plt.plot(history_1.history['val_loss'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Ol8la_eiaHBH",
        "outputId": "ee6e2ec8-e0dd-4d21-9c30-1fb1c2f89cc1"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history_1.history['accuracy'])#[5:])\n",
        "plt.plot(history_1.history['val_accuracy'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Binary Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpjBSazcc9L9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvLBB1x4c9g2"
      },
      "source": [
        "## Model 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTEe3fbAc9g3"
      },
      "source": [
        "### Declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd08u9vRc9g3"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model_2 = keras.Sequential([\n",
        "    layers.Dense(512, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(256, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(128, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(8, activation='softmax')\n",
        "])\n",
        "\n",
        "model_2.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate = .0003),\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    patience=250,\n",
        "    min_delta=0.0001,\n",
        "    restore_best_weights=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUgoNB_Ic9g3"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHPgDrOyc9g4",
        "outputId": "fc659d1f-5157-4cea-bf9c-8a0cca3b73cd"
      },
      "source": [
        "history_2 = model_2.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=2000,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1, \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "10/10 [==============================] - 1s 40ms/step - loss: 2.3370 - accuracy: 0.1197 - val_loss: 2.0476 - val_accuracy: 0.1923\n",
            "Epoch 2/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.1680 - accuracy: 0.1521 - val_loss: 2.0481 - val_accuracy: 0.2308\n",
            "Epoch 3/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.0783 - accuracy: 0.1748 - val_loss: 2.0494 - val_accuracy: 0.2179\n",
            "Epoch 4/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.0566 - accuracy: 0.1877 - val_loss: 2.0518 - val_accuracy: 0.2179\n",
            "Epoch 5/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.0354 - accuracy: 0.1974 - val_loss: 2.0357 - val_accuracy: 0.2179\n",
            "Epoch 6/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 2.0093 - accuracy: 0.2136 - val_loss: 2.0471 - val_accuracy: 0.2179\n",
            "Epoch 7/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 2.0490 - accuracy: 0.1942 - val_loss: 2.0366 - val_accuracy: 0.2051\n",
            "Epoch 8/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.0294 - accuracy: 0.2071 - val_loss: 2.0210 - val_accuracy: 0.2179\n",
            "Epoch 9/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.0306 - accuracy: 0.1618 - val_loss: 2.0315 - val_accuracy: 0.2179\n",
            "Epoch 10/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 2.0132 - accuracy: 0.1715 - val_loss: 2.0334 - val_accuracy: 0.1667\n",
            "Epoch 11/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.9519 - accuracy: 0.2168 - val_loss: 2.0289 - val_accuracy: 0.1410\n",
            "Epoch 12/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.0298 - accuracy: 0.2298 - val_loss: 2.0057 - val_accuracy: 0.0897\n",
            "Epoch 13/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.9677 - accuracy: 0.2136 - val_loss: 1.9988 - val_accuracy: 0.1282\n",
            "Epoch 14/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.9634 - accuracy: 0.2039 - val_loss: 1.9680 - val_accuracy: 0.2051\n",
            "Epoch 15/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.9597 - accuracy: 0.1942 - val_loss: 1.9811 - val_accuracy: 0.1538\n",
            "Epoch 16/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.9563 - accuracy: 0.1942 - val_loss: 1.9999 - val_accuracy: 0.1026\n",
            "Epoch 17/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.9493 - accuracy: 0.1715 - val_loss: 1.9905 - val_accuracy: 0.1410\n",
            "Epoch 18/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.9941 - accuracy: 0.1877 - val_loss: 1.9841 - val_accuracy: 0.1154\n",
            "Epoch 19/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.9127 - accuracy: 0.2104 - val_loss: 1.9805 - val_accuracy: 0.1026\n",
            "Epoch 20/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.9606 - accuracy: 0.1845 - val_loss: 1.9634 - val_accuracy: 0.1026\n",
            "Epoch 21/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8969 - accuracy: 0.2006 - val_loss: 1.9297 - val_accuracy: 0.1538\n",
            "Epoch 22/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8828 - accuracy: 0.2298 - val_loss: 1.9449 - val_accuracy: 0.1282\n",
            "Epoch 23/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8956 - accuracy: 0.2006 - val_loss: 1.9270 - val_accuracy: 0.1538\n",
            "Epoch 24/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8748 - accuracy: 0.2265 - val_loss: 1.9051 - val_accuracy: 0.1667\n",
            "Epoch 25/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8933 - accuracy: 0.2168 - val_loss: 1.9244 - val_accuracy: 0.1026\n",
            "Epoch 26/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8906 - accuracy: 0.2168 - val_loss: 1.9158 - val_accuracy: 0.1410\n",
            "Epoch 27/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8666 - accuracy: 0.2201 - val_loss: 1.9138 - val_accuracy: 0.1538\n",
            "Epoch 28/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.9205 - accuracy: 0.1748 - val_loss: 1.9072 - val_accuracy: 0.2436\n",
            "Epoch 29/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.9226 - accuracy: 0.2201 - val_loss: 1.9167 - val_accuracy: 0.2308\n",
            "Epoch 30/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8680 - accuracy: 0.2136 - val_loss: 1.9103 - val_accuracy: 0.2179\n",
            "Epoch 31/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8774 - accuracy: 0.2201 - val_loss: 1.9210 - val_accuracy: 0.1538\n",
            "Epoch 32/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8649 - accuracy: 0.2136 - val_loss: 1.9093 - val_accuracy: 0.1282\n",
            "Epoch 33/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8438 - accuracy: 0.2265 - val_loss: 1.9031 - val_accuracy: 0.1538\n",
            "Epoch 34/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8799 - accuracy: 0.2395 - val_loss: 1.8929 - val_accuracy: 0.1667\n",
            "Epoch 35/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8700 - accuracy: 0.1845 - val_loss: 1.8907 - val_accuracy: 0.1410\n",
            "Epoch 36/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8592 - accuracy: 0.2168 - val_loss: 1.8935 - val_accuracy: 0.1538\n",
            "Epoch 37/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8707 - accuracy: 0.2298 - val_loss: 1.8887 - val_accuracy: 0.1667\n",
            "Epoch 38/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8500 - accuracy: 0.2233 - val_loss: 1.8715 - val_accuracy: 0.1667\n",
            "Epoch 39/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8324 - accuracy: 0.2265 - val_loss: 1.8643 - val_accuracy: 0.1538\n",
            "Epoch 40/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8303 - accuracy: 0.2460 - val_loss: 1.8680 - val_accuracy: 0.1282\n",
            "Epoch 41/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8665 - accuracy: 0.2427 - val_loss: 1.8712 - val_accuracy: 0.1410\n",
            "Epoch 42/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8463 - accuracy: 0.2039 - val_loss: 1.8756 - val_accuracy: 0.1282\n",
            "Epoch 43/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8120 - accuracy: 0.2395 - val_loss: 1.8550 - val_accuracy: 0.1667\n",
            "Epoch 44/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8423 - accuracy: 0.2071 - val_loss: 1.8528 - val_accuracy: 0.1795\n",
            "Epoch 45/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.8583 - accuracy: 0.2006 - val_loss: 1.8615 - val_accuracy: 0.1282\n",
            "Epoch 46/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8398 - accuracy: 0.2104 - val_loss: 1.8739 - val_accuracy: 0.1410\n",
            "Epoch 47/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8332 - accuracy: 0.2298 - val_loss: 1.8700 - val_accuracy: 0.1538\n",
            "Epoch 48/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8207 - accuracy: 0.2298 - val_loss: 1.8542 - val_accuracy: 0.1538\n",
            "Epoch 49/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8166 - accuracy: 0.2298 - val_loss: 1.8283 - val_accuracy: 0.1795\n",
            "Epoch 50/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8146 - accuracy: 0.2718 - val_loss: 1.8304 - val_accuracy: 0.1795\n",
            "Epoch 51/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8167 - accuracy: 0.2104 - val_loss: 1.8391 - val_accuracy: 0.1923\n",
            "Epoch 52/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8287 - accuracy: 0.2071 - val_loss: 1.8451 - val_accuracy: 0.1795\n",
            "Epoch 53/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8116 - accuracy: 0.2460 - val_loss: 1.8578 - val_accuracy: 0.1538\n",
            "Epoch 54/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7941 - accuracy: 0.2298 - val_loss: 1.8376 - val_accuracy: 0.1795\n",
            "Epoch 55/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8180 - accuracy: 0.2201 - val_loss: 1.8336 - val_accuracy: 0.1923\n",
            "Epoch 56/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8088 - accuracy: 0.2298 - val_loss: 1.8427 - val_accuracy: 0.1795\n",
            "Epoch 57/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8114 - accuracy: 0.1974 - val_loss: 1.8475 - val_accuracy: 0.1410\n",
            "Epoch 58/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8218 - accuracy: 0.1845 - val_loss: 1.8416 - val_accuracy: 0.1795\n",
            "Epoch 59/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8322 - accuracy: 0.2362 - val_loss: 1.8415 - val_accuracy: 0.1282\n",
            "Epoch 60/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8207 - accuracy: 0.2427 - val_loss: 1.8389 - val_accuracy: 0.1538\n",
            "Epoch 61/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8372 - accuracy: 0.2265 - val_loss: 1.8517 - val_accuracy: 0.1538\n",
            "Epoch 62/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8118 - accuracy: 0.2168 - val_loss: 1.8526 - val_accuracy: 0.1538\n",
            "Epoch 63/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8091 - accuracy: 0.2298 - val_loss: 1.8424 - val_accuracy: 0.1538\n",
            "Epoch 64/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7983 - accuracy: 0.2265 - val_loss: 1.8383 - val_accuracy: 0.1410\n",
            "Epoch 65/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7999 - accuracy: 0.2233 - val_loss: 1.8365 - val_accuracy: 0.1410\n",
            "Epoch 66/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8376 - accuracy: 0.2006 - val_loss: 1.8380 - val_accuracy: 0.1667\n",
            "Epoch 67/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.8140 - accuracy: 0.2168 - val_loss: 1.8438 - val_accuracy: 0.1410\n",
            "Epoch 68/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8207 - accuracy: 0.2071 - val_loss: 1.8326 - val_accuracy: 0.1410\n",
            "Epoch 69/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8015 - accuracy: 0.2265 - val_loss: 1.8360 - val_accuracy: 0.1282\n",
            "Epoch 70/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7945 - accuracy: 0.2460 - val_loss: 1.8372 - val_accuracy: 0.1154\n",
            "Epoch 71/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8369 - accuracy: 0.2395 - val_loss: 1.8280 - val_accuracy: 0.1282\n",
            "Epoch 72/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.7985 - accuracy: 0.2330 - val_loss: 1.8232 - val_accuracy: 0.1667\n",
            "Epoch 73/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8011 - accuracy: 0.2168 - val_loss: 1.8319 - val_accuracy: 0.1667\n",
            "Epoch 74/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.7781 - accuracy: 0.2168 - val_loss: 1.8321 - val_accuracy: 0.1282\n",
            "Epoch 75/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7857 - accuracy: 0.2330 - val_loss: 1.8293 - val_accuracy: 0.1538\n",
            "Epoch 76/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7640 - accuracy: 0.2654 - val_loss: 1.8312 - val_accuracy: 0.1795\n",
            "Epoch 77/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.7889 - accuracy: 0.2718 - val_loss: 1.8377 - val_accuracy: 0.1410\n",
            "Epoch 78/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8264 - accuracy: 0.2168 - val_loss: 1.8301 - val_accuracy: 0.1410\n",
            "Epoch 79/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7783 - accuracy: 0.2330 - val_loss: 1.8156 - val_accuracy: 0.1410\n",
            "Epoch 80/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7880 - accuracy: 0.2168 - val_loss: 1.8125 - val_accuracy: 0.1538\n",
            "Epoch 81/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7949 - accuracy: 0.2492 - val_loss: 1.8157 - val_accuracy: 0.1538\n",
            "Epoch 82/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.7827 - accuracy: 0.2718 - val_loss: 1.8181 - val_accuracy: 0.1538\n",
            "Epoch 83/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7801 - accuracy: 0.2427 - val_loss: 1.8154 - val_accuracy: 0.1538\n",
            "Epoch 84/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7835 - accuracy: 0.2589 - val_loss: 1.8087 - val_accuracy: 0.1538\n",
            "Epoch 85/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7828 - accuracy: 0.2492 - val_loss: 1.8077 - val_accuracy: 0.1410\n",
            "Epoch 86/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7772 - accuracy: 0.2460 - val_loss: 1.8090 - val_accuracy: 0.1667\n",
            "Epoch 87/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7535 - accuracy: 0.2492 - val_loss: 1.8031 - val_accuracy: 0.1667\n",
            "Epoch 88/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7541 - accuracy: 0.2265 - val_loss: 1.8083 - val_accuracy: 0.1538\n",
            "Epoch 89/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7758 - accuracy: 0.2686 - val_loss: 1.8184 - val_accuracy: 0.1410\n",
            "Epoch 90/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7759 - accuracy: 0.2621 - val_loss: 1.7812 - val_accuracy: 0.1667\n",
            "Epoch 91/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7724 - accuracy: 0.2395 - val_loss: 1.7989 - val_accuracy: 0.1667\n",
            "Epoch 92/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7754 - accuracy: 0.2557 - val_loss: 1.7977 - val_accuracy: 0.1538\n",
            "Epoch 93/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7790 - accuracy: 0.2460 - val_loss: 1.7981 - val_accuracy: 0.1538\n",
            "Epoch 94/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7581 - accuracy: 0.2330 - val_loss: 1.7854 - val_accuracy: 0.1667\n",
            "Epoch 95/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7896 - accuracy: 0.2524 - val_loss: 1.7967 - val_accuracy: 0.1538\n",
            "Epoch 96/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7939 - accuracy: 0.2362 - val_loss: 1.8069 - val_accuracy: 0.1538\n",
            "Epoch 97/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7590 - accuracy: 0.2654 - val_loss: 1.7782 - val_accuracy: 0.1667\n",
            "Epoch 98/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7483 - accuracy: 0.2751 - val_loss: 1.7648 - val_accuracy: 0.1923\n",
            "Epoch 99/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.7796 - accuracy: 0.2492 - val_loss: 1.7601 - val_accuracy: 0.2436\n",
            "Epoch 100/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7538 - accuracy: 0.2557 - val_loss: 1.7380 - val_accuracy: 0.2821\n",
            "Epoch 101/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7569 - accuracy: 0.2557 - val_loss: 1.7582 - val_accuracy: 0.1667\n",
            "Epoch 102/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7362 - accuracy: 0.2880 - val_loss: 1.7545 - val_accuracy: 0.2821\n",
            "Epoch 103/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7666 - accuracy: 0.2589 - val_loss: 1.7670 - val_accuracy: 0.2564\n",
            "Epoch 104/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7616 - accuracy: 0.2816 - val_loss: 1.7822 - val_accuracy: 0.1795\n",
            "Epoch 105/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7796 - accuracy: 0.2557 - val_loss: 1.7545 - val_accuracy: 0.2308\n",
            "Epoch 106/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7228 - accuracy: 0.2913 - val_loss: 1.7606 - val_accuracy: 0.1923\n",
            "Epoch 107/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7445 - accuracy: 0.2589 - val_loss: 1.7643 - val_accuracy: 0.1410\n",
            "Epoch 108/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7266 - accuracy: 0.3301 - val_loss: 1.7406 - val_accuracy: 0.1923\n",
            "Epoch 109/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7335 - accuracy: 0.3301 - val_loss: 1.7224 - val_accuracy: 0.2179\n",
            "Epoch 110/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7161 - accuracy: 0.2751 - val_loss: 1.7063 - val_accuracy: 0.2821\n",
            "Epoch 111/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7065 - accuracy: 0.2945 - val_loss: 1.7000 - val_accuracy: 0.2692\n",
            "Epoch 112/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7156 - accuracy: 0.3172 - val_loss: 1.6986 - val_accuracy: 0.2179\n",
            "Epoch 113/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7577 - accuracy: 0.2848 - val_loss: 1.6848 - val_accuracy: 0.2949\n",
            "Epoch 114/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.7049 - accuracy: 0.3042 - val_loss: 1.6621 - val_accuracy: 0.3205\n",
            "Epoch 115/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.7076 - accuracy: 0.3074 - val_loss: 1.7154 - val_accuracy: 0.2436\n",
            "Epoch 116/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.7017 - accuracy: 0.3269 - val_loss: 1.6580 - val_accuracy: 0.3205\n",
            "Epoch 117/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.6712 - accuracy: 0.3301 - val_loss: 1.7175 - val_accuracy: 0.2308\n",
            "Epoch 118/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.6832 - accuracy: 0.3010 - val_loss: 1.6368 - val_accuracy: 0.2949\n",
            "Epoch 119/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.6379 - accuracy: 0.3333 - val_loss: 1.6348 - val_accuracy: 0.3077\n",
            "Epoch 120/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.6569 - accuracy: 0.3398 - val_loss: 1.6340 - val_accuracy: 0.3077\n",
            "Epoch 121/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.6054 - accuracy: 0.3366 - val_loss: 1.6162 - val_accuracy: 0.3077\n",
            "Epoch 122/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.6415 - accuracy: 0.3269 - val_loss: 1.6614 - val_accuracy: 0.3333\n",
            "Epoch 123/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5978 - accuracy: 0.3592 - val_loss: 1.5114 - val_accuracy: 0.3205\n",
            "Epoch 124/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6324 - accuracy: 0.3236 - val_loss: 1.4859 - val_accuracy: 0.3333\n",
            "Epoch 125/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.5781 - accuracy: 0.3657 - val_loss: 1.5389 - val_accuracy: 0.3077\n",
            "Epoch 126/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5833 - accuracy: 0.3366 - val_loss: 1.4828 - val_accuracy: 0.3205\n",
            "Epoch 127/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.6167 - accuracy: 0.3689 - val_loss: 1.4845 - val_accuracy: 0.3590\n",
            "Epoch 128/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5634 - accuracy: 0.3819 - val_loss: 1.4822 - val_accuracy: 0.3205\n",
            "Epoch 129/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.6097 - accuracy: 0.3722 - val_loss: 1.4871 - val_accuracy: 0.3333\n",
            "Epoch 130/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.5143 - accuracy: 0.3819 - val_loss: 1.4837 - val_accuracy: 0.3205\n",
            "Epoch 131/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.5350 - accuracy: 0.3625 - val_loss: 1.4468 - val_accuracy: 0.3590\n",
            "Epoch 132/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5049 - accuracy: 0.3981 - val_loss: 1.4545 - val_accuracy: 0.3333\n",
            "Epoch 133/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4767 - accuracy: 0.3981 - val_loss: 1.4462 - val_accuracy: 0.3333\n",
            "Epoch 134/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.4941 - accuracy: 0.3657 - val_loss: 1.4118 - val_accuracy: 0.3462\n",
            "Epoch 135/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5277 - accuracy: 0.3657 - val_loss: 1.4440 - val_accuracy: 0.3590\n",
            "Epoch 136/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4565 - accuracy: 0.3948 - val_loss: 1.4291 - val_accuracy: 0.3205\n",
            "Epoch 137/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.4505 - accuracy: 0.4045 - val_loss: 1.4011 - val_accuracy: 0.3333\n",
            "Epoch 138/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4284 - accuracy: 0.4239 - val_loss: 1.4173 - val_accuracy: 0.3205\n",
            "Epoch 139/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4443 - accuracy: 0.3883 - val_loss: 1.4344 - val_accuracy: 0.3333\n",
            "Epoch 140/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4924 - accuracy: 0.3560 - val_loss: 1.3979 - val_accuracy: 0.3462\n",
            "Epoch 141/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.4623 - accuracy: 0.3851 - val_loss: 1.3945 - val_accuracy: 0.3462\n",
            "Epoch 142/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4550 - accuracy: 0.4078 - val_loss: 1.4803 - val_accuracy: 0.2949\n",
            "Epoch 143/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.5422 - accuracy: 0.3301 - val_loss: 1.4113 - val_accuracy: 0.3590\n",
            "Epoch 144/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4708 - accuracy: 0.3851 - val_loss: 1.4357 - val_accuracy: 0.3205\n",
            "Epoch 145/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4098 - accuracy: 0.4110 - val_loss: 1.4157 - val_accuracy: 0.3333\n",
            "Epoch 146/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4094 - accuracy: 0.4207 - val_loss: 1.3901 - val_accuracy: 0.3333\n",
            "Epoch 147/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.4138 - accuracy: 0.4013 - val_loss: 1.3894 - val_accuracy: 0.3718\n",
            "Epoch 148/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4240 - accuracy: 0.4013 - val_loss: 1.3781 - val_accuracy: 0.3462\n",
            "Epoch 149/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.4424 - accuracy: 0.4175 - val_loss: 1.4324 - val_accuracy: 0.3590\n",
            "Epoch 150/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4552 - accuracy: 0.3786 - val_loss: 1.4212 - val_accuracy: 0.3333\n",
            "Epoch 151/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.5278 - accuracy: 0.3722 - val_loss: 1.6025 - val_accuracy: 0.3077\n",
            "Epoch 152/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4625 - accuracy: 0.3786 - val_loss: 1.3966 - val_accuracy: 0.3462\n",
            "Epoch 153/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4351 - accuracy: 0.3819 - val_loss: 1.4338 - val_accuracy: 0.3205\n",
            "Epoch 154/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.4505 - accuracy: 0.3592 - val_loss: 1.3841 - val_accuracy: 0.3333\n",
            "Epoch 155/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3680 - accuracy: 0.4142 - val_loss: 1.3340 - val_accuracy: 0.3462\n",
            "Epoch 156/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.4000 - accuracy: 0.4142 - val_loss: 1.3420 - val_accuracy: 0.3462\n",
            "Epoch 157/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3413 - accuracy: 0.4142 - val_loss: 1.3749 - val_accuracy: 0.3333\n",
            "Epoch 158/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4115 - accuracy: 0.4272 - val_loss: 1.3384 - val_accuracy: 0.3462\n",
            "Epoch 159/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3663 - accuracy: 0.4175 - val_loss: 1.3640 - val_accuracy: 0.3205\n",
            "Epoch 160/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3412 - accuracy: 0.4175 - val_loss: 1.3464 - val_accuracy: 0.3462\n",
            "Epoch 161/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3494 - accuracy: 0.4466 - val_loss: 1.3719 - val_accuracy: 0.3333\n",
            "Epoch 162/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3389 - accuracy: 0.4401 - val_loss: 1.3454 - val_accuracy: 0.3205\n",
            "Epoch 163/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.3742 - accuracy: 0.4401 - val_loss: 1.3972 - val_accuracy: 0.3077\n",
            "Epoch 164/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.3678 - accuracy: 0.4142 - val_loss: 1.3518 - val_accuracy: 0.3333\n",
            "Epoch 165/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3870 - accuracy: 0.4078 - val_loss: 1.3606 - val_accuracy: 0.3462\n",
            "Epoch 166/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3382 - accuracy: 0.4498 - val_loss: 1.3600 - val_accuracy: 0.3333\n",
            "Epoch 167/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3450 - accuracy: 0.4304 - val_loss: 1.3283 - val_accuracy: 0.3333\n",
            "Epoch 168/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3308 - accuracy: 0.4304 - val_loss: 1.3523 - val_accuracy: 0.3718\n",
            "Epoch 169/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3566 - accuracy: 0.4466 - val_loss: 1.3655 - val_accuracy: 0.3333\n",
            "Epoch 170/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3461 - accuracy: 0.4369 - val_loss: 1.3295 - val_accuracy: 0.3333\n",
            "Epoch 171/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.3654 - accuracy: 0.4078 - val_loss: 1.3441 - val_accuracy: 0.3205\n",
            "Epoch 172/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3895 - accuracy: 0.4207 - val_loss: 1.3320 - val_accuracy: 0.3333\n",
            "Epoch 173/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3753 - accuracy: 0.4239 - val_loss: 1.3343 - val_accuracy: 0.3205\n",
            "Epoch 174/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3585 - accuracy: 0.4207 - val_loss: 1.3297 - val_accuracy: 0.3462\n",
            "Epoch 175/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3884 - accuracy: 0.4304 - val_loss: 1.5212 - val_accuracy: 0.3718\n",
            "Epoch 176/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4583 - accuracy: 0.4013 - val_loss: 1.3781 - val_accuracy: 0.3333\n",
            "Epoch 177/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.3718 - accuracy: 0.4304 - val_loss: 1.3358 - val_accuracy: 0.3590\n",
            "Epoch 178/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3833 - accuracy: 0.4563 - val_loss: 1.3032 - val_accuracy: 0.3718\n",
            "Epoch 179/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3817 - accuracy: 0.3819 - val_loss: 1.3492 - val_accuracy: 0.3590\n",
            "Epoch 180/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3904 - accuracy: 0.4239 - val_loss: 1.3491 - val_accuracy: 0.3718\n",
            "Epoch 181/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3641 - accuracy: 0.4272 - val_loss: 1.3773 - val_accuracy: 0.3333\n",
            "Epoch 182/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3340 - accuracy: 0.4369 - val_loss: 1.3198 - val_accuracy: 0.3333\n",
            "Epoch 183/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3397 - accuracy: 0.4207 - val_loss: 1.3911 - val_accuracy: 0.3846\n",
            "Epoch 184/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3876 - accuracy: 0.4013 - val_loss: 1.3724 - val_accuracy: 0.3462\n",
            "Epoch 185/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3648 - accuracy: 0.4304 - val_loss: 1.3042 - val_accuracy: 0.3462\n",
            "Epoch 186/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.3288 - accuracy: 0.4272 - val_loss: 1.3166 - val_accuracy: 0.3590\n",
            "Epoch 187/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3323 - accuracy: 0.4369 - val_loss: 1.3204 - val_accuracy: 0.3333\n",
            "Epoch 188/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3266 - accuracy: 0.4563 - val_loss: 1.4025 - val_accuracy: 0.3333\n",
            "Epoch 189/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3341 - accuracy: 0.4369 - val_loss: 1.3362 - val_accuracy: 0.3462\n",
            "Epoch 190/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.3213 - accuracy: 0.4628 - val_loss: 1.3421 - val_accuracy: 0.3333\n",
            "Epoch 191/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2993 - accuracy: 0.4272 - val_loss: 1.3306 - val_accuracy: 0.3974\n",
            "Epoch 192/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3027 - accuracy: 0.4498 - val_loss: 1.3456 - val_accuracy: 0.3846\n",
            "Epoch 193/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3978 - accuracy: 0.4175 - val_loss: 1.3601 - val_accuracy: 0.3462\n",
            "Epoch 194/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3036 - accuracy: 0.4628 - val_loss: 1.3138 - val_accuracy: 0.3718\n",
            "Epoch 195/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3430 - accuracy: 0.4207 - val_loss: 1.3834 - val_accuracy: 0.3590\n",
            "Epoch 196/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3483 - accuracy: 0.4304 - val_loss: 1.3129 - val_accuracy: 0.3846\n",
            "Epoch 197/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4173 - accuracy: 0.4045 - val_loss: 1.3346 - val_accuracy: 0.3205\n",
            "Epoch 198/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3846 - accuracy: 0.3754 - val_loss: 1.4057 - val_accuracy: 0.2949\n",
            "Epoch 199/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3286 - accuracy: 0.4272 - val_loss: 1.3435 - val_accuracy: 0.3333\n",
            "Epoch 200/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3310 - accuracy: 0.4337 - val_loss: 1.3875 - val_accuracy: 0.3333\n",
            "Epoch 201/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.3851 - accuracy: 0.4304 - val_loss: 1.3064 - val_accuracy: 0.3462\n",
            "Epoch 202/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3115 - accuracy: 0.4531 - val_loss: 1.3500 - val_accuracy: 0.3718\n",
            "Epoch 203/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3331 - accuracy: 0.4401 - val_loss: 1.2944 - val_accuracy: 0.3974\n",
            "Epoch 204/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3328 - accuracy: 0.4239 - val_loss: 1.2918 - val_accuracy: 0.3718\n",
            "Epoch 205/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3308 - accuracy: 0.4304 - val_loss: 1.3222 - val_accuracy: 0.3333\n",
            "Epoch 206/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3407 - accuracy: 0.4563 - val_loss: 1.3216 - val_accuracy: 0.3462\n",
            "Epoch 207/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3384 - accuracy: 0.4434 - val_loss: 1.3279 - val_accuracy: 0.3462\n",
            "Epoch 208/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3378 - accuracy: 0.3916 - val_loss: 1.3314 - val_accuracy: 0.3462\n",
            "Epoch 209/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3468 - accuracy: 0.4531 - val_loss: 1.3326 - val_accuracy: 0.3590\n",
            "Epoch 210/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3032 - accuracy: 0.4207 - val_loss: 1.3488 - val_accuracy: 0.3462\n",
            "Epoch 211/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3496 - accuracy: 0.4078 - val_loss: 1.3250 - val_accuracy: 0.3590\n",
            "Epoch 212/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3050 - accuracy: 0.4304 - val_loss: 1.3249 - val_accuracy: 0.3590\n",
            "Epoch 213/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2954 - accuracy: 0.4725 - val_loss: 1.3074 - val_accuracy: 0.3718\n",
            "Epoch 214/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3223 - accuracy: 0.4239 - val_loss: 1.3639 - val_accuracy: 0.3077\n",
            "Epoch 215/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3128 - accuracy: 0.4304 - val_loss: 1.3664 - val_accuracy: 0.3462\n",
            "Epoch 216/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3028 - accuracy: 0.4693 - val_loss: 1.3446 - val_accuracy: 0.3205\n",
            "Epoch 217/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3190 - accuracy: 0.4175 - val_loss: 1.3176 - val_accuracy: 0.3462\n",
            "Epoch 218/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3143 - accuracy: 0.4207 - val_loss: 1.3549 - val_accuracy: 0.3462\n",
            "Epoch 219/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3186 - accuracy: 0.4434 - val_loss: 1.3134 - val_accuracy: 0.3590\n",
            "Epoch 220/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2981 - accuracy: 0.4304 - val_loss: 1.3671 - val_accuracy: 0.3205\n",
            "Epoch 221/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2899 - accuracy: 0.4531 - val_loss: 1.3174 - val_accuracy: 0.3590\n",
            "Epoch 222/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2803 - accuracy: 0.4660 - val_loss: 1.3220 - val_accuracy: 0.3590\n",
            "Epoch 223/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2953 - accuracy: 0.4725 - val_loss: 1.3273 - val_accuracy: 0.3462\n",
            "Epoch 224/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2772 - accuracy: 0.4595 - val_loss: 1.3520 - val_accuracy: 0.3205\n",
            "Epoch 225/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3051 - accuracy: 0.4272 - val_loss: 1.3591 - val_accuracy: 0.3333\n",
            "Epoch 226/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3124 - accuracy: 0.4434 - val_loss: 1.3195 - val_accuracy: 0.4103\n",
            "Epoch 227/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.3097 - accuracy: 0.4272 - val_loss: 1.3144 - val_accuracy: 0.3718\n",
            "Epoch 228/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2681 - accuracy: 0.4693 - val_loss: 1.2969 - val_accuracy: 0.3590\n",
            "Epoch 229/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2737 - accuracy: 0.4822 - val_loss: 1.3291 - val_accuracy: 0.3590\n",
            "Epoch 230/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2857 - accuracy: 0.4693 - val_loss: 1.3069 - val_accuracy: 0.3590\n",
            "Epoch 231/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2671 - accuracy: 0.4725 - val_loss: 1.3013 - val_accuracy: 0.3974\n",
            "Epoch 232/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2741 - accuracy: 0.4595 - val_loss: 1.3133 - val_accuracy: 0.3462\n",
            "Epoch 233/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2929 - accuracy: 0.4498 - val_loss: 1.2974 - val_accuracy: 0.3846\n",
            "Epoch 234/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2853 - accuracy: 0.4725 - val_loss: 1.3308 - val_accuracy: 0.3846\n",
            "Epoch 235/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3095 - accuracy: 0.4401 - val_loss: 1.3132 - val_accuracy: 0.3462\n",
            "Epoch 236/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2747 - accuracy: 0.4595 - val_loss: 1.2721 - val_accuracy: 0.3974\n",
            "Epoch 237/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2696 - accuracy: 0.4434 - val_loss: 1.3119 - val_accuracy: 0.3462\n",
            "Epoch 238/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2814 - accuracy: 0.4531 - val_loss: 1.3442 - val_accuracy: 0.3462\n",
            "Epoch 239/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2939 - accuracy: 0.4110 - val_loss: 1.3348 - val_accuracy: 0.3718\n",
            "Epoch 240/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3055 - accuracy: 0.4531 - val_loss: 1.2953 - val_accuracy: 0.3974\n",
            "Epoch 241/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2873 - accuracy: 0.4628 - val_loss: 1.2588 - val_accuracy: 0.3974\n",
            "Epoch 242/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2885 - accuracy: 0.4628 - val_loss: 1.4025 - val_accuracy: 0.3846\n",
            "Epoch 243/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3097 - accuracy: 0.4563 - val_loss: 1.3100 - val_accuracy: 0.3846\n",
            "Epoch 244/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2922 - accuracy: 0.4531 - val_loss: 1.3508 - val_accuracy: 0.3846\n",
            "Epoch 245/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3141 - accuracy: 0.4466 - val_loss: 1.3130 - val_accuracy: 0.3718\n",
            "Epoch 246/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3023 - accuracy: 0.4304 - val_loss: 1.3082 - val_accuracy: 0.3846\n",
            "Epoch 247/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2807 - accuracy: 0.4401 - val_loss: 1.3194 - val_accuracy: 0.3718\n",
            "Epoch 248/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2881 - accuracy: 0.4628 - val_loss: 1.3225 - val_accuracy: 0.3974\n",
            "Epoch 249/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2625 - accuracy: 0.4595 - val_loss: 1.2820 - val_accuracy: 0.3974\n",
            "Epoch 250/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2652 - accuracy: 0.4628 - val_loss: 1.2808 - val_accuracy: 0.3974\n",
            "Epoch 251/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2672 - accuracy: 0.4854 - val_loss: 1.3190 - val_accuracy: 0.3974\n",
            "Epoch 252/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2705 - accuracy: 0.4919 - val_loss: 1.3525 - val_accuracy: 0.3590\n",
            "Epoch 253/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2903 - accuracy: 0.4563 - val_loss: 1.3325 - val_accuracy: 0.3846\n",
            "Epoch 254/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2948 - accuracy: 0.4531 - val_loss: 1.3025 - val_accuracy: 0.4103\n",
            "Epoch 255/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2707 - accuracy: 0.4531 - val_loss: 1.3164 - val_accuracy: 0.3718\n",
            "Epoch 256/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2606 - accuracy: 0.4434 - val_loss: 1.2954 - val_accuracy: 0.3846\n",
            "Epoch 257/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2723 - accuracy: 0.4725 - val_loss: 1.2676 - val_accuracy: 0.3974\n",
            "Epoch 258/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.3255 - accuracy: 0.4304 - val_loss: 1.4618 - val_accuracy: 0.3205\n",
            "Epoch 259/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2911 - accuracy: 0.4628 - val_loss: 1.2806 - val_accuracy: 0.3974\n",
            "Epoch 260/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2902 - accuracy: 0.4660 - val_loss: 1.3636 - val_accuracy: 0.3462\n",
            "Epoch 261/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.3227 - accuracy: 0.4369 - val_loss: 1.2570 - val_accuracy: 0.3718\n",
            "Epoch 262/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2769 - accuracy: 0.4660 - val_loss: 1.3554 - val_accuracy: 0.3590\n",
            "Epoch 263/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2703 - accuracy: 0.4628 - val_loss: 1.2770 - val_accuracy: 0.4103\n",
            "Epoch 264/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2966 - accuracy: 0.4531 - val_loss: 1.3162 - val_accuracy: 0.4231\n",
            "Epoch 265/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2583 - accuracy: 0.4951 - val_loss: 1.2558 - val_accuracy: 0.3974\n",
            "Epoch 266/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2471 - accuracy: 0.4822 - val_loss: 1.3389 - val_accuracy: 0.3590\n",
            "Epoch 267/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2353 - accuracy: 0.4854 - val_loss: 1.2860 - val_accuracy: 0.3974\n",
            "Epoch 268/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2502 - accuracy: 0.4822 - val_loss: 1.2974 - val_accuracy: 0.3974\n",
            "Epoch 269/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2862 - accuracy: 0.4498 - val_loss: 1.3913 - val_accuracy: 0.3205\n",
            "Epoch 270/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3749 - accuracy: 0.4045 - val_loss: 1.3377 - val_accuracy: 0.3974\n",
            "Epoch 271/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.2640 - accuracy: 0.5210 - val_loss: 1.3177 - val_accuracy: 0.4103\n",
            "Epoch 272/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2431 - accuracy: 0.4725 - val_loss: 1.3435 - val_accuracy: 0.3846\n",
            "Epoch 273/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2316 - accuracy: 0.4757 - val_loss: 1.2649 - val_accuracy: 0.4231\n",
            "Epoch 274/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3123 - accuracy: 0.4369 - val_loss: 1.3497 - val_accuracy: 0.4103\n",
            "Epoch 275/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2862 - accuracy: 0.4369 - val_loss: 1.3314 - val_accuracy: 0.4103\n",
            "Epoch 276/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2676 - accuracy: 0.4628 - val_loss: 1.2938 - val_accuracy: 0.3846\n",
            "Epoch 277/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2691 - accuracy: 0.4466 - val_loss: 1.2686 - val_accuracy: 0.4103\n",
            "Epoch 278/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2551 - accuracy: 0.4790 - val_loss: 1.2779 - val_accuracy: 0.3846\n",
            "Epoch 279/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3122 - accuracy: 0.4531 - val_loss: 1.4363 - val_accuracy: 0.3333\n",
            "Epoch 280/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2855 - accuracy: 0.4693 - val_loss: 1.2830 - val_accuracy: 0.3974\n",
            "Epoch 281/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3027 - accuracy: 0.4239 - val_loss: 1.3239 - val_accuracy: 0.3974\n",
            "Epoch 282/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2761 - accuracy: 0.4660 - val_loss: 1.3756 - val_accuracy: 0.3846\n",
            "Epoch 283/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3039 - accuracy: 0.4531 - val_loss: 1.2558 - val_accuracy: 0.4103\n",
            "Epoch 284/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2474 - accuracy: 0.4531 - val_loss: 1.3195 - val_accuracy: 0.3590\n",
            "Epoch 285/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2603 - accuracy: 0.4757 - val_loss: 1.2515 - val_accuracy: 0.3974\n",
            "Epoch 286/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2098 - accuracy: 0.5113 - val_loss: 1.2727 - val_accuracy: 0.3846\n",
            "Epoch 287/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2506 - accuracy: 0.4984 - val_loss: 1.2571 - val_accuracy: 0.3974\n",
            "Epoch 288/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2223 - accuracy: 0.4919 - val_loss: 1.2934 - val_accuracy: 0.3846\n",
            "Epoch 289/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2860 - accuracy: 0.4337 - val_loss: 1.3609 - val_accuracy: 0.4103\n",
            "Epoch 290/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2676 - accuracy: 0.4660 - val_loss: 1.2805 - val_accuracy: 0.3974\n",
            "Epoch 291/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2594 - accuracy: 0.4466 - val_loss: 1.3038 - val_accuracy: 0.3846\n",
            "Epoch 292/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2506 - accuracy: 0.4563 - val_loss: 1.2322 - val_accuracy: 0.4359\n",
            "Epoch 293/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2527 - accuracy: 0.4790 - val_loss: 1.2506 - val_accuracy: 0.4103\n",
            "Epoch 294/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2243 - accuracy: 0.4757 - val_loss: 1.3299 - val_accuracy: 0.3333\n",
            "Epoch 295/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2751 - accuracy: 0.4434 - val_loss: 1.2076 - val_accuracy: 0.4487\n",
            "Epoch 296/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2121 - accuracy: 0.4822 - val_loss: 1.2541 - val_accuracy: 0.3974\n",
            "Epoch 297/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2268 - accuracy: 0.4725 - val_loss: 1.2280 - val_accuracy: 0.4231\n",
            "Epoch 298/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1786 - accuracy: 0.5146 - val_loss: 1.2390 - val_accuracy: 0.3974\n",
            "Epoch 299/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.2555 - accuracy: 0.4790 - val_loss: 1.2313 - val_accuracy: 0.4359\n",
            "Epoch 300/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2753 - accuracy: 0.4272 - val_loss: 1.2337 - val_accuracy: 0.4231\n",
            "Epoch 301/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2616 - accuracy: 0.4563 - val_loss: 1.2965 - val_accuracy: 0.4359\n",
            "Epoch 302/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2283 - accuracy: 0.4693 - val_loss: 1.2333 - val_accuracy: 0.3974\n",
            "Epoch 303/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2623 - accuracy: 0.4660 - val_loss: 1.2085 - val_accuracy: 0.4103\n",
            "Epoch 304/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2347 - accuracy: 0.4790 - val_loss: 1.2804 - val_accuracy: 0.4103\n",
            "Epoch 305/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2968 - accuracy: 0.4337 - val_loss: 1.2410 - val_accuracy: 0.3974\n",
            "Epoch 306/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2269 - accuracy: 0.4693 - val_loss: 1.2652 - val_accuracy: 0.3974\n",
            "Epoch 307/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2915 - accuracy: 0.5016 - val_loss: 1.2775 - val_accuracy: 0.3846\n",
            "Epoch 308/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.2116 - accuracy: 0.4854 - val_loss: 1.3067 - val_accuracy: 0.3846\n",
            "Epoch 309/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2418 - accuracy: 0.4887 - val_loss: 1.2508 - val_accuracy: 0.4103\n",
            "Epoch 310/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2160 - accuracy: 0.5210 - val_loss: 1.3118 - val_accuracy: 0.4103\n",
            "Epoch 311/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2039 - accuracy: 0.4660 - val_loss: 1.2911 - val_accuracy: 0.3846\n",
            "Epoch 312/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 1.2741 - accuracy: 0.4401 - val_loss: 1.2183 - val_accuracy: 0.4103\n",
            "Epoch 313/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2717 - accuracy: 0.4531 - val_loss: 1.2549 - val_accuracy: 0.4231\n",
            "Epoch 314/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 1.2754 - accuracy: 0.4854 - val_loss: 1.3764 - val_accuracy: 0.3718\n",
            "Epoch 315/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3248 - accuracy: 0.4207 - val_loss: 1.2973 - val_accuracy: 0.4103\n",
            "Epoch 316/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2107 - accuracy: 0.4887 - val_loss: 1.2500 - val_accuracy: 0.3974\n",
            "Epoch 317/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2363 - accuracy: 0.4693 - val_loss: 1.3024 - val_accuracy: 0.3974\n",
            "Epoch 318/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2380 - accuracy: 0.4790 - val_loss: 1.2641 - val_accuracy: 0.3974\n",
            "Epoch 319/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2004 - accuracy: 0.5081 - val_loss: 1.2358 - val_accuracy: 0.4231\n",
            "Epoch 320/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2553 - accuracy: 0.4757 - val_loss: 1.2586 - val_accuracy: 0.3974\n",
            "Epoch 321/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2872 - accuracy: 0.4466 - val_loss: 1.2692 - val_accuracy: 0.4231\n",
            "Epoch 322/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2556 - accuracy: 0.4660 - val_loss: 1.2407 - val_accuracy: 0.3974\n",
            "Epoch 323/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2073 - accuracy: 0.5113 - val_loss: 1.3121 - val_accuracy: 0.4615\n",
            "Epoch 324/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2410 - accuracy: 0.4757 - val_loss: 1.2876 - val_accuracy: 0.4103\n",
            "Epoch 325/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2028 - accuracy: 0.4951 - val_loss: 1.2139 - val_accuracy: 0.4615\n",
            "Epoch 326/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.1993 - accuracy: 0.5081 - val_loss: 1.3836 - val_accuracy: 0.3462\n",
            "Epoch 327/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2672 - accuracy: 0.4854 - val_loss: 1.2056 - val_accuracy: 0.4231\n",
            "Epoch 328/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2424 - accuracy: 0.4854 - val_loss: 1.3613 - val_accuracy: 0.3974\n",
            "Epoch 329/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2114 - accuracy: 0.5081 - val_loss: 1.2261 - val_accuracy: 0.3974\n",
            "Epoch 330/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1809 - accuracy: 0.5243 - val_loss: 1.2069 - val_accuracy: 0.4744\n",
            "Epoch 331/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2288 - accuracy: 0.4725 - val_loss: 1.3505 - val_accuracy: 0.3974\n",
            "Epoch 332/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2295 - accuracy: 0.4660 - val_loss: 1.2701 - val_accuracy: 0.4615\n",
            "Epoch 333/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2116 - accuracy: 0.4757 - val_loss: 1.2249 - val_accuracy: 0.4487\n",
            "Epoch 334/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2552 - accuracy: 0.4854 - val_loss: 1.2334 - val_accuracy: 0.4744\n",
            "Epoch 335/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.2072 - accuracy: 0.5016 - val_loss: 1.2580 - val_accuracy: 0.4359\n",
            "Epoch 336/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2334 - accuracy: 0.4919 - val_loss: 1.2166 - val_accuracy: 0.4744\n",
            "Epoch 337/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2059 - accuracy: 0.5113 - val_loss: 1.2353 - val_accuracy: 0.4359\n",
            "Epoch 338/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2006 - accuracy: 0.5146 - val_loss: 1.2269 - val_accuracy: 0.4744\n",
            "Epoch 339/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1843 - accuracy: 0.5016 - val_loss: 1.2371 - val_accuracy: 0.4103\n",
            "Epoch 340/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2866 - accuracy: 0.4693 - val_loss: 1.3968 - val_accuracy: 0.4359\n",
            "Epoch 341/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2959 - accuracy: 0.4919 - val_loss: 1.2087 - val_accuracy: 0.4359\n",
            "Epoch 342/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2193 - accuracy: 0.4984 - val_loss: 1.2292 - val_accuracy: 0.4615\n",
            "Epoch 343/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.2048 - accuracy: 0.5016 - val_loss: 1.2738 - val_accuracy: 0.3974\n",
            "Epoch 344/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2224 - accuracy: 0.4660 - val_loss: 1.2018 - val_accuracy: 0.4231\n",
            "Epoch 345/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2137 - accuracy: 0.4984 - val_loss: 1.2414 - val_accuracy: 0.4359\n",
            "Epoch 346/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1830 - accuracy: 0.5275 - val_loss: 1.1877 - val_accuracy: 0.4487\n",
            "Epoch 347/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2852 - accuracy: 0.4660 - val_loss: 1.2463 - val_accuracy: 0.4359\n",
            "Epoch 348/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.3486 - accuracy: 0.4272 - val_loss: 1.3573 - val_accuracy: 0.4359\n",
            "Epoch 349/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.3194 - accuracy: 0.4401 - val_loss: 1.3336 - val_accuracy: 0.4359\n",
            "Epoch 350/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2767 - accuracy: 0.4207 - val_loss: 1.2375 - val_accuracy: 0.5128\n",
            "Epoch 351/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2331 - accuracy: 0.4790 - val_loss: 1.2339 - val_accuracy: 0.4103\n",
            "Epoch 352/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2457 - accuracy: 0.4822 - val_loss: 1.2756 - val_accuracy: 0.3846\n",
            "Epoch 353/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1903 - accuracy: 0.5049 - val_loss: 1.2539 - val_accuracy: 0.3974\n",
            "Epoch 354/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2337 - accuracy: 0.4790 - val_loss: 1.1919 - val_accuracy: 0.4487\n",
            "Epoch 355/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2183 - accuracy: 0.4757 - val_loss: 1.2338 - val_accuracy: 0.4615\n",
            "Epoch 356/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2232 - accuracy: 0.4984 - val_loss: 1.2060 - val_accuracy: 0.4359\n",
            "Epoch 357/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1912 - accuracy: 0.5049 - val_loss: 1.2378 - val_accuracy: 0.3974\n",
            "Epoch 358/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2334 - accuracy: 0.4984 - val_loss: 1.2434 - val_accuracy: 0.4231\n",
            "Epoch 359/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1876 - accuracy: 0.5307 - val_loss: 1.1935 - val_accuracy: 0.4872\n",
            "Epoch 360/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1731 - accuracy: 0.5081 - val_loss: 1.2010 - val_accuracy: 0.4872\n",
            "Epoch 361/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2117 - accuracy: 0.4951 - val_loss: 1.3280 - val_accuracy: 0.4231\n",
            "Epoch 362/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1943 - accuracy: 0.4887 - val_loss: 1.2593 - val_accuracy: 0.4231\n",
            "Epoch 363/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2051 - accuracy: 0.5049 - val_loss: 1.3028 - val_accuracy: 0.4103\n",
            "Epoch 364/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1827 - accuracy: 0.4887 - val_loss: 1.2022 - val_accuracy: 0.4359\n",
            "Epoch 365/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2068 - accuracy: 0.5178 - val_loss: 1.2007 - val_accuracy: 0.4615\n",
            "Epoch 366/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1896 - accuracy: 0.5275 - val_loss: 1.1914 - val_accuracy: 0.4487\n",
            "Epoch 367/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1655 - accuracy: 0.5113 - val_loss: 1.2079 - val_accuracy: 0.4231\n",
            "Epoch 368/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1964 - accuracy: 0.5016 - val_loss: 1.2049 - val_accuracy: 0.5000\n",
            "Epoch 369/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.1860 - accuracy: 0.5146 - val_loss: 1.2032 - val_accuracy: 0.5128\n",
            "Epoch 370/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1656 - accuracy: 0.5307 - val_loss: 1.1852 - val_accuracy: 0.5000\n",
            "Epoch 371/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1803 - accuracy: 0.5146 - val_loss: 1.2676 - val_accuracy: 0.4103\n",
            "Epoch 372/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1640 - accuracy: 0.4919 - val_loss: 1.2134 - val_accuracy: 0.4359\n",
            "Epoch 373/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1867 - accuracy: 0.4854 - val_loss: 1.2065 - val_accuracy: 0.4359\n",
            "Epoch 374/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1844 - accuracy: 0.5210 - val_loss: 1.2230 - val_accuracy: 0.4103\n",
            "Epoch 375/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1706 - accuracy: 0.5307 - val_loss: 1.2298 - val_accuracy: 0.4231\n",
            "Epoch 376/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2012 - accuracy: 0.5081 - val_loss: 1.2083 - val_accuracy: 0.4359\n",
            "Epoch 377/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1524 - accuracy: 0.5372 - val_loss: 1.2395 - val_accuracy: 0.4231\n",
            "Epoch 378/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1400 - accuracy: 0.5049 - val_loss: 1.1797 - val_accuracy: 0.4872\n",
            "Epoch 379/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1857 - accuracy: 0.4854 - val_loss: 1.2106 - val_accuracy: 0.4359\n",
            "Epoch 380/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1796 - accuracy: 0.5113 - val_loss: 1.1842 - val_accuracy: 0.4487\n",
            "Epoch 381/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1873 - accuracy: 0.5049 - val_loss: 1.2171 - val_accuracy: 0.4231\n",
            "Epoch 382/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1476 - accuracy: 0.4822 - val_loss: 1.2121 - val_accuracy: 0.4359\n",
            "Epoch 383/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2244 - accuracy: 0.5049 - val_loss: 1.2287 - val_accuracy: 0.5000\n",
            "Epoch 384/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2629 - accuracy: 0.4822 - val_loss: 1.2533 - val_accuracy: 0.4487\n",
            "Epoch 385/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1509 - accuracy: 0.5502 - val_loss: 1.1821 - val_accuracy: 0.4487\n",
            "Epoch 386/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1618 - accuracy: 0.5243 - val_loss: 1.2210 - val_accuracy: 0.4744\n",
            "Epoch 387/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2255 - accuracy: 0.5178 - val_loss: 1.1913 - val_accuracy: 0.4615\n",
            "Epoch 388/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1577 - accuracy: 0.5340 - val_loss: 1.1942 - val_accuracy: 0.4231\n",
            "Epoch 389/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1813 - accuracy: 0.4984 - val_loss: 1.1684 - val_accuracy: 0.4615\n",
            "Epoch 390/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1229 - accuracy: 0.5243 - val_loss: 1.3311 - val_accuracy: 0.3846\n",
            "Epoch 391/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1651 - accuracy: 0.5081 - val_loss: 1.1995 - val_accuracy: 0.4231\n",
            "Epoch 392/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1299 - accuracy: 0.5696 - val_loss: 1.2031 - val_accuracy: 0.4744\n",
            "Epoch 393/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1487 - accuracy: 0.5178 - val_loss: 1.1910 - val_accuracy: 0.4487\n",
            "Epoch 394/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1367 - accuracy: 0.4984 - val_loss: 1.2383 - val_accuracy: 0.4872\n",
            "Epoch 395/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1993 - accuracy: 0.4951 - val_loss: 1.1685 - val_accuracy: 0.4359\n",
            "Epoch 396/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1397 - accuracy: 0.5307 - val_loss: 1.2547 - val_accuracy: 0.4487\n",
            "Epoch 397/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1665 - accuracy: 0.5372 - val_loss: 1.2560 - val_accuracy: 0.4359\n",
            "Epoch 398/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1152 - accuracy: 0.5631 - val_loss: 1.1927 - val_accuracy: 0.4615\n",
            "Epoch 399/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1685 - accuracy: 0.5275 - val_loss: 1.6029 - val_accuracy: 0.3590\n",
            "Epoch 400/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2685 - accuracy: 0.4693 - val_loss: 1.2455 - val_accuracy: 0.4872\n",
            "Epoch 401/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1337 - accuracy: 0.5243 - val_loss: 1.1884 - val_accuracy: 0.4744\n",
            "Epoch 402/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1894 - accuracy: 0.5049 - val_loss: 1.1448 - val_accuracy: 0.5000\n",
            "Epoch 403/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2228 - accuracy: 0.4822 - val_loss: 1.1881 - val_accuracy: 0.5000\n",
            "Epoch 404/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1949 - accuracy: 0.4854 - val_loss: 1.1548 - val_accuracy: 0.5128\n",
            "Epoch 405/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1804 - accuracy: 0.4822 - val_loss: 1.2017 - val_accuracy: 0.5128\n",
            "Epoch 406/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1469 - accuracy: 0.5372 - val_loss: 1.1403 - val_accuracy: 0.5000\n",
            "Epoch 407/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1722 - accuracy: 0.5210 - val_loss: 1.1518 - val_accuracy: 0.5256\n",
            "Epoch 408/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1527 - accuracy: 0.5307 - val_loss: 1.2305 - val_accuracy: 0.4872\n",
            "Epoch 409/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1973 - accuracy: 0.4984 - val_loss: 1.2320 - val_accuracy: 0.4487\n",
            "Epoch 410/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1216 - accuracy: 0.5307 - val_loss: 1.1600 - val_accuracy: 0.5000\n",
            "Epoch 411/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1529 - accuracy: 0.5210 - val_loss: 1.1851 - val_accuracy: 0.4615\n",
            "Epoch 412/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1604 - accuracy: 0.5081 - val_loss: 1.1826 - val_accuracy: 0.4744\n",
            "Epoch 413/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2107 - accuracy: 0.5113 - val_loss: 1.2327 - val_accuracy: 0.4744\n",
            "Epoch 414/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1999 - accuracy: 0.5178 - val_loss: 1.1626 - val_accuracy: 0.4872\n",
            "Epoch 415/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2424 - accuracy: 0.4693 - val_loss: 1.2466 - val_accuracy: 0.4744\n",
            "Epoch 416/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2168 - accuracy: 0.5146 - val_loss: 1.2701 - val_accuracy: 0.4231\n",
            "Epoch 417/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2363 - accuracy: 0.4919 - val_loss: 1.1831 - val_accuracy: 0.4744\n",
            "Epoch 418/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1523 - accuracy: 0.5146 - val_loss: 1.1620 - val_accuracy: 0.5385\n",
            "Epoch 419/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.2205 - accuracy: 0.4725 - val_loss: 1.1623 - val_accuracy: 0.4872\n",
            "Epoch 420/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1497 - accuracy: 0.5340 - val_loss: 1.1471 - val_accuracy: 0.5513\n",
            "Epoch 421/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 1.1387 - accuracy: 0.5146 - val_loss: 1.1384 - val_accuracy: 0.5385\n",
            "Epoch 422/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1229 - accuracy: 0.5178 - val_loss: 1.1773 - val_accuracy: 0.4487\n",
            "Epoch 423/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1559 - accuracy: 0.5146 - val_loss: 1.1418 - val_accuracy: 0.5000\n",
            "Epoch 424/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1028 - accuracy: 0.5696 - val_loss: 1.1781 - val_accuracy: 0.5385\n",
            "Epoch 425/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1045 - accuracy: 0.5307 - val_loss: 1.1607 - val_accuracy: 0.5000\n",
            "Epoch 426/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0973 - accuracy: 0.5405 - val_loss: 1.1710 - val_accuracy: 0.4231\n",
            "Epoch 427/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1097 - accuracy: 0.5534 - val_loss: 1.1338 - val_accuracy: 0.4872\n",
            "Epoch 428/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1661 - accuracy: 0.5307 - val_loss: 1.1237 - val_accuracy: 0.4744\n",
            "Epoch 429/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0908 - accuracy: 0.5243 - val_loss: 1.1242 - val_accuracy: 0.4872\n",
            "Epoch 430/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1249 - accuracy: 0.5307 - val_loss: 1.1872 - val_accuracy: 0.4359\n",
            "Epoch 431/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1782 - accuracy: 0.5081 - val_loss: 1.3280 - val_accuracy: 0.4231\n",
            "Epoch 432/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1487 - accuracy: 0.5502 - val_loss: 1.1387 - val_accuracy: 0.5256\n",
            "Epoch 433/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1596 - accuracy: 0.5437 - val_loss: 1.1540 - val_accuracy: 0.5128\n",
            "Epoch 434/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.2020 - accuracy: 0.4919 - val_loss: 1.2002 - val_accuracy: 0.5513\n",
            "Epoch 435/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1173 - accuracy: 0.5405 - val_loss: 1.2167 - val_accuracy: 0.5000\n",
            "Epoch 436/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1890 - accuracy: 0.5146 - val_loss: 1.1419 - val_accuracy: 0.5385\n",
            "Epoch 437/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1167 - accuracy: 0.5566 - val_loss: 1.1412 - val_accuracy: 0.5513\n",
            "Epoch 438/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1426 - accuracy: 0.5275 - val_loss: 1.1865 - val_accuracy: 0.4744\n",
            "Epoch 439/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1692 - accuracy: 0.5016 - val_loss: 1.1351 - val_accuracy: 0.5128\n",
            "Epoch 440/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1077 - accuracy: 0.5372 - val_loss: 1.1635 - val_accuracy: 0.4615\n",
            "Epoch 441/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1231 - accuracy: 0.5178 - val_loss: 1.1540 - val_accuracy: 0.5128\n",
            "Epoch 442/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1200 - accuracy: 0.5210 - val_loss: 1.1709 - val_accuracy: 0.5128\n",
            "Epoch 443/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1662 - accuracy: 0.4951 - val_loss: 1.1956 - val_accuracy: 0.4231\n",
            "Epoch 444/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0676 - accuracy: 0.5890 - val_loss: 1.0910 - val_accuracy: 0.5513\n",
            "Epoch 445/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1019 - accuracy: 0.5599 - val_loss: 1.1237 - val_accuracy: 0.5385\n",
            "Epoch 446/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0871 - accuracy: 0.5534 - val_loss: 1.1201 - val_accuracy: 0.5385\n",
            "Epoch 447/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2250 - accuracy: 0.4854 - val_loss: 1.2080 - val_accuracy: 0.4744\n",
            "Epoch 448/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.1028 - accuracy: 0.5599 - val_loss: 1.1424 - val_accuracy: 0.5256\n",
            "Epoch 449/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1235 - accuracy: 0.5178 - val_loss: 1.1500 - val_accuracy: 0.4744\n",
            "Epoch 450/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0597 - accuracy: 0.5599 - val_loss: 1.1766 - val_accuracy: 0.4487\n",
            "Epoch 451/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1078 - accuracy: 0.5340 - val_loss: 1.1871 - val_accuracy: 0.4103\n",
            "Epoch 452/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1243 - accuracy: 0.5372 - val_loss: 1.3558 - val_accuracy: 0.3974\n",
            "Epoch 453/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1978 - accuracy: 0.4951 - val_loss: 1.4330 - val_accuracy: 0.4103\n",
            "Epoch 454/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1622 - accuracy: 0.5372 - val_loss: 1.0945 - val_accuracy: 0.5513\n",
            "Epoch 455/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0634 - accuracy: 0.5955 - val_loss: 1.1028 - val_accuracy: 0.5385\n",
            "Epoch 456/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1459 - accuracy: 0.5113 - val_loss: 1.1040 - val_accuracy: 0.5513\n",
            "Epoch 457/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0929 - accuracy: 0.5663 - val_loss: 1.0854 - val_accuracy: 0.5256\n",
            "Epoch 458/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0664 - accuracy: 0.5761 - val_loss: 1.1303 - val_accuracy: 0.5000\n",
            "Epoch 459/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0640 - accuracy: 0.5566 - val_loss: 1.0972 - val_accuracy: 0.5513\n",
            "Epoch 460/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1256 - accuracy: 0.5534 - val_loss: 1.1634 - val_accuracy: 0.5128\n",
            "Epoch 461/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1096 - accuracy: 0.5405 - val_loss: 1.1134 - val_accuracy: 0.5128\n",
            "Epoch 462/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1311 - accuracy: 0.5405 - val_loss: 1.1074 - val_accuracy: 0.5256\n",
            "Epoch 463/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0867 - accuracy: 0.5566 - val_loss: 1.2184 - val_accuracy: 0.4615\n",
            "Epoch 464/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0769 - accuracy: 0.5728 - val_loss: 1.2885 - val_accuracy: 0.4231\n",
            "Epoch 465/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0931 - accuracy: 0.5793 - val_loss: 1.1958 - val_accuracy: 0.4744\n",
            "Epoch 466/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1086 - accuracy: 0.5631 - val_loss: 1.1410 - val_accuracy: 0.5256\n",
            "Epoch 467/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0546 - accuracy: 0.5696 - val_loss: 1.0716 - val_accuracy: 0.5769\n",
            "Epoch 468/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0751 - accuracy: 0.5696 - val_loss: 1.1027 - val_accuracy: 0.5897\n",
            "Epoch 469/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1100 - accuracy: 0.5566 - val_loss: 1.0938 - val_accuracy: 0.5000\n",
            "Epoch 470/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1156 - accuracy: 0.5696 - val_loss: 1.1169 - val_accuracy: 0.5128\n",
            "Epoch 471/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0271 - accuracy: 0.5696 - val_loss: 1.0961 - val_accuracy: 0.5385\n",
            "Epoch 472/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1019 - accuracy: 0.5502 - val_loss: 1.0811 - val_accuracy: 0.5128\n",
            "Epoch 473/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0510 - accuracy: 0.5728 - val_loss: 1.0886 - val_accuracy: 0.5385\n",
            "Epoch 474/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0618 - accuracy: 0.5761 - val_loss: 1.0750 - val_accuracy: 0.5128\n",
            "Epoch 475/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0231 - accuracy: 0.5372 - val_loss: 1.0848 - val_accuracy: 0.5641\n",
            "Epoch 476/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0785 - accuracy: 0.5534 - val_loss: 1.0941 - val_accuracy: 0.5128\n",
            "Epoch 477/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1089 - accuracy: 0.5631 - val_loss: 1.0800 - val_accuracy: 0.5128\n",
            "Epoch 478/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0809 - accuracy: 0.5372 - val_loss: 1.0717 - val_accuracy: 0.5513\n",
            "Epoch 479/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1362 - accuracy: 0.5405 - val_loss: 1.3082 - val_accuracy: 0.4359\n",
            "Epoch 480/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1560 - accuracy: 0.5275 - val_loss: 1.1768 - val_accuracy: 0.5128\n",
            "Epoch 481/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1515 - accuracy: 0.5405 - val_loss: 1.1767 - val_accuracy: 0.4615\n",
            "Epoch 482/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 1.0831 - accuracy: 0.5372 - val_loss: 1.0859 - val_accuracy: 0.5128\n",
            "Epoch 483/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1274 - accuracy: 0.5372 - val_loss: 1.1038 - val_accuracy: 0.5128\n",
            "Epoch 484/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0657 - accuracy: 0.5696 - val_loss: 1.0949 - val_accuracy: 0.5256\n",
            "Epoch 485/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.1029 - accuracy: 0.5178 - val_loss: 1.0716 - val_accuracy: 0.5641\n",
            "Epoch 486/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0600 - accuracy: 0.5696 - val_loss: 1.0363 - val_accuracy: 0.5641\n",
            "Epoch 487/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0991 - accuracy: 0.5534 - val_loss: 1.0770 - val_accuracy: 0.5513\n",
            "Epoch 488/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0335 - accuracy: 0.5858 - val_loss: 1.0894 - val_accuracy: 0.5000\n",
            "Epoch 489/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0333 - accuracy: 0.5858 - val_loss: 1.1402 - val_accuracy: 0.4615\n",
            "Epoch 490/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0438 - accuracy: 0.5728 - val_loss: 1.0489 - val_accuracy: 0.5513\n",
            "Epoch 491/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0478 - accuracy: 0.5534 - val_loss: 1.0588 - val_accuracy: 0.5641\n",
            "Epoch 492/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0567 - accuracy: 0.5469 - val_loss: 1.0446 - val_accuracy: 0.5513\n",
            "Epoch 493/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0982 - accuracy: 0.5696 - val_loss: 1.0396 - val_accuracy: 0.5641\n",
            "Epoch 494/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.9912 - accuracy: 0.6149 - val_loss: 1.0558 - val_accuracy: 0.5385\n",
            "Epoch 495/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0297 - accuracy: 0.5728 - val_loss: 1.0898 - val_accuracy: 0.5256\n",
            "Epoch 496/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0583 - accuracy: 0.5890 - val_loss: 1.1834 - val_accuracy: 0.5000\n",
            "Epoch 497/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1012 - accuracy: 0.5340 - val_loss: 1.1013 - val_accuracy: 0.5000\n",
            "Epoch 498/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0261 - accuracy: 0.5761 - val_loss: 1.0650 - val_accuracy: 0.5385\n",
            "Epoch 499/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0519 - accuracy: 0.5825 - val_loss: 1.0497 - val_accuracy: 0.5385\n",
            "Epoch 500/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0694 - accuracy: 0.5275 - val_loss: 1.0415 - val_accuracy: 0.5256\n",
            "Epoch 501/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9841 - accuracy: 0.5825 - val_loss: 1.0841 - val_accuracy: 0.5000\n",
            "Epoch 502/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0763 - accuracy: 0.5728 - val_loss: 1.1963 - val_accuracy: 0.4872\n",
            "Epoch 503/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1816 - accuracy: 0.4984 - val_loss: 1.0816 - val_accuracy: 0.6026\n",
            "Epoch 504/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1073 - accuracy: 0.5534 - val_loss: 1.1047 - val_accuracy: 0.5385\n",
            "Epoch 505/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1642 - accuracy: 0.5275 - val_loss: 1.0944 - val_accuracy: 0.5513\n",
            "Epoch 506/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1693 - accuracy: 0.5243 - val_loss: 1.1484 - val_accuracy: 0.5000\n",
            "Epoch 507/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1670 - accuracy: 0.5016 - val_loss: 1.1849 - val_accuracy: 0.5385\n",
            "Epoch 508/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1286 - accuracy: 0.5307 - val_loss: 1.1157 - val_accuracy: 0.5128\n",
            "Epoch 509/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0883 - accuracy: 0.5340 - val_loss: 1.0767 - val_accuracy: 0.5385\n",
            "Epoch 510/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1037 - accuracy: 0.5372 - val_loss: 1.1012 - val_accuracy: 0.5513\n",
            "Epoch 511/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0368 - accuracy: 0.5793 - val_loss: 1.0967 - val_accuracy: 0.5513\n",
            "Epoch 512/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0468 - accuracy: 0.5631 - val_loss: 1.0836 - val_accuracy: 0.5385\n",
            "Epoch 513/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9929 - accuracy: 0.5987 - val_loss: 1.0402 - val_accuracy: 0.5897\n",
            "Epoch 514/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0315 - accuracy: 0.5599 - val_loss: 1.1788 - val_accuracy: 0.4615\n",
            "Epoch 515/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0405 - accuracy: 0.5663 - val_loss: 1.0518 - val_accuracy: 0.5385\n",
            "Epoch 516/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9543 - accuracy: 0.6181 - val_loss: 1.0383 - val_accuracy: 0.5769\n",
            "Epoch 517/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.9983 - accuracy: 0.5987 - val_loss: 1.1078 - val_accuracy: 0.5513\n",
            "Epoch 518/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0129 - accuracy: 0.6278 - val_loss: 1.0592 - val_accuracy: 0.5769\n",
            "Epoch 519/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0684 - accuracy: 0.5825 - val_loss: 1.0793 - val_accuracy: 0.5128\n",
            "Epoch 520/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0936 - accuracy: 0.5858 - val_loss: 1.0742 - val_accuracy: 0.5256\n",
            "Epoch 521/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9942 - accuracy: 0.6214 - val_loss: 1.1351 - val_accuracy: 0.5128\n",
            "Epoch 522/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0388 - accuracy: 0.5534 - val_loss: 0.9906 - val_accuracy: 0.5641\n",
            "Epoch 523/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0117 - accuracy: 0.5922 - val_loss: 1.0281 - val_accuracy: 0.5385\n",
            "Epoch 524/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0952 - accuracy: 0.5793 - val_loss: 1.0107 - val_accuracy: 0.5641\n",
            "Epoch 525/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0179 - accuracy: 0.6019 - val_loss: 1.0042 - val_accuracy: 0.6282\n",
            "Epoch 526/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0303 - accuracy: 0.5793 - val_loss: 1.0009 - val_accuracy: 0.6154\n",
            "Epoch 527/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0591 - accuracy: 0.5922 - val_loss: 1.0406 - val_accuracy: 0.5256\n",
            "Epoch 528/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0402 - accuracy: 0.5825 - val_loss: 1.0191 - val_accuracy: 0.5385\n",
            "Epoch 529/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0574 - accuracy: 0.5728 - val_loss: 1.0611 - val_accuracy: 0.5256\n",
            "Epoch 530/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0013 - accuracy: 0.5955 - val_loss: 1.0811 - val_accuracy: 0.5385\n",
            "Epoch 531/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0437 - accuracy: 0.5761 - val_loss: 1.0404 - val_accuracy: 0.5769\n",
            "Epoch 532/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9932 - accuracy: 0.6246 - val_loss: 1.0309 - val_accuracy: 0.6026\n",
            "Epoch 533/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0346 - accuracy: 0.5599 - val_loss: 1.1363 - val_accuracy: 0.5128\n",
            "Epoch 534/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0949 - accuracy: 0.5469 - val_loss: 1.0966 - val_accuracy: 0.6026\n",
            "Epoch 535/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0183 - accuracy: 0.5825 - val_loss: 1.0324 - val_accuracy: 0.5897\n",
            "Epoch 536/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0093 - accuracy: 0.5987 - val_loss: 1.0279 - val_accuracy: 0.5769\n",
            "Epoch 537/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0517 - accuracy: 0.5469 - val_loss: 1.0228 - val_accuracy: 0.5513\n",
            "Epoch 538/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9905 - accuracy: 0.6052 - val_loss: 1.0333 - val_accuracy: 0.5385\n",
            "Epoch 539/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0273 - accuracy: 0.5793 - val_loss: 1.0486 - val_accuracy: 0.5000\n",
            "Epoch 540/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0073 - accuracy: 0.5858 - val_loss: 1.0187 - val_accuracy: 0.5641\n",
            "Epoch 541/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9879 - accuracy: 0.6214 - val_loss: 1.0297 - val_accuracy: 0.5513\n",
            "Epoch 542/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0136 - accuracy: 0.5858 - val_loss: 1.0618 - val_accuracy: 0.5897\n",
            "Epoch 543/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9652 - accuracy: 0.6375 - val_loss: 1.0533 - val_accuracy: 0.5385\n",
            "Epoch 544/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9274 - accuracy: 0.6699 - val_loss: 1.0317 - val_accuracy: 0.5256\n",
            "Epoch 545/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9815 - accuracy: 0.6246 - val_loss: 1.0431 - val_accuracy: 0.5513\n",
            "Epoch 546/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.9776 - accuracy: 0.6117 - val_loss: 1.0892 - val_accuracy: 0.5641\n",
            "Epoch 547/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9879 - accuracy: 0.5728 - val_loss: 1.2565 - val_accuracy: 0.5000\n",
            "Epoch 548/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0608 - accuracy: 0.5405 - val_loss: 1.1705 - val_accuracy: 0.4615\n",
            "Epoch 549/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0022 - accuracy: 0.5728 - val_loss: 1.1674 - val_accuracy: 0.4872\n",
            "Epoch 550/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0516 - accuracy: 0.5858 - val_loss: 1.1525 - val_accuracy: 0.5256\n",
            "Epoch 551/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0351 - accuracy: 0.5922 - val_loss: 1.1308 - val_accuracy: 0.5000\n",
            "Epoch 552/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0249 - accuracy: 0.5663 - val_loss: 1.0032 - val_accuracy: 0.5513\n",
            "Epoch 553/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0334 - accuracy: 0.5534 - val_loss: 1.0282 - val_accuracy: 0.5256\n",
            "Epoch 554/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 1.0023 - accuracy: 0.5728 - val_loss: 1.0003 - val_accuracy: 0.5385\n",
            "Epoch 555/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0452 - accuracy: 0.5987 - val_loss: 1.0264 - val_accuracy: 0.4872\n",
            "Epoch 556/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0345 - accuracy: 0.5761 - val_loss: 1.0217 - val_accuracy: 0.5385\n",
            "Epoch 557/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9976 - accuracy: 0.5728 - val_loss: 1.0513 - val_accuracy: 0.5385\n",
            "Epoch 558/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0245 - accuracy: 0.6052 - val_loss: 1.0338 - val_accuracy: 0.5897\n",
            "Epoch 559/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0122 - accuracy: 0.5793 - val_loss: 1.0274 - val_accuracy: 0.5385\n",
            "Epoch 560/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0214 - accuracy: 0.5761 - val_loss: 1.0414 - val_accuracy: 0.6026\n",
            "Epoch 561/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9958 - accuracy: 0.6019 - val_loss: 1.1015 - val_accuracy: 0.5641\n",
            "Epoch 562/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9767 - accuracy: 0.6019 - val_loss: 1.0367 - val_accuracy: 0.5513\n",
            "Epoch 563/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9649 - accuracy: 0.6019 - val_loss: 1.0632 - val_accuracy: 0.5256\n",
            "Epoch 564/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9610 - accuracy: 0.6214 - val_loss: 1.0655 - val_accuracy: 0.5385\n",
            "Epoch 565/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0222 - accuracy: 0.5728 - val_loss: 1.0585 - val_accuracy: 0.5385\n",
            "Epoch 566/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9970 - accuracy: 0.5955 - val_loss: 1.0437 - val_accuracy: 0.5641\n",
            "Epoch 567/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9896 - accuracy: 0.5922 - val_loss: 1.0163 - val_accuracy: 0.5897\n",
            "Epoch 568/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0058 - accuracy: 0.5987 - val_loss: 0.9798 - val_accuracy: 0.6026\n",
            "Epoch 569/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0069 - accuracy: 0.5987 - val_loss: 0.9654 - val_accuracy: 0.5641\n",
            "Epoch 570/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9533 - accuracy: 0.6117 - val_loss: 1.0089 - val_accuracy: 0.5385\n",
            "Epoch 571/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9688 - accuracy: 0.6117 - val_loss: 0.9966 - val_accuracy: 0.5897\n",
            "Epoch 572/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9427 - accuracy: 0.6343 - val_loss: 1.0236 - val_accuracy: 0.6026\n",
            "Epoch 573/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0001 - accuracy: 0.5793 - val_loss: 1.0645 - val_accuracy: 0.5641\n",
            "Epoch 574/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9647 - accuracy: 0.6117 - val_loss: 0.9716 - val_accuracy: 0.5256\n",
            "Epoch 575/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9779 - accuracy: 0.5955 - val_loss: 0.9977 - val_accuracy: 0.5897\n",
            "Epoch 576/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9521 - accuracy: 0.6117 - val_loss: 0.9750 - val_accuracy: 0.6154\n",
            "Epoch 577/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9506 - accuracy: 0.6214 - val_loss: 1.0186 - val_accuracy: 0.5385\n",
            "Epoch 578/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9974 - accuracy: 0.5825 - val_loss: 1.0378 - val_accuracy: 0.5385\n",
            "Epoch 579/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8980 - accuracy: 0.6505 - val_loss: 1.1305 - val_accuracy: 0.5256\n",
            "Epoch 580/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0081 - accuracy: 0.6084 - val_loss: 1.0751 - val_accuracy: 0.5513\n",
            "Epoch 581/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9310 - accuracy: 0.6246 - val_loss: 0.9941 - val_accuracy: 0.5513\n",
            "Epoch 582/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0394 - accuracy: 0.6052 - val_loss: 1.0931 - val_accuracy: 0.5641\n",
            "Epoch 583/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9617 - accuracy: 0.6311 - val_loss: 1.0013 - val_accuracy: 0.5769\n",
            "Epoch 584/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9319 - accuracy: 0.6149 - val_loss: 0.9831 - val_accuracy: 0.5513\n",
            "Epoch 585/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9983 - accuracy: 0.5955 - val_loss: 1.1707 - val_accuracy: 0.5000\n",
            "Epoch 586/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9831 - accuracy: 0.6084 - val_loss: 0.9424 - val_accuracy: 0.6538\n",
            "Epoch 587/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0143 - accuracy: 0.5793 - val_loss: 0.9101 - val_accuracy: 0.6026\n",
            "Epoch 588/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0370 - accuracy: 0.5793 - val_loss: 1.0221 - val_accuracy: 0.6026\n",
            "Epoch 589/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9788 - accuracy: 0.5793 - val_loss: 1.0405 - val_accuracy: 0.5128\n",
            "Epoch 590/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9158 - accuracy: 0.5955 - val_loss: 0.9681 - val_accuracy: 0.5769\n",
            "Epoch 591/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0219 - accuracy: 0.5858 - val_loss: 0.9410 - val_accuracy: 0.6410\n",
            "Epoch 592/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9375 - accuracy: 0.6149 - val_loss: 1.0219 - val_accuracy: 0.5385\n",
            "Epoch 593/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9671 - accuracy: 0.5955 - val_loss: 1.0546 - val_accuracy: 0.5641\n",
            "Epoch 594/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9275 - accuracy: 0.6375 - val_loss: 1.0014 - val_accuracy: 0.5513\n",
            "Epoch 595/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9097 - accuracy: 0.6408 - val_loss: 0.9660 - val_accuracy: 0.6154\n",
            "Epoch 596/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0645 - accuracy: 0.5469 - val_loss: 1.1075 - val_accuracy: 0.5256\n",
            "Epoch 597/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9316 - accuracy: 0.6214 - val_loss: 1.1589 - val_accuracy: 0.5385\n",
            "Epoch 598/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9882 - accuracy: 0.6214 - val_loss: 0.9786 - val_accuracy: 0.5897\n",
            "Epoch 599/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9418 - accuracy: 0.6375 - val_loss: 0.9505 - val_accuracy: 0.5769\n",
            "Epoch 600/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9288 - accuracy: 0.6311 - val_loss: 1.0149 - val_accuracy: 0.5769\n",
            "Epoch 601/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.9366 - accuracy: 0.6214 - val_loss: 0.9863 - val_accuracy: 0.6154\n",
            "Epoch 602/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8823 - accuracy: 0.6537 - val_loss: 0.9675 - val_accuracy: 0.5897\n",
            "Epoch 603/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.9242 - accuracy: 0.6052 - val_loss: 0.9207 - val_accuracy: 0.6282\n",
            "Epoch 604/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8931 - accuracy: 0.6343 - val_loss: 0.9950 - val_accuracy: 0.5513\n",
            "Epoch 605/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9804 - accuracy: 0.6117 - val_loss: 0.9511 - val_accuracy: 0.6410\n",
            "Epoch 606/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9174 - accuracy: 0.6181 - val_loss: 1.0530 - val_accuracy: 0.5128\n",
            "Epoch 607/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9081 - accuracy: 0.6537 - val_loss: 0.9206 - val_accuracy: 0.6154\n",
            "Epoch 608/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9107 - accuracy: 0.6472 - val_loss: 0.9677 - val_accuracy: 0.5897\n",
            "Epoch 609/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8784 - accuracy: 0.6570 - val_loss: 0.9800 - val_accuracy: 0.5513\n",
            "Epoch 610/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9029 - accuracy: 0.6408 - val_loss: 0.9415 - val_accuracy: 0.6026\n",
            "Epoch 611/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8569 - accuracy: 0.6570 - val_loss: 0.9226 - val_accuracy: 0.5641\n",
            "Epoch 612/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9130 - accuracy: 0.6149 - val_loss: 0.9100 - val_accuracy: 0.6154\n",
            "Epoch 613/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9405 - accuracy: 0.6214 - val_loss: 0.8767 - val_accuracy: 0.6410\n",
            "Epoch 614/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9266 - accuracy: 0.6602 - val_loss: 0.9552 - val_accuracy: 0.5897\n",
            "Epoch 615/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9324 - accuracy: 0.6408 - val_loss: 1.0109 - val_accuracy: 0.5641\n",
            "Epoch 616/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9162 - accuracy: 0.6214 - val_loss: 1.0049 - val_accuracy: 0.5897\n",
            "Epoch 617/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9984 - accuracy: 0.5922 - val_loss: 1.0795 - val_accuracy: 0.5385\n",
            "Epoch 618/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0324 - accuracy: 0.5890 - val_loss: 0.9512 - val_accuracy: 0.5128\n",
            "Epoch 619/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9190 - accuracy: 0.6181 - val_loss: 0.9673 - val_accuracy: 0.6026\n",
            "Epoch 620/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9520 - accuracy: 0.6343 - val_loss: 1.0181 - val_accuracy: 0.5256\n",
            "Epoch 621/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9451 - accuracy: 0.6246 - val_loss: 0.9939 - val_accuracy: 0.5641\n",
            "Epoch 622/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9928 - accuracy: 0.6052 - val_loss: 0.9842 - val_accuracy: 0.5769\n",
            "Epoch 623/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9670 - accuracy: 0.6019 - val_loss: 0.9619 - val_accuracy: 0.5897\n",
            "Epoch 624/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0383 - accuracy: 0.6117 - val_loss: 0.9416 - val_accuracy: 0.5385\n",
            "Epoch 625/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0190 - accuracy: 0.5696 - val_loss: 0.9936 - val_accuracy: 0.6410\n",
            "Epoch 626/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9944 - accuracy: 0.6084 - val_loss: 0.9469 - val_accuracy: 0.6026\n",
            "Epoch 627/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9502 - accuracy: 0.6084 - val_loss: 1.0394 - val_accuracy: 0.5000\n",
            "Epoch 628/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9745 - accuracy: 0.6214 - val_loss: 1.0364 - val_accuracy: 0.5128\n",
            "Epoch 629/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9100 - accuracy: 0.6505 - val_loss: 0.9447 - val_accuracy: 0.5641\n",
            "Epoch 630/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9719 - accuracy: 0.5987 - val_loss: 0.9183 - val_accuracy: 0.6026\n",
            "Epoch 631/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9979 - accuracy: 0.5955 - val_loss: 0.9242 - val_accuracy: 0.5641\n",
            "Epoch 632/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0352 - accuracy: 0.5922 - val_loss: 1.0159 - val_accuracy: 0.5641\n",
            "Epoch 633/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0024 - accuracy: 0.6214 - val_loss: 0.9443 - val_accuracy: 0.5897\n",
            "Epoch 634/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9787 - accuracy: 0.6181 - val_loss: 0.9801 - val_accuracy: 0.5769\n",
            "Epoch 635/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9858 - accuracy: 0.5858 - val_loss: 1.0275 - val_accuracy: 0.5769\n",
            "Epoch 636/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0328 - accuracy: 0.5599 - val_loss: 0.9921 - val_accuracy: 0.5769\n",
            "Epoch 637/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9872 - accuracy: 0.6052 - val_loss: 0.9716 - val_accuracy: 0.5641\n",
            "Epoch 638/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9622 - accuracy: 0.6505 - val_loss: 1.1568 - val_accuracy: 0.4872\n",
            "Epoch 639/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0243 - accuracy: 0.6084 - val_loss: 0.9609 - val_accuracy: 0.5897\n",
            "Epoch 640/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9904 - accuracy: 0.6019 - val_loss: 0.9527 - val_accuracy: 0.5897\n",
            "Epoch 641/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9576 - accuracy: 0.6117 - val_loss: 0.9071 - val_accuracy: 0.5769\n",
            "Epoch 642/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1558 - accuracy: 0.5243 - val_loss: 1.0332 - val_accuracy: 0.5641\n",
            "Epoch 643/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0140 - accuracy: 0.5793 - val_loss: 1.0298 - val_accuracy: 0.5641\n",
            "Epoch 644/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9278 - accuracy: 0.6667 - val_loss: 0.9270 - val_accuracy: 0.6154\n",
            "Epoch 645/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0520 - accuracy: 0.5987 - val_loss: 0.9613 - val_accuracy: 0.5513\n",
            "Epoch 646/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0173 - accuracy: 0.5955 - val_loss: 1.0050 - val_accuracy: 0.5641\n",
            "Epoch 647/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0497 - accuracy: 0.5534 - val_loss: 0.9479 - val_accuracy: 0.5769\n",
            "Epoch 648/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0965 - accuracy: 0.5631 - val_loss: 1.0488 - val_accuracy: 0.5385\n",
            "Epoch 649/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0821 - accuracy: 0.5566 - val_loss: 1.0568 - val_accuracy: 0.5385\n",
            "Epoch 650/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9763 - accuracy: 0.6019 - val_loss: 0.9552 - val_accuracy: 0.6282\n",
            "Epoch 651/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0361 - accuracy: 0.6084 - val_loss: 0.9366 - val_accuracy: 0.5769\n",
            "Epoch 652/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9498 - accuracy: 0.6440 - val_loss: 0.9186 - val_accuracy: 0.6026\n",
            "Epoch 653/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0283 - accuracy: 0.6052 - val_loss: 0.9764 - val_accuracy: 0.5000\n",
            "Epoch 654/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0033 - accuracy: 0.6052 - val_loss: 0.9697 - val_accuracy: 0.5641\n",
            "Epoch 655/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9873 - accuracy: 0.6149 - val_loss: 0.9445 - val_accuracy: 0.6154\n",
            "Epoch 656/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9795 - accuracy: 0.6278 - val_loss: 0.9224 - val_accuracy: 0.5513\n",
            "Epoch 657/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9512 - accuracy: 0.6214 - val_loss: 0.9199 - val_accuracy: 0.6154\n",
            "Epoch 658/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9832 - accuracy: 0.6408 - val_loss: 0.9862 - val_accuracy: 0.6154\n",
            "Epoch 659/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0132 - accuracy: 0.5955 - val_loss: 1.0727 - val_accuracy: 0.5128\n",
            "Epoch 660/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0064 - accuracy: 0.5696 - val_loss: 0.8918 - val_accuracy: 0.6154\n",
            "Epoch 661/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.9804 - accuracy: 0.5761 - val_loss: 0.9214 - val_accuracy: 0.6026\n",
            "Epoch 662/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9301 - accuracy: 0.6019 - val_loss: 0.9950 - val_accuracy: 0.5385\n",
            "Epoch 663/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9841 - accuracy: 0.6117 - val_loss: 0.9586 - val_accuracy: 0.5897\n",
            "Epoch 664/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0309 - accuracy: 0.5890 - val_loss: 0.9793 - val_accuracy: 0.5897\n",
            "Epoch 665/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0020 - accuracy: 0.5858 - val_loss: 1.0585 - val_accuracy: 0.5641\n",
            "Epoch 666/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9966 - accuracy: 0.6019 - val_loss: 0.9364 - val_accuracy: 0.5769\n",
            "Epoch 667/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9918 - accuracy: 0.5890 - val_loss: 0.9408 - val_accuracy: 0.6026\n",
            "Epoch 668/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9577 - accuracy: 0.6311 - val_loss: 0.9476 - val_accuracy: 0.5897\n",
            "Epoch 669/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0116 - accuracy: 0.6052 - val_loss: 1.0074 - val_accuracy: 0.6154\n",
            "Epoch 670/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0043 - accuracy: 0.5922 - val_loss: 1.1096 - val_accuracy: 0.5385\n",
            "Epoch 671/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0155 - accuracy: 0.5890 - val_loss: 0.9457 - val_accuracy: 0.5128\n",
            "Epoch 672/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0042 - accuracy: 0.5922 - val_loss: 0.9104 - val_accuracy: 0.6026\n",
            "Epoch 673/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9018 - accuracy: 0.6570 - val_loss: 0.9622 - val_accuracy: 0.5897\n",
            "Epoch 674/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9642 - accuracy: 0.6343 - val_loss: 0.9314 - val_accuracy: 0.5897\n",
            "Epoch 675/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9876 - accuracy: 0.6019 - val_loss: 0.9684 - val_accuracy: 0.5769\n",
            "Epoch 676/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.9043 - accuracy: 0.6440 - val_loss: 1.0100 - val_accuracy: 0.5641\n",
            "Epoch 677/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9917 - accuracy: 0.6019 - val_loss: 1.0467 - val_accuracy: 0.5385\n",
            "Epoch 678/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9411 - accuracy: 0.6472 - val_loss: 0.9500 - val_accuracy: 0.6282\n",
            "Epoch 679/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9227 - accuracy: 0.6537 - val_loss: 0.9457 - val_accuracy: 0.6410\n",
            "Epoch 680/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9608 - accuracy: 0.6505 - val_loss: 0.9670 - val_accuracy: 0.6154\n",
            "Epoch 681/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0262 - accuracy: 0.5663 - val_loss: 1.0069 - val_accuracy: 0.6026\n",
            "Epoch 682/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9188 - accuracy: 0.6926 - val_loss: 0.9914 - val_accuracy: 0.5385\n",
            "Epoch 683/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0621 - accuracy: 0.5696 - val_loss: 0.9251 - val_accuracy: 0.5897\n",
            "Epoch 684/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0382 - accuracy: 0.5922 - val_loss: 1.0359 - val_accuracy: 0.5897\n",
            "Epoch 685/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9983 - accuracy: 0.6343 - val_loss: 0.9278 - val_accuracy: 0.6282\n",
            "Epoch 686/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9560 - accuracy: 0.6278 - val_loss: 1.0003 - val_accuracy: 0.5385\n",
            "Epoch 687/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9864 - accuracy: 0.5922 - val_loss: 0.8907 - val_accuracy: 0.5897\n",
            "Epoch 688/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9094 - accuracy: 0.6472 - val_loss: 0.9263 - val_accuracy: 0.5641\n",
            "Epoch 689/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9251 - accuracy: 0.6570 - val_loss: 0.9083 - val_accuracy: 0.6026\n",
            "Epoch 690/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9406 - accuracy: 0.6537 - val_loss: 0.9760 - val_accuracy: 0.6026\n",
            "Epoch 691/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9033 - accuracy: 0.6408 - val_loss: 0.9429 - val_accuracy: 0.5897\n",
            "Epoch 692/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8951 - accuracy: 0.6505 - val_loss: 0.8642 - val_accuracy: 0.6282\n",
            "Epoch 693/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9575 - accuracy: 0.6117 - val_loss: 0.9717 - val_accuracy: 0.6026\n",
            "Epoch 694/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9476 - accuracy: 0.6052 - val_loss: 0.9262 - val_accuracy: 0.5769\n",
            "Epoch 695/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9779 - accuracy: 0.6052 - val_loss: 0.9392 - val_accuracy: 0.6410\n",
            "Epoch 696/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9072 - accuracy: 0.6505 - val_loss: 0.9060 - val_accuracy: 0.5769\n",
            "Epoch 697/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9550 - accuracy: 0.6181 - val_loss: 0.9162 - val_accuracy: 0.5897\n",
            "Epoch 698/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9300 - accuracy: 0.6214 - val_loss: 0.8890 - val_accuracy: 0.6282\n",
            "Epoch 699/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8832 - accuracy: 0.6634 - val_loss: 0.9039 - val_accuracy: 0.5897\n",
            "Epoch 700/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9378 - accuracy: 0.6375 - val_loss: 0.9574 - val_accuracy: 0.5897\n",
            "Epoch 701/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8699 - accuracy: 0.6472 - val_loss: 0.9104 - val_accuracy: 0.6282\n",
            "Epoch 702/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9597 - accuracy: 0.6181 - val_loss: 0.8648 - val_accuracy: 0.6154\n",
            "Epoch 703/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9573 - accuracy: 0.6311 - val_loss: 0.9442 - val_accuracy: 0.6026\n",
            "Epoch 704/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9059 - accuracy: 0.6408 - val_loss: 0.9894 - val_accuracy: 0.5769\n",
            "Epoch 705/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8944 - accuracy: 0.6570 - val_loss: 0.8767 - val_accuracy: 0.5641\n",
            "Epoch 706/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9744 - accuracy: 0.6343 - val_loss: 0.8732 - val_accuracy: 0.6154\n",
            "Epoch 707/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9214 - accuracy: 0.6408 - val_loss: 0.8714 - val_accuracy: 0.6154\n",
            "Epoch 708/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.1714 - accuracy: 0.6278 - val_loss: 1.0513 - val_accuracy: 0.5128\n",
            "Epoch 709/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0246 - accuracy: 0.5566 - val_loss: 1.3685 - val_accuracy: 0.5256\n",
            "Epoch 710/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0194 - accuracy: 0.5922 - val_loss: 0.9342 - val_accuracy: 0.6154\n",
            "Epoch 711/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8718 - accuracy: 0.6311 - val_loss: 0.9932 - val_accuracy: 0.6026\n",
            "Epoch 712/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0016 - accuracy: 0.6246 - val_loss: 1.0990 - val_accuracy: 0.5769\n",
            "Epoch 713/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 1.0481 - accuracy: 0.5696 - val_loss: 0.9527 - val_accuracy: 0.5897\n",
            "Epoch 714/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9969 - accuracy: 0.6117 - val_loss: 0.9862 - val_accuracy: 0.5897\n",
            "Epoch 715/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9898 - accuracy: 0.6375 - val_loss: 1.0550 - val_accuracy: 0.5769\n",
            "Epoch 716/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0704 - accuracy: 0.5599 - val_loss: 1.0472 - val_accuracy: 0.5641\n",
            "Epoch 717/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0586 - accuracy: 0.5631 - val_loss: 0.9969 - val_accuracy: 0.6026\n",
            "Epoch 718/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0367 - accuracy: 0.5987 - val_loss: 0.9694 - val_accuracy: 0.5769\n",
            "Epoch 719/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9299 - accuracy: 0.5955 - val_loss: 0.9836 - val_accuracy: 0.5513\n",
            "Epoch 720/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.1117 - accuracy: 0.5696 - val_loss: 1.1296 - val_accuracy: 0.5000\n",
            "Epoch 721/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0678 - accuracy: 0.5566 - val_loss: 1.0941 - val_accuracy: 0.5641\n",
            "Epoch 722/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0098 - accuracy: 0.5987 - val_loss: 0.9887 - val_accuracy: 0.5385\n",
            "Epoch 723/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9212 - accuracy: 0.6311 - val_loss: 0.9763 - val_accuracy: 0.5513\n",
            "Epoch 724/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9657 - accuracy: 0.6149 - val_loss: 0.9730 - val_accuracy: 0.5897\n",
            "Epoch 725/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.0095 - accuracy: 0.5955 - val_loss: 0.9638 - val_accuracy: 0.5256\n",
            "Epoch 726/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9132 - accuracy: 0.6311 - val_loss: 0.9735 - val_accuracy: 0.5769\n",
            "Epoch 727/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8751 - accuracy: 0.6667 - val_loss: 0.9299 - val_accuracy: 0.5641\n",
            "Epoch 728/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9648 - accuracy: 0.6214 - val_loss: 1.0332 - val_accuracy: 0.5513\n",
            "Epoch 729/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9387 - accuracy: 0.6181 - val_loss: 0.9037 - val_accuracy: 0.6154\n",
            "Epoch 730/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9406 - accuracy: 0.6019 - val_loss: 0.9524 - val_accuracy: 0.5385\n",
            "Epoch 731/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8818 - accuracy: 0.6602 - val_loss: 0.9244 - val_accuracy: 0.6026\n",
            "Epoch 732/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8559 - accuracy: 0.6731 - val_loss: 0.9164 - val_accuracy: 0.5897\n",
            "Epoch 733/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9124 - accuracy: 0.6343 - val_loss: 0.9412 - val_accuracy: 0.6154\n",
            "Epoch 734/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8753 - accuracy: 0.6634 - val_loss: 0.8985 - val_accuracy: 0.5769\n",
            "Epoch 735/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8728 - accuracy: 0.6602 - val_loss: 0.9621 - val_accuracy: 0.6410\n",
            "Epoch 736/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9517 - accuracy: 0.6375 - val_loss: 0.8907 - val_accuracy: 0.6154\n",
            "Epoch 737/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9344 - accuracy: 0.6084 - val_loss: 0.9415 - val_accuracy: 0.6026\n",
            "Epoch 738/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9010 - accuracy: 0.6375 - val_loss: 0.9314 - val_accuracy: 0.5641\n",
            "Epoch 739/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8353 - accuracy: 0.6505 - val_loss: 0.9348 - val_accuracy: 0.6282\n",
            "Epoch 740/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8380 - accuracy: 0.6731 - val_loss: 0.8801 - val_accuracy: 0.6154\n",
            "Epoch 741/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8981 - accuracy: 0.6634 - val_loss: 0.9109 - val_accuracy: 0.5641\n",
            "Epoch 742/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8491 - accuracy: 0.6893 - val_loss: 0.9575 - val_accuracy: 0.6282\n",
            "Epoch 743/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8469 - accuracy: 0.6796 - val_loss: 0.9164 - val_accuracy: 0.6154\n",
            "Epoch 744/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8340 - accuracy: 0.6537 - val_loss: 0.9835 - val_accuracy: 0.5641\n",
            "Epoch 745/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9110 - accuracy: 0.6343 - val_loss: 0.9167 - val_accuracy: 0.5897\n",
            "Epoch 746/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8860 - accuracy: 0.6408 - val_loss: 0.9971 - val_accuracy: 0.5641\n",
            "Epoch 747/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8671 - accuracy: 0.6537 - val_loss: 0.8982 - val_accuracy: 0.6154\n",
            "Epoch 748/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8712 - accuracy: 0.6408 - val_loss: 0.8728 - val_accuracy: 0.6026\n",
            "Epoch 749/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8724 - accuracy: 0.6408 - val_loss: 0.8924 - val_accuracy: 0.6282\n",
            "Epoch 750/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8769 - accuracy: 0.6796 - val_loss: 0.9463 - val_accuracy: 0.5641\n",
            "Epoch 751/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8455 - accuracy: 0.6731 - val_loss: 0.9268 - val_accuracy: 0.6154\n",
            "Epoch 752/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9002 - accuracy: 0.6311 - val_loss: 0.9600 - val_accuracy: 0.5897\n",
            "Epoch 753/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8858 - accuracy: 0.6246 - val_loss: 0.9112 - val_accuracy: 0.6154\n",
            "Epoch 754/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9038 - accuracy: 0.6699 - val_loss: 0.8794 - val_accuracy: 0.6282\n",
            "Epoch 755/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9566 - accuracy: 0.6408 - val_loss: 0.9008 - val_accuracy: 0.5897\n",
            "Epoch 756/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9078 - accuracy: 0.6408 - val_loss: 0.8694 - val_accuracy: 0.6410\n",
            "Epoch 757/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9243 - accuracy: 0.6311 - val_loss: 0.8835 - val_accuracy: 0.5641\n",
            "Epoch 758/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9456 - accuracy: 0.6246 - val_loss: 0.9725 - val_accuracy: 0.5897\n",
            "Epoch 759/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9343 - accuracy: 0.6084 - val_loss: 0.8168 - val_accuracy: 0.6282\n",
            "Epoch 760/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8618 - accuracy: 0.6537 - val_loss: 0.9456 - val_accuracy: 0.5513\n",
            "Epoch 761/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9212 - accuracy: 0.6472 - val_loss: 0.8552 - val_accuracy: 0.6282\n",
            "Epoch 762/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8426 - accuracy: 0.6634 - val_loss: 0.9204 - val_accuracy: 0.6154\n",
            "Epoch 763/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9006 - accuracy: 0.6149 - val_loss: 0.8623 - val_accuracy: 0.6410\n",
            "Epoch 764/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8236 - accuracy: 0.6570 - val_loss: 0.9772 - val_accuracy: 0.6026\n",
            "Epoch 765/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8379 - accuracy: 0.6828 - val_loss: 0.8740 - val_accuracy: 0.6282\n",
            "Epoch 766/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8284 - accuracy: 0.6861 - val_loss: 0.9266 - val_accuracy: 0.5769\n",
            "Epoch 767/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8842 - accuracy: 0.6214 - val_loss: 0.9054 - val_accuracy: 0.6154\n",
            "Epoch 768/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8588 - accuracy: 0.6699 - val_loss: 0.9151 - val_accuracy: 0.5769\n",
            "Epoch 769/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8635 - accuracy: 0.6246 - val_loss: 0.8816 - val_accuracy: 0.6154\n",
            "Epoch 770/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8994 - accuracy: 0.6505 - val_loss: 1.0040 - val_accuracy: 0.5769\n",
            "Epoch 771/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9030 - accuracy: 0.6472 - val_loss: 0.8615 - val_accuracy: 0.6282\n",
            "Epoch 772/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8063 - accuracy: 0.6958 - val_loss: 0.9373 - val_accuracy: 0.5769\n",
            "Epoch 773/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8456 - accuracy: 0.6667 - val_loss: 0.9472 - val_accuracy: 0.5641\n",
            "Epoch 774/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8213 - accuracy: 0.6731 - val_loss: 0.8405 - val_accuracy: 0.6410\n",
            "Epoch 775/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8644 - accuracy: 0.6667 - val_loss: 0.8948 - val_accuracy: 0.6154\n",
            "Epoch 776/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8702 - accuracy: 0.6634 - val_loss: 0.8794 - val_accuracy: 0.5897\n",
            "Epoch 777/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9303 - accuracy: 0.6084 - val_loss: 0.8745 - val_accuracy: 0.6154\n",
            "Epoch 778/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8292 - accuracy: 0.6990 - val_loss: 0.8919 - val_accuracy: 0.6026\n",
            "Epoch 779/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8116 - accuracy: 0.6602 - val_loss: 0.9247 - val_accuracy: 0.6154\n",
            "Epoch 780/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8790 - accuracy: 0.6634 - val_loss: 0.9007 - val_accuracy: 0.6154\n",
            "Epoch 781/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8965 - accuracy: 0.6408 - val_loss: 0.8781 - val_accuracy: 0.5769\n",
            "Epoch 782/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8647 - accuracy: 0.6861 - val_loss: 0.8452 - val_accuracy: 0.6154\n",
            "Epoch 783/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8268 - accuracy: 0.6828 - val_loss: 0.9790 - val_accuracy: 0.5897\n",
            "Epoch 784/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9067 - accuracy: 0.6181 - val_loss: 0.9098 - val_accuracy: 0.6282\n",
            "Epoch 785/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8457 - accuracy: 0.6699 - val_loss: 0.8758 - val_accuracy: 0.6538\n",
            "Epoch 786/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7960 - accuracy: 0.6699 - val_loss: 0.8927 - val_accuracy: 0.5641\n",
            "Epoch 787/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9524 - accuracy: 0.6343 - val_loss: 0.9064 - val_accuracy: 0.6026\n",
            "Epoch 788/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9032 - accuracy: 0.6440 - val_loss: 0.9616 - val_accuracy: 0.5897\n",
            "Epoch 789/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9307 - accuracy: 0.6149 - val_loss: 0.9883 - val_accuracy: 0.5641\n",
            "Epoch 790/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8812 - accuracy: 0.6667 - val_loss: 0.9061 - val_accuracy: 0.6026\n",
            "Epoch 791/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8917 - accuracy: 0.6278 - val_loss: 0.9893 - val_accuracy: 0.6026\n",
            "Epoch 792/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0077 - accuracy: 0.5987 - val_loss: 0.9188 - val_accuracy: 0.6154\n",
            "Epoch 793/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9825 - accuracy: 0.6181 - val_loss: 0.8959 - val_accuracy: 0.5897\n",
            "Epoch 794/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8757 - accuracy: 0.6052 - val_loss: 0.9013 - val_accuracy: 0.6026\n",
            "Epoch 795/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8716 - accuracy: 0.6861 - val_loss: 0.9503 - val_accuracy: 0.6154\n",
            "Epoch 796/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8750 - accuracy: 0.6343 - val_loss: 0.9011 - val_accuracy: 0.6026\n",
            "Epoch 797/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9114 - accuracy: 0.6149 - val_loss: 0.9633 - val_accuracy: 0.5897\n",
            "Epoch 798/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9195 - accuracy: 0.6440 - val_loss: 0.9737 - val_accuracy: 0.5385\n",
            "Epoch 799/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8791 - accuracy: 0.6311 - val_loss: 0.9256 - val_accuracy: 0.5513\n",
            "Epoch 800/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8547 - accuracy: 0.6246 - val_loss: 0.8631 - val_accuracy: 0.5897\n",
            "Epoch 801/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8867 - accuracy: 0.6634 - val_loss: 0.9218 - val_accuracy: 0.5897\n",
            "Epoch 802/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9133 - accuracy: 0.6117 - val_loss: 0.8457 - val_accuracy: 0.6026\n",
            "Epoch 803/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8813 - accuracy: 0.6537 - val_loss: 0.8594 - val_accuracy: 0.6410\n",
            "Epoch 804/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9548 - accuracy: 0.6019 - val_loss: 0.9724 - val_accuracy: 0.5513\n",
            "Epoch 805/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8989 - accuracy: 0.6570 - val_loss: 0.9612 - val_accuracy: 0.6026\n",
            "Epoch 806/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8661 - accuracy: 0.6699 - val_loss: 0.9199 - val_accuracy: 0.5897\n",
            "Epoch 807/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8811 - accuracy: 0.6472 - val_loss: 0.8159 - val_accuracy: 0.6795\n",
            "Epoch 808/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8672 - accuracy: 0.6667 - val_loss: 0.9183 - val_accuracy: 0.5769\n",
            "Epoch 809/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9418 - accuracy: 0.6343 - val_loss: 1.1257 - val_accuracy: 0.4872\n",
            "Epoch 810/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9817 - accuracy: 0.6117 - val_loss: 1.0118 - val_accuracy: 0.5897\n",
            "Epoch 811/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9243 - accuracy: 0.6343 - val_loss: 1.0541 - val_accuracy: 0.5128\n",
            "Epoch 812/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9128 - accuracy: 0.6472 - val_loss: 0.9763 - val_accuracy: 0.5513\n",
            "Epoch 813/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8842 - accuracy: 0.6278 - val_loss: 0.8952 - val_accuracy: 0.5769\n",
            "Epoch 814/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8603 - accuracy: 0.6699 - val_loss: 0.8161 - val_accuracy: 0.6538\n",
            "Epoch 815/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8669 - accuracy: 0.6731 - val_loss: 0.8765 - val_accuracy: 0.6538\n",
            "Epoch 816/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9989 - accuracy: 0.5793 - val_loss: 0.9126 - val_accuracy: 0.6026\n",
            "Epoch 817/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9163 - accuracy: 0.6311 - val_loss: 0.9617 - val_accuracy: 0.5128\n",
            "Epoch 818/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8758 - accuracy: 0.6375 - val_loss: 0.9467 - val_accuracy: 0.6154\n",
            "Epoch 819/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8403 - accuracy: 0.6893 - val_loss: 0.9125 - val_accuracy: 0.6026\n",
            "Epoch 820/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8869 - accuracy: 0.6408 - val_loss: 0.9107 - val_accuracy: 0.5641\n",
            "Epoch 821/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9065 - accuracy: 0.6634 - val_loss: 0.9273 - val_accuracy: 0.6026\n",
            "Epoch 822/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8806 - accuracy: 0.6408 - val_loss: 0.9389 - val_accuracy: 0.6538\n",
            "Epoch 823/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8742 - accuracy: 0.6570 - val_loss: 0.9126 - val_accuracy: 0.5897\n",
            "Epoch 824/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8527 - accuracy: 0.6537 - val_loss: 0.9192 - val_accuracy: 0.6026\n",
            "Epoch 825/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8332 - accuracy: 0.6731 - val_loss: 0.9104 - val_accuracy: 0.6154\n",
            "Epoch 826/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9401 - accuracy: 0.6019 - val_loss: 0.9661 - val_accuracy: 0.5769\n",
            "Epoch 827/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.9370 - accuracy: 0.6019 - val_loss: 0.9623 - val_accuracy: 0.5769\n",
            "Epoch 828/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9425 - accuracy: 0.6246 - val_loss: 0.9703 - val_accuracy: 0.5385\n",
            "Epoch 829/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.0102 - accuracy: 0.5825 - val_loss: 0.9859 - val_accuracy: 0.5897\n",
            "Epoch 830/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9598 - accuracy: 0.6117 - val_loss: 0.9642 - val_accuracy: 0.5897\n",
            "Epoch 831/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9027 - accuracy: 0.6375 - val_loss: 0.8848 - val_accuracy: 0.6154\n",
            "Epoch 832/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8767 - accuracy: 0.6893 - val_loss: 0.8832 - val_accuracy: 0.6026\n",
            "Epoch 833/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8806 - accuracy: 0.6472 - val_loss: 0.9134 - val_accuracy: 0.5513\n",
            "Epoch 834/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9351 - accuracy: 0.6505 - val_loss: 0.8585 - val_accuracy: 0.6410\n",
            "Epoch 835/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9280 - accuracy: 0.6311 - val_loss: 0.8555 - val_accuracy: 0.6154\n",
            "Epoch 836/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8577 - accuracy: 0.6731 - val_loss: 0.9733 - val_accuracy: 0.6026\n",
            "Epoch 837/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8830 - accuracy: 0.6343 - val_loss: 0.9328 - val_accuracy: 0.5897\n",
            "Epoch 838/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8766 - accuracy: 0.6278 - val_loss: 0.8906 - val_accuracy: 0.6282\n",
            "Epoch 839/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9207 - accuracy: 0.6343 - val_loss: 0.8990 - val_accuracy: 0.6026\n",
            "Epoch 840/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9120 - accuracy: 0.6246 - val_loss: 0.9274 - val_accuracy: 0.6026\n",
            "Epoch 841/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8713 - accuracy: 0.6537 - val_loss: 0.8942 - val_accuracy: 0.6282\n",
            "Epoch 842/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8583 - accuracy: 0.6440 - val_loss: 0.9410 - val_accuracy: 0.6282\n",
            "Epoch 843/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9250 - accuracy: 0.6375 - val_loss: 0.9312 - val_accuracy: 0.5769\n",
            "Epoch 844/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8927 - accuracy: 0.6052 - val_loss: 0.9207 - val_accuracy: 0.6026\n",
            "Epoch 845/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9186 - accuracy: 0.6311 - val_loss: 0.9025 - val_accuracy: 0.6282\n",
            "Epoch 846/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9244 - accuracy: 0.6084 - val_loss: 0.9893 - val_accuracy: 0.5385\n",
            "Epoch 847/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9030 - accuracy: 0.6375 - val_loss: 0.9163 - val_accuracy: 0.6410\n",
            "Epoch 848/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9616 - accuracy: 0.6149 - val_loss: 0.9876 - val_accuracy: 0.6282\n",
            "Epoch 849/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9381 - accuracy: 0.6149 - val_loss: 0.9389 - val_accuracy: 0.5897\n",
            "Epoch 850/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9099 - accuracy: 0.6537 - val_loss: 0.9405 - val_accuracy: 0.5897\n",
            "Epoch 851/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9254 - accuracy: 0.6246 - val_loss: 1.0245 - val_accuracy: 0.5513\n",
            "Epoch 852/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9447 - accuracy: 0.6246 - val_loss: 1.0359 - val_accuracy: 0.5897\n",
            "Epoch 853/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 1.0063 - accuracy: 0.5761 - val_loss: 0.8627 - val_accuracy: 0.6410\n",
            "Epoch 854/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9706 - accuracy: 0.6019 - val_loss: 0.9705 - val_accuracy: 0.5897\n",
            "Epoch 855/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9946 - accuracy: 0.6052 - val_loss: 0.9061 - val_accuracy: 0.5769\n",
            "Epoch 856/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9360 - accuracy: 0.6246 - val_loss: 0.8843 - val_accuracy: 0.5769\n",
            "Epoch 857/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9177 - accuracy: 0.5955 - val_loss: 1.0312 - val_accuracy: 0.5000\n",
            "Epoch 858/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9577 - accuracy: 0.6181 - val_loss: 0.9163 - val_accuracy: 0.6154\n",
            "Epoch 859/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9444 - accuracy: 0.6019 - val_loss: 0.9312 - val_accuracy: 0.6282\n",
            "Epoch 860/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9961 - accuracy: 0.5955 - val_loss: 1.0579 - val_accuracy: 0.5256\n",
            "Epoch 861/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 1.0327 - accuracy: 0.5793 - val_loss: 0.8842 - val_accuracy: 0.6282\n",
            "Epoch 862/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9008 - accuracy: 0.6343 - val_loss: 0.8941 - val_accuracy: 0.6026\n",
            "Epoch 863/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8943 - accuracy: 0.6278 - val_loss: 0.9369 - val_accuracy: 0.6026\n",
            "Epoch 864/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8888 - accuracy: 0.6472 - val_loss: 0.9609 - val_accuracy: 0.5641\n",
            "Epoch 865/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8385 - accuracy: 0.6602 - val_loss: 0.9055 - val_accuracy: 0.6026\n",
            "Epoch 866/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8397 - accuracy: 0.6537 - val_loss: 0.9269 - val_accuracy: 0.5769\n",
            "Epoch 867/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9129 - accuracy: 0.6311 - val_loss: 0.9405 - val_accuracy: 0.6538\n",
            "Epoch 868/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8929 - accuracy: 0.6375 - val_loss: 0.8972 - val_accuracy: 0.6282\n",
            "Epoch 869/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9107 - accuracy: 0.6278 - val_loss: 1.0441 - val_accuracy: 0.5256\n",
            "Epoch 870/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8648 - accuracy: 0.6796 - val_loss: 0.8318 - val_accuracy: 0.6667\n",
            "Epoch 871/2000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.9057 - accuracy: 0.6408 - val_loss: 0.9119 - val_accuracy: 0.6282\n",
            "Epoch 872/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9135 - accuracy: 0.6181 - val_loss: 0.8833 - val_accuracy: 0.6282\n",
            "Epoch 873/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9274 - accuracy: 0.6311 - val_loss: 0.9162 - val_accuracy: 0.6026\n",
            "Epoch 874/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9280 - accuracy: 0.6181 - val_loss: 0.9417 - val_accuracy: 0.6026\n",
            "Epoch 875/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9140 - accuracy: 0.5922 - val_loss: 1.0131 - val_accuracy: 0.5256\n",
            "Epoch 876/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9327 - accuracy: 0.6311 - val_loss: 0.9257 - val_accuracy: 0.6026\n",
            "Epoch 877/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9570 - accuracy: 0.5890 - val_loss: 0.8578 - val_accuracy: 0.6410\n",
            "Epoch 878/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8795 - accuracy: 0.6472 - val_loss: 0.9649 - val_accuracy: 0.6282\n",
            "Epoch 879/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8169 - accuracy: 0.6634 - val_loss: 0.9264 - val_accuracy: 0.6154\n",
            "Epoch 880/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8797 - accuracy: 0.6440 - val_loss: 0.9160 - val_accuracy: 0.6026\n",
            "Epoch 881/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8818 - accuracy: 0.6505 - val_loss: 0.9241 - val_accuracy: 0.6026\n",
            "Epoch 882/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8598 - accuracy: 0.6602 - val_loss: 0.9314 - val_accuracy: 0.5641\n",
            "Epoch 883/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8832 - accuracy: 0.6311 - val_loss: 0.8749 - val_accuracy: 0.6282\n",
            "Epoch 884/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8996 - accuracy: 0.6278 - val_loss: 0.9668 - val_accuracy: 0.5897\n",
            "Epoch 885/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8368 - accuracy: 0.6861 - val_loss: 0.8729 - val_accuracy: 0.6410\n",
            "Epoch 886/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8317 - accuracy: 0.6731 - val_loss: 0.9403 - val_accuracy: 0.5641\n",
            "Epoch 887/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8743 - accuracy: 0.6667 - val_loss: 0.8858 - val_accuracy: 0.6410\n",
            "Epoch 888/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8755 - accuracy: 0.6472 - val_loss: 0.9238 - val_accuracy: 0.5641\n",
            "Epoch 889/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8677 - accuracy: 0.6731 - val_loss: 0.8898 - val_accuracy: 0.6282\n",
            "Epoch 890/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8527 - accuracy: 0.6472 - val_loss: 0.8616 - val_accuracy: 0.6410\n",
            "Epoch 891/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8468 - accuracy: 0.6505 - val_loss: 0.8987 - val_accuracy: 0.6026\n",
            "Epoch 892/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8783 - accuracy: 0.6408 - val_loss: 0.8734 - val_accuracy: 0.6154\n",
            "Epoch 893/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8440 - accuracy: 0.6602 - val_loss: 0.9449 - val_accuracy: 0.5769\n",
            "Epoch 894/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9038 - accuracy: 0.6246 - val_loss: 0.8787 - val_accuracy: 0.6410\n",
            "Epoch 895/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8493 - accuracy: 0.6537 - val_loss: 1.2337 - val_accuracy: 0.5000\n",
            "Epoch 896/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9430 - accuracy: 0.6181 - val_loss: 0.9098 - val_accuracy: 0.6154\n",
            "Epoch 897/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9908 - accuracy: 0.6019 - val_loss: 0.9518 - val_accuracy: 0.5513\n",
            "Epoch 898/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9326 - accuracy: 0.6278 - val_loss: 0.9658 - val_accuracy: 0.5385\n",
            "Epoch 899/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.7778 - accuracy: 0.6764 - val_loss: 0.9350 - val_accuracy: 0.6154\n",
            "Epoch 900/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8757 - accuracy: 0.6764 - val_loss: 0.9469 - val_accuracy: 0.5769\n",
            "Epoch 901/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8886 - accuracy: 0.6052 - val_loss: 0.8786 - val_accuracy: 0.6154\n",
            "Epoch 902/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8867 - accuracy: 0.6278 - val_loss: 0.9412 - val_accuracy: 0.5513\n",
            "Epoch 903/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8126 - accuracy: 0.6667 - val_loss: 0.8847 - val_accuracy: 0.6026\n",
            "Epoch 904/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8572 - accuracy: 0.6117 - val_loss: 0.8474 - val_accuracy: 0.6538\n",
            "Epoch 905/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8544 - accuracy: 0.6570 - val_loss: 0.8448 - val_accuracy: 0.6154\n",
            "Epoch 906/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.7903 - accuracy: 0.6893 - val_loss: 0.8857 - val_accuracy: 0.6026\n",
            "Epoch 907/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9421 - accuracy: 0.6343 - val_loss: 0.8812 - val_accuracy: 0.6026\n",
            "Epoch 908/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8529 - accuracy: 0.6828 - val_loss: 0.8418 - val_accuracy: 0.6410\n",
            "Epoch 909/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8056 - accuracy: 0.6602 - val_loss: 0.9067 - val_accuracy: 0.5897\n",
            "Epoch 910/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8464 - accuracy: 0.6667 - val_loss: 0.8972 - val_accuracy: 0.6026\n",
            "Epoch 911/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7903 - accuracy: 0.6926 - val_loss: 0.8973 - val_accuracy: 0.5641\n",
            "Epoch 912/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7979 - accuracy: 0.6667 - val_loss: 0.8315 - val_accuracy: 0.6538\n",
            "Epoch 913/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8000 - accuracy: 0.6731 - val_loss: 0.9639 - val_accuracy: 0.5641\n",
            "Epoch 914/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8344 - accuracy: 0.6505 - val_loss: 0.8852 - val_accuracy: 0.5641\n",
            "Epoch 915/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8324 - accuracy: 0.6667 - val_loss: 0.9646 - val_accuracy: 0.5385\n",
            "Epoch 916/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8236 - accuracy: 0.6570 - val_loss: 0.9213 - val_accuracy: 0.5897\n",
            "Epoch 917/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8826 - accuracy: 0.6375 - val_loss: 1.0464 - val_accuracy: 0.5256\n",
            "Epoch 918/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8522 - accuracy: 0.6117 - val_loss: 0.8982 - val_accuracy: 0.6154\n",
            "Epoch 919/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8193 - accuracy: 0.6537 - val_loss: 0.7995 - val_accuracy: 0.6410\n",
            "Epoch 920/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8510 - accuracy: 0.6343 - val_loss: 0.8473 - val_accuracy: 0.6282\n",
            "Epoch 921/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8457 - accuracy: 0.6537 - val_loss: 0.9449 - val_accuracy: 0.5513\n",
            "Epoch 922/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8702 - accuracy: 0.6440 - val_loss: 0.8270 - val_accuracy: 0.6154\n",
            "Epoch 923/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8435 - accuracy: 0.6440 - val_loss: 0.9368 - val_accuracy: 0.5897\n",
            "Epoch 924/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8503 - accuracy: 0.6537 - val_loss: 0.9079 - val_accuracy: 0.6282\n",
            "Epoch 925/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8158 - accuracy: 0.6570 - val_loss: 1.1112 - val_accuracy: 0.5256\n",
            "Epoch 926/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9205 - accuracy: 0.6246 - val_loss: 0.8469 - val_accuracy: 0.6282\n",
            "Epoch 927/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8348 - accuracy: 0.6699 - val_loss: 0.9114 - val_accuracy: 0.6282\n",
            "Epoch 928/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8396 - accuracy: 0.6570 - val_loss: 0.8494 - val_accuracy: 0.6410\n",
            "Epoch 929/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7719 - accuracy: 0.6731 - val_loss: 0.8688 - val_accuracy: 0.6282\n",
            "Epoch 930/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8470 - accuracy: 0.6537 - val_loss: 0.9094 - val_accuracy: 0.5769\n",
            "Epoch 931/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.7960 - accuracy: 0.6667 - val_loss: 0.8790 - val_accuracy: 0.6026\n",
            "Epoch 932/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.7854 - accuracy: 0.6764 - val_loss: 1.0042 - val_accuracy: 0.5641\n",
            "Epoch 933/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8199 - accuracy: 0.6667 - val_loss: 0.8569 - val_accuracy: 0.6026\n",
            "Epoch 934/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8978 - accuracy: 0.6440 - val_loss: 0.8855 - val_accuracy: 0.6026\n",
            "Epoch 935/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8676 - accuracy: 0.6570 - val_loss: 0.9159 - val_accuracy: 0.6026\n",
            "Epoch 936/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8471 - accuracy: 0.6246 - val_loss: 0.8854 - val_accuracy: 0.6154\n",
            "Epoch 937/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8991 - accuracy: 0.6278 - val_loss: 0.8568 - val_accuracy: 0.6410\n",
            "Epoch 938/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9794 - accuracy: 0.5955 - val_loss: 0.8565 - val_accuracy: 0.6410\n",
            "Epoch 939/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9030 - accuracy: 0.6375 - val_loss: 0.8209 - val_accuracy: 0.6282\n",
            "Epoch 940/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8345 - accuracy: 0.6343 - val_loss: 0.9585 - val_accuracy: 0.5513\n",
            "Epoch 941/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8345 - accuracy: 0.6796 - val_loss: 0.8925 - val_accuracy: 0.5897\n",
            "Epoch 942/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8607 - accuracy: 0.6537 - val_loss: 0.8178 - val_accuracy: 0.6282\n",
            "Epoch 943/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8637 - accuracy: 0.6570 - val_loss: 0.8544 - val_accuracy: 0.6154\n",
            "Epoch 944/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.7978 - accuracy: 0.6667 - val_loss: 0.8719 - val_accuracy: 0.6282\n",
            "Epoch 945/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8794 - accuracy: 0.6764 - val_loss: 0.8888 - val_accuracy: 0.6026\n",
            "Epoch 946/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8097 - accuracy: 0.6861 - val_loss: 0.8480 - val_accuracy: 0.5897\n",
            "Epoch 947/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8834 - accuracy: 0.6537 - val_loss: 0.7994 - val_accuracy: 0.6667\n",
            "Epoch 948/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9602 - accuracy: 0.6181 - val_loss: 0.9861 - val_accuracy: 0.5897\n",
            "Epoch 949/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1.0006 - accuracy: 0.6019 - val_loss: 0.9392 - val_accuracy: 0.5385\n",
            "Epoch 950/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9628 - accuracy: 0.6084 - val_loss: 0.9356 - val_accuracy: 0.5641\n",
            "Epoch 951/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9392 - accuracy: 0.6311 - val_loss: 0.8561 - val_accuracy: 0.6538\n",
            "Epoch 952/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8844 - accuracy: 0.6537 - val_loss: 0.8642 - val_accuracy: 0.6026\n",
            "Epoch 953/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8480 - accuracy: 0.6570 - val_loss: 0.8661 - val_accuracy: 0.6154\n",
            "Epoch 954/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8791 - accuracy: 0.6408 - val_loss: 0.9311 - val_accuracy: 0.5897\n",
            "Epoch 955/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8928 - accuracy: 0.6278 - val_loss: 1.0786 - val_accuracy: 0.5513\n",
            "Epoch 956/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9302 - accuracy: 0.6440 - val_loss: 0.8597 - val_accuracy: 0.6154\n",
            "Epoch 957/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9093 - accuracy: 0.6375 - val_loss: 0.8934 - val_accuracy: 0.6026\n",
            "Epoch 958/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9669 - accuracy: 0.6019 - val_loss: 0.9566 - val_accuracy: 0.5769\n",
            "Epoch 959/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9286 - accuracy: 0.6408 - val_loss: 0.9258 - val_accuracy: 0.6410\n",
            "Epoch 960/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9802 - accuracy: 0.6181 - val_loss: 0.9319 - val_accuracy: 0.6154\n",
            "Epoch 961/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9514 - accuracy: 0.6181 - val_loss: 0.8982 - val_accuracy: 0.5897\n",
            "Epoch 962/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8832 - accuracy: 0.6246 - val_loss: 0.8485 - val_accuracy: 0.6154\n",
            "Epoch 963/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8869 - accuracy: 0.6667 - val_loss: 0.8650 - val_accuracy: 0.6410\n",
            "Epoch 964/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8169 - accuracy: 0.7087 - val_loss: 0.9204 - val_accuracy: 0.5897\n",
            "Epoch 965/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9554 - accuracy: 0.5922 - val_loss: 0.9306 - val_accuracy: 0.5641\n",
            "Epoch 966/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9964 - accuracy: 0.6052 - val_loss: 0.9396 - val_accuracy: 0.5513\n",
            "Epoch 967/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8902 - accuracy: 0.6278 - val_loss: 0.8493 - val_accuracy: 0.5897\n",
            "Epoch 968/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8844 - accuracy: 0.6667 - val_loss: 0.9716 - val_accuracy: 0.5769\n",
            "Epoch 969/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9021 - accuracy: 0.6505 - val_loss: 0.9704 - val_accuracy: 0.5513\n",
            "Epoch 970/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8683 - accuracy: 0.6667 - val_loss: 0.9282 - val_accuracy: 0.6154\n",
            "Epoch 971/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9201 - accuracy: 0.6214 - val_loss: 0.9195 - val_accuracy: 0.6026\n",
            "Epoch 972/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9287 - accuracy: 0.6343 - val_loss: 0.9349 - val_accuracy: 0.6026\n",
            "Epoch 973/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0235 - accuracy: 0.6311 - val_loss: 0.9124 - val_accuracy: 0.6154\n",
            "Epoch 974/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9594 - accuracy: 0.5890 - val_loss: 1.0851 - val_accuracy: 0.5256\n",
            "Epoch 975/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8426 - accuracy: 0.6634 - val_loss: 0.8356 - val_accuracy: 0.6410\n",
            "Epoch 976/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8762 - accuracy: 0.6343 - val_loss: 0.8685 - val_accuracy: 0.6667\n",
            "Epoch 977/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8718 - accuracy: 0.6764 - val_loss: 0.9705 - val_accuracy: 0.6026\n",
            "Epoch 978/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8740 - accuracy: 0.6408 - val_loss: 0.8268 - val_accuracy: 0.6282\n",
            "Epoch 979/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8863 - accuracy: 0.6505 - val_loss: 0.8481 - val_accuracy: 0.6282\n",
            "Epoch 980/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8681 - accuracy: 0.6634 - val_loss: 0.8652 - val_accuracy: 0.6282\n",
            "Epoch 981/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8845 - accuracy: 0.6214 - val_loss: 0.9114 - val_accuracy: 0.5897\n",
            "Epoch 982/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8716 - accuracy: 0.6505 - val_loss: 0.8665 - val_accuracy: 0.5897\n",
            "Epoch 983/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9428 - accuracy: 0.6181 - val_loss: 1.0171 - val_accuracy: 0.5385\n",
            "Epoch 984/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8688 - accuracy: 0.6375 - val_loss: 0.8970 - val_accuracy: 0.6282\n",
            "Epoch 985/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8689 - accuracy: 0.6570 - val_loss: 0.8273 - val_accuracy: 0.6667\n",
            "Epoch 986/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8477 - accuracy: 0.6796 - val_loss: 0.8393 - val_accuracy: 0.6026\n",
            "Epoch 987/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8906 - accuracy: 0.6278 - val_loss: 0.8832 - val_accuracy: 0.6026\n",
            "Epoch 988/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9059 - accuracy: 0.6472 - val_loss: 0.9796 - val_accuracy: 0.5385\n",
            "Epoch 989/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9249 - accuracy: 0.6084 - val_loss: 1.0973 - val_accuracy: 0.5641\n",
            "Epoch 990/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9166 - accuracy: 0.6214 - val_loss: 1.0155 - val_accuracy: 0.6538\n",
            "Epoch 991/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9850 - accuracy: 0.6181 - val_loss: 0.8514 - val_accuracy: 0.6026\n",
            "Epoch 992/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8873 - accuracy: 0.6440 - val_loss: 0.8911 - val_accuracy: 0.5769\n",
            "Epoch 993/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8689 - accuracy: 0.6796 - val_loss: 0.8315 - val_accuracy: 0.6282\n",
            "Epoch 994/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8570 - accuracy: 0.6634 - val_loss: 0.8213 - val_accuracy: 0.6667\n",
            "Epoch 995/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8466 - accuracy: 0.6893 - val_loss: 0.9323 - val_accuracy: 0.5641\n",
            "Epoch 996/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8942 - accuracy: 0.6440 - val_loss: 0.8862 - val_accuracy: 0.6154\n",
            "Epoch 997/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8222 - accuracy: 0.6667 - val_loss: 0.8292 - val_accuracy: 0.6410\n",
            "Epoch 998/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8165 - accuracy: 0.6990 - val_loss: 0.8501 - val_accuracy: 0.6154\n",
            "Epoch 999/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9196 - accuracy: 0.6375 - val_loss: 0.8573 - val_accuracy: 0.5769\n",
            "Epoch 1000/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9098 - accuracy: 0.6311 - val_loss: 0.8765 - val_accuracy: 0.6154\n",
            "Epoch 1001/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9235 - accuracy: 0.6311 - val_loss: 0.8083 - val_accuracy: 0.5769\n",
            "Epoch 1002/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8585 - accuracy: 0.6634 - val_loss: 0.9989 - val_accuracy: 0.5641\n",
            "Epoch 1003/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8397 - accuracy: 0.6440 - val_loss: 0.8926 - val_accuracy: 0.5769\n",
            "Epoch 1004/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9109 - accuracy: 0.6375 - val_loss: 0.9113 - val_accuracy: 0.6154\n",
            "Epoch 1005/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9126 - accuracy: 0.6019 - val_loss: 0.9043 - val_accuracy: 0.6410\n",
            "Epoch 1006/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9599 - accuracy: 0.5890 - val_loss: 0.8984 - val_accuracy: 0.5769\n",
            "Epoch 1007/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8861 - accuracy: 0.6440 - val_loss: 1.0423 - val_accuracy: 0.5513\n",
            "Epoch 1008/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8225 - accuracy: 0.6796 - val_loss: 0.8413 - val_accuracy: 0.6282\n",
            "Epoch 1009/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8959 - accuracy: 0.6602 - val_loss: 0.8937 - val_accuracy: 0.5641\n",
            "Epoch 1010/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8987 - accuracy: 0.6343 - val_loss: 0.9052 - val_accuracy: 0.5897\n",
            "Epoch 1011/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8006 - accuracy: 0.6699 - val_loss: 0.9456 - val_accuracy: 0.5641\n",
            "Epoch 1012/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9094 - accuracy: 0.6570 - val_loss: 0.9151 - val_accuracy: 0.5897\n",
            "Epoch 1013/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9438 - accuracy: 0.6181 - val_loss: 0.9313 - val_accuracy: 0.6026\n",
            "Epoch 1014/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8688 - accuracy: 0.6440 - val_loss: 0.8952 - val_accuracy: 0.6154\n",
            "Epoch 1015/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8446 - accuracy: 0.6602 - val_loss: 0.8686 - val_accuracy: 0.6667\n",
            "Epoch 1016/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8369 - accuracy: 0.6861 - val_loss: 0.9359 - val_accuracy: 0.5641\n",
            "Epoch 1017/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8933 - accuracy: 0.6764 - val_loss: 0.9371 - val_accuracy: 0.5641\n",
            "Epoch 1018/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8680 - accuracy: 0.6505 - val_loss: 0.8214 - val_accuracy: 0.6282\n",
            "Epoch 1019/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8965 - accuracy: 0.6570 - val_loss: 0.9127 - val_accuracy: 0.5769\n",
            "Epoch 1020/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8602 - accuracy: 0.6537 - val_loss: 0.8547 - val_accuracy: 0.6154\n",
            "Epoch 1021/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8932 - accuracy: 0.6440 - val_loss: 0.9142 - val_accuracy: 0.5769\n",
            "Epoch 1022/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8413 - accuracy: 0.6699 - val_loss: 0.8912 - val_accuracy: 0.6410\n",
            "Epoch 1023/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.7953 - accuracy: 0.6958 - val_loss: 0.9169 - val_accuracy: 0.6026\n",
            "Epoch 1024/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8268 - accuracy: 0.6667 - val_loss: 0.8926 - val_accuracy: 0.6282\n",
            "Epoch 1025/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8045 - accuracy: 0.6602 - val_loss: 0.8662 - val_accuracy: 0.6026\n",
            "Epoch 1026/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8176 - accuracy: 0.6764 - val_loss: 0.8747 - val_accuracy: 0.6282\n",
            "Epoch 1027/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8589 - accuracy: 0.6311 - val_loss: 0.8300 - val_accuracy: 0.6026\n",
            "Epoch 1028/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8849 - accuracy: 0.6278 - val_loss: 0.9173 - val_accuracy: 0.5769\n",
            "Epoch 1029/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8430 - accuracy: 0.6505 - val_loss: 0.8903 - val_accuracy: 0.5769\n",
            "Epoch 1030/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8975 - accuracy: 0.6311 - val_loss: 0.8146 - val_accuracy: 0.6026\n",
            "Epoch 1031/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8593 - accuracy: 0.6375 - val_loss: 0.9383 - val_accuracy: 0.5769\n",
            "Epoch 1032/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8611 - accuracy: 0.6440 - val_loss: 0.9287 - val_accuracy: 0.5769\n",
            "Epoch 1033/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.9538 - accuracy: 0.6278 - val_loss: 1.1330 - val_accuracy: 0.5128\n",
            "Epoch 1034/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9425 - accuracy: 0.6375 - val_loss: 0.9161 - val_accuracy: 0.6154\n",
            "Epoch 1035/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9664 - accuracy: 0.6246 - val_loss: 0.9231 - val_accuracy: 0.5385\n",
            "Epoch 1036/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.9522 - accuracy: 0.5955 - val_loss: 0.8569 - val_accuracy: 0.6026\n",
            "Epoch 1037/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9262 - accuracy: 0.5955 - val_loss: 0.9607 - val_accuracy: 0.5513\n",
            "Epoch 1038/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9231 - accuracy: 0.6117 - val_loss: 0.9165 - val_accuracy: 0.6282\n",
            "Epoch 1039/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8338 - accuracy: 0.6570 - val_loss: 0.8443 - val_accuracy: 0.6282\n",
            "Epoch 1040/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8108 - accuracy: 0.7023 - val_loss: 0.8568 - val_accuracy: 0.6026\n",
            "Epoch 1041/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8587 - accuracy: 0.6602 - val_loss: 0.8786 - val_accuracy: 0.5897\n",
            "Epoch 1042/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8375 - accuracy: 0.6731 - val_loss: 0.8565 - val_accuracy: 0.6154\n",
            "Epoch 1043/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8209 - accuracy: 0.6958 - val_loss: 0.8690 - val_accuracy: 0.6282\n",
            "Epoch 1044/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8403 - accuracy: 0.6570 - val_loss: 0.9286 - val_accuracy: 0.5641\n",
            "Epoch 1045/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8241 - accuracy: 0.6731 - val_loss: 0.8095 - val_accuracy: 0.6795\n",
            "Epoch 1046/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8112 - accuracy: 0.6764 - val_loss: 0.8970 - val_accuracy: 0.5897\n",
            "Epoch 1047/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8163 - accuracy: 0.6796 - val_loss: 0.8066 - val_accuracy: 0.6410\n",
            "Epoch 1048/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8545 - accuracy: 0.6634 - val_loss: 0.8329 - val_accuracy: 0.6154\n",
            "Epoch 1049/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8475 - accuracy: 0.6602 - val_loss: 0.9808 - val_accuracy: 0.5641\n",
            "Epoch 1050/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8819 - accuracy: 0.6214 - val_loss: 0.9421 - val_accuracy: 0.5897\n",
            "Epoch 1051/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8220 - accuracy: 0.6861 - val_loss: 0.8577 - val_accuracy: 0.5769\n",
            "Epoch 1052/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8260 - accuracy: 0.6667 - val_loss: 0.8811 - val_accuracy: 0.6410\n",
            "Epoch 1053/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8729 - accuracy: 0.6408 - val_loss: 0.8525 - val_accuracy: 0.5897\n",
            "Epoch 1054/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.7900 - accuracy: 0.6990 - val_loss: 0.8140 - val_accuracy: 0.6410\n",
            "Epoch 1055/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8971 - accuracy: 0.6311 - val_loss: 0.9094 - val_accuracy: 0.5897\n",
            "Epoch 1056/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8732 - accuracy: 0.6731 - val_loss: 0.8793 - val_accuracy: 0.5897\n",
            "Epoch 1057/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9729 - accuracy: 0.5987 - val_loss: 1.0356 - val_accuracy: 0.5385\n",
            "Epoch 1058/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.0090 - accuracy: 0.5955 - val_loss: 0.9227 - val_accuracy: 0.6282\n",
            "Epoch 1059/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.8967 - accuracy: 0.6278 - val_loss: 0.8799 - val_accuracy: 0.6282\n",
            "Epoch 1060/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8776 - accuracy: 0.6990 - val_loss: 1.0108 - val_accuracy: 0.5769\n",
            "Epoch 1061/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9855 - accuracy: 0.6343 - val_loss: 0.9595 - val_accuracy: 0.5897\n",
            "Epoch 1062/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9730 - accuracy: 0.6181 - val_loss: 0.9376 - val_accuracy: 0.5769\n",
            "Epoch 1063/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9656 - accuracy: 0.6246 - val_loss: 0.9456 - val_accuracy: 0.5769\n",
            "Epoch 1064/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8593 - accuracy: 0.6343 - val_loss: 0.8408 - val_accuracy: 0.6410\n",
            "Epoch 1065/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8639 - accuracy: 0.6570 - val_loss: 0.9540 - val_accuracy: 0.6026\n",
            "Epoch 1066/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8206 - accuracy: 0.6796 - val_loss: 0.8498 - val_accuracy: 0.6282\n",
            "Epoch 1067/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8156 - accuracy: 0.6634 - val_loss: 0.8972 - val_accuracy: 0.6154\n",
            "Epoch 1068/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8371 - accuracy: 0.6699 - val_loss: 0.9872 - val_accuracy: 0.5641\n",
            "Epoch 1069/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8231 - accuracy: 0.6861 - val_loss: 0.9404 - val_accuracy: 0.5897\n",
            "Epoch 1070/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9493 - accuracy: 0.5922 - val_loss: 0.9217 - val_accuracy: 0.6410\n",
            "Epoch 1071/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9002 - accuracy: 0.6440 - val_loss: 0.9114 - val_accuracy: 0.6282\n",
            "Epoch 1072/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8115 - accuracy: 0.6861 - val_loss: 0.8906 - val_accuracy: 0.6410\n",
            "Epoch 1073/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.7797 - accuracy: 0.7055 - val_loss: 0.8614 - val_accuracy: 0.6410\n",
            "Epoch 1074/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8700 - accuracy: 0.6602 - val_loss: 0.9040 - val_accuracy: 0.6154\n",
            "Epoch 1075/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8663 - accuracy: 0.6570 - val_loss: 0.9635 - val_accuracy: 0.5897\n",
            "Epoch 1076/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8320 - accuracy: 0.6602 - val_loss: 0.8127 - val_accuracy: 0.6410\n",
            "Epoch 1077/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8865 - accuracy: 0.6505 - val_loss: 0.8378 - val_accuracy: 0.6410\n",
            "Epoch 1078/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8885 - accuracy: 0.6505 - val_loss: 0.8685 - val_accuracy: 0.6154\n",
            "Epoch 1079/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.7965 - accuracy: 0.7055 - val_loss: 1.1055 - val_accuracy: 0.5385\n",
            "Epoch 1080/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8137 - accuracy: 0.6958 - val_loss: 0.8272 - val_accuracy: 0.6282\n",
            "Epoch 1081/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8293 - accuracy: 0.6893 - val_loss: 0.8965 - val_accuracy: 0.6154\n",
            "Epoch 1082/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8470 - accuracy: 0.6634 - val_loss: 0.9963 - val_accuracy: 0.5641\n",
            "Epoch 1083/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8258 - accuracy: 0.6570 - val_loss: 1.0066 - val_accuracy: 0.5897\n",
            "Epoch 1084/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.9301 - accuracy: 0.6117 - val_loss: 0.9548 - val_accuracy: 0.5897\n",
            "Epoch 1085/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9058 - accuracy: 0.6505 - val_loss: 0.9609 - val_accuracy: 0.5897\n",
            "Epoch 1086/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8507 - accuracy: 0.6796 - val_loss: 1.0663 - val_accuracy: 0.5385\n",
            "Epoch 1087/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8918 - accuracy: 0.6472 - val_loss: 0.9763 - val_accuracy: 0.6410\n",
            "Epoch 1088/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8652 - accuracy: 0.6440 - val_loss: 1.0102 - val_accuracy: 0.5769\n",
            "Epoch 1089/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8885 - accuracy: 0.6505 - val_loss: 0.8953 - val_accuracy: 0.6282\n",
            "Epoch 1090/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8799 - accuracy: 0.6505 - val_loss: 0.8712 - val_accuracy: 0.6538\n",
            "Epoch 1091/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8158 - accuracy: 0.6796 - val_loss: 0.9646 - val_accuracy: 0.5769\n",
            "Epoch 1092/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8663 - accuracy: 0.6408 - val_loss: 1.0386 - val_accuracy: 0.5897\n",
            "Epoch 1093/2000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.7756 - accuracy: 0.6861 - val_loss: 0.8208 - val_accuracy: 0.6667\n",
            "Epoch 1094/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8145 - accuracy: 0.6828 - val_loss: 0.8317 - val_accuracy: 0.6538\n",
            "Epoch 1095/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8565 - accuracy: 0.6505 - val_loss: 1.0109 - val_accuracy: 0.5897\n",
            "Epoch 1096/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.7903 - accuracy: 0.6893 - val_loss: 0.9531 - val_accuracy: 0.5769\n",
            "Epoch 1097/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8067 - accuracy: 0.6861 - val_loss: 0.8884 - val_accuracy: 0.6282\n",
            "Epoch 1098/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8560 - accuracy: 0.6731 - val_loss: 0.8314 - val_accuracy: 0.6282\n",
            "Epoch 1099/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8977 - accuracy: 0.6214 - val_loss: 0.8248 - val_accuracy: 0.6538\n",
            "Epoch 1100/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8383 - accuracy: 0.6731 - val_loss: 0.9268 - val_accuracy: 0.6410\n",
            "Epoch 1101/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8308 - accuracy: 0.6796 - val_loss: 0.9197 - val_accuracy: 0.6282\n",
            "Epoch 1102/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8580 - accuracy: 0.6278 - val_loss: 0.9866 - val_accuracy: 0.5897\n",
            "Epoch 1103/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8036 - accuracy: 0.6764 - val_loss: 0.9227 - val_accuracy: 0.6026\n",
            "Epoch 1104/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8543 - accuracy: 0.6570 - val_loss: 0.8732 - val_accuracy: 0.6154\n",
            "Epoch 1105/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8453 - accuracy: 0.6375 - val_loss: 0.9394 - val_accuracy: 0.6026\n",
            "Epoch 1106/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8032 - accuracy: 0.6828 - val_loss: 0.9443 - val_accuracy: 0.5897\n",
            "Epoch 1107/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8593 - accuracy: 0.6570 - val_loss: 0.9470 - val_accuracy: 0.5897\n",
            "Epoch 1108/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8099 - accuracy: 0.6731 - val_loss: 0.9571 - val_accuracy: 0.6026\n",
            "Epoch 1109/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8857 - accuracy: 0.6472 - val_loss: 1.0424 - val_accuracy: 0.5385\n",
            "Epoch 1110/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.9202 - accuracy: 0.6537 - val_loss: 1.0022 - val_accuracy: 0.5897\n",
            "Epoch 1111/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8544 - accuracy: 0.6602 - val_loss: 0.9326 - val_accuracy: 0.6154\n",
            "Epoch 1112/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8737 - accuracy: 0.6570 - val_loss: 0.8457 - val_accuracy: 0.6410\n",
            "Epoch 1113/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8562 - accuracy: 0.6472 - val_loss: 1.0292 - val_accuracy: 0.5641\n",
            "Epoch 1114/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8820 - accuracy: 0.6570 - val_loss: 0.8025 - val_accuracy: 0.6667\n",
            "Epoch 1115/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7708 - accuracy: 0.6828 - val_loss: 0.8849 - val_accuracy: 0.6410\n",
            "Epoch 1116/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.9062 - accuracy: 0.6278 - val_loss: 0.9233 - val_accuracy: 0.6026\n",
            "Epoch 1117/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8108 - accuracy: 0.6634 - val_loss: 0.8467 - val_accuracy: 0.6410\n",
            "Epoch 1118/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8043 - accuracy: 0.6537 - val_loss: 0.8182 - val_accuracy: 0.6538\n",
            "Epoch 1119/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8145 - accuracy: 0.6926 - val_loss: 0.8172 - val_accuracy: 0.6154\n",
            "Epoch 1120/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8214 - accuracy: 0.6667 - val_loss: 0.8877 - val_accuracy: 0.6026\n",
            "Epoch 1121/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8389 - accuracy: 0.6699 - val_loss: 0.8742 - val_accuracy: 0.6154\n",
            "Epoch 1122/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8022 - accuracy: 0.6926 - val_loss: 0.9486 - val_accuracy: 0.6282\n",
            "Epoch 1123/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.7900 - accuracy: 0.6699 - val_loss: 0.8827 - val_accuracy: 0.6667\n",
            "Epoch 1124/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8013 - accuracy: 0.6634 - val_loss: 0.8700 - val_accuracy: 0.6410\n",
            "Epoch 1125/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8352 - accuracy: 0.6764 - val_loss: 0.8457 - val_accuracy: 0.6282\n",
            "Epoch 1126/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.8466 - accuracy: 0.6570 - val_loss: 0.8384 - val_accuracy: 0.6282\n",
            "Epoch 1127/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8146 - accuracy: 0.6861 - val_loss: 0.9023 - val_accuracy: 0.6282\n",
            "Epoch 1128/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.7601 - accuracy: 0.6958 - val_loss: 0.8645 - val_accuracy: 0.6538\n",
            "Epoch 1129/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.7685 - accuracy: 0.6926 - val_loss: 0.9500 - val_accuracy: 0.6282\n",
            "Epoch 1130/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8091 - accuracy: 0.7120 - val_loss: 0.8246 - val_accuracy: 0.6538\n",
            "Epoch 1131/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8060 - accuracy: 0.6634 - val_loss: 0.8343 - val_accuracy: 0.6026\n",
            "Epoch 1132/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7525 - accuracy: 0.7023 - val_loss: 0.9684 - val_accuracy: 0.5897\n",
            "Epoch 1133/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7919 - accuracy: 0.7152 - val_loss: 0.9044 - val_accuracy: 0.5641\n",
            "Epoch 1134/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8028 - accuracy: 0.6731 - val_loss: 0.8924 - val_accuracy: 0.6026\n",
            "Epoch 1135/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8403 - accuracy: 0.6667 - val_loss: 0.9050 - val_accuracy: 0.6154\n",
            "Epoch 1136/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8267 - accuracy: 0.6602 - val_loss: 0.9175 - val_accuracy: 0.6282\n",
            "Epoch 1137/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8287 - accuracy: 0.6731 - val_loss: 0.8466 - val_accuracy: 0.6154\n",
            "Epoch 1138/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8255 - accuracy: 0.6408 - val_loss: 0.9529 - val_accuracy: 0.5769\n",
            "Epoch 1139/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8057 - accuracy: 0.6602 - val_loss: 0.8799 - val_accuracy: 0.5897\n",
            "Epoch 1140/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8070 - accuracy: 0.6699 - val_loss: 0.9464 - val_accuracy: 0.6154\n",
            "Epoch 1141/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8699 - accuracy: 0.6343 - val_loss: 0.9227 - val_accuracy: 0.6026\n",
            "Epoch 1142/2000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.7291 - accuracy: 0.7055 - val_loss: 0.8677 - val_accuracy: 0.6667\n",
            "Epoch 1143/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.7851 - accuracy: 0.6667 - val_loss: 0.9139 - val_accuracy: 0.6154\n",
            "Epoch 1144/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7863 - accuracy: 0.7120 - val_loss: 0.8846 - val_accuracy: 0.6538\n",
            "Epoch 1145/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.7932 - accuracy: 0.6667 - val_loss: 0.8643 - val_accuracy: 0.6410\n",
            "Epoch 1146/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7900 - accuracy: 0.6764 - val_loss: 0.9492 - val_accuracy: 0.5769\n",
            "Epoch 1147/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8579 - accuracy: 0.6699 - val_loss: 1.0565 - val_accuracy: 0.5385\n",
            "Epoch 1148/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.7898 - accuracy: 0.6796 - val_loss: 0.8711 - val_accuracy: 0.6026\n",
            "Epoch 1149/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7657 - accuracy: 0.6893 - val_loss: 1.0151 - val_accuracy: 0.5641\n",
            "Epoch 1150/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8367 - accuracy: 0.6667 - val_loss: 0.9119 - val_accuracy: 0.6026\n",
            "Epoch 1151/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8079 - accuracy: 0.6958 - val_loss: 0.8372 - val_accuracy: 0.6282\n",
            "Epoch 1152/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.7766 - accuracy: 0.6990 - val_loss: 0.8245 - val_accuracy: 0.6410\n",
            "Epoch 1153/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7682 - accuracy: 0.6796 - val_loss: 0.9899 - val_accuracy: 0.5769\n",
            "Epoch 1154/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8262 - accuracy: 0.6570 - val_loss: 0.9438 - val_accuracy: 0.5897\n",
            "Epoch 1155/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8057 - accuracy: 0.6796 - val_loss: 0.9525 - val_accuracy: 0.5641\n",
            "Epoch 1156/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7608 - accuracy: 0.7152 - val_loss: 0.8376 - val_accuracy: 0.6026\n",
            "Epoch 1157/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8478 - accuracy: 0.6505 - val_loss: 0.8014 - val_accuracy: 0.6282\n",
            "Epoch 1158/2000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.8245 - accuracy: 0.7023 - val_loss: 0.9294 - val_accuracy: 0.5641\n",
            "Epoch 1159/2000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.8402 - accuracy: 0.6667 - val_loss: 1.0594 - val_accuracy: 0.5513\n",
            "Epoch 1160/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8324 - accuracy: 0.6731 - val_loss: 0.9806 - val_accuracy: 0.5769\n",
            "Epoch 1161/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8562 - accuracy: 0.6375 - val_loss: 0.9145 - val_accuracy: 0.5897\n",
            "Epoch 1162/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.7727 - accuracy: 0.6828 - val_loss: 0.8612 - val_accuracy: 0.5897\n",
            "Epoch 1163/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7895 - accuracy: 0.6958 - val_loss: 0.8866 - val_accuracy: 0.5897\n",
            "Epoch 1164/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8911 - accuracy: 0.6796 - val_loss: 0.8729 - val_accuracy: 0.6154\n",
            "Epoch 1165/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.9072 - accuracy: 0.6375 - val_loss: 0.8930 - val_accuracy: 0.5897\n",
            "Epoch 1166/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8575 - accuracy: 0.6861 - val_loss: 0.8465 - val_accuracy: 0.6282\n",
            "Epoch 1167/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.8264 - accuracy: 0.6796 - val_loss: 1.0361 - val_accuracy: 0.5641\n",
            "Epoch 1168/2000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.7839 - accuracy: 0.6926 - val_loss: 0.8248 - val_accuracy: 0.6538\n",
            "Epoch 1169/2000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8424 - accuracy: 0.6472 - val_loss: 0.8677 - val_accuracy: 0.5769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJR5pfQ1c9g4"
      },
      "source": [
        "### Evaluation and Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "413JtwURc9g5",
        "outputId": "4725b60f-af5e-4113-9da3-031d483b06ea"
      },
      "source": [
        "# Evaluate our model on the test set\n",
        "loss, accuracy = model_2.evaluate(X_test, y_test)\n",
        "print(f\"Model loss on the test set: {loss}\")\n",
        "print(f\"Model accuracy on the test set: {100*accuracy:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 5ms/step - loss: 0.7995 - accuracy: 0.6410\n",
            "Model loss on the test set: 0.7994661927223206\n",
            "Model accuracy on the test set: 64.10%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "OJB0Jvw9c9g5",
        "outputId": "124252bd-a206-48f1-edaa-5107209b8409"
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history_2.history['loss'])#[5:])\n",
        "plt.plot(history_2.history['val_loss'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "NOjoGnLic9g6",
        "outputId": "671609fd-bb22-48e4-f317-16e0fa7a3e45"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history_2.history['accuracy'])#[5:])\n",
        "plt.plot(history_2.history['val_accuracy'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Binary Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}