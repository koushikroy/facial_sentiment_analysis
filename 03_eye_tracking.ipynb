{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_eye_tracking.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMdjcGddCqJUQoE1fLYvKgO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koushikroy/facial_sentiment_analysis/blob/main/03_eye_tracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxOCPcq7GOJz"
      },
      "source": [
        "**In this we are going to make a NN where the inputs are distances and output are the 9 classes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDgbP5LGDuTv"
      },
      "source": [
        "# Dataset Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igon8YsMD3ci"
      },
      "source": [
        "## Drive Mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMMfR7x8D0Rw",
        "outputId": "4cca9fcb-4cfc-4671-bb86-b84572edd97a"
      },
      "source": [
        "# Google Drive Mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlfNiUhoE57P",
        "outputId": "d488ce86-3f58-4bc4-bb8a-bb7300423a11"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/Codes/Eye Tracking/final_dataset.zip\" -d \"/tmp\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/Codes/Eye Tracking/final_dataset.zip\n",
            "  inflating: /tmp/final_dataset.csv  \n",
            "  inflating: /tmp/__MACOSX/._final_dataset.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EBz-M1hFGaM"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7burwVveFH-G"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sngB8V1KFLj1"
      },
      "source": [
        "## Dataset Loading and EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1B9_r-NFPYF"
      },
      "source": [
        "input_df = pd.read_csv('/tmp/final_dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "EdZoGHAAFeNy",
        "outputId": "117862a3-0c45-45ad-f531-c3657e0c73eb"
      },
      "source": [
        "display(input_df.head())\n",
        "display(input_df.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>2172</th>\n",
              "      <th>2173</th>\n",
              "      <th>2174</th>\n",
              "      <th>2175</th>\n",
              "      <th>2176</th>\n",
              "      <th>2177</th>\n",
              "      <th>2178</th>\n",
              "      <th>2179</th>\n",
              "      <th>2180</th>\n",
              "      <th>2181</th>\n",
              "      <th>2182</th>\n",
              "      <th>2183</th>\n",
              "      <th>2184</th>\n",
              "      <th>2185</th>\n",
              "      <th>2186</th>\n",
              "      <th>2187</th>\n",
              "      <th>2188</th>\n",
              "      <th>2189</th>\n",
              "      <th>2190</th>\n",
              "      <th>2191</th>\n",
              "      <th>2192</th>\n",
              "      <th>2193</th>\n",
              "      <th>2194</th>\n",
              "      <th>2195</th>\n",
              "      <th>2196</th>\n",
              "      <th>2197</th>\n",
              "      <th>2198</th>\n",
              "      <th>2199</th>\n",
              "      <th>2200</th>\n",
              "      <th>2201</th>\n",
              "      <th>2202</th>\n",
              "      <th>2203</th>\n",
              "      <th>2204</th>\n",
              "      <th>2205</th>\n",
              "      <th>2206</th>\n",
              "      <th>2207</th>\n",
              "      <th>2208</th>\n",
              "      <th>2209</th>\n",
              "      <th>2210</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.058757</td>\n",
              "      <td>0.110986</td>\n",
              "      <td>0.078615</td>\n",
              "      <td>0.228407</td>\n",
              "      <td>0.328576</td>\n",
              "      <td>0.283223</td>\n",
              "      <td>0.370292</td>\n",
              "      <td>0.378883</td>\n",
              "      <td>0.339486</td>\n",
              "      <td>0.281941</td>\n",
              "      <td>0.204064</td>\n",
              "      <td>0.137100</td>\n",
              "      <td>0.124728</td>\n",
              "      <td>0.150299</td>\n",
              "      <td>0.208915</td>\n",
              "      <td>0.280805</td>\n",
              "      <td>0.242965</td>\n",
              "      <td>0.310228</td>\n",
              "      <td>0.286812</td>\n",
              "      <td>0.248601</td>\n",
              "      <td>0.182099</td>\n",
              "      <td>0.152411</td>\n",
              "      <td>0.322290</td>\n",
              "      <td>0.349934</td>\n",
              "      <td>0.264387</td>\n",
              "      <td>0.327862</td>\n",
              "      <td>0.175787</td>\n",
              "      <td>0.046164</td>\n",
              "      <td>0.202702</td>\n",
              "      <td>0.256533</td>\n",
              "      <td>0.312418</td>\n",
              "      <td>0.331482</td>\n",
              "      <td>0.376683</td>\n",
              "      <td>0.159383</td>\n",
              "      <td>0.078885</td>\n",
              "      <td>0.066579</td>\n",
              "      <td>0.093475</td>\n",
              "      <td>0.085122</td>\n",
              "      <td>0.111178</td>\n",
              "      <td>...</td>\n",
              "      <td>0.078615</td>\n",
              "      <td>0.111178</td>\n",
              "      <td>0.147292</td>\n",
              "      <td>0.041290</td>\n",
              "      <td>0.061936</td>\n",
              "      <td>0.093475</td>\n",
              "      <td>0.066579</td>\n",
              "      <td>0.079424</td>\n",
              "      <td>0.041290</td>\n",
              "      <td>0.117696</td>\n",
              "      <td>0.201648</td>\n",
              "      <td>0.020645</td>\n",
              "      <td>0.052635</td>\n",
              "      <td>0.026114</td>\n",
              "      <td>0.047078</td>\n",
              "      <td>0.026114</td>\n",
              "      <td>0.080754</td>\n",
              "      <td>0.161244</td>\n",
              "      <td>0.032643</td>\n",
              "      <td>0.009233</td>\n",
              "      <td>0.038068</td>\n",
              "      <td>0.038068</td>\n",
              "      <td>0.064299</td>\n",
              "      <td>0.141235</td>\n",
              "      <td>0.026918</td>\n",
              "      <td>0.035157</td>\n",
              "      <td>0.061591</td>\n",
              "      <td>0.036931</td>\n",
              "      <td>0.115502</td>\n",
              "      <td>0.029197</td>\n",
              "      <td>0.036931</td>\n",
              "      <td>0.055780</td>\n",
              "      <td>0.139718</td>\n",
              "      <td>0.039171</td>\n",
              "      <td>0.039712</td>\n",
              "      <td>0.148013</td>\n",
              "      <td>0.078615</td>\n",
              "      <td>0.176393</td>\n",
              "      <td>0.119849</td>\n",
              "      <td>down</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.052316</td>\n",
              "      <td>0.110313</td>\n",
              "      <td>0.073986</td>\n",
              "      <td>0.229422</td>\n",
              "      <td>0.330431</td>\n",
              "      <td>0.284631</td>\n",
              "      <td>0.374457</td>\n",
              "      <td>0.376587</td>\n",
              "      <td>0.337429</td>\n",
              "      <td>0.286695</td>\n",
              "      <td>0.202828</td>\n",
              "      <td>0.142906</td>\n",
              "      <td>0.123462</td>\n",
              "      <td>0.149389</td>\n",
              "      <td>0.207750</td>\n",
              "      <td>0.279028</td>\n",
              "      <td>0.248708</td>\n",
              "      <td>0.314768</td>\n",
              "      <td>0.291429</td>\n",
              "      <td>0.254978</td>\n",
              "      <td>0.180996</td>\n",
              "      <td>0.151488</td>\n",
              "      <td>0.326779</td>\n",
              "      <td>0.347814</td>\n",
              "      <td>0.260613</td>\n",
              "      <td>0.324516</td>\n",
              "      <td>0.180763</td>\n",
              "      <td>0.045884</td>\n",
              "      <td>0.203242</td>\n",
              "      <td>0.254978</td>\n",
              "      <td>0.311811</td>\n",
              "      <td>0.326070</td>\n",
              "      <td>0.377537</td>\n",
              "      <td>0.153147</td>\n",
              "      <td>0.078407</td>\n",
              "      <td>0.066175</td>\n",
              "      <td>0.092909</td>\n",
              "      <td>0.084607</td>\n",
              "      <td>0.110504</td>\n",
              "      <td>...</td>\n",
              "      <td>0.072550</td>\n",
              "      <td>0.116983</td>\n",
              "      <td>0.160530</td>\n",
              "      <td>0.041040</td>\n",
              "      <td>0.061560</td>\n",
              "      <td>0.094482</td>\n",
              "      <td>0.066175</td>\n",
              "      <td>0.078942</td>\n",
              "      <td>0.041040</td>\n",
              "      <td>0.123462</td>\n",
              "      <td>0.206122</td>\n",
              "      <td>0.020520</td>\n",
              "      <td>0.053510</td>\n",
              "      <td>0.025956</td>\n",
              "      <td>0.046793</td>\n",
              "      <td>0.025956</td>\n",
              "      <td>0.086574</td>\n",
              "      <td>0.165820</td>\n",
              "      <td>0.033088</td>\n",
              "      <td>0.009177</td>\n",
              "      <td>0.037837</td>\n",
              "      <td>0.037837</td>\n",
              "      <td>0.069889</td>\n",
              "      <td>0.145823</td>\n",
              "      <td>0.029020</td>\n",
              "      <td>0.041040</td>\n",
              "      <td>0.064890</td>\n",
              "      <td>0.045884</td>\n",
              "      <td>0.115534</td>\n",
              "      <td>0.029020</td>\n",
              "      <td>0.036707</td>\n",
              "      <td>0.061560</td>\n",
              "      <td>0.144080</td>\n",
              "      <td>0.038934</td>\n",
              "      <td>0.045884</td>\n",
              "      <td>0.151488</td>\n",
              "      <td>0.084607</td>\n",
              "      <td>0.180414</td>\n",
              "      <td>0.119123</td>\n",
              "      <td>down</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.051589</td>\n",
              "      <td>0.109627</td>\n",
              "      <td>0.068550</td>\n",
              "      <td>0.219254</td>\n",
              "      <td>0.320168</td>\n",
              "      <td>0.274352</td>\n",
              "      <td>0.363935</td>\n",
              "      <td>0.367573</td>\n",
              "      <td>0.322690</td>\n",
              "      <td>0.272756</td>\n",
              "      <td>0.196128</td>\n",
              "      <td>0.129616</td>\n",
              "      <td>0.116255</td>\n",
              "      <td>0.141870</td>\n",
              "      <td>0.200324</td>\n",
              "      <td>0.270920</td>\n",
              "      <td>0.235354</td>\n",
              "      <td>0.299151</td>\n",
              "      <td>0.280942</td>\n",
              "      <td>0.244114</td>\n",
              "      <td>0.172071</td>\n",
              "      <td>0.143183</td>\n",
              "      <td>0.310608</td>\n",
              "      <td>0.338355</td>\n",
              "      <td>0.250835</td>\n",
              "      <td>0.314929</td>\n",
              "      <td>0.165292</td>\n",
              "      <td>0.040785</td>\n",
              "      <td>0.197817</td>\n",
              "      <td>0.248921</td>\n",
              "      <td>0.305001</td>\n",
              "      <td>0.324041</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>0.157432</td>\n",
              "      <td>0.083832</td>\n",
              "      <td>0.065764</td>\n",
              "      <td>0.098645</td>\n",
              "      <td>0.090511</td>\n",
              "      <td>0.109817</td>\n",
              "      <td>...</td>\n",
              "      <td>0.077384</td>\n",
              "      <td>0.109817</td>\n",
              "      <td>0.151783</td>\n",
              "      <td>0.040785</td>\n",
              "      <td>0.061177</td>\n",
              "      <td>0.087711</td>\n",
              "      <td>0.065764</td>\n",
              "      <td>0.078451</td>\n",
              "      <td>0.034727</td>\n",
              "      <td>0.116255</td>\n",
              "      <td>0.204840</td>\n",
              "      <td>0.020392</td>\n",
              "      <td>0.046947</td>\n",
              "      <td>0.025795</td>\n",
              "      <td>0.046502</td>\n",
              "      <td>0.026588</td>\n",
              "      <td>0.079765</td>\n",
              "      <td>0.164788</td>\n",
              "      <td>0.026588</td>\n",
              "      <td>0.009120</td>\n",
              "      <td>0.037602</td>\n",
              "      <td>0.041292</td>\n",
              "      <td>0.063512</td>\n",
              "      <td>0.144915</td>\n",
              "      <td>0.023251</td>\n",
              "      <td>0.039226</td>\n",
              "      <td>0.064487</td>\n",
              "      <td>0.045599</td>\n",
              "      <td>0.119952</td>\n",
              "      <td>0.028839</td>\n",
              "      <td>0.041292</td>\n",
              "      <td>0.055097</td>\n",
              "      <td>0.143183</td>\n",
              "      <td>0.045141</td>\n",
              "      <td>0.039226</td>\n",
              "      <td>0.150545</td>\n",
              "      <td>0.084080</td>\n",
              "      <td>0.184436</td>\n",
              "      <td>0.121673</td>\n",
              "      <td>down</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.053499</td>\n",
              "      <td>0.099756</td>\n",
              "      <td>0.071776</td>\n",
              "      <td>0.219681</td>\n",
              "      <td>0.325420</td>\n",
              "      <td>0.277274</td>\n",
              "      <td>0.366469</td>\n",
              "      <td>0.371836</td>\n",
              "      <td>0.332382</td>\n",
              "      <td>0.282544</td>\n",
              "      <td>0.203013</td>\n",
              "      <td>0.140764</td>\n",
              "      <td>0.119443</td>\n",
              "      <td>0.152765</td>\n",
              "      <td>0.206668</td>\n",
              "      <td>0.279015</td>\n",
              "      <td>0.243359</td>\n",
              "      <td>0.306394</td>\n",
              "      <td>0.287258</td>\n",
              "      <td>0.248728</td>\n",
              "      <td>0.174558</td>\n",
              "      <td>0.146587</td>\n",
              "      <td>0.318790</td>\n",
              "      <td>0.339460</td>\n",
              "      <td>0.254330</td>\n",
              "      <td>0.321883</td>\n",
              "      <td>0.172273</td>\n",
              "      <td>0.048309</td>\n",
              "      <td>0.203555</td>\n",
              "      <td>0.258111</td>\n",
              "      <td>0.309041</td>\n",
              "      <td>0.323588</td>\n",
              "      <td>0.369699</td>\n",
              "      <td>0.150442</td>\n",
              "      <td>0.077669</td>\n",
              "      <td>0.069279</td>\n",
              "      <td>0.093843</td>\n",
              "      <td>0.087279</td>\n",
              "      <td>0.112807</td>\n",
              "      <td>...</td>\n",
              "      <td>0.073294</td>\n",
              "      <td>0.113002</td>\n",
              "      <td>0.149708</td>\n",
              "      <td>0.040363</td>\n",
              "      <td>0.061178</td>\n",
              "      <td>0.087279</td>\n",
              "      <td>0.066688</td>\n",
              "      <td>0.082079</td>\n",
              "      <td>0.035734</td>\n",
              "      <td>0.113585</td>\n",
              "      <td>0.195950</td>\n",
              "      <td>0.020984</td>\n",
              "      <td>0.046921</td>\n",
              "      <td>0.026543</td>\n",
              "      <td>0.047851</td>\n",
              "      <td>0.020984</td>\n",
              "      <td>0.075659</td>\n",
              "      <td>0.158286</td>\n",
              "      <td>0.026543</td>\n",
              "      <td>0.009384</td>\n",
              "      <td>0.038692</td>\n",
              "      <td>0.037537</td>\n",
              "      <td>0.059352</td>\n",
              "      <td>0.138080</td>\n",
              "      <td>0.020984</td>\n",
              "      <td>0.033836</td>\n",
              "      <td>0.059352</td>\n",
              "      <td>0.037537</td>\n",
              "      <td>0.117398</td>\n",
              "      <td>0.029676</td>\n",
              "      <td>0.038692</td>\n",
              "      <td>0.050536</td>\n",
              "      <td>0.136799</td>\n",
              "      <td>0.046921</td>\n",
              "      <td>0.033836</td>\n",
              "      <td>0.146136</td>\n",
              "      <td>0.079628</td>\n",
              "      <td>0.175188</td>\n",
              "      <td>0.121815</td>\n",
              "      <td>down</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.057782</td>\n",
              "      <td>0.115565</td>\n",
              "      <td>0.077310</td>\n",
              "      <td>0.221383</td>\n",
              "      <td>0.320885</td>\n",
              "      <td>0.275773</td>\n",
              "      <td>0.363185</td>\n",
              "      <td>0.372431</td>\n",
              "      <td>0.327496</td>\n",
              "      <td>0.277931</td>\n",
              "      <td>0.195265</td>\n",
              "      <td>0.134978</td>\n",
              "      <td>0.115743</td>\n",
              "      <td>0.147806</td>\n",
              "      <td>0.199132</td>\n",
              "      <td>0.269651</td>\n",
              "      <td>0.239709</td>\n",
              "      <td>0.304201</td>\n",
              "      <td>0.280809</td>\n",
              "      <td>0.244476</td>\n",
              "      <td>0.171314</td>\n",
              "      <td>0.143561</td>\n",
              "      <td>0.316227</td>\n",
              "      <td>0.336865</td>\n",
              "      <td>0.251786</td>\n",
              "      <td>0.321077</td>\n",
              "      <td>0.172871</td>\n",
              "      <td>0.039053</td>\n",
              "      <td>0.194948</td>\n",
              "      <td>0.247826</td>\n",
              "      <td>0.303659</td>\n",
              "      <td>0.325983</td>\n",
              "      <td>0.367697</td>\n",
              "      <td>0.156739</td>\n",
              "      <td>0.077576</td>\n",
              "      <td>0.065474</td>\n",
              "      <td>0.091924</td>\n",
              "      <td>0.083710</td>\n",
              "      <td>0.109333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.070623</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.152608</td>\n",
              "      <td>0.039053</td>\n",
              "      <td>0.060908</td>\n",
              "      <td>0.085657</td>\n",
              "      <td>0.064523</td>\n",
              "      <td>0.078106</td>\n",
              "      <td>0.034574</td>\n",
              "      <td>0.115743</td>\n",
              "      <td>0.203938</td>\n",
              "      <td>0.023149</td>\n",
              "      <td>0.046740</td>\n",
              "      <td>0.025681</td>\n",
              "      <td>0.043068</td>\n",
              "      <td>0.020303</td>\n",
              "      <td>0.078106</td>\n",
              "      <td>0.167420</td>\n",
              "      <td>0.025681</td>\n",
              "      <td>0.014356</td>\n",
              "      <td>0.037436</td>\n",
              "      <td>0.041110</td>\n",
              "      <td>0.063232</td>\n",
              "      <td>0.144278</td>\n",
              "      <td>0.023149</td>\n",
              "      <td>0.032737</td>\n",
              "      <td>0.060569</td>\n",
              "      <td>0.041110</td>\n",
              "      <td>0.123329</td>\n",
              "      <td>0.023149</td>\n",
              "      <td>0.037436</td>\n",
              "      <td>0.052943</td>\n",
              "      <td>0.146405</td>\n",
              "      <td>0.044942</td>\n",
              "      <td>0.039053</td>\n",
              "      <td>0.149883</td>\n",
              "      <td>0.083710</td>\n",
              "      <td>0.183624</td>\n",
              "      <td>0.121137</td>\n",
              "      <td>down</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2213 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0         0         1  ...      2209      2210  output\n",
              "0           0  0.058757  0.110986  ...  0.176393  0.119849    down\n",
              "1           1  0.052316  0.110313  ...  0.180414  0.119123    down\n",
              "2           2  0.051589  0.109627  ...  0.184436  0.121673    down\n",
              "3           3  0.053499  0.099756  ...  0.175188  0.121815    down\n",
              "4           4  0.057782  0.115565  ...  0.183624  0.121137    down\n",
              "\n",
              "[5 rows x 2213 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7203 entries, 0 to 7202\n",
            "Columns: 2213 entries, Unnamed: 0 to output\n",
            "dtypes: float64(2211), int64(1), object(1)\n",
            "memory usage: 121.6+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zwomESlGEcm"
      },
      "source": [
        "## Mapping The Output Column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvPk2c_VHdKE"
      },
      "source": [
        "input_df_copy = input_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq5ambOKGCO3"
      },
      "source": [
        "uniqueValues = input_df_copy['output'].unique()\n",
        "input_df_copy['output'] = input_df_copy['output'].map({uniqueValues[0]:0,uniqueValues[1]:1,uniqueValues[2]:2,\n",
        "                                                       uniqueValues[3]:3,uniqueValues[4]:4,uniqueValues[5]:5,\n",
        "                                                       uniqueValues[6]:6,uniqueValues[7]:7})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygtGHyvNISy5",
        "outputId": "2a9a91bb-0a4a-488a-d39f-c1cec9eac4d7"
      },
      "source": [
        "input_df_copy.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7203 entries, 0 to 7202\n",
            "Columns: 2213 entries, Unnamed: 0 to output\n",
            "dtypes: float64(2211), int64(2)\n",
            "memory usage: 121.6 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RaOtKOKOzXQ"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxbGrJCyO2Er"
      },
      "source": [
        "# Create X & y\n",
        "X = input_df_copy.drop(\"output\", axis=1)\n",
        "y = input_df_copy[\"output\"]\n",
        "\n",
        "# Build our train and test sets (use random state to ensure same split as before)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RQGXTjJPPHn"
      },
      "source": [
        "# Model Declaration and Training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXintQxcPTMS"
      },
      "source": [
        "## Model Making"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMxONUeqPSab"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model_binary = keras.Sequential([\n",
        "    layers.Dense(256, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(128, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(8, activation='softmax')\n",
        "])\n",
        "\n",
        "model_binary.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate = .0003),\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    patience=250,\n",
        "    min_delta=0.0001,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZg44uz7PaUE"
      },
      "source": [
        "## Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay7cKQODPcEg",
        "outputId": "c230f198-9ea2-4ad5-f6af-e93af6e4ec48"
      },
      "source": [
        "history = model_binary.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=1000,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1, \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "181/181 [==============================] - 2s 8ms/step - loss: 19.0492 - accuracy: 0.2010 - val_loss: 1.5949 - val_accuracy: 0.2831\n",
            "Epoch 2/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 3.7850 - accuracy: 0.3124 - val_loss: 1.5201 - val_accuracy: 0.4421\n",
            "Epoch 3/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 1.9266 - accuracy: 0.3733 - val_loss: 1.4502 - val_accuracy: 0.6308\n",
            "Epoch 4/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 1.4882 - accuracy: 0.4361 - val_loss: 1.1258 - val_accuracy: 0.5753\n",
            "Epoch 5/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 1.3009 - accuracy: 0.4790 - val_loss: 0.9612 - val_accuracy: 0.5996\n",
            "Epoch 6/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 1.1662 - accuracy: 0.5302 - val_loss: 0.8409 - val_accuracy: 0.6572\n",
            "Epoch 7/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 1.0605 - accuracy: 0.5611 - val_loss: 0.8060 - val_accuracy: 0.6176\n",
            "Epoch 8/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.9640 - accuracy: 0.5965 - val_loss: 0.6794 - val_accuracy: 0.6898\n",
            "Epoch 9/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.9330 - accuracy: 0.6005 - val_loss: 0.6217 - val_accuracy: 0.7356\n",
            "Epoch 10/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.8494 - accuracy: 0.6288 - val_loss: 0.5343 - val_accuracy: 0.7689\n",
            "Epoch 11/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.8111 - accuracy: 0.6562 - val_loss: 0.5458 - val_accuracy: 0.7523\n",
            "Epoch 12/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.7712 - accuracy: 0.6678 - val_loss: 0.4917 - val_accuracy: 0.8112\n",
            "Epoch 13/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.7175 - accuracy: 0.6919 - val_loss: 0.4691 - val_accuracy: 0.8050\n",
            "Epoch 14/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.6780 - accuracy: 0.7161 - val_loss: 0.4521 - val_accuracy: 0.8688\n",
            "Epoch 15/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.6682 - accuracy: 0.7156 - val_loss: 0.4099 - val_accuracy: 0.8716\n",
            "Epoch 16/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.6287 - accuracy: 0.7416 - val_loss: 0.3942 - val_accuracy: 0.8744\n",
            "Epoch 17/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.6122 - accuracy: 0.7518 - val_loss: 0.3707 - val_accuracy: 0.8897\n",
            "Epoch 18/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.5916 - accuracy: 0.7588 - val_loss: 0.4014 - val_accuracy: 0.8772\n",
            "Epoch 19/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.5588 - accuracy: 0.7726 - val_loss: 0.3379 - val_accuracy: 0.9035\n",
            "Epoch 20/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.5630 - accuracy: 0.7709 - val_loss: 0.3384 - val_accuracy: 0.8904\n",
            "Epoch 21/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.5448 - accuracy: 0.7789 - val_loss: 0.4005 - val_accuracy: 0.7807\n",
            "Epoch 22/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.5091 - accuracy: 0.7933 - val_loss: 0.3341 - val_accuracy: 0.8869\n",
            "Epoch 23/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.5134 - accuracy: 0.7980 - val_loss: 0.3927 - val_accuracy: 0.8730\n",
            "Epoch 24/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4852 - accuracy: 0.8025 - val_loss: 0.3305 - val_accuracy: 0.8987\n",
            "Epoch 25/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.4656 - accuracy: 0.8108 - val_loss: 0.3628 - val_accuracy: 0.8175\n",
            "Epoch 26/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.4873 - accuracy: 0.8006 - val_loss: 0.3202 - val_accuracy: 0.8772\n",
            "Epoch 27/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4597 - accuracy: 0.8197 - val_loss: 0.3242 - val_accuracy: 0.8799\n",
            "Epoch 28/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.5116 - accuracy: 0.7987 - val_loss: 0.3153 - val_accuracy: 0.9112\n",
            "Epoch 29/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4567 - accuracy: 0.8148 - val_loss: 0.3136 - val_accuracy: 0.8841\n",
            "Epoch 30/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4517 - accuracy: 0.8178 - val_loss: 0.2804 - val_accuracy: 0.9146\n",
            "Epoch 31/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4237 - accuracy: 0.8291 - val_loss: 0.2858 - val_accuracy: 0.8987\n",
            "Epoch 32/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4501 - accuracy: 0.8244 - val_loss: 0.2542 - val_accuracy: 0.9202\n",
            "Epoch 33/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4181 - accuracy: 0.8308 - val_loss: 0.3059 - val_accuracy: 0.8876\n",
            "Epoch 34/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4314 - accuracy: 0.8258 - val_loss: 0.3162 - val_accuracy: 0.8897\n",
            "Epoch 35/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4201 - accuracy: 0.8332 - val_loss: 0.2896 - val_accuracy: 0.8924\n",
            "Epoch 36/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4162 - accuracy: 0.8381 - val_loss: 0.2547 - val_accuracy: 0.9098\n",
            "Epoch 37/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4374 - accuracy: 0.8261 - val_loss: 0.2576 - val_accuracy: 0.9244\n",
            "Epoch 38/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4222 - accuracy: 0.8310 - val_loss: 0.3348 - val_accuracy: 0.8473\n",
            "Epoch 39/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.4102 - accuracy: 0.8343 - val_loss: 0.3023 - val_accuracy: 0.8723\n",
            "Epoch 40/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4139 - accuracy: 0.8372 - val_loss: 0.2828 - val_accuracy: 0.9070\n",
            "Epoch 41/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3959 - accuracy: 0.8445 - val_loss: 0.2732 - val_accuracy: 0.9146\n",
            "Epoch 42/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3734 - accuracy: 0.8539 - val_loss: 0.2356 - val_accuracy: 0.9257\n",
            "Epoch 43/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3760 - accuracy: 0.8459 - val_loss: 0.2537 - val_accuracy: 0.9188\n",
            "Epoch 44/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3743 - accuracy: 0.8523 - val_loss: 0.2859 - val_accuracy: 0.8904\n",
            "Epoch 45/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3797 - accuracy: 0.8494 - val_loss: 0.2931 - val_accuracy: 0.8334\n",
            "Epoch 46/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3809 - accuracy: 0.8509 - val_loss: 0.2436 - val_accuracy: 0.9195\n",
            "Epoch 47/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3745 - accuracy: 0.8528 - val_loss: 0.2314 - val_accuracy: 0.9119\n",
            "Epoch 48/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3709 - accuracy: 0.8540 - val_loss: 0.2378 - val_accuracy: 0.9174\n",
            "Epoch 49/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3537 - accuracy: 0.8672 - val_loss: 0.2405 - val_accuracy: 0.8973\n",
            "Epoch 50/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3552 - accuracy: 0.8586 - val_loss: 0.2660 - val_accuracy: 0.8758\n",
            "Epoch 51/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3584 - accuracy: 0.8579 - val_loss: 0.2686 - val_accuracy: 0.8786\n",
            "Epoch 52/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3852 - accuracy: 0.8440 - val_loss: 0.2332 - val_accuracy: 0.9223\n",
            "Epoch 53/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3568 - accuracy: 0.8580 - val_loss: 0.2542 - val_accuracy: 0.9022\n",
            "Epoch 54/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3571 - accuracy: 0.8566 - val_loss: 0.2307 - val_accuracy: 0.9216\n",
            "Epoch 55/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3257 - accuracy: 0.8695 - val_loss: 0.2200 - val_accuracy: 0.9244\n",
            "Epoch 56/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3290 - accuracy: 0.8662 - val_loss: 0.2455 - val_accuracy: 0.9008\n",
            "Epoch 57/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3326 - accuracy: 0.8643 - val_loss: 0.3205 - val_accuracy: 0.8751\n",
            "Epoch 58/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3491 - accuracy: 0.8601 - val_loss: 0.2304 - val_accuracy: 0.9139\n",
            "Epoch 59/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3422 - accuracy: 0.8671 - val_loss: 0.2470 - val_accuracy: 0.9160\n",
            "Epoch 60/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3404 - accuracy: 0.8627 - val_loss: 0.2236 - val_accuracy: 0.9133\n",
            "Epoch 61/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3179 - accuracy: 0.8771 - val_loss: 0.2088 - val_accuracy: 0.9146\n",
            "Epoch 62/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3257 - accuracy: 0.8690 - val_loss: 0.2541 - val_accuracy: 0.8980\n",
            "Epoch 63/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3271 - accuracy: 0.8684 - val_loss: 0.2071 - val_accuracy: 0.9445\n",
            "Epoch 64/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3168 - accuracy: 0.8775 - val_loss: 0.2392 - val_accuracy: 0.9077\n",
            "Epoch 65/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3187 - accuracy: 0.8707 - val_loss: 0.2867 - val_accuracy: 0.9084\n",
            "Epoch 66/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3216 - accuracy: 0.8705 - val_loss: 0.2586 - val_accuracy: 0.8772\n",
            "Epoch 67/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3217 - accuracy: 0.8724 - val_loss: 0.2308 - val_accuracy: 0.9153\n",
            "Epoch 68/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3209 - accuracy: 0.8704 - val_loss: 0.2974 - val_accuracy: 0.8765\n",
            "Epoch 69/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3330 - accuracy: 0.8686 - val_loss: 0.2127 - val_accuracy: 0.9133\n",
            "Epoch 70/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3028 - accuracy: 0.8778 - val_loss: 0.2405 - val_accuracy: 0.8931\n",
            "Epoch 71/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3140 - accuracy: 0.8787 - val_loss: 0.2529 - val_accuracy: 0.8980\n",
            "Epoch 72/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3002 - accuracy: 0.8816 - val_loss: 0.2209 - val_accuracy: 0.9188\n",
            "Epoch 73/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3044 - accuracy: 0.8801 - val_loss: 0.2526 - val_accuracy: 0.8758\n",
            "Epoch 74/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3073 - accuracy: 0.8783 - val_loss: 0.2385 - val_accuracy: 0.8966\n",
            "Epoch 75/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3123 - accuracy: 0.8747 - val_loss: 0.2458 - val_accuracy: 0.8952\n",
            "Epoch 76/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3190 - accuracy: 0.8759 - val_loss: 0.2049 - val_accuracy: 0.9375\n",
            "Epoch 77/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3032 - accuracy: 0.8804 - val_loss: 0.2065 - val_accuracy: 0.9320\n",
            "Epoch 78/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.3123 - accuracy: 0.8747 - val_loss: 0.3064 - val_accuracy: 0.8737\n",
            "Epoch 79/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3071 - accuracy: 0.8757 - val_loss: 0.2151 - val_accuracy: 0.9389\n",
            "Epoch 80/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2921 - accuracy: 0.8806 - val_loss: 0.2684 - val_accuracy: 0.8966\n",
            "Epoch 81/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3079 - accuracy: 0.8789 - val_loss: 0.2112 - val_accuracy: 0.9438\n",
            "Epoch 82/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3198 - accuracy: 0.8719 - val_loss: 0.2055 - val_accuracy: 0.9320\n",
            "Epoch 83/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3027 - accuracy: 0.8827 - val_loss: 0.2058 - val_accuracy: 0.9209\n",
            "Epoch 84/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2930 - accuracy: 0.8877 - val_loss: 0.2649 - val_accuracy: 0.8966\n",
            "Epoch 85/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2989 - accuracy: 0.8856 - val_loss: 0.1874 - val_accuracy: 0.9410\n",
            "Epoch 86/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2703 - accuracy: 0.8888 - val_loss: 0.2209 - val_accuracy: 0.9015\n",
            "Epoch 87/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3097 - accuracy: 0.8799 - val_loss: 0.2276 - val_accuracy: 0.9070\n",
            "Epoch 88/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2810 - accuracy: 0.8907 - val_loss: 0.2016 - val_accuracy: 0.9320\n",
            "Epoch 89/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2847 - accuracy: 0.8924 - val_loss: 0.2035 - val_accuracy: 0.9375\n",
            "Epoch 90/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.3064 - accuracy: 0.8794 - val_loss: 0.2034 - val_accuracy: 0.9160\n",
            "Epoch 91/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2757 - accuracy: 0.8955 - val_loss: 0.1925 - val_accuracy: 0.9382\n",
            "Epoch 92/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2853 - accuracy: 0.8889 - val_loss: 0.1976 - val_accuracy: 0.9160\n",
            "Epoch 93/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2908 - accuracy: 0.8893 - val_loss: 0.2391 - val_accuracy: 0.9008\n",
            "Epoch 94/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2803 - accuracy: 0.8917 - val_loss: 0.2892 - val_accuracy: 0.8883\n",
            "Epoch 95/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2952 - accuracy: 0.8841 - val_loss: 0.2163 - val_accuracy: 0.9320\n",
            "Epoch 96/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2709 - accuracy: 0.8969 - val_loss: 0.2253 - val_accuracy: 0.9063\n",
            "Epoch 97/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2746 - accuracy: 0.8955 - val_loss: 0.2209 - val_accuracy: 0.9167\n",
            "Epoch 98/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2759 - accuracy: 0.8969 - val_loss: 0.2681 - val_accuracy: 0.8730\n",
            "Epoch 99/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2696 - accuracy: 0.8960 - val_loss: 0.2066 - val_accuracy: 0.9042\n",
            "Epoch 100/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2727 - accuracy: 0.8971 - val_loss: 0.1828 - val_accuracy: 0.9264\n",
            "Epoch 101/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2806 - accuracy: 0.8940 - val_loss: 0.1910 - val_accuracy: 0.9278\n",
            "Epoch 102/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2766 - accuracy: 0.8941 - val_loss: 0.1739 - val_accuracy: 0.9431\n",
            "Epoch 103/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2559 - accuracy: 0.9059 - val_loss: 0.2290 - val_accuracy: 0.9216\n",
            "Epoch 104/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2758 - accuracy: 0.8940 - val_loss: 0.2107 - val_accuracy: 0.9209\n",
            "Epoch 105/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2741 - accuracy: 0.8947 - val_loss: 0.2151 - val_accuracy: 0.8952\n",
            "Epoch 106/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2933 - accuracy: 0.8879 - val_loss: 0.2018 - val_accuracy: 0.9195\n",
            "Epoch 107/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2685 - accuracy: 0.8966 - val_loss: 0.1980 - val_accuracy: 0.9209\n",
            "Epoch 108/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2482 - accuracy: 0.9032 - val_loss: 0.1768 - val_accuracy: 0.9292\n",
            "Epoch 109/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2639 - accuracy: 0.8983 - val_loss: 0.2083 - val_accuracy: 0.9188\n",
            "Epoch 110/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2781 - accuracy: 0.8950 - val_loss: 0.1890 - val_accuracy: 0.9126\n",
            "Epoch 111/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2753 - accuracy: 0.8952 - val_loss: 0.2310 - val_accuracy: 0.9230\n",
            "Epoch 112/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2599 - accuracy: 0.9035 - val_loss: 0.2732 - val_accuracy: 0.8938\n",
            "Epoch 113/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2597 - accuracy: 0.9044 - val_loss: 0.1757 - val_accuracy: 0.9577\n",
            "Epoch 114/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2533 - accuracy: 0.9052 - val_loss: 0.2231 - val_accuracy: 0.9105\n",
            "Epoch 115/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2500 - accuracy: 0.9045 - val_loss: 0.2434 - val_accuracy: 0.9042\n",
            "Epoch 116/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2513 - accuracy: 0.9051 - val_loss: 0.1842 - val_accuracy: 0.9160\n",
            "Epoch 117/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2581 - accuracy: 0.9026 - val_loss: 0.1860 - val_accuracy: 0.9355\n",
            "Epoch 118/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2482 - accuracy: 0.9078 - val_loss: 0.1882 - val_accuracy: 0.9251\n",
            "Epoch 119/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2574 - accuracy: 0.9011 - val_loss: 0.1760 - val_accuracy: 0.9459\n",
            "Epoch 120/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2487 - accuracy: 0.9056 - val_loss: 0.2191 - val_accuracy: 0.9244\n",
            "Epoch 121/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2396 - accuracy: 0.9124 - val_loss: 0.1972 - val_accuracy: 0.9271\n",
            "Epoch 122/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2656 - accuracy: 0.8992 - val_loss: 0.1837 - val_accuracy: 0.9341\n",
            "Epoch 123/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2677 - accuracy: 0.9006 - val_loss: 0.1757 - val_accuracy: 0.9313\n",
            "Epoch 124/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2562 - accuracy: 0.9047 - val_loss: 0.1733 - val_accuracy: 0.9271\n",
            "Epoch 125/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2502 - accuracy: 0.9039 - val_loss: 0.2143 - val_accuracy: 0.9188\n",
            "Epoch 126/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2449 - accuracy: 0.9085 - val_loss: 0.1726 - val_accuracy: 0.9306\n",
            "Epoch 127/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2438 - accuracy: 0.9073 - val_loss: 0.2144 - val_accuracy: 0.9063\n",
            "Epoch 128/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2423 - accuracy: 0.9129 - val_loss: 0.1796 - val_accuracy: 0.9188\n",
            "Epoch 129/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2418 - accuracy: 0.9144 - val_loss: 0.1898 - val_accuracy: 0.9195\n",
            "Epoch 130/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2488 - accuracy: 0.9092 - val_loss: 0.1702 - val_accuracy: 0.9598\n",
            "Epoch 131/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2639 - accuracy: 0.9025 - val_loss: 0.1857 - val_accuracy: 0.9251\n",
            "Epoch 132/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2234 - accuracy: 0.9184 - val_loss: 0.1492 - val_accuracy: 0.9452\n",
            "Epoch 133/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2304 - accuracy: 0.9131 - val_loss: 0.1859 - val_accuracy: 0.9320\n",
            "Epoch 134/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2300 - accuracy: 0.9158 - val_loss: 0.1906 - val_accuracy: 0.9126\n",
            "Epoch 135/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2420 - accuracy: 0.9094 - val_loss: 0.1830 - val_accuracy: 0.9244\n",
            "Epoch 136/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2345 - accuracy: 0.9054 - val_loss: 0.1904 - val_accuracy: 0.9174\n",
            "Epoch 137/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2419 - accuracy: 0.9122 - val_loss: 0.1611 - val_accuracy: 0.9507\n",
            "Epoch 138/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2366 - accuracy: 0.9134 - val_loss: 0.1640 - val_accuracy: 0.9396\n",
            "Epoch 139/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2385 - accuracy: 0.9084 - val_loss: 0.1879 - val_accuracy: 0.9368\n",
            "Epoch 140/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2406 - accuracy: 0.9096 - val_loss: 0.1980 - val_accuracy: 0.9285\n",
            "Epoch 141/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2295 - accuracy: 0.9165 - val_loss: 0.1687 - val_accuracy: 0.9348\n",
            "Epoch 142/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2204 - accuracy: 0.9212 - val_loss: 0.1982 - val_accuracy: 0.9160\n",
            "Epoch 143/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2330 - accuracy: 0.9146 - val_loss: 0.2046 - val_accuracy: 0.9313\n",
            "Epoch 144/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2234 - accuracy: 0.9183 - val_loss: 0.1529 - val_accuracy: 0.9424\n",
            "Epoch 145/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2281 - accuracy: 0.9104 - val_loss: 0.1697 - val_accuracy: 0.9341\n",
            "Epoch 146/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2100 - accuracy: 0.9231 - val_loss: 0.1847 - val_accuracy: 0.9244\n",
            "Epoch 147/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2156 - accuracy: 0.9216 - val_loss: 0.2205 - val_accuracy: 0.9112\n",
            "Epoch 148/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2389 - accuracy: 0.9134 - val_loss: 0.2077 - val_accuracy: 0.9105\n",
            "Epoch 149/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2140 - accuracy: 0.9184 - val_loss: 0.1646 - val_accuracy: 0.9542\n",
            "Epoch 150/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2260 - accuracy: 0.9160 - val_loss: 0.1941 - val_accuracy: 0.9126\n",
            "Epoch 151/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2137 - accuracy: 0.9238 - val_loss: 0.1829 - val_accuracy: 0.9195\n",
            "Epoch 152/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2219 - accuracy: 0.9157 - val_loss: 0.1712 - val_accuracy: 0.9285\n",
            "Epoch 153/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2418 - accuracy: 0.9122 - val_loss: 0.1796 - val_accuracy: 0.9382\n",
            "Epoch 154/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2135 - accuracy: 0.9202 - val_loss: 0.2142 - val_accuracy: 0.9084\n",
            "Epoch 155/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2327 - accuracy: 0.9132 - val_loss: 0.1714 - val_accuracy: 0.9264\n",
            "Epoch 156/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2301 - accuracy: 0.9157 - val_loss: 0.1512 - val_accuracy: 0.9362\n",
            "Epoch 157/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2351 - accuracy: 0.9124 - val_loss: 0.1866 - val_accuracy: 0.9285\n",
            "Epoch 158/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2234 - accuracy: 0.9144 - val_loss: 0.2115 - val_accuracy: 0.9181\n",
            "Epoch 159/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2273 - accuracy: 0.9170 - val_loss: 0.1870 - val_accuracy: 0.9341\n",
            "Epoch 160/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2129 - accuracy: 0.9275 - val_loss: 0.1762 - val_accuracy: 0.9230\n",
            "Epoch 161/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2128 - accuracy: 0.9245 - val_loss: 0.1517 - val_accuracy: 0.9431\n",
            "Epoch 162/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2162 - accuracy: 0.9193 - val_loss: 0.2207 - val_accuracy: 0.9022\n",
            "Epoch 163/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2134 - accuracy: 0.9210 - val_loss: 0.1598 - val_accuracy: 0.9611\n",
            "Epoch 164/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2127 - accuracy: 0.9249 - val_loss: 0.1433 - val_accuracy: 0.9604\n",
            "Epoch 165/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2105 - accuracy: 0.9202 - val_loss: 0.1559 - val_accuracy: 0.9375\n",
            "Epoch 166/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2200 - accuracy: 0.9160 - val_loss: 0.1878 - val_accuracy: 0.9126\n",
            "Epoch 167/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2160 - accuracy: 0.9229 - val_loss: 0.1619 - val_accuracy: 0.9341\n",
            "Epoch 168/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2143 - accuracy: 0.9200 - val_loss: 0.1484 - val_accuracy: 0.9591\n",
            "Epoch 169/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2348 - accuracy: 0.9096 - val_loss: 0.1737 - val_accuracy: 0.9188\n",
            "Epoch 170/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2152 - accuracy: 0.9188 - val_loss: 0.1461 - val_accuracy: 0.9507\n",
            "Epoch 171/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2097 - accuracy: 0.9235 - val_loss: 0.1686 - val_accuracy: 0.9382\n",
            "Epoch 172/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2172 - accuracy: 0.9195 - val_loss: 0.1476 - val_accuracy: 0.9410\n",
            "Epoch 173/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2295 - accuracy: 0.9174 - val_loss: 0.1645 - val_accuracy: 0.9264\n",
            "Epoch 174/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2264 - accuracy: 0.9177 - val_loss: 0.1495 - val_accuracy: 0.9452\n",
            "Epoch 175/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2098 - accuracy: 0.9229 - val_loss: 0.1565 - val_accuracy: 0.9396\n",
            "Epoch 176/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2119 - accuracy: 0.9191 - val_loss: 0.1667 - val_accuracy: 0.9320\n",
            "Epoch 177/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2238 - accuracy: 0.9155 - val_loss: 0.1723 - val_accuracy: 0.9473\n",
            "Epoch 178/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2168 - accuracy: 0.9245 - val_loss: 0.1646 - val_accuracy: 0.9355\n",
            "Epoch 179/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2085 - accuracy: 0.9229 - val_loss: 0.1564 - val_accuracy: 0.9313\n",
            "Epoch 180/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2185 - accuracy: 0.9169 - val_loss: 0.1686 - val_accuracy: 0.9251\n",
            "Epoch 181/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2079 - accuracy: 0.9247 - val_loss: 0.1722 - val_accuracy: 0.9521\n",
            "Epoch 182/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1995 - accuracy: 0.9278 - val_loss: 0.1448 - val_accuracy: 0.9542\n",
            "Epoch 183/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2112 - accuracy: 0.9200 - val_loss: 0.1754 - val_accuracy: 0.9313\n",
            "Epoch 184/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2174 - accuracy: 0.9158 - val_loss: 0.1496 - val_accuracy: 0.9389\n",
            "Epoch 185/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2108 - accuracy: 0.9200 - val_loss: 0.1752 - val_accuracy: 0.9368\n",
            "Epoch 186/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2154 - accuracy: 0.9169 - val_loss: 0.1701 - val_accuracy: 0.9299\n",
            "Epoch 187/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2035 - accuracy: 0.9243 - val_loss: 0.1462 - val_accuracy: 0.9591\n",
            "Epoch 188/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1987 - accuracy: 0.9285 - val_loss: 0.1628 - val_accuracy: 0.9271\n",
            "Epoch 189/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2086 - accuracy: 0.9224 - val_loss: 0.1619 - val_accuracy: 0.9209\n",
            "Epoch 190/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2098 - accuracy: 0.9198 - val_loss: 0.1654 - val_accuracy: 0.9271\n",
            "Epoch 191/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2020 - accuracy: 0.9226 - val_loss: 0.1388 - val_accuracy: 0.9438\n",
            "Epoch 192/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2077 - accuracy: 0.9262 - val_loss: 0.3258 - val_accuracy: 0.8681\n",
            "Epoch 193/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2308 - accuracy: 0.9139 - val_loss: 0.1864 - val_accuracy: 0.9313\n",
            "Epoch 194/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2212 - accuracy: 0.9148 - val_loss: 0.1680 - val_accuracy: 0.9264\n",
            "Epoch 195/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2352 - accuracy: 0.9179 - val_loss: 0.1590 - val_accuracy: 0.9431\n",
            "Epoch 196/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2031 - accuracy: 0.9233 - val_loss: 0.1764 - val_accuracy: 0.9306\n",
            "Epoch 197/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2113 - accuracy: 0.9249 - val_loss: 0.1546 - val_accuracy: 0.9417\n",
            "Epoch 198/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2096 - accuracy: 0.9240 - val_loss: 0.2028 - val_accuracy: 0.9015\n",
            "Epoch 199/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2203 - accuracy: 0.9188 - val_loss: 0.1609 - val_accuracy: 0.9389\n",
            "Epoch 200/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2084 - accuracy: 0.9228 - val_loss: 0.1799 - val_accuracy: 0.9223\n",
            "Epoch 201/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2110 - accuracy: 0.9222 - val_loss: 0.1701 - val_accuracy: 0.9368\n",
            "Epoch 202/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2115 - accuracy: 0.9243 - val_loss: 0.1641 - val_accuracy: 0.9299\n",
            "Epoch 203/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2097 - accuracy: 0.9210 - val_loss: 0.1707 - val_accuracy: 0.9355\n",
            "Epoch 204/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2056 - accuracy: 0.9229 - val_loss: 0.1519 - val_accuracy: 0.9375\n",
            "Epoch 205/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2249 - accuracy: 0.9169 - val_loss: 0.2016 - val_accuracy: 0.8966\n",
            "Epoch 206/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2316 - accuracy: 0.9134 - val_loss: 0.1787 - val_accuracy: 0.9223\n",
            "Epoch 207/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2096 - accuracy: 0.9264 - val_loss: 0.1433 - val_accuracy: 0.9389\n",
            "Epoch 208/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2036 - accuracy: 0.9278 - val_loss: 0.1739 - val_accuracy: 0.9174\n",
            "Epoch 209/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2124 - accuracy: 0.9191 - val_loss: 0.1692 - val_accuracy: 0.9292\n",
            "Epoch 210/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2152 - accuracy: 0.9195 - val_loss: 0.1515 - val_accuracy: 0.9375\n",
            "Epoch 211/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2015 - accuracy: 0.9285 - val_loss: 0.1497 - val_accuracy: 0.9431\n",
            "Epoch 212/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2099 - accuracy: 0.9219 - val_loss: 0.2284 - val_accuracy: 0.8917\n",
            "Epoch 213/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2032 - accuracy: 0.9285 - val_loss: 0.1520 - val_accuracy: 0.9403\n",
            "Epoch 214/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1980 - accuracy: 0.9262 - val_loss: 0.2391 - val_accuracy: 0.8917\n",
            "Epoch 215/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2073 - accuracy: 0.9243 - val_loss: 0.1695 - val_accuracy: 0.9306\n",
            "Epoch 216/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2107 - accuracy: 0.9224 - val_loss: 0.1541 - val_accuracy: 0.9486\n",
            "Epoch 217/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1945 - accuracy: 0.9273 - val_loss: 0.1637 - val_accuracy: 0.9368\n",
            "Epoch 218/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1924 - accuracy: 0.9275 - val_loss: 0.1713 - val_accuracy: 0.9251\n",
            "Epoch 219/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2014 - accuracy: 0.9259 - val_loss: 0.1595 - val_accuracy: 0.9285\n",
            "Epoch 220/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1925 - accuracy: 0.9335 - val_loss: 0.1791 - val_accuracy: 0.9126\n",
            "Epoch 221/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2047 - accuracy: 0.9249 - val_loss: 0.1384 - val_accuracy: 0.9473\n",
            "Epoch 222/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2025 - accuracy: 0.9229 - val_loss: 0.1448 - val_accuracy: 0.9341\n",
            "Epoch 223/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2258 - accuracy: 0.9153 - val_loss: 0.1580 - val_accuracy: 0.9320\n",
            "Epoch 224/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1964 - accuracy: 0.9269 - val_loss: 0.1500 - val_accuracy: 0.9507\n",
            "Epoch 225/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2047 - accuracy: 0.9224 - val_loss: 0.1623 - val_accuracy: 0.9452\n",
            "Epoch 226/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2435 - accuracy: 0.9094 - val_loss: 0.1838 - val_accuracy: 0.9334\n",
            "Epoch 227/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2137 - accuracy: 0.9219 - val_loss: 0.1525 - val_accuracy: 0.9382\n",
            "Epoch 228/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1979 - accuracy: 0.9301 - val_loss: 0.1790 - val_accuracy: 0.9251\n",
            "Epoch 229/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2215 - accuracy: 0.9184 - val_loss: 0.1730 - val_accuracy: 0.9285\n",
            "Epoch 230/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1879 - accuracy: 0.9308 - val_loss: 0.1467 - val_accuracy: 0.9271\n",
            "Epoch 231/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1877 - accuracy: 0.9278 - val_loss: 0.1769 - val_accuracy: 0.9174\n",
            "Epoch 232/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1920 - accuracy: 0.9292 - val_loss: 0.1972 - val_accuracy: 0.9098\n",
            "Epoch 233/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2022 - accuracy: 0.9231 - val_loss: 0.2342 - val_accuracy: 0.9070\n",
            "Epoch 234/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1892 - accuracy: 0.9346 - val_loss: 0.1423 - val_accuracy: 0.9438\n",
            "Epoch 235/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1876 - accuracy: 0.9299 - val_loss: 0.1662 - val_accuracy: 0.9257\n",
            "Epoch 236/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2188 - accuracy: 0.9176 - val_loss: 0.1436 - val_accuracy: 0.9646\n",
            "Epoch 237/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2000 - accuracy: 0.9261 - val_loss: 0.1987 - val_accuracy: 0.8931\n",
            "Epoch 238/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2013 - accuracy: 0.9266 - val_loss: 0.1813 - val_accuracy: 0.9035\n",
            "Epoch 239/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2107 - accuracy: 0.9169 - val_loss: 0.1687 - val_accuracy: 0.9542\n",
            "Epoch 240/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2054 - accuracy: 0.9229 - val_loss: 0.1614 - val_accuracy: 0.9368\n",
            "Epoch 241/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1997 - accuracy: 0.9271 - val_loss: 0.1505 - val_accuracy: 0.9618\n",
            "Epoch 242/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1881 - accuracy: 0.9297 - val_loss: 0.1385 - val_accuracy: 0.9431\n",
            "Epoch 243/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1840 - accuracy: 0.9287 - val_loss: 0.1420 - val_accuracy: 0.9611\n",
            "Epoch 244/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1961 - accuracy: 0.9255 - val_loss: 0.1829 - val_accuracy: 0.9160\n",
            "Epoch 245/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1928 - accuracy: 0.9287 - val_loss: 0.1621 - val_accuracy: 0.9320\n",
            "Epoch 246/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1877 - accuracy: 0.9285 - val_loss: 0.1378 - val_accuracy: 0.9500\n",
            "Epoch 247/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1892 - accuracy: 0.9278 - val_loss: 0.1664 - val_accuracy: 0.9306\n",
            "Epoch 248/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1981 - accuracy: 0.9271 - val_loss: 0.1643 - val_accuracy: 0.9320\n",
            "Epoch 249/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1931 - accuracy: 0.9306 - val_loss: 0.1678 - val_accuracy: 0.9285\n",
            "Epoch 250/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2029 - accuracy: 0.9259 - val_loss: 0.1253 - val_accuracy: 0.9715\n",
            "Epoch 251/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1869 - accuracy: 0.9304 - val_loss: 0.1320 - val_accuracy: 0.9514\n",
            "Epoch 252/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1838 - accuracy: 0.9313 - val_loss: 0.2116 - val_accuracy: 0.8980\n",
            "Epoch 253/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1899 - accuracy: 0.9294 - val_loss: 0.1395 - val_accuracy: 0.9598\n",
            "Epoch 254/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1811 - accuracy: 0.9342 - val_loss: 0.1565 - val_accuracy: 0.9493\n",
            "Epoch 255/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1858 - accuracy: 0.9309 - val_loss: 0.1290 - val_accuracy: 0.9556\n",
            "Epoch 256/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1819 - accuracy: 0.9299 - val_loss: 0.1395 - val_accuracy: 0.9466\n",
            "Epoch 257/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1748 - accuracy: 0.9370 - val_loss: 0.1912 - val_accuracy: 0.9195\n",
            "Epoch 258/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1928 - accuracy: 0.9257 - val_loss: 0.1888 - val_accuracy: 0.9278\n",
            "Epoch 259/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1962 - accuracy: 0.9299 - val_loss: 0.1570 - val_accuracy: 0.9410\n",
            "Epoch 260/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2052 - accuracy: 0.9242 - val_loss: 0.1280 - val_accuracy: 0.9667\n",
            "Epoch 261/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2007 - accuracy: 0.9238 - val_loss: 0.1558 - val_accuracy: 0.9500\n",
            "Epoch 262/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1998 - accuracy: 0.9276 - val_loss: 0.2131 - val_accuracy: 0.9008\n",
            "Epoch 263/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1845 - accuracy: 0.9339 - val_loss: 0.2066 - val_accuracy: 0.9146\n",
            "Epoch 264/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2035 - accuracy: 0.9243 - val_loss: 0.1446 - val_accuracy: 0.9438\n",
            "Epoch 265/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1892 - accuracy: 0.9278 - val_loss: 0.2045 - val_accuracy: 0.9070\n",
            "Epoch 266/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1880 - accuracy: 0.9271 - val_loss: 0.1471 - val_accuracy: 0.9403\n",
            "Epoch 267/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1871 - accuracy: 0.9283 - val_loss: 0.1481 - val_accuracy: 0.9362\n",
            "Epoch 268/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1835 - accuracy: 0.9321 - val_loss: 0.1443 - val_accuracy: 0.9424\n",
            "Epoch 269/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1800 - accuracy: 0.9290 - val_loss: 0.1878 - val_accuracy: 0.9160\n",
            "Epoch 270/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1846 - accuracy: 0.9280 - val_loss: 0.1576 - val_accuracy: 0.9500\n",
            "Epoch 271/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1944 - accuracy: 0.9271 - val_loss: 0.2244 - val_accuracy: 0.8980\n",
            "Epoch 272/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2214 - accuracy: 0.9170 - val_loss: 0.1465 - val_accuracy: 0.9382\n",
            "Epoch 273/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1871 - accuracy: 0.9287 - val_loss: 0.1289 - val_accuracy: 0.9500\n",
            "Epoch 274/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1904 - accuracy: 0.9295 - val_loss: 0.1691 - val_accuracy: 0.9105\n",
            "Epoch 275/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1848 - accuracy: 0.9328 - val_loss: 0.1351 - val_accuracy: 0.9382\n",
            "Epoch 276/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1927 - accuracy: 0.9266 - val_loss: 0.1462 - val_accuracy: 0.9368\n",
            "Epoch 277/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2044 - accuracy: 0.9242 - val_loss: 0.1914 - val_accuracy: 0.9091\n",
            "Epoch 278/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1876 - accuracy: 0.9280 - val_loss: 0.1311 - val_accuracy: 0.9702\n",
            "Epoch 279/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1781 - accuracy: 0.9341 - val_loss: 0.1299 - val_accuracy: 0.9625\n",
            "Epoch 280/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1827 - accuracy: 0.9335 - val_loss: 0.1683 - val_accuracy: 0.9119\n",
            "Epoch 281/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1841 - accuracy: 0.9309 - val_loss: 0.1967 - val_accuracy: 0.9112\n",
            "Epoch 282/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1840 - accuracy: 0.9321 - val_loss: 0.1437 - val_accuracy: 0.9327\n",
            "Epoch 283/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2040 - accuracy: 0.9214 - val_loss: 0.1490 - val_accuracy: 0.9368\n",
            "Epoch 284/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1860 - accuracy: 0.9342 - val_loss: 0.1954 - val_accuracy: 0.9070\n",
            "Epoch 285/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1957 - accuracy: 0.9285 - val_loss: 0.1663 - val_accuracy: 0.9202\n",
            "Epoch 286/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1836 - accuracy: 0.9332 - val_loss: 0.1530 - val_accuracy: 0.9257\n",
            "Epoch 287/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1955 - accuracy: 0.9273 - val_loss: 0.1466 - val_accuracy: 0.9452\n",
            "Epoch 288/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1833 - accuracy: 0.9318 - val_loss: 0.2062 - val_accuracy: 0.9153\n",
            "Epoch 289/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1947 - accuracy: 0.9273 - val_loss: 0.1663 - val_accuracy: 0.9264\n",
            "Epoch 290/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1956 - accuracy: 0.9259 - val_loss: 0.1604 - val_accuracy: 0.9160\n",
            "Epoch 291/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1870 - accuracy: 0.9264 - val_loss: 0.1612 - val_accuracy: 0.9230\n",
            "Epoch 292/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2038 - accuracy: 0.9290 - val_loss: 0.1978 - val_accuracy: 0.9028\n",
            "Epoch 293/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2070 - accuracy: 0.9217 - val_loss: 0.1651 - val_accuracy: 0.9341\n",
            "Epoch 294/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1932 - accuracy: 0.9252 - val_loss: 0.2147 - val_accuracy: 0.9008\n",
            "Epoch 295/1000\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.2032 - accuracy: 0.9228 - val_loss: 0.1738 - val_accuracy: 0.9216\n",
            "Epoch 296/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2158 - accuracy: 0.9134 - val_loss: 0.1865 - val_accuracy: 0.9139\n",
            "Epoch 297/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2033 - accuracy: 0.9214 - val_loss: 0.1769 - val_accuracy: 0.9167\n",
            "Epoch 298/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2095 - accuracy: 0.9193 - val_loss: 0.1773 - val_accuracy: 0.9223\n",
            "Epoch 299/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1978 - accuracy: 0.9249 - val_loss: 0.1853 - val_accuracy: 0.9160\n",
            "Epoch 300/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2063 - accuracy: 0.9214 - val_loss: 0.1693 - val_accuracy: 0.9251\n",
            "Epoch 301/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1878 - accuracy: 0.9281 - val_loss: 0.1829 - val_accuracy: 0.9056\n",
            "Epoch 302/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2096 - accuracy: 0.9235 - val_loss: 0.1751 - val_accuracy: 0.9292\n",
            "Epoch 303/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2002 - accuracy: 0.9235 - val_loss: 0.1644 - val_accuracy: 0.9271\n",
            "Epoch 304/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1980 - accuracy: 0.9259 - val_loss: 0.2227 - val_accuracy: 0.9022\n",
            "Epoch 305/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1950 - accuracy: 0.9233 - val_loss: 0.2067 - val_accuracy: 0.9077\n",
            "Epoch 306/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2116 - accuracy: 0.9179 - val_loss: 0.1700 - val_accuracy: 0.9285\n",
            "Epoch 307/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1899 - accuracy: 0.9254 - val_loss: 0.2065 - val_accuracy: 0.9056\n",
            "Epoch 308/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1875 - accuracy: 0.9320 - val_loss: 0.1578 - val_accuracy: 0.9313\n",
            "Epoch 309/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1849 - accuracy: 0.9308 - val_loss: 0.1834 - val_accuracy: 0.9105\n",
            "Epoch 310/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1996 - accuracy: 0.9255 - val_loss: 0.1640 - val_accuracy: 0.9334\n",
            "Epoch 311/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1880 - accuracy: 0.9290 - val_loss: 0.1878 - val_accuracy: 0.9257\n",
            "Epoch 312/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2061 - accuracy: 0.9202 - val_loss: 0.1957 - val_accuracy: 0.9230\n",
            "Epoch 313/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2178 - accuracy: 0.9184 - val_loss: 0.1751 - val_accuracy: 0.9209\n",
            "Epoch 314/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1938 - accuracy: 0.9233 - val_loss: 0.1507 - val_accuracy: 0.9348\n",
            "Epoch 315/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1906 - accuracy: 0.9295 - val_loss: 0.1791 - val_accuracy: 0.9244\n",
            "Epoch 316/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1985 - accuracy: 0.9226 - val_loss: 0.2326 - val_accuracy: 0.9042\n",
            "Epoch 317/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2060 - accuracy: 0.9222 - val_loss: 0.2563 - val_accuracy: 0.8876\n",
            "Epoch 318/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1866 - accuracy: 0.9311 - val_loss: 0.1831 - val_accuracy: 0.9181\n",
            "Epoch 319/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2066 - accuracy: 0.9228 - val_loss: 0.2076 - val_accuracy: 0.9056\n",
            "Epoch 320/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2009 - accuracy: 0.9210 - val_loss: 0.1781 - val_accuracy: 0.9139\n",
            "Epoch 321/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2166 - accuracy: 0.9202 - val_loss: 0.1660 - val_accuracy: 0.9591\n",
            "Epoch 322/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2033 - accuracy: 0.9205 - val_loss: 0.1699 - val_accuracy: 0.9257\n",
            "Epoch 323/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1728 - accuracy: 0.9349 - val_loss: 0.1352 - val_accuracy: 0.9389\n",
            "Epoch 324/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1811 - accuracy: 0.9314 - val_loss: 0.1710 - val_accuracy: 0.9230\n",
            "Epoch 325/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1985 - accuracy: 0.9207 - val_loss: 0.2093 - val_accuracy: 0.9070\n",
            "Epoch 326/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1900 - accuracy: 0.9269 - val_loss: 0.1409 - val_accuracy: 0.9514\n",
            "Epoch 327/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1888 - accuracy: 0.9268 - val_loss: 0.1894 - val_accuracy: 0.9174\n",
            "Epoch 328/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1842 - accuracy: 0.9332 - val_loss: 0.1790 - val_accuracy: 0.9146\n",
            "Epoch 329/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1849 - accuracy: 0.9332 - val_loss: 0.1907 - val_accuracy: 0.9223\n",
            "Epoch 330/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1900 - accuracy: 0.9254 - val_loss: 0.1747 - val_accuracy: 0.9216\n",
            "Epoch 331/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1889 - accuracy: 0.9255 - val_loss: 0.1810 - val_accuracy: 0.9056\n",
            "Epoch 332/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1873 - accuracy: 0.9294 - val_loss: 0.1693 - val_accuracy: 0.9264\n",
            "Epoch 333/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1942 - accuracy: 0.9271 - val_loss: 0.1495 - val_accuracy: 0.9355\n",
            "Epoch 334/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1760 - accuracy: 0.9320 - val_loss: 0.2266 - val_accuracy: 0.9091\n",
            "Epoch 335/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1844 - accuracy: 0.9316 - val_loss: 0.1732 - val_accuracy: 0.9237\n",
            "Epoch 336/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1807 - accuracy: 0.9299 - val_loss: 0.1928 - val_accuracy: 0.9174\n",
            "Epoch 337/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1823 - accuracy: 0.9294 - val_loss: 0.1587 - val_accuracy: 0.9355\n",
            "Epoch 338/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1925 - accuracy: 0.9259 - val_loss: 0.2728 - val_accuracy: 0.9008\n",
            "Epoch 339/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2047 - accuracy: 0.9219 - val_loss: 0.1478 - val_accuracy: 0.9403\n",
            "Epoch 340/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2089 - accuracy: 0.9222 - val_loss: 0.2456 - val_accuracy: 0.9015\n",
            "Epoch 341/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1744 - accuracy: 0.9330 - val_loss: 0.1444 - val_accuracy: 0.9452\n",
            "Epoch 342/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1908 - accuracy: 0.9264 - val_loss: 0.2031 - val_accuracy: 0.8973\n",
            "Epoch 343/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1822 - accuracy: 0.9313 - val_loss: 0.2171 - val_accuracy: 0.8980\n",
            "Epoch 344/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1715 - accuracy: 0.9327 - val_loss: 0.2199 - val_accuracy: 0.9119\n",
            "Epoch 345/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1881 - accuracy: 0.9280 - val_loss: 0.1462 - val_accuracy: 0.9604\n",
            "Epoch 346/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1788 - accuracy: 0.9301 - val_loss: 0.1616 - val_accuracy: 0.9216\n",
            "Epoch 347/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 0.1832 - accuracy: 0.9325 - val_loss: 0.2420 - val_accuracy: 0.8952\n",
            "Epoch 348/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1918 - accuracy: 0.9281 - val_loss: 0.1687 - val_accuracy: 0.9480\n",
            "Epoch 349/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1866 - accuracy: 0.9332 - val_loss: 0.2135 - val_accuracy: 0.8917\n",
            "Epoch 350/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1943 - accuracy: 0.9257 - val_loss: 0.1851 - val_accuracy: 0.9230\n",
            "Epoch 351/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1856 - accuracy: 0.9255 - val_loss: 0.2747 - val_accuracy: 0.8813\n",
            "Epoch 352/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1830 - accuracy: 0.9273 - val_loss: 0.2522 - val_accuracy: 0.8834\n",
            "Epoch 353/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1891 - accuracy: 0.9269 - val_loss: 0.1908 - val_accuracy: 0.9285\n",
            "Epoch 354/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1991 - accuracy: 0.9264 - val_loss: 0.2061 - val_accuracy: 0.9223\n",
            "Epoch 355/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1867 - accuracy: 0.9306 - val_loss: 0.1821 - val_accuracy: 0.9257\n",
            "Epoch 356/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1868 - accuracy: 0.9264 - val_loss: 0.2361 - val_accuracy: 0.9015\n",
            "Epoch 357/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1813 - accuracy: 0.9309 - val_loss: 0.2068 - val_accuracy: 0.9001\n",
            "Epoch 358/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1986 - accuracy: 0.9268 - val_loss: 0.2269 - val_accuracy: 0.9070\n",
            "Epoch 359/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1883 - accuracy: 0.9281 - val_loss: 0.2132 - val_accuracy: 0.9063\n",
            "Epoch 360/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1840 - accuracy: 0.9321 - val_loss: 0.2041 - val_accuracy: 0.9195\n",
            "Epoch 361/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1839 - accuracy: 0.9314 - val_loss: 0.2068 - val_accuracy: 0.9146\n",
            "Epoch 362/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1705 - accuracy: 0.9347 - val_loss: 0.2532 - val_accuracy: 0.8883\n",
            "Epoch 363/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1857 - accuracy: 0.9306 - val_loss: 0.1775 - val_accuracy: 0.9251\n",
            "Epoch 364/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1755 - accuracy: 0.9344 - val_loss: 0.2117 - val_accuracy: 0.9112\n",
            "Epoch 365/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1731 - accuracy: 0.9314 - val_loss: 0.2745 - val_accuracy: 0.8834\n",
            "Epoch 366/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1703 - accuracy: 0.9347 - val_loss: 0.1625 - val_accuracy: 0.9237\n",
            "Epoch 367/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1642 - accuracy: 0.9356 - val_loss: 0.1722 - val_accuracy: 0.9299\n",
            "Epoch 368/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1817 - accuracy: 0.9332 - val_loss: 0.1719 - val_accuracy: 0.9139\n",
            "Epoch 369/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1884 - accuracy: 0.9280 - val_loss: 0.1861 - val_accuracy: 0.9251\n",
            "Epoch 370/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1867 - accuracy: 0.9288 - val_loss: 0.2366 - val_accuracy: 0.8994\n",
            "Epoch 371/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1730 - accuracy: 0.9341 - val_loss: 0.2253 - val_accuracy: 0.9056\n",
            "Epoch 372/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1787 - accuracy: 0.9306 - val_loss: 0.1960 - val_accuracy: 0.9105\n",
            "Epoch 373/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1877 - accuracy: 0.9313 - val_loss: 0.1372 - val_accuracy: 0.9410\n",
            "Epoch 374/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1707 - accuracy: 0.9346 - val_loss: 0.2100 - val_accuracy: 0.9167\n",
            "Epoch 375/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1685 - accuracy: 0.9384 - val_loss: 0.2166 - val_accuracy: 0.9035\n",
            "Epoch 376/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1799 - accuracy: 0.9328 - val_loss: 0.2318 - val_accuracy: 0.9056\n",
            "Epoch 377/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1917 - accuracy: 0.9283 - val_loss: 0.1563 - val_accuracy: 0.9334\n",
            "Epoch 378/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1686 - accuracy: 0.9384 - val_loss: 0.1930 - val_accuracy: 0.9271\n",
            "Epoch 379/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1788 - accuracy: 0.9327 - val_loss: 0.1711 - val_accuracy: 0.9292\n",
            "Epoch 380/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1770 - accuracy: 0.9328 - val_loss: 0.1823 - val_accuracy: 0.9285\n",
            "Epoch 381/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1843 - accuracy: 0.9302 - val_loss: 0.1682 - val_accuracy: 0.9389\n",
            "Epoch 382/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1649 - accuracy: 0.9341 - val_loss: 0.1538 - val_accuracy: 0.9306\n",
            "Epoch 383/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1864 - accuracy: 0.9323 - val_loss: 0.2085 - val_accuracy: 0.9188\n",
            "Epoch 384/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1780 - accuracy: 0.9304 - val_loss: 0.2109 - val_accuracy: 0.9209\n",
            "Epoch 385/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1736 - accuracy: 0.9335 - val_loss: 0.2005 - val_accuracy: 0.9195\n",
            "Epoch 386/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1753 - accuracy: 0.9313 - val_loss: 0.1798 - val_accuracy: 0.9223\n",
            "Epoch 387/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1826 - accuracy: 0.9292 - val_loss: 0.2536 - val_accuracy: 0.8966\n",
            "Epoch 388/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1893 - accuracy: 0.9294 - val_loss: 0.1841 - val_accuracy: 0.9334\n",
            "Epoch 389/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1755 - accuracy: 0.9337 - val_loss: 0.1602 - val_accuracy: 0.9285\n",
            "Epoch 390/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1859 - accuracy: 0.9295 - val_loss: 0.2059 - val_accuracy: 0.9209\n",
            "Epoch 391/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1802 - accuracy: 0.9271 - val_loss: 0.1847 - val_accuracy: 0.9188\n",
            "Epoch 392/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1754 - accuracy: 0.9330 - val_loss: 0.2039 - val_accuracy: 0.9146\n",
            "Epoch 393/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1775 - accuracy: 0.9306 - val_loss: 0.1824 - val_accuracy: 0.9278\n",
            "Epoch 394/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1617 - accuracy: 0.9379 - val_loss: 0.1838 - val_accuracy: 0.9292\n",
            "Epoch 395/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1666 - accuracy: 0.9354 - val_loss: 0.2058 - val_accuracy: 0.9216\n",
            "Epoch 396/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1748 - accuracy: 0.9332 - val_loss: 0.2223 - val_accuracy: 0.9098\n",
            "Epoch 397/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1822 - accuracy: 0.9321 - val_loss: 0.2527 - val_accuracy: 0.9091\n",
            "Epoch 398/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1713 - accuracy: 0.9327 - val_loss: 0.2434 - val_accuracy: 0.9098\n",
            "Epoch 399/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1697 - accuracy: 0.9365 - val_loss: 0.1786 - val_accuracy: 0.9362\n",
            "Epoch 400/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1667 - accuracy: 0.9341 - val_loss: 0.1876 - val_accuracy: 0.9264\n",
            "Epoch 401/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1706 - accuracy: 0.9347 - val_loss: 0.1715 - val_accuracy: 0.9188\n",
            "Epoch 402/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1733 - accuracy: 0.9330 - val_loss: 0.2463 - val_accuracy: 0.9063\n",
            "Epoch 403/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1611 - accuracy: 0.9347 - val_loss: 0.2208 - val_accuracy: 0.9160\n",
            "Epoch 404/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 0.1588 - accuracy: 0.9400 - val_loss: 0.2078 - val_accuracy: 0.9160\n",
            "Epoch 405/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1570 - accuracy: 0.9406 - val_loss: 0.1774 - val_accuracy: 0.9341\n",
            "Epoch 406/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1658 - accuracy: 0.9386 - val_loss: 0.2197 - val_accuracy: 0.9112\n",
            "Epoch 407/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1674 - accuracy: 0.9372 - val_loss: 0.1743 - val_accuracy: 0.9299\n",
            "Epoch 408/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1713 - accuracy: 0.9360 - val_loss: 0.2462 - val_accuracy: 0.9035\n",
            "Epoch 409/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1758 - accuracy: 0.9325 - val_loss: 0.1742 - val_accuracy: 0.9348\n",
            "Epoch 410/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1650 - accuracy: 0.9356 - val_loss: 0.2020 - val_accuracy: 0.9167\n",
            "Epoch 411/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1826 - accuracy: 0.9309 - val_loss: 0.2143 - val_accuracy: 0.9167\n",
            "Epoch 412/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1655 - accuracy: 0.9370 - val_loss: 0.1438 - val_accuracy: 0.9389\n",
            "Epoch 413/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1639 - accuracy: 0.9361 - val_loss: 0.1502 - val_accuracy: 0.9389\n",
            "Epoch 414/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1685 - accuracy: 0.9354 - val_loss: 0.2524 - val_accuracy: 0.8931\n",
            "Epoch 415/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1694 - accuracy: 0.9323 - val_loss: 0.2113 - val_accuracy: 0.9237\n",
            "Epoch 416/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1577 - accuracy: 0.9424 - val_loss: 0.2107 - val_accuracy: 0.9153\n",
            "Epoch 417/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1731 - accuracy: 0.9302 - val_loss: 0.1835 - val_accuracy: 0.9160\n",
            "Epoch 418/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1697 - accuracy: 0.9327 - val_loss: 0.2159 - val_accuracy: 0.9153\n",
            "Epoch 419/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1717 - accuracy: 0.9353 - val_loss: 0.2991 - val_accuracy: 0.8952\n",
            "Epoch 420/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1863 - accuracy: 0.9255 - val_loss: 0.3187 - val_accuracy: 0.8806\n",
            "Epoch 421/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1723 - accuracy: 0.9318 - val_loss: 0.2356 - val_accuracy: 0.9077\n",
            "Epoch 422/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1620 - accuracy: 0.9373 - val_loss: 0.1932 - val_accuracy: 0.9105\n",
            "Epoch 423/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1843 - accuracy: 0.9283 - val_loss: 0.1757 - val_accuracy: 0.9348\n",
            "Epoch 424/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1678 - accuracy: 0.9328 - val_loss: 0.2828 - val_accuracy: 0.8834\n",
            "Epoch 425/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2040 - accuracy: 0.9235 - val_loss: 0.2292 - val_accuracy: 0.9181\n",
            "Epoch 426/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1753 - accuracy: 0.9361 - val_loss: 0.1772 - val_accuracy: 0.9368\n",
            "Epoch 427/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1601 - accuracy: 0.9396 - val_loss: 0.2220 - val_accuracy: 0.8924\n",
            "Epoch 428/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1707 - accuracy: 0.9363 - val_loss: 0.2062 - val_accuracy: 0.9077\n",
            "Epoch 429/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1602 - accuracy: 0.9424 - val_loss: 0.2185 - val_accuracy: 0.9195\n",
            "Epoch 430/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1542 - accuracy: 0.9429 - val_loss: 0.2205 - val_accuracy: 0.9188\n",
            "Epoch 431/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1625 - accuracy: 0.9412 - val_loss: 0.1971 - val_accuracy: 0.9327\n",
            "Epoch 432/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1603 - accuracy: 0.9403 - val_loss: 0.3930 - val_accuracy: 0.8765\n",
            "Epoch 433/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1525 - accuracy: 0.9424 - val_loss: 0.2452 - val_accuracy: 0.9153\n",
            "Epoch 434/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1760 - accuracy: 0.9320 - val_loss: 0.2552 - val_accuracy: 0.9056\n",
            "Epoch 435/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1659 - accuracy: 0.9382 - val_loss: 0.2162 - val_accuracy: 0.9216\n",
            "Epoch 436/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1562 - accuracy: 0.9412 - val_loss: 0.2388 - val_accuracy: 0.9008\n",
            "Epoch 437/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1556 - accuracy: 0.9422 - val_loss: 0.2116 - val_accuracy: 0.9098\n",
            "Epoch 438/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1533 - accuracy: 0.9400 - val_loss: 0.2773 - val_accuracy: 0.9022\n",
            "Epoch 439/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1494 - accuracy: 0.9448 - val_loss: 0.1535 - val_accuracy: 0.9341\n",
            "Epoch 440/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1678 - accuracy: 0.9351 - val_loss: 0.3781 - val_accuracy: 0.8924\n",
            "Epoch 441/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2000 - accuracy: 0.9221 - val_loss: 0.3347 - val_accuracy: 0.8834\n",
            "Epoch 442/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1859 - accuracy: 0.9240 - val_loss: 0.2738 - val_accuracy: 0.8966\n",
            "Epoch 443/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1798 - accuracy: 0.9287 - val_loss: 0.2487 - val_accuracy: 0.8987\n",
            "Epoch 444/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1756 - accuracy: 0.9344 - val_loss: 0.2856 - val_accuracy: 0.8938\n",
            "Epoch 445/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1957 - accuracy: 0.9219 - val_loss: 0.3171 - val_accuracy: 0.8709\n",
            "Epoch 446/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1791 - accuracy: 0.9349 - val_loss: 0.3153 - val_accuracy: 0.8820\n",
            "Epoch 447/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1781 - accuracy: 0.9313 - val_loss: 0.3761 - val_accuracy: 0.8605\n",
            "Epoch 448/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1928 - accuracy: 0.9262 - val_loss: 0.2973 - val_accuracy: 0.8938\n",
            "Epoch 449/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 0.1833 - accuracy: 0.9295 - val_loss: 0.3596 - val_accuracy: 0.8633\n",
            "Epoch 450/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1944 - accuracy: 0.9229 - val_loss: 0.2416 - val_accuracy: 0.8959\n",
            "Epoch 451/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1869 - accuracy: 0.9264 - val_loss: 0.3089 - val_accuracy: 0.8952\n",
            "Epoch 452/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1951 - accuracy: 0.9255 - val_loss: 0.2833 - val_accuracy: 0.8987\n",
            "Epoch 453/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1693 - accuracy: 0.9346 - val_loss: 0.3458 - val_accuracy: 0.8751\n",
            "Epoch 454/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1693 - accuracy: 0.9377 - val_loss: 0.2921 - val_accuracy: 0.8904\n",
            "Epoch 455/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1935 - accuracy: 0.9261 - val_loss: 0.2681 - val_accuracy: 0.9022\n",
            "Epoch 456/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1738 - accuracy: 0.9318 - val_loss: 0.4013 - val_accuracy: 0.8716\n",
            "Epoch 457/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1753 - accuracy: 0.9327 - val_loss: 0.3234 - val_accuracy: 0.8876\n",
            "Epoch 458/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2102 - accuracy: 0.9301 - val_loss: 0.2636 - val_accuracy: 0.8987\n",
            "Epoch 459/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1854 - accuracy: 0.9262 - val_loss: 0.4720 - val_accuracy: 0.8362\n",
            "Epoch 460/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1813 - accuracy: 0.9309 - val_loss: 0.3326 - val_accuracy: 0.8987\n",
            "Epoch 461/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1791 - accuracy: 0.9304 - val_loss: 0.3180 - val_accuracy: 0.8806\n",
            "Epoch 462/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1860 - accuracy: 0.9278 - val_loss: 0.4136 - val_accuracy: 0.8626\n",
            "Epoch 463/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1875 - accuracy: 0.9224 - val_loss: 0.3272 - val_accuracy: 0.8695\n",
            "Epoch 464/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 0.1808 - accuracy: 0.9290 - val_loss: 0.3804 - val_accuracy: 0.8570\n",
            "Epoch 465/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1842 - accuracy: 0.9259 - val_loss: 0.2783 - val_accuracy: 0.8945\n",
            "Epoch 466/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1747 - accuracy: 0.9285 - val_loss: 0.3318 - val_accuracy: 0.8931\n",
            "Epoch 467/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1692 - accuracy: 0.9356 - val_loss: 0.3308 - val_accuracy: 0.8876\n",
            "Epoch 468/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 0.1692 - accuracy: 0.9288 - val_loss: 0.3541 - val_accuracy: 0.8779\n",
            "Epoch 469/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 0.1767 - accuracy: 0.9306 - val_loss: 0.2723 - val_accuracy: 0.8924\n",
            "Epoch 470/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1687 - accuracy: 0.9358 - val_loss: 0.3434 - val_accuracy: 0.8883\n",
            "Epoch 471/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 0.1737 - accuracy: 0.9302 - val_loss: 0.3314 - val_accuracy: 0.8848\n",
            "Epoch 472/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.2037 - accuracy: 0.9243 - val_loss: 0.4387 - val_accuracy: 0.8633\n",
            "Epoch 473/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1807 - accuracy: 0.9308 - val_loss: 0.3078 - val_accuracy: 0.8987\n",
            "Epoch 474/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1612 - accuracy: 0.9387 - val_loss: 0.3448 - val_accuracy: 0.8869\n",
            "Epoch 475/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1594 - accuracy: 0.9361 - val_loss: 0.3020 - val_accuracy: 0.8987\n",
            "Epoch 476/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1668 - accuracy: 0.9363 - val_loss: 0.4115 - val_accuracy: 0.8786\n",
            "Epoch 477/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1637 - accuracy: 0.9367 - val_loss: 0.2907 - val_accuracy: 0.8952\n",
            "Epoch 478/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1726 - accuracy: 0.9295 - val_loss: 0.4054 - val_accuracy: 0.8619\n",
            "Epoch 479/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1489 - accuracy: 0.9419 - val_loss: 0.3299 - val_accuracy: 0.8952\n",
            "Epoch 480/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1649 - accuracy: 0.9321 - val_loss: 0.3393 - val_accuracy: 0.8806\n",
            "Epoch 481/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1769 - accuracy: 0.9339 - val_loss: 0.4235 - val_accuracy: 0.8765\n",
            "Epoch 482/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 0.1731 - accuracy: 0.9308 - val_loss: 0.3064 - val_accuracy: 0.8987\n",
            "Epoch 483/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1790 - accuracy: 0.9299 - val_loss: 0.4492 - val_accuracy: 0.8681\n",
            "Epoch 484/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1609 - accuracy: 0.9375 - val_loss: 0.3084 - val_accuracy: 0.8987\n",
            "Epoch 485/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1668 - accuracy: 0.9327 - val_loss: 0.3314 - val_accuracy: 0.8793\n",
            "Epoch 486/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 0.1635 - accuracy: 0.9372 - val_loss: 0.3033 - val_accuracy: 0.8890\n",
            "Epoch 487/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1640 - accuracy: 0.9372 - val_loss: 0.5154 - val_accuracy: 0.8383\n",
            "Epoch 488/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1593 - accuracy: 0.9415 - val_loss: 0.3099 - val_accuracy: 0.8980\n",
            "Epoch 489/1000\n",
            "181/181 [==============================] - 1s 8ms/step - loss: 0.1577 - accuracy: 0.9373 - val_loss: 0.3829 - val_accuracy: 0.8827\n",
            "Epoch 490/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1731 - accuracy: 0.9320 - val_loss: 0.4032 - val_accuracy: 0.8716\n",
            "Epoch 491/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1572 - accuracy: 0.9363 - val_loss: 0.5870 - val_accuracy: 0.8321\n",
            "Epoch 492/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1650 - accuracy: 0.9318 - val_loss: 0.3882 - val_accuracy: 0.8855\n",
            "Epoch 493/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1619 - accuracy: 0.9368 - val_loss: 0.3851 - val_accuracy: 0.8702\n",
            "Epoch 494/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1565 - accuracy: 0.9396 - val_loss: 0.3273 - val_accuracy: 0.8980\n",
            "Epoch 495/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1546 - accuracy: 0.9384 - val_loss: 0.4313 - val_accuracy: 0.8675\n",
            "Epoch 496/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1679 - accuracy: 0.9342 - val_loss: 0.3607 - val_accuracy: 0.8675\n",
            "Epoch 497/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1788 - accuracy: 0.9297 - val_loss: 0.3993 - val_accuracy: 0.8799\n",
            "Epoch 498/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1449 - accuracy: 0.9460 - val_loss: 0.3247 - val_accuracy: 0.8897\n",
            "Epoch 499/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1542 - accuracy: 0.9384 - val_loss: 0.4333 - val_accuracy: 0.8786\n",
            "Epoch 500/1000\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1499 - accuracy: 0.9417 - val_loss: 0.4205 - val_accuracy: 0.8709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36lao7G1Pcaz"
      },
      "source": [
        "## Evaluation and Graphs "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnWRNP5FSYrs",
        "outputId": "dc73a0c0-dbe5-46ec-c1d5-d62b173aaa16"
      },
      "source": [
        "# Evaluate our model on the test set\n",
        "loss, accuracy = model_binary.evaluate(X_test, y_test)\n",
        "print(f\"Model loss on the test set: {loss}\")\n",
        "print(f\"Model accuracy on the test set: {100*accuracy:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.9715\n",
            "Model loss on the test set: 0.12533998489379883\n",
            "Model accuracy on the test set: 97.15%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "E2JbvSN4PfAT",
        "outputId": "d41f00fc-9706-4a4e-fe7b-3ff851380b6a"
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])#[5:])\n",
        "plt.plot(history.history['val_loss'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "nUJFw4hkSXzp",
        "outputId": "ee415727-1615-4a90-8284-6158ba665e91"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])#[5:])\n",
        "plt.plot(history.history['val_accuracy'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Binary Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXhU1dnAf2/2PSEJe1hl38EIKi7gCorgLlitaJVqta3W5VPbqnVvXdpaqRa1at1wLWJFUBHccAEUkVUCsoQ1CQESyDYz5/vjzGTuTCbJBDMEmPf3PPPce889995zJ5Pznnc57xFjDIqiKEr0EtPSDVAURVFaFhUEiqIoUY4KAkVRlChHBYGiKEqUo4JAURQlylFBoCiKEuVETBCIyL9FZIeILKvnvIjIYyJSICJLRWRYpNqiKIqi1E9cBO/9HPA48J96zo8Feno/I4AnvNsGyc3NNV27dm2eFiqKokQJixcvLjbGtA51LmKCwBjziYh0baDKBOA/xs5o+1JEskSkvTFma0P37dq1K4sWLWrGliqKohz+iMiG+s61pI+gI7DJcVzoLVMURVEOIIeEs1hEpojIIhFZVFRU1NLNURRFOaxoSUGwGejkOM7zltXBGDPNGJNvjMlv3TqkiUtRFEXZT1pSEMwEfu6NHjoa2N2Yf0BRFEVpfiLmLBaRV4BRQK6IFAJ3AvEAxpgngVnAGUABsA+4PFJtURRFUeonklFDkxo5b4BrI/V8RVEUJTwOCWexoiiKEjlUEChKc7BzHRR8+NPu4fFAVXnztEdRmoAKAkVpDp48Hl48D4JX/HNVwa6N4d1j/gPwQEeo3tv87VOUBlBBoCiN4XbBuzc13KFXe0fyFaWB5f+7Af42EGoqGn/Omvftdu28/WunouwnKgiUxtnyLWz7vvnut+Rl+M8E2L4cKndDab0z3+tSshaq9zVfW8Jh4xew8Cl457d2tH5XJvylu32PYFa9C1uW+I9Xz7LbnT82/pwOQ+x2XYQFgTGwLWQuyMZZ/3no91YOaVQQRCv7dsI9bWD9Z43XnTYKnjyu+Z696l1YNx+Wz4B598N/xjdc3+O2W3cN/GMYvPmL5mtLOLgqvTsCu71zHveVwIxr/HXikux25nUw7UTYsMAeJ6Tb7c51jT/H7bLbYK2iuVn6Gjw5ElbPbvq1z50R+N7KYYEKgmhl8zfgroJPH236tR43VO4Jfa5krR0xF8yt/3pXld2Wb7Md5J6tULErdN0fP4V7WsOyN23nC34TSnPi8dTfBl97ty6BqUeFrpOUGXj87Fj7HSWk2uOdaxtvQ41X04m0j2DH8sDtpq/r+jaUqEIFQbQS4/3TG3fTr33/j/BgJ38H6WTjl3b7/ev1X+/r8Mq2WSHgroI/dwkcNRevsQLni6m2jYWLYW+x96Q0vc1OKkrho3vBVW07wKLV8PU024ZQfgCfRuATRE7uz4Nv/gOxiXXPbfjcf22wRrD6PSswZ98Of/eahHx+hEgLghjv9CG3C1bNgmdOte/QFDYvtn8j5bBABUFLs/U7+GFOeHV3F8KOVU27f8Wu0I5KibVbn9ll+Qx44jg7Mq6Pj+6122Vv2G0oO7N4O+n6RpgVu6xZCqwgKHNkFdn4Fcy9BxY9C4/nw0f3wN4d9ty+YvsBkBgrFLZ+579PYyNaY6zQAWua+uQhWP8prPofTB0Os//PngvuEN01ttOuj+oymHULVIXQkNZ/BnuL/O+96WuoKrPHnzxkt19OhdIf7fdeqxE4QkiNgTm/txpccxETb7eeGihdb/d3rKi/vscDs26Goh/8ZU+dZP9Ghzi79lVT5QocDBWXV3H/rJVUVO/HICkCrNq2hxH3f8i6osiFFqsgaGn+dQK8fGHj9VzV8MEd8PIFtmOf8/v6zTNO/twFnjmtbrm7xm59guDNX8D27/0dl4+aSv/+Jw/Zjiy7uz3e7F0XYsdKO7rdvBj/aL2ejvnPXaBopd3fvcnfuQPMuBo+fRj+d709XvG2vz2l6/0agcTAP4+2313penikN/wpC5a+XldLcVXZd/3gDni0D3z+mG0vWCd4sAaw9qPA48/+5hd89REb7+/gAfJ/AdlHQEmBv1Pfs9mOvP/a3/pcNi8OvEd1eWiNYF8JfPE4vHR+w21oCj5hXbkbYrwDAt/vIRhXtRXIX0+D1y5tnucXLoYv/hlY5q4J/K2Fyaad+3hs7hpWbXP8L9RUwu7NfF5QTNdb32XzrroDoT2VNfz7sx8Zds8HHPvARwy5+32emL+Wy/79Nfn3fsi0T9Yxd9X2JrenIdwe///E715bwqsLA397324s5frp37K3yvqKCkv3sb54L68vKmT7nipOeuRjZn63pVnb5COSK5QpzcE3/7Ed4Nw/+cs+fdR2DrHx1jb97YtW3b/2q8BrfZ3itqV17+sbfXpcdrTq8Toq92yG9Lb+esEj3e0rID7Z7n/9FAy5GFa+Y48X/RvyHDb02bfZTrvvWZDZCdLbBd6rMado9V6/sNv0lf2AVyPwCgineeKtK+Et4LT77PtUlcGCf0CbPn7t4YM/+utvXQLdTgx85ubF8OL5cIm389+1PnTbep7m91W4awJNbPHJ1CTn4lq7gGRfmU/gVO62AiiYh44Ad7X/vUvWWs2lazM56Y3xCwCfcPp6GmR4lwDx/f0B9myB5FaAWE1p8XPeOk0bIbs9htgYobLGzYqtexiSl0VMjMDTJwFw0md9GDe4IzOWbGFem0eJ3fod3BY6RPcfc9ewo6yKO87qR8HKJezbW87Qo47nVy99w/ebd/PP+QVMOb4744d0JOPVs2lTspDX4u8A+rCgoJjT+rXj4zVF7NhTyWXD2/PaI7/jobLT8JBAu8wklm/Zw59nB2rbizeUMm5QBwAqa9wkxsUg3u9w2+5K/u/Npfz+zL70apsess0rtuyhR5s0lm/ZzcCOmZz210/Iy07hiNapvPXNZt76ZjMXHdWZR99fzertZcxZbgVPXGwMx3TP4b5ZK9m5t5pebdNq79mjdVrIZ/1UVBAcLLhdEBvizzHz13XLNnnt8DvX2VGzD1eV7fA6DLVCoqFIFd/o07jt6NrHh3dCahs4+58Ql1hX69i+zO9ULVkDD+T5z5WshdZ97L7HZQVUensrtBLSIM0hYBDq1Rp8lNc3InNcFzyyBnj/94HHPiEQzJYlfL4vj5G+47hkcFVAwQeY6r0Qn8L26iTaBV+XfwWktvYLAlfgiPO174rJ3gen4P3usrs3HjXkEwLA3rJdpP7DLuH9ZPp1XA1UxySTAFaIvHkVXDW3roPaizGGxSvXMqjwJRL6jrWmrc8ehTtK2efykFxZ5vey7LFRUEs3lfDm28v4w5gjiH+0L9s6jSUr3k3SOr9jvsLl8Qs2L8XlVeSm+f0jLreHskoXD7+/mpe+CuzULzm6M6mJcdzmPS4v2ULrT6YS4x5L7L5PAHjk9Y/Y4GrFbwYL+z59nO8H3MJedyyPfGDNUj9sL+PVrWMA6Prfl4nFzYLcP/PfzEvJ/eRJeiyYj9sICCTu2wr04Y9vL+O+WStJl0o+dV9K0fy2XOnezo5YQ48Jt3GhfMD1q/oxY3kpl4/syu+PiqHkqXO4cd1fWLY5j0uf+YrSfTVcenQX7jl7AAA3vf4dnxUUExcjHN09h0uP6QJAUrzVsD5csZ0r/7OIpPgYKms8/OHMvqwr3su64r188oNf67782a+Zt9p/nJEUxxuLC3ljcSEAMQI/bLeC+6UrR9CvQ0bIv/lPRQXBwULVHkjJrlvu65ycbPF2bMHhfz9+Ci+dB8N/CWf8xcbp+/B4rFN2/gMw8nr/PT2uQDv9j/YfkpoKWP0unPX3wGcUrbIj+f7nwvK3As8VLoSOR9r9zd/Yd/JpFNXlsNNh48zuVn/nGJsIsQnW/g64EzKJrd7tP1/jmEcw/4HQ92gEIzHI7k0M3PV8rTXLc8pdxHh9Ba/cN5l7qiZyQ9xWpjj/SxIzmdfjNorff5gL6rn3+t2GKkmHOKgycZRn9CXH8a7byKUdxfVcDanGbxrKLF0OcbB+j2H3+p10eOd2Opassf6UXtbkV1ZZQ8nH/6JrXh4cMZqN7zxI/nKv6WWBPyps9sefcPWcvczrtp1uQc9cu62U5zdtoG/V90wEUjfOJ0kCf3ebSyvoEWRMfvrTH/llzzLmr97BDZ9CXIyQkRzPzr1+wdaaUh5PfYbrv7ycreRwmzfSdnKHTVy680MujfOn5ti+ZBYz3aMZuvx5Lo+bw7sb43jKfSZXxM6hc9ee/Hljb/Bas07Pc9G7dSIdVi7j2vL/q+3NYsUOFNok1EAFVNZ4qKzx0Fq2QiK0dtsBxg2n9SU58Qv4741c0/c6ZnAsF+Z3Iu6r22jr3kqXok/50zu5lO6zZrMXvtzAiq17eOSCwSxcb/1cc1ftYO6qHdw3ayUicMmILvRsm8bMJdaEU1ljfW73vruS+Fjhi9tOJv9e//s6hcD/fn0cNW4P5/zThh5PPKoTp/VvyxXPLWLcoPaM7JFLpFBB8FOpKLXmiU7D7Wht0b/hzL+GHt2X74DiH0Kr+xWloQVBQkpdQVDl7RTdQfbwIq9qu/ELqx287zCD7Cu2JpzP/w7G4zAJhFD341OtEAD49qXAc+vmW+dmz1PhqKvsRCuwAmDzYr/ju7ThCVTb4jrQjkBBYOKSEVcF5v9+pLTCQ9yzp5KxayU3lV/M0OEn8PNBKax/+Qa6uhqPya9uO5SE7SFMMF5WSE/6m9VkyD7KTDKvjZ7PPTMKeP7sDzhx9qlcLO+TEb+HcpMUcN1uTwJXv7iY84yLC+LhC3c/tpDNebGfUWXiSZQaBnZtR4onDbbCWtORJQUVXOz4Oax0d6RdbP2CwMngGPuuvWI2M/Xp3zJQyugYC1/+WMLRvWBZ4S7ee+YubjbPArAzoQNdqkPbked9+D9gNFt3FNURBBlY4bpt6fsQBztjskk3getEJUk1wTz58Vpu/epizgFK48Zwt+vn7NxbzQVH5nF51xI8ZdvpsuNj0ld9w0uJ27kh9jbwxiP8rFs5eOMGjMQixs01PUo5fthQaj78H5TBhNgFbDXZ3BH/AmyGiX8shvvtNf86vgLSM2Fl6O/uxvx4RnQfzKY9Hv4w43u6p1aCwwKWnJpuNVygV7tMlt51GhlJ8bXzOaqMsHB9oPly8YZSRj08P6DslL5t+XDldoyxwsLJkV1akRgXw4K1JQzplEVuWiIvXzWC2cu2cce4fryycBObSyu45fTe1mwGfHfnabjcHjKS44mLEa4dfQTHdI+cEAAVBPtH5W4bqdK6Nzx7po3HvqMU3rne2p37nwN5wyE+xYZp7lgJb13ln517x06/k855z1A4bbeN4YsAcVVam3TZFmuzL1wI3zwPhV7n7hdTrTAAK5yctBsEZzwE/z7dHjuFTVpbK8jA2pBH307NqtnEl23CNfgS2LyEuJLwQgpnb0lhctCv78qkR7lpUCVXPPIlnbNT2LP95/wtfiqfeQaw4sc0eg7sz817f8NnidcHXPdOz3txrXqPc2I/B2CxpyfvFg7gjni/ICgyGbQWv5nrw+p+9I9bDUC6VHDP7LWAMHnGdqYn9GFEzCpOiV/KJzV9A55VXBVHjAhXjB4In0KPocdT2f8mni0q5/SvLqND2VLGDutuBftWKIjpSrkn0KAyaMhw+L4ec1UQ/WL8Hcu1cTNr97stuJXH15dyzZbbGSB+U1l2PUIAYKCs41VGE1dTDjGw06SRLVZLOzn2W77MuId2e22v2sXUXSwwN8EFQT7lgqSf1+5fETebVmc/QGZqMqO7pSAPnmBPtOkPQHfZzH9zpoJ3EJy5237/nPkoctQv4D8T6LbuDbrJdij7tPb97+2xGrxWpqRtvoAEAz/Mhu6j6n1fWfgUx29fBlfMZkPJXk7xbIVFjgpV5bDZ/kYkuRUZa/9nB0be/zm3CVR/Hr94KNe9bOsf1bUVN57Wm2837uLK47vxzGc/cubA9hz/Fzsr/IIj87hrfH9SE+NYuXUPY//+KVNOOAKAY4/I5dgjbMd+6dFd6rQ7Mzk+4Pjm0/vU+47NhQqC/eG5M22nftdu/6Qcd5XfzrvibXjhHDuyvugF62xzpmjYW2xNJq0c47JKx2Smsu3wSC+Y/G7dSIqEtMDwQifF3n+s4h9sqCLAiKutIPCFfoJfCIA/PPOil6wDNCaOABu8177+/piPSVzwMCfidQzvsR3O7rIycoFz/1vOn+M70DdmU+2lu00KmbKP3fGtyayx//2bTS4dpZhNpjUeI2ynFe1lJ5tNDnOLM5n7USZQydbdlUAXTq/+CwBF28uY9NSXQBu+yzyZnrs+I0WskLp3TWcezMyCcqgxsTyRczutdnwR8NVsNG0DBMHgvn2oGv05idNGBtQzxHBR9R2Mj1nAYwmPc1LSD5SkD2NVURUjY5ezlyTOGNieHl7XSOtOvRnduw30bgM/pEIZdgAgthM568JfULL2W1j8bu0zcroOhKZk7JCYwL8Z0FZ2cd3W2xqdUvFC+pWcuPtt8mKKGdlqF+8nPU+3ogI+dA/l++yx3LD7/tq6PiFQH0mmblRPHC47QPD6c87pEQ/fvwyv3u2vVFJQuxvjNOt5R+P09c4sbzvAapzrP/W9OMQlkrHxQxtssHuTNzDB+/tc84Fjbkk9bPwCitdw2xl94Yug1B2Ln/NP9Ksuh1k32f1+EwA4s086Fx13NGWVLjaU7GXcoA4M7JjJ+pJ9nNjLLpl7dPccAK4+0Xbyr1x1NMXlVZw1uEPtY/q2z2DVPWNq/QcHIxo+2lTeu9XfqTs76Ypd/giWIm+HXLMXXjwXkrMC7/HJX2wM9j05/rKNX9oQzBnX+mPZv3yirvkn54jA4xSHyrjdEQv+9q/stsNQOP5Gf/mEqaHfK6szJjaebwt3YyQGfu53Qs9NHccv395MUalfa3kzbgxvLC7kHdcIAH407VllOgfc8k23HREWVcVzdfX13FJzFe4eVtO4aexAdkkGW002v6y+gfOr7uI3J/WgV9s0zh1mzVZnDmpPRlIcM671d9ZDO2cx6Po3KTv9r7VlOypjGNypFQAbht7C0789l3suOrb2/M7sIZQcf09A20YN6kFi6x4hv4rje+Yy5IRxAMTVlJGVnUtamp0hXCnJTDmhO2R6TWvtBvkv9Hb+xCfDkJ/BFe8j/SaQm5NDADmhn1sv/c5uWn0HYy+7jdePe5fqXmfRrWwxvYrmEI+LY/p25doLTm/azVz1hHdW74Us78i2fLudk+LE+RtOcES9lG0FxG8SPe4GGPdX6OL9e7fuDRc8b/cz86BVV9v5A/Q+w3betULDQVygOY/H820EVvm2wHLnbO8P73K012oEp3RP4ejuOZzary1XHm9DprvkpNYKgVAcc0ROgBDwcTALAYiwIBCRMSKyWkQKROTWEOe7iMhcEVkqIvNFJC/UfQ4KjLEd9VdP+MucMfc/zLYTdGITayMxakkM8vQverbu/T+2I1+WvAjz7q173kerIOtuz9Pg+u+h/ZDAmHwf6e1tFBDYSWT9z61bJyae0pRuvPDlBs755wLmry7COMIqH915LMbAB24byXJK1V+48VPhpte/4z7Xz3hp5BzKSGGVJ1AQzMM6jstJYrZnOL3G/IrOufa7SI71kNZ1KJ36jWCO5yi2ksPvTuvN+zecyCMXDOblK0fw8PmDWXrX6QzplMXXt5/Msj+dzlvXHIuI0LaVP2LmX5ceRXaKVad7dLCdblKqX/imXPMRp50cNJciKQvivR1G7zN48Rcj+NUoK2Q7Z6dwxZhjakNhY5MzGdzVxg4N79WJ3u3Sod1AuH4ZdHKEyzoFQUwsdLZCsjbNRG2DcuDGH2iQ+BT//oTH4dIZdYT44uSReG5s2BSXm5PDjaf1Jql14O8mtV1PEtr0tAddj4exD9kgAycn/aHhNvqoLvcLt7JtoScwth9stw7tALDfhc9MmpprI7IGXWSP3dXQewyc+YgVEO2H+LXeHif779HaYb4bPgVu3eifPd3LRhixbVnghDgf3Uf5J9j58PnHwpmnc5gQyTWLY4GpwKlAIbBQRGYaY5xTGB8G/mOMeV5ETgIeAJpp1kozE8oc4zT3rHjbdvi9x8L3jglIMXF1HbLGDUecbB26G3xJ38LM9RIci5/WBrI6Q9v+1j/hJCmLMk88s1dX2wgXibHO55vWwMM9/fU8NQx94JPaw+8KdzHzuy3Ujrlb94EdlbQ/+kJu3nsGBd/5Bc5ZQ7vws1OH0KVrMVu3doTKXNuxdB/F1KJN8K/7GHLGFJYMOpWslASY45/AlHDpm+QCp1R9y/lHdqq9p4hwbFCERJuMoFGeY9R3Wv92sC7o+0vyC9+QozHf+T8UQUwcx8XE0L11Kv9bupXLR3a154ZdZs1q7mr/85ydelYnQiJBz4sPEgQJqYFzNc542EZRvXiefwSc1haeHeOvf8ToOhlMj7z5f9YHFZtg2+jb+hj3V//cgawgW3TPU+19MzpajXXEFFjse3Y7O3rud06gSbEhcnvC2rl2YmIozWHQRNuRf/O8/R32OBXWzLGCIJg078DFNw/mqCvtduAF1nSU3g76ToB3vZruFe/ByxNtWLXE2LBnn2/tmGttEMfyt/zBFE7aD4Z1H4d+p1CzxQ9TIukjGA4UGGPWAYjIdGAC4BQE/YDfeffnAUE6ZQvxxVSYczv8YYf9UYE/LYKTwq/9+yUF9p8hvb1/clGHofZHGCpM0tFRkZQZ2lkcKglaapBaesRou23Tt27d9Pa89NVGPlpVzQWJNmRy1EPzePSCwd6xusU30vfxtw/tKLM45lbuHu5mQnZXls9aRWJ8DFPGDmLxlq+4Z8IAuuWm0j7TdpDH9cyFnrnAkNr7ZLTvATevhZQcsnwdUqwvvYGdNyHA05fVk8itIeISA4+DU0wkho6xr8UXgx+XUFvUISuZT24Z7a8z9BK77TQCvviH3Q8e3TupTa8RlKbD5//pfSb0OaOuABl+ld3eFfQb+NmbdpTswxfp5cOXL+r8Z+08Ad+ciryj7EAj/wp/3VYOQZB9hD/Md/xjfvNinzPtnI8Lnoe2/UKn7UjKsgOb6rLAcp+m6hMC7QYGDpSSMvzfed+zvBPy5kD7QdQhWBD46DvOfnyceo/9n0tuBUdfbQVB8HeUkmP9C75Z8ElZgf64Nv2odxBWVRa63Memr+HHj+GEmxuudwgQSUHQEdjkOC4ERgTV+Q44F/g7cA6QLiI5xpgQ2b0OIJ97Y+eL11j75oJ/wDHX1a23aaF/3xdF5PzHze5uBYEvpcLYv8C8+2ynn5TpT1TWMd+Opurc/6u6Zc4OsO1A/8xYryAwiRmUtDmG3E1zKDbpFOwopxj7D+jywIaSfVz78rd4p6Sx5fLFFG+qYfCSEtYW7aVtRiJri/YyvFs2D150PR2zkrmk2sX6kn1cfmw32mUm8dGNoxr+/pykBo7sOebX9nt1dlL7Q7Ad+MjL7Gizp9cE5BO0MfX8xOuZjBWACAzzKqi+gUDb/g3U91lagzqWtnYSEiOmNBjlUoeepwQexyXYeR3v/NY789eLr4P8/g3rgD3lrrr3yurq37/6U785pofjGam5cJ3jNy0hPNGt+8CuDXUFQXKWjQ7asdwGOSx5OVAQJGb47zfwAmuyScqCXiH8FL6Jh+664aoBjPyNf7/f2XDRi9BrbGCdlBzrX6gVBJmBgiDXoRmf+YjVMnyaVdlWePta6HS0/3dgjE0xvuAf8IM3B1VCuhUIydnWjBfqe/thDnz1L/u7Pe8pO6Bwu+C/U+z6GgPOhS7HwnfT4bjfWSG/era9V6jvqJlp6aihm4DHRWQy8AmwGagT2C4iU4ApAJ07dw4+3fyktrFOr+3LbY6a8m2h/4ELHf80nhr7w3aO2H05eXZthA7DYMQvYeEzfkEwfIodxR19TWhB4AmR/8Vna23VFa75jL1VLp5bsJ73vyzlbWCPSWbejxVcEAdfbYc3CgtJx9rLN7itGr5tTyV4+9EOXXowqQtMOs6mBFi+ZTertpZxzrCOxMfaji0lIY77zxkY9tfXIKk5MPGlxus1RrBG0PHIwBG1r6MfcnHo68MRBE62etN0dBpef51T77HrEXQKGu90HQm3FUJiUCqCkdfXFWiNceRkGHwxIUexA8+3n1BkdcIXhRPgf2iM32+3wnTlTGv26X+ONYM6JyGCfber5tr/mbz8QPMoWMF83A1WkPQZZzs45+jeie9/qH8TnOQiVtMIJjnbCgKwHXzw953jEASt+8Ctm2xbnz3DP7ny2xftvTcvgi+fhIIPAu/hS1gIcMqdNj/Ugn/Y901Is+/jzCd2fwf7++t9pk2vDlao9BrjD4nNy4dXvL6SYE0xAkRSEGwGnDpwnresFmPMFqxGgIikAecZY+rYQ4wx04BpAPn5+ZFNnL51qT8T4/bv/SYbZwriC56D1yfXjehJbhUYxZPtiPDxdQLpba3DKzHD/kCvmgu7NlEvjtA8fvYGdDsB/m8DZTWwcNV2rnjOFxidzJ7EFLZVxlPuTQTQtm0HulakkBiXzi3FV/G5ewC/P6MvBsOy78+kX15OQLRAbIwwKC+LQXlBUU4HI411oHGJcFNB4Mi5KdcHM3iijfZqF8KU4aP9IPjlJ6HPBQsBgFP/VLcsHBzmrPCvSbRmS5HQI9b68DnUB5xrhYCI3Z9xDRT4Z8iSkGad5HnejKSxQW1MzLB/i/oEc3BbbyqoG23XFIb93EbfxSX4I+3c1XUHV8EmWt9x8O+mcGF4if9K11vtYMlL1nRUtg0GnFPX/Fu5G74LWunNF2Sya4P/ewTrfP/+dRhyid8c2MxEUhAsBHqKSDesAJgIBPwKRCQX2GmM8QC3Af+OYHvC41/H+/e/fNL/w9njGAE5c+acdi+8742uSM4K/PGmtbGjr5p9/o7Ad61zRBrsMPv1N3ZEUr4NTr/fvyJXq24YY7h8+g/Md0xNtwjLPV0xQLvcXNgF+X2PYP7J1uZ95fMpbF65neN75dKnXQaccIgvNxisEYQiLcifcvVnVqjGxDetMwQYfTuceIvfx3Eokt2tcbt3Q/i+s7Q2dlDy9TR47xZblhiUDK3dgLNVXnsAACAASURBVMDjpmpgwX+7pnLWYzDub3bfl/8K/FlWr5rn90X4cLYxL9+mKM/oaDvoPY6Jeukd7GTNUJRu8Hf4vsmV4a714DOllW6wS4L6mHc/LHjMajf1aVE/kYiFjxpjXMB1wBzsJPDXjDHLReRuEfGtTTgKWC0iPwBtgfsi1Z79wjl6cKrCSZlw3jN29OfMXpncKlDtjkv0O698IaS1gsAhMBICVXV3ahtcFd4fU6ZfqdpVE8uCtSUhhACM6t2aqrMe5xbXL8lI9tp/4/wzWh+9aDBPXjLMCoHDgaaO6ME6MHucAt1PbLxuMCKHthAAa7oa82Dz3EvERlX5CA6RHnopXP6e35QZH5yuLsKI+P0gTkHgG+mnt/ebjHw436Grd0DYurfdfuaft1JbForS9d703o7fSlN/q8Vr7JKgPnzZg32hsxEgoj4CY8wsYFZQ2R2O/TeARpK9H0DqW6oQrOM2Id2ahdr29zsNnbHJya0CO/XYRMhob0cGtaYhb/hnUgZbdlWQmhBHQVFZQBTPDW+t4TG3jcWeuV6olZp//4pdpJMUH8P715/ICQ/5Z0p2zk5h1PAB3JmWx/ANP8BWAjqujKR4xgxo36Sv46AmHI1ACSTvyMbrNIX4JKvNpuQGmkHBdsRdjoWJr9jZwBl1J1kdMHwT1nJ7wcSXrR0+I8T/glMQdBhmBeeA8+Cv/QJzZwWHcDspXW8d6dnd/R131+OtX2HQRFg6vfH2+hzbPnzrXxeGyLTbTLS0s/jgoqgBibu3CE64JUQkh6NDSsoK0ggS/CMDX55+h2no2Ac/IkbAY2C9Y9Awc+lW7k3JJMOzmxtmbWO891ylTURM15xUOuek8MTPhjGgYyavLtzEL46z4Xun9msLG7z+9kN9BNsQ+6MRKM3Pb5faCJj6TG2ZHW1oZ0vzmyVe020rf7iuj6zONqDDaX+PiQmMSnLSkLO9dL1NOJmUaSforZtvfRQFH9jnn36/DU1viOKgiW++6Kn1n9mFgvbHR9QImmLCR/Vea++MT4WrP/fHWTvpdkLdMmeHlBwsCJKsD2H84zDwfPZU1vBDWj4MvYTy7H6AFQIA/SufYVTNY1woD3NE61Qyrp3HxtGPc2S31nzc+mcA3DrOqtntvLH7Ywe2p1N2Cjed3ptWqY4fR3tvLH/bIDvt4YRqBAcHiWlN97e0BNnd6g8cuGqe9R+FjbGzvM9+ou6pwq9tyHhSpk0Ff93Xfl+ExNoJbj4uetG/75s0Vx9HX2uzDm9oSjvDRzUCH1/9y87MnfSqdXSFGnGGGgk4O6TUNgF1Kjyx/H5+BTedfj4dRHjwvVW8/NVGXr7yT/z5+cCsY61aZbOlLJX1FR4uG5ILOUfQ+cQjeO1EgGOAf3KZMSTEx3NSnyAnVzCDJ1pnlzNG+nDD1/k0NnFMURojNbfufBcn5z3jD9jw4Zts6HHZPGFLvCHR7mr7cQaNJHjNwjV7A+/RfrA1QW35pq6/Iphjf20n4DW2qt9+ooLAR/l226n09k7r95lVUtv4M3QmhBIEDoGR3jZAvfxiQzlvfbuZvdUu/nVpPss3WwfwxU/7J4rdMa4fg/Iyye9q7Zhf/7jT5rIJgYhw8Ygw5lGIHN5CwMek6d6ZoYoSQQaeb9cIr01a59CAhv3cTjJb0sDcGF9EVfC60Mmt4OJXrckn1LogF75gJ6KltbE+jV9HzkegpiEfNRWBkQ0+274z/jtU5INTI0gIDKHbuNvmO/lsTTFLNu3iu8LdnOwYzQ/tnMXPj+lSKwQAhnfLrpOPXKmH3mMDUycoSqTwRT91GQmjgvJn+qwAzvBT59ygfmfbRHqjvUuoDp9itwlptpMfcK4/dYmzD0nOgrOn2klqEUY1Ah81Ff7JM+CfEOOMjw5lGnLYRytdHtYV7cU3Rl2xw04421vt5uypNi74hF6t+cVx3SircnF6/waiDxRFOXg47yk70zjU7GXfALFVN5j0CjzaNzDVeEIKnDvNfzz2L9Zp7PSt+ASBcyJeQ3mtmhkVBD5cFYEdvW+pyYRGNAIHd769nFcXbaqNAJqxrJjxgztTsKOcFVv3kJ4Ux4X5nUhOOLhzkyuKEkRSZmghAIH9QkYHuOqjwLkLwYSak1KrCTgSJwRnrY0gahryUVMRaO8PVyNw8OHK7QHHFw3vzv3nDiTbG9Fzy5g+KgQU5XAjeIDY8cimj+Z99Z2Za0P5JCOEagQ+aioDO/pQPoLgdYZ9DL2U6rZDKXsncH3he7yJ2tKT7NfcPjinvqIohz7BeZX2h1pB4CxLC1k1EqhG4KNmX5CPwCsIGpHsa4vKcY17jI/SzqDa7eEfk4bWqfPHcf342YjOHN+rgRA1RVEOUZphHkUojaApWWJ/IioIfLgqA1U8nyCIrX/i0uINOzn5kY95bsF6XvxyI61S4hk7oK4DuENWMvedM5DEODULKcphhy9k/KdMcvSN/p3ZWQ/gpEk1Dfmo2ReQpK1W3asnTcPiDaU8+J5d+u7ed+3CM3dP6E9crMpWRYkq2g22C1f5wkL3h7gEuxZCQip8/S9bdgBnbKsg8FFTn0YQaP8rKa/i9L99QnF54OpJYwe049KjvTHtN6wIXNheUZTDl5gYOL0ZEif71kL42ZuhVyeMICoIfNQ3oSxII/hy3c4AIdAlJ4UNJfu4bWxfxCfBMzvaj6IoSlPpeUrd5JYRRgWBD1eQIPB16uK367+/fBtLN9tU1ZOGd+K0/u0Y0S2bLbsq6Zxz4Bw7iqIozYkKArB5PtzVgT4C443jctjpprywmB5t0hjcKYsHzvUvWdijzYEL81IURWlu1LMJdsFtqHfm8M6LZjKmyq7sVLCjnGtHHRGynqIoyqFIRAWBiIwRkdUiUiAit4Y431lE5onItyKyVETOCHWfiONbp7iexU6GPV/OKuPP+nlK37Yh6ymKohyKREwQiEgsMBUYC/QDJolIcM7gP2DXMh6KXdz+n5FqT1iUb69TVLqvuk5ZTMwhsBCHoihKmERSIxgOFBhj1hljqoHpwISgOgbwLRSaCWyJYHvqJ9M72j/ysjqnVm8rO8CNURRFObBEUhB0BBxJuSn0ljm5C7hERAqxi9z/OtSNRGSKiCwSkUVFRRGKzx98sV27tBbrLF60YReDO2VxdHe7ZoBvqyiKcrjQ0lFDk4DnjDGPiMgxwAsiMsAYZ8INMMZMA6YB5OfnmxD3+WnU7K3XUVxZ4+a+swcwoGMmq7eV0bFVw6moFUVRDjUiKQg2A50cx3neMie/AMYAGGO+EJEkIBfYEcF21SV4MpmDdplJDOhoVx6qbwlJRVGUQ5lImoYWAj1FpJuIJGCdwTOD6mwETgYQkb5AEnBgczMYY/MM1ZNlNDdNU0crinJ4EzFBYIxxAdcBc4CV2Oig5SJyt4iM91a7EbhKRL4DXgEmG2Oa3/TTEDUVdhukEVTU2MWkc9OaIde4oijKQUxEfQTGmFlYJ7Cz7A7H/gpgZCTb0Ci1giAwRcSq1mMZyt/w9Du7BRqlKIpy4GhpZ3HLU7PPbh2CYOfean71/l62V73M0oHDWqhhiqIoBwZNMfH9a3brMA09+fFatu6uZGjnVqQlqqxUFOXwJroFgccDc++2+w5nccGOcgAevXBwS7RKURTlgBLdgqBqj3/foRGs3lbG+MEd6JLT8HrFiqIohwPRLQgqSv37Xh/B7ooaNu+qoFdbTS2tKEp0oILAR4z1BcxdaRPPHXNETku0SFEU5YAT5YJgp38/yc4efm/ZNjpmJTOsc6sWapSiKMqBJcoFgV12kp+9ATlH4PEYFq7fycgeOf71hxVFUQ5zolwQeE1D7YcAsK64nF37asjvohlGFUWJHlQQACRnAbDKu/bAwLzMlmqRoijKAadRQSAib4nImSJy+AmNilJISIfYeACKyqoAaJuhieYURYkewunc/wlcDKwRkQdFpHeE23TgqNwDSRm1h8XlVcTGCFnJ8S3YKEVRlANLo4LAGPOhMeZnwDBgPfChiCwQkctF5NDuMav2QKJ/jYGisipy0xJ0TWJFUaKKsMw9IpIDTAauBL4F/o4VDB9ErGUHgupySPBPHCsuryY3LbEFG6QoinLgaTSjmoj8F+gNvACcZYzZ6j31qogsimTjIk5VOSQ6BUEVrdNVECiKEl2EoxE8ZozpZ4x5wCEEADDG5EeoXQeGqrJajeCtbwpZWrhbNQJFUaKOcARBPxHJ8h2ISCsR+VU4NxeRMSKyWkQKROTWEOf/KiJLvJ8fRGRXE9r+06kuh0TrLP76RzvLeOJRnRq6QlEU5bAjHEFwlTGmtoM2xpQCVzV2kYjEAlOBsUA/YJKI9HPWMcbcYIwZYowZAvwDeKspjf/JVJXVmoZ2lFXRv0MG+V11MpmiKNFFOIIgVhz5FrwdfDgL+Q4HCowx64wx1cB0YEID9Sdh1y0+MBgTYBraUVZJG/UPKIoShYQjCGZjHcMni8jJ2M56dhjXdQQ2OY4LvWV1EJEuQDfgozDu2zy4KsG4a8NHt++pok26TiRTFCX6CGcdxv8Dfglc4z3+AHi6mdsxEXjDGOMOdVJEpgBTADp37tw8T6yyq5CRmI7bYygpr6JNhmoEiqJEH40KAmOMB3jC+2kKmwGn5zXPWxaKicC1DbRhGjANID8/3zSxHaHxrU6WkEZJeRUeg5qGFEWJSsKZR9ATeADr8K21nRhjujdy6UKgp4h0wwqAidhUFcH37wO0Ar4Iv9nNQPVeu01IZYc3x1AbzTGkKEoUEo6P4FmsNuACRgP/AV5s7CJjjAu4DpgDrAReM8YsF5G7RWS8o+pEYLoxpnlG+uHiqrTb+BR2lNl91QgURYlGwvERJBtj5oqIGGM2AHeJyGLgjsYuNMbMAmYFld0RdHxXE9rbfNRU2G18EttLVSNQFCV6CUcQVHlTUK8RkeuwZp5Df2V3l+38iUtixx6731pnFSuKEoWEYxr6LZAC/AY4ErgEuCySjToguLwaQVwSO8oqaZUST0Lc4bfkgqIoSmM0qBF4J49dZIy5CSgHLj8grToQODWCsl26GI2iKFFLg0Ngb1z/cQeoLQcWn7M4LpEfi/eS1yq5ZdujKIrSQoTjI/hWRGYCrwN7fYXGmAObF6i5qbGCoNzEs7aonLMGdWjhBimKorQM4QiCJKAEOMlRZjjQCeKak41fwXs3A7BiRxXGwCBdsF5RlCglnJnFh49fwMesG2t315XarBY92x76gVCKoij7Qzgzi5/FagABGGOuiEiLDgQx/tcu3mcFgS5IoyhKtBKOaeh/jv0k4BxgS2Sac4CIia/dLS6vJj0xjqT42BZskKIoSssRjmnoTeexiLwCfBaxFh0IYv2CYOfearLTwlleQVEU5fBkf2ZQ9QTaNHdDDigO01DJ3ipyUlUQKIoSvYTjIygj0EewDbtGwaGJMQEaQUl5NZ2yU1qwQYqiKC1LOKah9APRkANC4WJ4+iRI8L9ScXk1QztntWCjFEVRWpZGTUMico6IZDqOs0Tk7Mg2K0Js+Nxuq8tqi0r3VZOTqhFDiqJEL+H4CO40xuz2HRhjdgF3Rq5JESSubj4ht8eQo85iRVGimHAEQag64YSdHnzEhR75Z6uzWFGUKCYcQbBIRB4VkSO8n0eBxZFuWEQIEgQFIx8GdDKZoijRTTiC4NdANfAqMB2opIGF5p2IyBgRWS0iBSJyaz11LhSRFSKyXEReDrfh+4VTEAy9hNVtxwGoaUhRlKgmnKihvUDITrwhvGsZTAVOBQqBhSIy0xizwlGnJ3AbMNIYUyoikZ2f4Jg/QHwqJXvtmgTqLFYUJZoJJ2roAxHJchy3EpE5Ydx7OFBgjFlnjKnGahMTgupcBUw1xpQCGGN2hN/0/cDj9u/HJ1NSXo0ItEqJr/8aRVGUw5xwTEO53kghALyddjgj947AJsdxobfMSS+gl4h8LiJfisiYMO67/xi/IDDxKXyxroR2GUnExeoSlYqiRC/h9IAeEensOxCRLoTIRrqfxGFTVowCJgFPObUPxzOniMgiEVlUVFS0/0/zeGp3t3sy+PrHnVx1fPf9v5+iKMphQDhhoL8HPhORjwEBjgd+GcZ1m4FOjuM8b5mTQuArY0wN8KOI/IAVDAudlYwx04BpAPn5+fsvhDyu2t2d0gqAAR11QRpFUaKbRjUCY8xsYBj+qKEjgblh3Hsh0FNEuolIAjARmBlUZwZWG0BEcrGmonXhNr7JOExDJV5BoP4BRVGinbCM48aYYuBdoAL4M3Yk39g1LuA6YA6wEnjNGLNcRO4WkfHeanOAEhFZAcwDbjbGlDT9NcLE4SzeYawFKlMFgaIoUU442UePBi4GzgaysXMIbgrn5saYWcCsoLI7HPsG+J33E3kcGsF2dzpQTFayziFQFCW6qVcjEJH7RWQNcB+wFBgKFBljnveFex5yODSCnZWQmhBLQpxGDCmKEt001AteCWwHngBe8JpsmitaqGXwCYLTH6B0Xw1ZKaoNKIqiNCQI2gP3AmcBa0XkBSBZRA7NhHPgNw0NuZjdFdVkJqt/QFEUpd5O3RjjBmYDs0UkERgHJAObRWSuMebiA9TG5sOnEcTEUrqvhlapKggURVHCjRqqMsa8aYw5HxvnPzuyzYoQPo0gJo5d+6rVUawoisJ+rCtgjNkD/CcCbYk8vgllEsvuihqyNHRUURQlPI3gsMGbYsJIDLv2qSBQFEWBaBMEXtNQebUHl8eoaUhRFIXw0lAvFpFrRbw5GQ5lPG6QGHZVWBORagSKoijhaQQXAR2wC8tMF5HTRUQi3K7I4HF5HcU1ADqPQFEUhfCSzhUYY36PTQj3MvBvYIOI/ElEsiPdwGbFuEFi2VVRDahGoCiKAmH6CERkEPAI8BDwJnABsAf4KHJNiwAeT+0cAtDMo4qiKBBe0rnFwC7gGeBWY0yV99RXIjIyko1rdrwawe4KKwgydGaxoihKw4JARGKAN40x94c6b4w5NyKtihQeN8TEsq/KOovTEg/dbBmKoijNRYOmIWOMBzi0OvuG8LggJpa91W5EICkutqVbpCiK0uKE4yP4UERuEpFOIpLt+0S8ZZHAaxraV+UiJT6WmJhDM/hJURSlOQk3fPRa4BNgsfezKJybi8gYEVktIgUicmuI85NFpEhElng/Vzal8U3G6yzeW+0mRc1CiqIoQBjOYmNMt/25sYjEAlOBU7FLWy4UkZnGmBVBVV81xly3P89oMj6NoNpFaoKahRRFUSDMpHMiMgDoByT5yowxjSWeGw4UGGPWee8xHZgABAuCA4fPR1DlJiVBNQJFURQIL8XEncA/vJ/RwF+A8Q1eZOkIbHIcF3rLgjlPRJaKyBsi0imM++4/vqihahepiaoRKIqiQHg+gvOBk4FtxpjLgcFAZjM9/x2gqzFmEPAB8HyoSiIyRUQWiciioqKi/X+a1zS0t9pNsmoEiqIoQHiCoMIbRuoSkQxgBxDOyH1zUL08b1ktxpgSxwS1p4EjQ93IGDPNGJNvjMlv3bp1GI+uB69GUKE+AkVRlFrCEQSLRCQLeAobMfQN8EUY1y0EeopINxFJACYCM50VRKS943A8sDKsVu8vxqM+AkVRlCDCiRr6lXf3SRGZDWQYY5aGcZ1LRK4D5gCxwL+NMctF5G5gkTFmJvAbERkPuICdwOT9fI/w8Lj8UUPqI1AURQHCjxrqCHTx1ReRE4wxnzR2nTFmFjArqOwOx/5twG1NafBPwmsa2lutGoGiKIqPcJLO/Rk7qWwF4F39HYOdYHZoYdx4JIZql4cU9REoiqIA4WkEZwO9HU7dQxePG4/XLZKepBqBoigKhOcsXgccHvmaPW5cxmoCmnlUURTFEk5vuA9YIiJzgVqtwBjzm4i1KlIYN26vTFONQFEUxRJObziToLDPQxaPG5ex6xSnJR4eSo6iKMpPJZzw0ZCzfQ9JjJsaY1NPp6lGoCiKAjQgCETkNWPMhSLyPTZKKABvWohDC4+bGqyPQE1DiqIoloZ6w996t+MOREMOCB43LrEaQbo6ixVFUYAGBIExZqt3u8FXJiK5QIkxpo6GcEigpiFFUZQ61Bs+KiJHi8h8EXlLRIaKyDJgGbBdRMYcuCY2Ix43NR4hRiA5XieUKYqiQMOmoceB27Eppz8CxhpjvhSRPsArwOwD0L7mxbipNkJaYhwiul6xoigKNDyhLM4Y874x5nXsWgRfAhhjVh2YpkUAj4tKTwzpSRo6qiiK4qMhjcDj2K8IOndo+gg8bmqIIVnzDCmKotTSkCAYLCJ7AAGSvft4j5Pqv+wgxuOimhiSNQW1oihKLQ1FDR1+vaXHRQ2ijmJFURQH4SSdO3zwuKkyMSSpaUhRFKWW6Aqm97ipFiEpLrrkn6IoSkNEtEcUkTEislpECkTk1gbqnSciRkTyI9kePC6qPKLOYkVRFAcREwQiEgtMBcYC/YBJItIvRL10bDqLryLVllo8LqrcMeojUBRFcRBJjWA4UGCMWWeMqQamAxNC1LsH+DNQGcG2WDwuqjyQpIJAURSllkgKgo7AJsdxobesFhEZBnQyxrwbwXZYPB7AWI1ATUOKoii1tJjXVERigEeBG8OoO0VEFonIoqKiov17oHEDUOVR05CiKIqTSAqCzUAnx3Get8xHOjAAmC8i64GjgZmhHMbGmGnGmHxjTH7r1q33rzUeFwBuYkiK16ghRVEUH5HsERcCPUWkm4gkABNxLHlpjNltjMk1xnQ1xnQFvgTGG2MWRaQ1XkHgIlY1AkVRFAcREwTGGBdwHTAHWAm8ZoxZLiJ3i8j4SD23XgI0AhUEiqIoPiI6ocwYMwuYFVR2Rz11R0WyLXisj8CtSecURVECiB5jea1GoKYhRVEUJ1EkCKxGoD4CRVGUQKJIEPh9BIkqCBRFUWqJOkHgMqoRKIqiOIkiQaDOYkVRlFBEkSDwm4ZUI1AURfEThYJATUOKoihOokcQGF/UUAxJCdHz2oqiKI0RPT2iz0cgsSTERs9rK4qiNEb09Ihe01BsbDwi0sKNURRFOXiIOkEQFxffwg1RFEU5uIg6QRAbF9H0SoqiKIccUSQIrI9ANQJFUZRAVBAoiqJEOVEkCLw+gngVBIqiKE6iTxCoRqAoihJA1AmCeNUIFEVRAoioIBCRMSKyWkQKROTWEOevFpHvRWSJiHwmIv0i1hifj0AFgaIoSgARi6UUkVhgKnAqUAgsFJGZxpgVjmovG2Oe9NYfDzwKjIlIg7wpJmJiNXxUUQ4WampqKCwspLKysqWbctiQlJREXl5ek6wfkewVhwMFxph1ACIyHZgA1AoCY8weR/1UwESsNY6ZxYqiHBwUFhaSnp5O165ddcZ/M2CMoaSkhMLCQrp16xb2dZE0DXUENjmOC71lAYjItSKyFvgL8JuItcYrCEQ1AkU5aKisrCQnJ0eFQDMhIuTk5DRZw2pxZ7ExZqox5gjg/4A/hKojIlNEZJGILCoqKtq/B9XOLFaNQFEOJlQINC/7831GUhBsBjo5jvO8ZfUxHTg71AljzDRjTL4xJr9169b71xqvs1hNQ4qi+CgpKWHIkCEMGTKEdu3a0bFjx9rj6urqBq9dtGgRv/lN5IwYB5JI2kkWAj1FpBtWAEwELnZWEJGexpg13sMzgTVEilqNQBelURTFkpOTw5IlSwC46667SEtL46abbqo973K5iKsnP1l+fj75+fkHpJ2RJmIagTHGBVwHzAFWAq8ZY5aLyN3eCCGA60RkuYgsAX4HXBax9nh8UUOqESiKUj+TJ0/m6quvZsSIEdxyyy18/fXXHHPMMQwdOpRjjz2W1atXAzB//nzGjRsHWCFyxRVXMGrUKLp3785jjz3Wkq/QZCLqOTXGzAJmBZXd4dj/bSSf78SV249XXScTG594oB6pKEoT+NM7y1mxZU/jFZtAvw4Z3HlW/yZfV1hYyIIFC4iNjWXPnj18+umnxMXF8eGHH3L77bfz5ptv1rlm1apVzJs3j7KyMnr37s0111xzyExgjZoQmuquo/iDq4rb4hJauimKohzkXHDBBcTGWjPy7t27ueyyy1izZg0iQk1NTchrzjzzTBITE0lMTKRNmzZs376dvLy8A9ns/SZqBIHLbacoxOsylYpyULI/I/dIkZqaWrv/xz/+kdGjR/Pf//6X9evXM2rUqJDXJCb6rQ2xsbG4XK5IN7PZiJpesdrtASA+VkPVFEUJn927d9Oxo50C9dxzz7VsYyJE1AgCl8cKgjjVCBRFaQK33HILt912G0OHDj2kRvlNQYyJXFaHSJCfn28WLVrU5Os2luzjhIfm8fAFgzn/yEPDbqcohzsrV66kb9++Ld2Mw45Q36uILDbGhIx3jZrhcY1HTUOKoiihiB5BUOsjiJpXVhRFCYuo6RV9UUNxMaoRKIqiOIkaQVAbNRQXNa+sKIoSFlHTK9bOI4iJmldWFEUJi6jpFV06j0BRFCUkUSMIfKYhnUegKIqP0aNHM2fOnICyv/3tb1xzzTUh648aNQpf+PoZZ5zBrl276tS56667ePjhhxt87owZM1ixwr9q7x133MGHH37Y1OY3G1HTK/pMQwkqCBRF8TJp0iSmT58eUDZ9+nQmTZrU6LWzZs0iKytrv54bLAjuvvtuTjnllP26V3MQNb1iTa1GoKYhRVEs559/Pu+++27tIjTr169ny5YtvPLKK+Tn59O/f3/uvPPOkNd27dqV4uJiAO677z569erFcccdV5umGuCpp57iqKOOYvDgwZx33nns27ePBQsWMHPmTG6++WaGDBnC2rVrmTx5Mm+88QYAc+fOZejQoQwcOJArrriCqqqq2ufdeeedDBs2jIEDB7Jq1apm+x6iJulcjceXdE4FgaIclLx3K2z7vnnv2W4gjH2w3tPZ2dkMHz6c9957jwkTJjB9+nQuvPBCbr/9drKzs3G73Zx88sksXbqUQYMGhbzH4sWLmT59OkuWLMHljb+acwAACYFJREFUcjFs2DCOPPJIAM4991yuuuoqAP7whz/wzDPP8Otf/5rx48czbtw4zj///IB7VVZWMnnyZObOnUuvXr34+c9/zhNPPMH1118PQG5uLt988w3//Oc/efjhh3n66aeb41uKIo3ApRPKFEWpi9M85DMLvfbaawwbNoyhQ4eyfPnyADNOMJ9++innnHMOKSkpZGRkMH78+Npzy5Yt4/jjj2fgwIG89NJLLF++vMG2rF69mm7dutGrVy8ALrvsMj755JPa8+eeey4ARx55JOvXr9/fV65DRDUCERkD/B2IBZ42xjwYdP53wJWACygCrjDGbIhEWzTpnKIc5DQwco8kEyZM4IYbbuCbb75h3759ZGdn8/DDD7Nw4UJatWrF5MmTqays3K97T548mRkzZjB48GCee+455s+f/5Pa6kt13dxpriPWK4pILDAVGAv0AyaJSL+gat8C+caYQcAbwF8i1Z5qt5qGFEWpS1paGqNHj+aKK65g0qRJ7Nmzh9TUVDIzM9m+fTvvvfdeg9efcMIJzJgxg4qKCsrKynjnnXdqz5WVldG+fXtqamp46aWXasvT09MpKyurc6/evXuzfv16CgoKAHjhhRc48cQTm+lN6yeSw+PhQIExZp0xphqYDkxwVjDGzDPG7PMefglELC1o7TwCnVCmKEoQkyZN4rvvvmPSpEkMHjyYoUOH0qdPHy6++GJGjhzZ4LXDhg3joosuYvDgwYwdO5ajjjqq9tw999zDiBEjGDlyJH369KktnzhxIg899BBDhw5l7dq1teVJSUk8++yzXHDBBQwcOJCYmBiuvvrq5n/hICKWhlpEzgfGGGOu9B5fCowwxlxXT/3HgW3GmHsbuu/+pqGe9sla7p+1imV/Op20xKjxkSvKQY2moY4MTU1DfVD0iCJyCZAPhNSBRGQKMAWgc+fO+/WMbrlpnDGwnc4jUBRFCSKSgmAz0MlxnOctC0BETgF+D5xojKkKdSNjzDRgGliNYH8ac2q/tpzar+3+XKooinJYE8nh8UKgp4h0E5EEYCIw01lBRIYC/wLGG2N2RLAtiqIoSj1ETBAYY1zAdcAcYCXwmjFmuYjcLSK+QNuHgDTgdRFZIiIz67mdoiiHKYfacrkHO/vzfUbUR2CMmQXMCiq7w7Hfcsk1FEVpcZKSkigpKSEnJwcRDe3+qRhjKCkpISkpqUnXHRTOYkVRopO8vDwKCwspKipq6aYcNiQlJZGX17RIfBUEiqK0GPHx8XTr1q2lmxH1aCyloihKlKOCQFEUJcpRQaAoihLlRCzFRKQQkSJgfzOU5gLFzdicQwF95+hA3zk6+Cnv3MUY0zrUiUNOEPwURGRRfbk2Dlf0naMDfefoIFLvrKYhRVGUKEcFgaIoSpQTbYJgWks3oAXQd44O9J2jg4i8c1T5CBRFUZS6RJtGoCiKogQRNYJARMaIyGoRKRCRW1u6Pc2FiPxbRHaIyDJHWbaIfCAia7zbVt5yEZHHvN/BUhEZ1nIt339EpJOIzBORFSKyXER+6y0/bN9bRJJE5GsR+c77zn/ylncTka+87/aqN+U7IpLoPS7wnu/aku3fX0QkVkS+FZH/eY8P6/cFEJH1IvK9NyPzIm9ZRH/bUSEIRCQWmAqMBfoBk0SkX8u2qtl4DhgTVHYrMNcY0xOY6z0G+/49vZ8pwBMHqI3NjQu40RjTDzgauNb79zyc37sKOMkYMxgYAowRkaOBPwN/Ncb0AEqBX3jr/wIo9Zb/1VvvUOS32DT2Pg739/Ux2hgzxBEqGtnftjHmsP8AxwBzHMe3Abe1dLua8f26Asscx6uB9t799sBq7/6/gEmh6h3KH+Bt4NRoeW8gBfgGGIGdXBTnLa/9nWPXATnGux/nrSct3fYmvmeet9M7CfgfIIfz+zreez2QG1QW0d92VGgEQEdgk+O40Ft2uNLWGLPVu78N/r+9OwjRog7jOP79EVZLhuZqEWyxSEEQioZElAdPHSS6JFgISXjyEHWpiMCTpw5hVhdDpIMURAnRIdx2I4IiQ1IzjNLwslirwW4EIbI9Hf7PLOOuhtvu+47O/D4wvPP+5+Xl/7zM7jPzn5nnTzVHZ+t+hxwCWA98S8vjzmGSY8AEMAKcASajTAIFl8c1E3NunwIG+9vjBdsDvAz8k+8HaXe8lQAOSzqa87VDj/dtl6FuuYgISa28NUzSUuAj4MWI+LM+sUkb446IaWCdpOXAIeCBhrvUM5KeACYi4qikTU33p882RsS4pDuBEUk/1Tf2Yt/uyhnBOHBP7f1QtrXV75LuBsjXaj7o1vwOkpZQksDBiPg4m1sfN0BETAJfUIZGlkuqDujqcc3EnNuXAX/0uasL8RjwpKSzwAeU4aE3aW+8MyJiPF8nKAn/YXq8b3clEXwH3J93HNwMPA20eX7kT4Dtub6dMoZetT+bdxo8AkzVTjdvGCqH/vuBUxHxRm1Ta+OWtCrPBJA0QLkmcoqSELbkx2bHXP0WW4CxyEHkG0FEvBoRQxExTPl7HYuIbbQ03oqk2yTdXq0DjwMn6fW+3fSFkT5egNkM/EwZV32t6f4sYlzvA+eAS5TxwR2UsdFR4Bfgc2BFflaUu6fOAD8AG5ru//+MeSNlHPUEcCyXzW2OG1gLfJ8xnwR2Zftq4AhwGvgQuCXbb833p3P76qZjWEDsm4BPuxBvxnc8lx+r/1W93rf9ZLGZWcd1ZWjIzMyuwonAzKzjnAjMzDrOicDMrOOcCMzMOs6JwGwWSdNZ+bFaFq1araRh1SrFml0PXGLCbK6/I2Jd050w6xefEZhdo6wT/3rWij8i6b5sH5Y0lvXgRyXdm+13STqUcwgcl/RoftVNkt7NeQUO55PCZo1xIjCba2DW0NDW2rapiFgDvE2pjgnwFvBeRKwFDgJ7s30v8GWUOQQeojwpCqV2/DsR8SAwCTzV43jM/pOfLDabRdJfEbH0Cu1nKZPD/JpF736LiEFJFyg14C9l+7mIWCnpPDAUERdr3zEMjESZYARJrwBLImJ37yMzuzKfEZjNT1xlfT4u1tan8bU6a5gTgdn8bK29fpPrX1MqZAJsA77K9VFgJ8xMKrOsX500mw8fiZjNNZAzgVU+i4jqFtI7JJ2gHNU/k23PAwckvQScB57L9heAfZJ2UI78d1IqxZpdV3yNwOwa5TWCDRFxoem+mC0mDw2ZmXWczwjMzDrOZwRmZh3nRGBm1nFOBGZmHedEYGbWcU4EZmYd50RgZtZx/wK+onUH0Lcz+gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}