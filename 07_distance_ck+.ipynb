{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "distance ck+.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMfSTLuu90C2X+2Xqjgz6wn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koushikroy/facial_sentiment_analysis/blob/main/07_distance_ck%2B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCXyx8lD8yuD"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZyNQK_p6gU3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvwNzEk69PpW"
      },
      "source": [
        "# Dateset Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLGsT1ORYjId"
      },
      "source": [
        "## Downloading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvhMNp1L9U-_",
        "outputId": "a6a9bac6-2617-4b73-e8dc-f8356fd6b38c"
      },
      "source": [
        "!wget -cO - 'https://s3.us-west-2.amazonaws.com/secure.notion-static.com/8d717e17-7c5d-47cd-b556-5bd7d6bb1273/distance_dataset.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210826%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210826T195531Z&X-Amz-Expires=86400&X-Amz-Signature=c4e600b897f0ce6d19a6e80426663001ac9a2ac2e3d961c584a77add547c15cc&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22distance_dataset.csv%22' > ck_dist.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-26 19:57:28--  https://s3.us-west-2.amazonaws.com/secure.notion-static.com/8d717e17-7c5d-47cd-b556-5bd7d6bb1273/distance_dataset.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210826%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210826T195531Z&X-Amz-Expires=86400&X-Amz-Signature=c4e600b897f0ce6d19a6e80426663001ac9a2ac2e3d961c584a77add547c15cc&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22distance_dataset.csv%22\n",
            "Resolving s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)... 52.218.236.56\n",
            "Connecting to s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)|52.218.236.56|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1797668726 (1.7G) [text/csv]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.67G  51.0MB/s    in 44s     \n",
            "\n",
            "2021-08-26 19:58:12 (38.8 MB/s) - written to stdout [1797668726/1797668726]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQnuCiaCYs2W"
      },
      "source": [
        "## Exploring and Cleaning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9COVLEMgBPcf"
      },
      "source": [
        "sentiment_data_original = pd.read_csv('/content/ck_dist.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "YUft2RE7BX-6",
        "outputId": "bab011c0-af64-44e1-efdd-481e43a0b83e"
      },
      "source": [
        "sentiment_data_original.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>108772</th>\n",
              "      <th>108773</th>\n",
              "      <th>108774</th>\n",
              "      <th>108775</th>\n",
              "      <th>108776</th>\n",
              "      <th>108777</th>\n",
              "      <th>108778</th>\n",
              "      <th>108779</th>\n",
              "      <th>108780</th>\n",
              "      <th>108781</th>\n",
              "      <th>108782</th>\n",
              "      <th>108783</th>\n",
              "      <th>108784</th>\n",
              "      <th>108785</th>\n",
              "      <th>108786</th>\n",
              "      <th>108787</th>\n",
              "      <th>108788</th>\n",
              "      <th>108789</th>\n",
              "      <th>108790</th>\n",
              "      <th>108791</th>\n",
              "      <th>108792</th>\n",
              "      <th>108793</th>\n",
              "      <th>108794</th>\n",
              "      <th>108795</th>\n",
              "      <th>108796</th>\n",
              "      <th>108797</th>\n",
              "      <th>108798</th>\n",
              "      <th>108799</th>\n",
              "      <th>108800</th>\n",
              "      <th>108801</th>\n",
              "      <th>108802</th>\n",
              "      <th>108803</th>\n",
              "      <th>108804</th>\n",
              "      <th>108805</th>\n",
              "      <th>108806</th>\n",
              "      <th>108807</th>\n",
              "      <th>108808</th>\n",
              "      <th>108809</th>\n",
              "      <th>108810</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.187956</td>\n",
              "      <td>0.135271</td>\n",
              "      <td>0.419206</td>\n",
              "      <td>0.254075</td>\n",
              "      <td>0.346495</td>\n",
              "      <td>0.571146</td>\n",
              "      <td>0.738945</td>\n",
              "      <td>0.723141</td>\n",
              "      <td>0.806195</td>\n",
              "      <td>1.116449</td>\n",
              "      <td>0.029100</td>\n",
              "      <td>0.048255</td>\n",
              "      <td>0.054430</td>\n",
              "      <td>0.058375</td>\n",
              "      <td>0.081279</td>\n",
              "      <td>0.109907</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>0.191198</td>\n",
              "      <td>0.157580</td>\n",
              "      <td>0.179609</td>\n",
              "      <td>1.046170</td>\n",
              "      <td>0.608358</td>\n",
              "      <td>0.629658</td>\n",
              "      <td>0.659367</td>\n",
              "      <td>0.730874</td>\n",
              "      <td>0.603732</td>\n",
              "      <td>0.768399</td>\n",
              "      <td>0.740817</td>\n",
              "      <td>0.788229</td>\n",
              "      <td>0.793099</td>\n",
              "      <td>0.727295</td>\n",
              "      <td>0.351643</td>\n",
              "      <td>0.763274</td>\n",
              "      <td>0.868677</td>\n",
              "      <td>0.803198</td>\n",
              "      <td>0.403602</td>\n",
              "      <td>0.071373</td>\n",
              "      <td>0.072551</td>\n",
              "      <td>0.140190</td>\n",
              "      <td>0.182667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.383090</td>\n",
              "      <td>0.367822</td>\n",
              "      <td>0.555479</td>\n",
              "      <td>0.038096</td>\n",
              "      <td>0.096757</td>\n",
              "      <td>0.013857</td>\n",
              "      <td>0.023125</td>\n",
              "      <td>0.439093</td>\n",
              "      <td>0.414083</td>\n",
              "      <td>0.397515</td>\n",
              "      <td>0.596772</td>\n",
              "      <td>0.068370</td>\n",
              "      <td>0.051937</td>\n",
              "      <td>0.060741</td>\n",
              "      <td>0.412759</td>\n",
              "      <td>0.390038</td>\n",
              "      <td>0.374819</td>\n",
              "      <td>0.560521</td>\n",
              "      <td>0.108174</td>\n",
              "      <td>0.113428</td>\n",
              "      <td>0.429644</td>\n",
              "      <td>0.412602</td>\n",
              "      <td>0.400537</td>\n",
              "      <td>0.541059</td>\n",
              "      <td>0.009956</td>\n",
              "      <td>0.449599</td>\n",
              "      <td>0.423889</td>\n",
              "      <td>0.406911</td>\n",
              "      <td>0.610217</td>\n",
              "      <td>0.459337</td>\n",
              "      <td>0.433453</td>\n",
              "      <td>0.416359</td>\n",
              "      <td>0.619876</td>\n",
              "      <td>0.040861</td>\n",
              "      <td>0.064414</td>\n",
              "      <td>0.287163</td>\n",
              "      <td>0.023774</td>\n",
              "      <td>0.325599</td>\n",
              "      <td>0.346695</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.207567</td>\n",
              "      <td>0.149162</td>\n",
              "      <td>0.413281</td>\n",
              "      <td>0.268064</td>\n",
              "      <td>0.350784</td>\n",
              "      <td>0.550446</td>\n",
              "      <td>0.729772</td>\n",
              "      <td>0.661067</td>\n",
              "      <td>0.733735</td>\n",
              "      <td>1.052325</td>\n",
              "      <td>0.029055</td>\n",
              "      <td>0.048058</td>\n",
              "      <td>0.054046</td>\n",
              "      <td>0.052564</td>\n",
              "      <td>0.073975</td>\n",
              "      <td>0.102124</td>\n",
              "      <td>0.133495</td>\n",
              "      <td>0.196838</td>\n",
              "      <td>0.178358</td>\n",
              "      <td>0.193430</td>\n",
              "      <td>1.071643</td>\n",
              "      <td>0.590631</td>\n",
              "      <td>0.617111</td>\n",
              "      <td>0.652965</td>\n",
              "      <td>0.726510</td>\n",
              "      <td>0.583013</td>\n",
              "      <td>0.725266</td>\n",
              "      <td>0.698325</td>\n",
              "      <td>0.749550</td>\n",
              "      <td>0.762678</td>\n",
              "      <td>0.737213</td>\n",
              "      <td>0.403877</td>\n",
              "      <td>0.753039</td>\n",
              "      <td>0.920617</td>\n",
              "      <td>0.821129</td>\n",
              "      <td>0.411357</td>\n",
              "      <td>0.072746</td>\n",
              "      <td>0.077174</td>\n",
              "      <td>0.147522</td>\n",
              "      <td>0.198965</td>\n",
              "      <td>...</td>\n",
              "      <td>0.334787</td>\n",
              "      <td>0.322138</td>\n",
              "      <td>0.507045</td>\n",
              "      <td>0.038844</td>\n",
              "      <td>0.088166</td>\n",
              "      <td>0.011825</td>\n",
              "      <td>0.025459</td>\n",
              "      <td>0.388988</td>\n",
              "      <td>0.365276</td>\n",
              "      <td>0.351106</td>\n",
              "      <td>0.552140</td>\n",
              "      <td>0.063657</td>\n",
              "      <td>0.050616</td>\n",
              "      <td>0.063830</td>\n",
              "      <td>0.363319</td>\n",
              "      <td>0.342413</td>\n",
              "      <td>0.329606</td>\n",
              "      <td>0.514974</td>\n",
              "      <td>0.096696</td>\n",
              "      <td>0.105036</td>\n",
              "      <td>0.393837</td>\n",
              "      <td>0.378244</td>\n",
              "      <td>0.367825</td>\n",
              "      <td>0.508859</td>\n",
              "      <td>0.013846</td>\n",
              "      <td>0.398088</td>\n",
              "      <td>0.373699</td>\n",
              "      <td>0.359201</td>\n",
              "      <td>0.563786</td>\n",
              "      <td>0.410744</td>\n",
              "      <td>0.385853</td>\n",
              "      <td>0.371103</td>\n",
              "      <td>0.577582</td>\n",
              "      <td>0.040470</td>\n",
              "      <td>0.060192</td>\n",
              "      <td>0.291065</td>\n",
              "      <td>0.020054</td>\n",
              "      <td>0.329249</td>\n",
              "      <td>0.346610</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.209710</td>\n",
              "      <td>0.151796</td>\n",
              "      <td>0.425649</td>\n",
              "      <td>0.272657</td>\n",
              "      <td>0.358480</td>\n",
              "      <td>0.568503</td>\n",
              "      <td>0.729258</td>\n",
              "      <td>0.702382</td>\n",
              "      <td>0.781597</td>\n",
              "      <td>1.093249</td>\n",
              "      <td>0.029604</td>\n",
              "      <td>0.048569</td>\n",
              "      <td>0.053562</td>\n",
              "      <td>0.059927</td>\n",
              "      <td>0.081331</td>\n",
              "      <td>0.108687</td>\n",
              "      <td>0.138396</td>\n",
              "      <td>0.192105</td>\n",
              "      <td>0.180009</td>\n",
              "      <td>0.198394</td>\n",
              "      <td>1.054637</td>\n",
              "      <td>0.598924</td>\n",
              "      <td>0.621862</td>\n",
              "      <td>0.654303</td>\n",
              "      <td>0.723751</td>\n",
              "      <td>0.593897</td>\n",
              "      <td>0.747247</td>\n",
              "      <td>0.722203</td>\n",
              "      <td>0.766800</td>\n",
              "      <td>0.773796</td>\n",
              "      <td>0.727711</td>\n",
              "      <td>0.367211</td>\n",
              "      <td>0.751856</td>\n",
              "      <td>0.886812</td>\n",
              "      <td>0.806554</td>\n",
              "      <td>0.410377</td>\n",
              "      <td>0.075550</td>\n",
              "      <td>0.076730</td>\n",
              "      <td>0.150007</td>\n",
              "      <td>0.198634</td>\n",
              "      <td>...</td>\n",
              "      <td>0.351177</td>\n",
              "      <td>0.338624</td>\n",
              "      <td>0.516268</td>\n",
              "      <td>0.039003</td>\n",
              "      <td>0.102248</td>\n",
              "      <td>0.013609</td>\n",
              "      <td>0.024207</td>\n",
              "      <td>0.404742</td>\n",
              "      <td>0.382472</td>\n",
              "      <td>0.368544</td>\n",
              "      <td>0.559361</td>\n",
              "      <td>0.075464</td>\n",
              "      <td>0.052612</td>\n",
              "      <td>0.062633</td>\n",
              "      <td>0.378595</td>\n",
              "      <td>0.358844</td>\n",
              "      <td>0.346298</td>\n",
              "      <td>0.522152</td>\n",
              "      <td>0.113270</td>\n",
              "      <td>0.118113</td>\n",
              "      <td>0.406730</td>\n",
              "      <td>0.393133</td>\n",
              "      <td>0.383738</td>\n",
              "      <td>0.507482</td>\n",
              "      <td>0.011729</td>\n",
              "      <td>0.414348</td>\n",
              "      <td>0.391303</td>\n",
              "      <td>0.376955</td>\n",
              "      <td>0.572403</td>\n",
              "      <td>0.425904</td>\n",
              "      <td>0.402678</td>\n",
              "      <td>0.388212</td>\n",
              "      <td>0.583566</td>\n",
              "      <td>0.038252</td>\n",
              "      <td>0.058773</td>\n",
              "      <td>0.283944</td>\n",
              "      <td>0.020728</td>\n",
              "      <td>0.320051</td>\n",
              "      <td>0.338464</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.220117</td>\n",
              "      <td>0.154567</td>\n",
              "      <td>0.419507</td>\n",
              "      <td>0.281169</td>\n",
              "      <td>0.360029</td>\n",
              "      <td>0.550323</td>\n",
              "      <td>0.703096</td>\n",
              "      <td>0.681569</td>\n",
              "      <td>0.758550</td>\n",
              "      <td>1.051571</td>\n",
              "      <td>0.031128</td>\n",
              "      <td>0.053641</td>\n",
              "      <td>0.062343</td>\n",
              "      <td>0.080691</td>\n",
              "      <td>0.106775</td>\n",
              "      <td>0.139166</td>\n",
              "      <td>0.173484</td>\n",
              "      <td>0.226350</td>\n",
              "      <td>0.188956</td>\n",
              "      <td>0.200879</td>\n",
              "      <td>1.006257</td>\n",
              "      <td>0.570464</td>\n",
              "      <td>0.593828</td>\n",
              "      <td>0.626521</td>\n",
              "      <td>0.696045</td>\n",
              "      <td>0.565623</td>\n",
              "      <td>0.727810</td>\n",
              "      <td>0.700437</td>\n",
              "      <td>0.747852</td>\n",
              "      <td>0.753084</td>\n",
              "      <td>0.696103</td>\n",
              "      <td>0.378425</td>\n",
              "      <td>0.726623</td>\n",
              "      <td>0.840830</td>\n",
              "      <td>0.771020</td>\n",
              "      <td>0.388281</td>\n",
              "      <td>0.070420</td>\n",
              "      <td>0.077821</td>\n",
              "      <td>0.140447</td>\n",
              "      <td>0.189135</td>\n",
              "      <td>...</td>\n",
              "      <td>0.316014</td>\n",
              "      <td>0.306317</td>\n",
              "      <td>0.480409</td>\n",
              "      <td>0.036040</td>\n",
              "      <td>0.091339</td>\n",
              "      <td>0.011044</td>\n",
              "      <td>0.024080</td>\n",
              "      <td>0.367595</td>\n",
              "      <td>0.348075</td>\n",
              "      <td>0.337083</td>\n",
              "      <td>0.523092</td>\n",
              "      <td>0.072915</td>\n",
              "      <td>0.047083</td>\n",
              "      <td>0.059317</td>\n",
              "      <td>0.342587</td>\n",
              "      <td>0.325369</td>\n",
              "      <td>0.315623</td>\n",
              "      <td>0.488236</td>\n",
              "      <td>0.098981</td>\n",
              "      <td>0.102791</td>\n",
              "      <td>0.383284</td>\n",
              "      <td>0.371268</td>\n",
              "      <td>0.364060</td>\n",
              "      <td>0.488672</td>\n",
              "      <td>0.014147</td>\n",
              "      <td>0.375583</td>\n",
              "      <td>0.355437</td>\n",
              "      <td>0.344108</td>\n",
              "      <td>0.533792</td>\n",
              "      <td>0.389574</td>\n",
              "      <td>0.369229</td>\n",
              "      <td>0.357770</td>\n",
              "      <td>0.547088</td>\n",
              "      <td>0.034734</td>\n",
              "      <td>0.052466</td>\n",
              "      <td>0.273859</td>\n",
              "      <td>0.017829</td>\n",
              "      <td>0.307068</td>\n",
              "      <td>0.323504</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.169271</td>\n",
              "      <td>0.126485</td>\n",
              "      <td>0.385130</td>\n",
              "      <td>0.230463</td>\n",
              "      <td>0.317255</td>\n",
              "      <td>0.533089</td>\n",
              "      <td>0.748044</td>\n",
              "      <td>0.664228</td>\n",
              "      <td>0.743196</td>\n",
              "      <td>1.106701</td>\n",
              "      <td>0.028413</td>\n",
              "      <td>0.046252</td>\n",
              "      <td>0.049930</td>\n",
              "      <td>0.063039</td>\n",
              "      <td>0.087407</td>\n",
              "      <td>0.118559</td>\n",
              "      <td>0.152797</td>\n",
              "      <td>0.220146</td>\n",
              "      <td>0.142418</td>\n",
              "      <td>0.164354</td>\n",
              "      <td>1.124805</td>\n",
              "      <td>0.593084</td>\n",
              "      <td>0.623172</td>\n",
              "      <td>0.663476</td>\n",
              "      <td>0.749090</td>\n",
              "      <td>0.581652</td>\n",
              "      <td>0.748947</td>\n",
              "      <td>0.715505</td>\n",
              "      <td>0.777167</td>\n",
              "      <td>0.791096</td>\n",
              "      <td>0.760509</td>\n",
              "      <td>0.409146</td>\n",
              "      <td>0.775943</td>\n",
              "      <td>0.954549</td>\n",
              "      <td>0.847544</td>\n",
              "      <td>0.423438</td>\n",
              "      <td>0.084630</td>\n",
              "      <td>0.086811</td>\n",
              "      <td>0.170919</td>\n",
              "      <td>0.227653</td>\n",
              "      <td>...</td>\n",
              "      <td>0.366696</td>\n",
              "      <td>0.351569</td>\n",
              "      <td>0.553719</td>\n",
              "      <td>0.040489</td>\n",
              "      <td>0.096791</td>\n",
              "      <td>0.013174</td>\n",
              "      <td>0.024401</td>\n",
              "      <td>0.418736</td>\n",
              "      <td>0.394968</td>\n",
              "      <td>0.378423</td>\n",
              "      <td>0.597067</td>\n",
              "      <td>0.062927</td>\n",
              "      <td>0.053452</td>\n",
              "      <td>0.064736</td>\n",
              "      <td>0.393140</td>\n",
              "      <td>0.371993</td>\n",
              "      <td>0.356768</td>\n",
              "      <td>0.559273</td>\n",
              "      <td>0.107512</td>\n",
              "      <td>0.117794</td>\n",
              "      <td>0.403877</td>\n",
              "      <td>0.388160</td>\n",
              "      <td>0.375618</td>\n",
              "      <td>0.534734</td>\n",
              "      <td>0.011285</td>\n",
              "      <td>0.429354</td>\n",
              "      <td>0.404976</td>\n",
              "      <td>0.388124</td>\n",
              "      <td>0.610098</td>\n",
              "      <td>0.437590</td>\n",
              "      <td>0.412636</td>\n",
              "      <td>0.395503</td>\n",
              "      <td>0.620943</td>\n",
              "      <td>0.039031</td>\n",
              "      <td>0.060149</td>\n",
              "      <td>0.302577</td>\n",
              "      <td>0.021634</td>\n",
              "      <td>0.339729</td>\n",
              "      <td>0.358177</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.201214</td>\n",
              "      <td>0.151782</td>\n",
              "      <td>0.421794</td>\n",
              "      <td>0.263214</td>\n",
              "      <td>0.350937</td>\n",
              "      <td>0.567104</td>\n",
              "      <td>0.778336</td>\n",
              "      <td>0.695609</td>\n",
              "      <td>0.772108</td>\n",
              "      <td>1.107092</td>\n",
              "      <td>0.028564</td>\n",
              "      <td>0.044086</td>\n",
              "      <td>0.045230</td>\n",
              "      <td>0.049422</td>\n",
              "      <td>0.071696</td>\n",
              "      <td>0.099870</td>\n",
              "      <td>0.131883</td>\n",
              "      <td>0.193947</td>\n",
              "      <td>0.173874</td>\n",
              "      <td>0.198542</td>\n",
              "      <td>1.119847</td>\n",
              "      <td>0.628621</td>\n",
              "      <td>0.656638</td>\n",
              "      <td>0.693945</td>\n",
              "      <td>0.774810</td>\n",
              "      <td>0.618773</td>\n",
              "      <td>0.780738</td>\n",
              "      <td>0.748902</td>\n",
              "      <td>0.806958</td>\n",
              "      <td>0.819018</td>\n",
              "      <td>0.781056</td>\n",
              "      <td>0.385107</td>\n",
              "      <td>0.805113</td>\n",
              "      <td>0.956332</td>\n",
              "      <td>0.862971</td>\n",
              "      <td>0.445626</td>\n",
              "      <td>0.084873</td>\n",
              "      <td>0.083246</td>\n",
              "      <td>0.169230</td>\n",
              "      <td>0.224749</td>\n",
              "      <td>...</td>\n",
              "      <td>0.363406</td>\n",
              "      <td>0.348437</td>\n",
              "      <td>0.548580</td>\n",
              "      <td>0.040810</td>\n",
              "      <td>0.104221</td>\n",
              "      <td>0.014204</td>\n",
              "      <td>0.024438</td>\n",
              "      <td>0.417262</td>\n",
              "      <td>0.392878</td>\n",
              "      <td>0.376410</td>\n",
              "      <td>0.592104</td>\n",
              "      <td>0.071560</td>\n",
              "      <td>0.054951</td>\n",
              "      <td>0.064953</td>\n",
              "      <td>0.390691</td>\n",
              "      <td>0.369076</td>\n",
              "      <td>0.354074</td>\n",
              "      <td>0.553403</td>\n",
              "      <td>0.116046</td>\n",
              "      <td>0.123771</td>\n",
              "      <td>0.406107</td>\n",
              "      <td>0.390981</td>\n",
              "      <td>0.379279</td>\n",
              "      <td>0.527054</td>\n",
              "      <td>0.010362</td>\n",
              "      <td>0.428094</td>\n",
              "      <td>0.402946</td>\n",
              "      <td>0.386077</td>\n",
              "      <td>0.606026</td>\n",
              "      <td>0.437283</td>\n",
              "      <td>0.411742</td>\n",
              "      <td>0.394661</td>\n",
              "      <td>0.616388</td>\n",
              "      <td>0.040926</td>\n",
              "      <td>0.063137</td>\n",
              "      <td>0.306602</td>\n",
              "      <td>0.022623</td>\n",
              "      <td>0.345332</td>\n",
              "      <td>0.364837</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.201445</td>\n",
              "      <td>0.142092</td>\n",
              "      <td>0.402971</td>\n",
              "      <td>0.262329</td>\n",
              "      <td>0.342025</td>\n",
              "      <td>0.531263</td>\n",
              "      <td>0.713764</td>\n",
              "      <td>0.648947</td>\n",
              "      <td>0.722268</td>\n",
              "      <td>1.035393</td>\n",
              "      <td>0.030960</td>\n",
              "      <td>0.056085</td>\n",
              "      <td>0.068495</td>\n",
              "      <td>0.114359</td>\n",
              "      <td>0.143733</td>\n",
              "      <td>0.179653</td>\n",
              "      <td>0.215819</td>\n",
              "      <td>0.265837</td>\n",
              "      <td>0.171497</td>\n",
              "      <td>0.187828</td>\n",
              "      <td>1.014264</td>\n",
              "      <td>0.573812</td>\n",
              "      <td>0.601036</td>\n",
              "      <td>0.636922</td>\n",
              "      <td>0.710729</td>\n",
              "      <td>0.564168</td>\n",
              "      <td>0.718312</td>\n",
              "      <td>0.687400</td>\n",
              "      <td>0.744814</td>\n",
              "      <td>0.756857</td>\n",
              "      <td>0.718459</td>\n",
              "      <td>0.413091</td>\n",
              "      <td>0.736380</td>\n",
              "      <td>0.869702</td>\n",
              "      <td>0.794389</td>\n",
              "      <td>0.405554</td>\n",
              "      <td>0.077319</td>\n",
              "      <td>0.082075</td>\n",
              "      <td>0.152301</td>\n",
              "      <td>0.199589</td>\n",
              "      <td>...</td>\n",
              "      <td>0.325847</td>\n",
              "      <td>0.311424</td>\n",
              "      <td>0.533286</td>\n",
              "      <td>0.041044</td>\n",
              "      <td>0.108038</td>\n",
              "      <td>0.013479</td>\n",
              "      <td>0.024760</td>\n",
              "      <td>0.387766</td>\n",
              "      <td>0.360072</td>\n",
              "      <td>0.343858</td>\n",
              "      <td>0.578735</td>\n",
              "      <td>0.080488</td>\n",
              "      <td>0.054518</td>\n",
              "      <td>0.065088</td>\n",
              "      <td>0.358947</td>\n",
              "      <td>0.334179</td>\n",
              "      <td>0.319822</td>\n",
              "      <td>0.538894</td>\n",
              "      <td>0.119029</td>\n",
              "      <td>0.123410</td>\n",
              "      <td>0.388418</td>\n",
              "      <td>0.371290</td>\n",
              "      <td>0.361279</td>\n",
              "      <td>0.520165</td>\n",
              "      <td>0.012824</td>\n",
              "      <td>0.397418</td>\n",
              "      <td>0.368870</td>\n",
              "      <td>0.352118</td>\n",
              "      <td>0.591755</td>\n",
              "      <td>0.410210</td>\n",
              "      <td>0.381542</td>\n",
              "      <td>0.364677</td>\n",
              "      <td>0.603436</td>\n",
              "      <td>0.043291</td>\n",
              "      <td>0.067886</td>\n",
              "      <td>0.309477</td>\n",
              "      <td>0.024666</td>\n",
              "      <td>0.350341</td>\n",
              "      <td>0.373090</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.229665</td>\n",
              "      <td>0.162953</td>\n",
              "      <td>0.423904</td>\n",
              "      <td>0.289620</td>\n",
              "      <td>0.366386</td>\n",
              "      <td>0.554114</td>\n",
              "      <td>0.695700</td>\n",
              "      <td>0.669631</td>\n",
              "      <td>0.743736</td>\n",
              "      <td>1.070072</td>\n",
              "      <td>0.032345</td>\n",
              "      <td>0.055883</td>\n",
              "      <td>0.066026</td>\n",
              "      <td>0.083836</td>\n",
              "      <td>0.109215</td>\n",
              "      <td>0.141375</td>\n",
              "      <td>0.175506</td>\n",
              "      <td>0.229806</td>\n",
              "      <td>0.199053</td>\n",
              "      <td>0.209095</td>\n",
              "      <td>0.984146</td>\n",
              "      <td>0.566460</td>\n",
              "      <td>0.589285</td>\n",
              "      <td>0.621117</td>\n",
              "      <td>0.688129</td>\n",
              "      <td>0.562217</td>\n",
              "      <td>0.715803</td>\n",
              "      <td>0.689945</td>\n",
              "      <td>0.735879</td>\n",
              "      <td>0.742015</td>\n",
              "      <td>0.689711</td>\n",
              "      <td>0.380862</td>\n",
              "      <td>0.716315</td>\n",
              "      <td>0.819460</td>\n",
              "      <td>0.759189</td>\n",
              "      <td>0.389090</td>\n",
              "      <td>0.072795</td>\n",
              "      <td>0.079407</td>\n",
              "      <td>0.142314</td>\n",
              "      <td>0.188936</td>\n",
              "      <td>...</td>\n",
              "      <td>0.318474</td>\n",
              "      <td>0.304276</td>\n",
              "      <td>0.534882</td>\n",
              "      <td>0.039581</td>\n",
              "      <td>0.114430</td>\n",
              "      <td>0.014209</td>\n",
              "      <td>0.024212</td>\n",
              "      <td>0.382200</td>\n",
              "      <td>0.355067</td>\n",
              "      <td>0.339385</td>\n",
              "      <td>0.578492</td>\n",
              "      <td>0.090986</td>\n",
              "      <td>0.053709</td>\n",
              "      <td>0.062717</td>\n",
              "      <td>0.352041</td>\n",
              "      <td>0.327375</td>\n",
              "      <td>0.313412</td>\n",
              "      <td>0.539565</td>\n",
              "      <td>0.125921</td>\n",
              "      <td>0.125901</td>\n",
              "      <td>0.386563</td>\n",
              "      <td>0.370149</td>\n",
              "      <td>0.361212</td>\n",
              "      <td>0.521859</td>\n",
              "      <td>0.013623</td>\n",
              "      <td>0.392283</td>\n",
              "      <td>0.364286</td>\n",
              "      <td>0.348014</td>\n",
              "      <td>0.592079</td>\n",
              "      <td>0.405454</td>\n",
              "      <td>0.377692</td>\n",
              "      <td>0.361526</td>\n",
              "      <td>0.602225</td>\n",
              "      <td>0.041439</td>\n",
              "      <td>0.066086</td>\n",
              "      <td>0.302470</td>\n",
              "      <td>0.024663</td>\n",
              "      <td>0.342028</td>\n",
              "      <td>0.365451</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.202947</td>\n",
              "      <td>0.136122</td>\n",
              "      <td>0.403073</td>\n",
              "      <td>0.265638</td>\n",
              "      <td>0.345050</td>\n",
              "      <td>0.527880</td>\n",
              "      <td>0.659657</td>\n",
              "      <td>0.636934</td>\n",
              "      <td>0.708961</td>\n",
              "      <td>0.999804</td>\n",
              "      <td>0.028783</td>\n",
              "      <td>0.050522</td>\n",
              "      <td>0.059664</td>\n",
              "      <td>0.065190</td>\n",
              "      <td>0.084318</td>\n",
              "      <td>0.111167</td>\n",
              "      <td>0.143145</td>\n",
              "      <td>0.212148</td>\n",
              "      <td>0.169972</td>\n",
              "      <td>0.182799</td>\n",
              "      <td>0.921014</td>\n",
              "      <td>0.539363</td>\n",
              "      <td>0.560920</td>\n",
              "      <td>0.590740</td>\n",
              "      <td>0.652537</td>\n",
              "      <td>0.534494</td>\n",
              "      <td>0.674838</td>\n",
              "      <td>0.650788</td>\n",
              "      <td>0.694318</td>\n",
              "      <td>0.700837</td>\n",
              "      <td>0.655022</td>\n",
              "      <td>0.388863</td>\n",
              "      <td>0.678553</td>\n",
              "      <td>0.777336</td>\n",
              "      <td>0.721673</td>\n",
              "      <td>0.372380</td>\n",
              "      <td>0.072174</td>\n",
              "      <td>0.075148</td>\n",
              "      <td>0.142220</td>\n",
              "      <td>0.188177</td>\n",
              "      <td>...</td>\n",
              "      <td>0.311425</td>\n",
              "      <td>0.300645</td>\n",
              "      <td>0.494920</td>\n",
              "      <td>0.038747</td>\n",
              "      <td>0.107794</td>\n",
              "      <td>0.013411</td>\n",
              "      <td>0.024303</td>\n",
              "      <td>0.370802</td>\n",
              "      <td>0.346829</td>\n",
              "      <td>0.334400</td>\n",
              "      <td>0.538421</td>\n",
              "      <td>0.082576</td>\n",
              "      <td>0.052078</td>\n",
              "      <td>0.062079</td>\n",
              "      <td>0.342569</td>\n",
              "      <td>0.321431</td>\n",
              "      <td>0.310854</td>\n",
              "      <td>0.500563</td>\n",
              "      <td>0.119173</td>\n",
              "      <td>0.121215</td>\n",
              "      <td>0.371764</td>\n",
              "      <td>0.358866</td>\n",
              "      <td>0.352982</td>\n",
              "      <td>0.481096</td>\n",
              "      <td>0.013947</td>\n",
              "      <td>0.379843</td>\n",
              "      <td>0.354911</td>\n",
              "      <td>0.341864</td>\n",
              "      <td>0.551111</td>\n",
              "      <td>0.393665</td>\n",
              "      <td>0.368844</td>\n",
              "      <td>0.355811</td>\n",
              "      <td>0.562447</td>\n",
              "      <td>0.041660</td>\n",
              "      <td>0.064933</td>\n",
              "      <td>0.281306</td>\n",
              "      <td>0.023279</td>\n",
              "      <td>0.321330</td>\n",
              "      <td>0.343704</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.190090</td>\n",
              "      <td>0.134454</td>\n",
              "      <td>0.397736</td>\n",
              "      <td>0.252823</td>\n",
              "      <td>0.335747</td>\n",
              "      <td>0.533425</td>\n",
              "      <td>0.699587</td>\n",
              "      <td>0.659145</td>\n",
              "      <td>0.737174</td>\n",
              "      <td>1.055481</td>\n",
              "      <td>0.028178</td>\n",
              "      <td>0.045347</td>\n",
              "      <td>0.048341</td>\n",
              "      <td>0.066484</td>\n",
              "      <td>0.086756</td>\n",
              "      <td>0.113838</td>\n",
              "      <td>0.146531</td>\n",
              "      <td>0.214499</td>\n",
              "      <td>0.159292</td>\n",
              "      <td>0.177222</td>\n",
              "      <td>1.017778</td>\n",
              "      <td>0.566561</td>\n",
              "      <td>0.592075</td>\n",
              "      <td>0.626114</td>\n",
              "      <td>0.698645</td>\n",
              "      <td>0.558526</td>\n",
              "      <td>0.713824</td>\n",
              "      <td>0.686168</td>\n",
              "      <td>0.736074</td>\n",
              "      <td>0.744427</td>\n",
              "      <td>0.706240</td>\n",
              "      <td>0.397103</td>\n",
              "      <td>0.721832</td>\n",
              "      <td>0.860965</td>\n",
              "      <td>0.780058</td>\n",
              "      <td>0.408079</td>\n",
              "      <td>0.085810</td>\n",
              "      <td>0.088344</td>\n",
              "      <td>0.173263</td>\n",
              "      <td>0.231297</td>\n",
              "      <td>...</td>\n",
              "      <td>0.329700</td>\n",
              "      <td>0.319722</td>\n",
              "      <td>0.477639</td>\n",
              "      <td>0.038850</td>\n",
              "      <td>0.100831</td>\n",
              "      <td>0.012174</td>\n",
              "      <td>0.023939</td>\n",
              "      <td>0.379498</td>\n",
              "      <td>0.360818</td>\n",
              "      <td>0.349367</td>\n",
              "      <td>0.521613</td>\n",
              "      <td>0.071357</td>\n",
              "      <td>0.051015</td>\n",
              "      <td>0.062335</td>\n",
              "      <td>0.354211</td>\n",
              "      <td>0.338137</td>\n",
              "      <td>0.328119</td>\n",
              "      <td>0.484586</td>\n",
              "      <td>0.110986</td>\n",
              "      <td>0.118454</td>\n",
              "      <td>0.375262</td>\n",
              "      <td>0.365304</td>\n",
              "      <td>0.358435</td>\n",
              "      <td>0.462950</td>\n",
              "      <td>0.012266</td>\n",
              "      <td>0.388259</td>\n",
              "      <td>0.368885</td>\n",
              "      <td>0.357053</td>\n",
              "      <td>0.533411</td>\n",
              "      <td>0.399802</td>\n",
              "      <td>0.380080</td>\n",
              "      <td>0.368042</td>\n",
              "      <td>0.545525</td>\n",
              "      <td>0.035131</td>\n",
              "      <td>0.053746</td>\n",
              "      <td>0.271671</td>\n",
              "      <td>0.018766</td>\n",
              "      <td>0.305077</td>\n",
              "      <td>0.322051</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 108812 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3  ...    108808    108809    108810  output\n",
              "0  0.187956  0.135271  0.419206  0.254075  ...  0.023774  0.325599  0.346695   Anger\n",
              "1  0.207567  0.149162  0.413281  0.268064  ...  0.020054  0.329249  0.346610   Anger\n",
              "2  0.209710  0.151796  0.425649  0.272657  ...  0.020728  0.320051  0.338464   Anger\n",
              "3  0.220117  0.154567  0.419507  0.281169  ...  0.017829  0.307068  0.323504   Anger\n",
              "4  0.169271  0.126485  0.385130  0.230463  ...  0.021634  0.339729  0.358177   Anger\n",
              "5  0.201214  0.151782  0.421794  0.263214  ...  0.022623  0.345332  0.364837   Anger\n",
              "6  0.201445  0.142092  0.402971  0.262329  ...  0.024666  0.350341  0.373090   Anger\n",
              "7  0.229665  0.162953  0.423904  0.289620  ...  0.024663  0.342028  0.365451   Anger\n",
              "8  0.202947  0.136122  0.403073  0.265638  ...  0.023279  0.321330  0.343704   Anger\n",
              "9  0.190090  0.134454  0.397736  0.252823  ...  0.018766  0.305077  0.322051   Anger\n",
              "\n",
              "[10 rows x 108812 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7f55_uZCFEG"
      },
      "source": [
        "\n",
        "**From the dataset, we can see that:**\n",
        "*   There are in total 937 Columns excluding the index column \n",
        "*   The first 936 columns represents the landmark points in the face and the 'output' column represnts the emotion\n",
        "*   The face has been cropped and resized thus no need for further normalization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQZ4VOKCBdTM",
        "outputId": "9b40da11-2074-4249-9b8f-52ca5e494a8c"
      },
      "source": [
        "sentiment_data_original.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 863 entries, 0 to 862\n",
            "Columns: 108812 entries, 0 to output\n",
            "dtypes: float64(108811), object(1)\n",
            "memory usage: 716.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcv0dQIABi8O",
        "outputId": "f2064816-e740-4d69-c80c-f43a56a22202"
      },
      "source": [
        "#value_count in the output column \n",
        "sentiment_data_original['output'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Neutral     555\n",
              "Surprise     82\n",
              "Happy        69\n",
              "Disgust      59\n",
              "Anger        45\n",
              "Sad          28\n",
              "Fear         25\n",
              "Name: output, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh4iA1inDAXi"
      },
      "source": [
        "\n",
        "\n",
        "> So you can see that the neutral category has a staggering number of input compared to othet categories. This can be a later as the model might be overflitted. So, we need to take care of this.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqHvZrsMC_4a"
      },
      "source": [
        "all_neutral = sentiment_data_original['output'] == 'Neutral' \n",
        "list_of_neutral_index = []   \n",
        "for i in range (len(all_neutral)):\n",
        "    if all_neutral[i]:\n",
        "        list_of_neutral_index.append(i)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCcvMUQuhDpP"
      },
      "source": [
        "# Here we need to generate a list of random number\n",
        "import random\n",
        "random.shuffle(list_of_neutral_index)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1DK8UOGpc8F"
      },
      "source": [
        "# Dropping the random values\n",
        "sentiment_data_small_version = sentiment_data_original.drop(list_of_neutral_index[1:500])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "csLqjscvWdWt",
        "outputId": "12e29088-3b95-408f-8db6-7cc4e3fd14d8"
      },
      "source": [
        "sentiment_data_small_version.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>108772</th>\n",
              "      <th>108773</th>\n",
              "      <th>108774</th>\n",
              "      <th>108775</th>\n",
              "      <th>108776</th>\n",
              "      <th>108777</th>\n",
              "      <th>108778</th>\n",
              "      <th>108779</th>\n",
              "      <th>108780</th>\n",
              "      <th>108781</th>\n",
              "      <th>108782</th>\n",
              "      <th>108783</th>\n",
              "      <th>108784</th>\n",
              "      <th>108785</th>\n",
              "      <th>108786</th>\n",
              "      <th>108787</th>\n",
              "      <th>108788</th>\n",
              "      <th>108789</th>\n",
              "      <th>108790</th>\n",
              "      <th>108791</th>\n",
              "      <th>108792</th>\n",
              "      <th>108793</th>\n",
              "      <th>108794</th>\n",
              "      <th>108795</th>\n",
              "      <th>108796</th>\n",
              "      <th>108797</th>\n",
              "      <th>108798</th>\n",
              "      <th>108799</th>\n",
              "      <th>108800</th>\n",
              "      <th>108801</th>\n",
              "      <th>108802</th>\n",
              "      <th>108803</th>\n",
              "      <th>108804</th>\n",
              "      <th>108805</th>\n",
              "      <th>108806</th>\n",
              "      <th>108807</th>\n",
              "      <th>108808</th>\n",
              "      <th>108809</th>\n",
              "      <th>108810</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.187956</td>\n",
              "      <td>0.135271</td>\n",
              "      <td>0.419206</td>\n",
              "      <td>0.254075</td>\n",
              "      <td>0.346495</td>\n",
              "      <td>0.571146</td>\n",
              "      <td>0.738945</td>\n",
              "      <td>0.723141</td>\n",
              "      <td>0.806195</td>\n",
              "      <td>1.116449</td>\n",
              "      <td>0.029100</td>\n",
              "      <td>0.048255</td>\n",
              "      <td>0.054430</td>\n",
              "      <td>0.058375</td>\n",
              "      <td>0.081279</td>\n",
              "      <td>0.109907</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>0.191198</td>\n",
              "      <td>0.157580</td>\n",
              "      <td>0.179609</td>\n",
              "      <td>1.046170</td>\n",
              "      <td>0.608358</td>\n",
              "      <td>0.629658</td>\n",
              "      <td>0.659367</td>\n",
              "      <td>0.730874</td>\n",
              "      <td>0.603732</td>\n",
              "      <td>0.768399</td>\n",
              "      <td>0.740817</td>\n",
              "      <td>0.788229</td>\n",
              "      <td>0.793099</td>\n",
              "      <td>0.727295</td>\n",
              "      <td>0.351643</td>\n",
              "      <td>0.763274</td>\n",
              "      <td>0.868677</td>\n",
              "      <td>0.803198</td>\n",
              "      <td>0.403602</td>\n",
              "      <td>0.071373</td>\n",
              "      <td>0.072551</td>\n",
              "      <td>0.140190</td>\n",
              "      <td>0.182667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.383090</td>\n",
              "      <td>0.367822</td>\n",
              "      <td>0.555479</td>\n",
              "      <td>0.038096</td>\n",
              "      <td>0.096757</td>\n",
              "      <td>0.013857</td>\n",
              "      <td>0.023125</td>\n",
              "      <td>0.439093</td>\n",
              "      <td>0.414083</td>\n",
              "      <td>0.397515</td>\n",
              "      <td>0.596772</td>\n",
              "      <td>0.068370</td>\n",
              "      <td>0.051937</td>\n",
              "      <td>0.060741</td>\n",
              "      <td>0.412759</td>\n",
              "      <td>0.390038</td>\n",
              "      <td>0.374819</td>\n",
              "      <td>0.560521</td>\n",
              "      <td>0.108174</td>\n",
              "      <td>0.113428</td>\n",
              "      <td>0.429644</td>\n",
              "      <td>0.412602</td>\n",
              "      <td>0.400537</td>\n",
              "      <td>0.541059</td>\n",
              "      <td>0.009956</td>\n",
              "      <td>0.449599</td>\n",
              "      <td>0.423889</td>\n",
              "      <td>0.406911</td>\n",
              "      <td>0.610217</td>\n",
              "      <td>0.459337</td>\n",
              "      <td>0.433453</td>\n",
              "      <td>0.416359</td>\n",
              "      <td>0.619876</td>\n",
              "      <td>0.040861</td>\n",
              "      <td>0.064414</td>\n",
              "      <td>0.287163</td>\n",
              "      <td>0.023774</td>\n",
              "      <td>0.325599</td>\n",
              "      <td>0.346695</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.207567</td>\n",
              "      <td>0.149162</td>\n",
              "      <td>0.413281</td>\n",
              "      <td>0.268064</td>\n",
              "      <td>0.350784</td>\n",
              "      <td>0.550446</td>\n",
              "      <td>0.729772</td>\n",
              "      <td>0.661067</td>\n",
              "      <td>0.733735</td>\n",
              "      <td>1.052325</td>\n",
              "      <td>0.029055</td>\n",
              "      <td>0.048058</td>\n",
              "      <td>0.054046</td>\n",
              "      <td>0.052564</td>\n",
              "      <td>0.073975</td>\n",
              "      <td>0.102124</td>\n",
              "      <td>0.133495</td>\n",
              "      <td>0.196838</td>\n",
              "      <td>0.178358</td>\n",
              "      <td>0.193430</td>\n",
              "      <td>1.071643</td>\n",
              "      <td>0.590631</td>\n",
              "      <td>0.617111</td>\n",
              "      <td>0.652965</td>\n",
              "      <td>0.726510</td>\n",
              "      <td>0.583013</td>\n",
              "      <td>0.725266</td>\n",
              "      <td>0.698325</td>\n",
              "      <td>0.749550</td>\n",
              "      <td>0.762678</td>\n",
              "      <td>0.737213</td>\n",
              "      <td>0.403877</td>\n",
              "      <td>0.753039</td>\n",
              "      <td>0.920617</td>\n",
              "      <td>0.821129</td>\n",
              "      <td>0.411357</td>\n",
              "      <td>0.072746</td>\n",
              "      <td>0.077174</td>\n",
              "      <td>0.147522</td>\n",
              "      <td>0.198965</td>\n",
              "      <td>...</td>\n",
              "      <td>0.334787</td>\n",
              "      <td>0.322138</td>\n",
              "      <td>0.507045</td>\n",
              "      <td>0.038844</td>\n",
              "      <td>0.088166</td>\n",
              "      <td>0.011825</td>\n",
              "      <td>0.025459</td>\n",
              "      <td>0.388988</td>\n",
              "      <td>0.365276</td>\n",
              "      <td>0.351106</td>\n",
              "      <td>0.552140</td>\n",
              "      <td>0.063657</td>\n",
              "      <td>0.050616</td>\n",
              "      <td>0.063830</td>\n",
              "      <td>0.363319</td>\n",
              "      <td>0.342413</td>\n",
              "      <td>0.329606</td>\n",
              "      <td>0.514974</td>\n",
              "      <td>0.096696</td>\n",
              "      <td>0.105036</td>\n",
              "      <td>0.393837</td>\n",
              "      <td>0.378244</td>\n",
              "      <td>0.367825</td>\n",
              "      <td>0.508859</td>\n",
              "      <td>0.013846</td>\n",
              "      <td>0.398088</td>\n",
              "      <td>0.373699</td>\n",
              "      <td>0.359201</td>\n",
              "      <td>0.563786</td>\n",
              "      <td>0.410744</td>\n",
              "      <td>0.385853</td>\n",
              "      <td>0.371103</td>\n",
              "      <td>0.577582</td>\n",
              "      <td>0.040470</td>\n",
              "      <td>0.060192</td>\n",
              "      <td>0.291065</td>\n",
              "      <td>0.020054</td>\n",
              "      <td>0.329249</td>\n",
              "      <td>0.346610</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.209710</td>\n",
              "      <td>0.151796</td>\n",
              "      <td>0.425649</td>\n",
              "      <td>0.272657</td>\n",
              "      <td>0.358480</td>\n",
              "      <td>0.568503</td>\n",
              "      <td>0.729258</td>\n",
              "      <td>0.702382</td>\n",
              "      <td>0.781597</td>\n",
              "      <td>1.093249</td>\n",
              "      <td>0.029604</td>\n",
              "      <td>0.048569</td>\n",
              "      <td>0.053562</td>\n",
              "      <td>0.059927</td>\n",
              "      <td>0.081331</td>\n",
              "      <td>0.108687</td>\n",
              "      <td>0.138396</td>\n",
              "      <td>0.192105</td>\n",
              "      <td>0.180009</td>\n",
              "      <td>0.198394</td>\n",
              "      <td>1.054637</td>\n",
              "      <td>0.598924</td>\n",
              "      <td>0.621862</td>\n",
              "      <td>0.654303</td>\n",
              "      <td>0.723751</td>\n",
              "      <td>0.593897</td>\n",
              "      <td>0.747247</td>\n",
              "      <td>0.722203</td>\n",
              "      <td>0.766800</td>\n",
              "      <td>0.773796</td>\n",
              "      <td>0.727711</td>\n",
              "      <td>0.367211</td>\n",
              "      <td>0.751856</td>\n",
              "      <td>0.886812</td>\n",
              "      <td>0.806554</td>\n",
              "      <td>0.410377</td>\n",
              "      <td>0.075550</td>\n",
              "      <td>0.076730</td>\n",
              "      <td>0.150007</td>\n",
              "      <td>0.198634</td>\n",
              "      <td>...</td>\n",
              "      <td>0.351177</td>\n",
              "      <td>0.338624</td>\n",
              "      <td>0.516268</td>\n",
              "      <td>0.039003</td>\n",
              "      <td>0.102248</td>\n",
              "      <td>0.013609</td>\n",
              "      <td>0.024207</td>\n",
              "      <td>0.404742</td>\n",
              "      <td>0.382472</td>\n",
              "      <td>0.368544</td>\n",
              "      <td>0.559361</td>\n",
              "      <td>0.075464</td>\n",
              "      <td>0.052612</td>\n",
              "      <td>0.062633</td>\n",
              "      <td>0.378595</td>\n",
              "      <td>0.358844</td>\n",
              "      <td>0.346298</td>\n",
              "      <td>0.522152</td>\n",
              "      <td>0.113270</td>\n",
              "      <td>0.118113</td>\n",
              "      <td>0.406730</td>\n",
              "      <td>0.393133</td>\n",
              "      <td>0.383738</td>\n",
              "      <td>0.507482</td>\n",
              "      <td>0.011729</td>\n",
              "      <td>0.414348</td>\n",
              "      <td>0.391303</td>\n",
              "      <td>0.376955</td>\n",
              "      <td>0.572403</td>\n",
              "      <td>0.425904</td>\n",
              "      <td>0.402678</td>\n",
              "      <td>0.388212</td>\n",
              "      <td>0.583566</td>\n",
              "      <td>0.038252</td>\n",
              "      <td>0.058773</td>\n",
              "      <td>0.283944</td>\n",
              "      <td>0.020728</td>\n",
              "      <td>0.320051</td>\n",
              "      <td>0.338464</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.220117</td>\n",
              "      <td>0.154567</td>\n",
              "      <td>0.419507</td>\n",
              "      <td>0.281169</td>\n",
              "      <td>0.360029</td>\n",
              "      <td>0.550323</td>\n",
              "      <td>0.703096</td>\n",
              "      <td>0.681569</td>\n",
              "      <td>0.758550</td>\n",
              "      <td>1.051571</td>\n",
              "      <td>0.031128</td>\n",
              "      <td>0.053641</td>\n",
              "      <td>0.062343</td>\n",
              "      <td>0.080691</td>\n",
              "      <td>0.106775</td>\n",
              "      <td>0.139166</td>\n",
              "      <td>0.173484</td>\n",
              "      <td>0.226350</td>\n",
              "      <td>0.188956</td>\n",
              "      <td>0.200879</td>\n",
              "      <td>1.006257</td>\n",
              "      <td>0.570464</td>\n",
              "      <td>0.593828</td>\n",
              "      <td>0.626521</td>\n",
              "      <td>0.696045</td>\n",
              "      <td>0.565623</td>\n",
              "      <td>0.727810</td>\n",
              "      <td>0.700437</td>\n",
              "      <td>0.747852</td>\n",
              "      <td>0.753084</td>\n",
              "      <td>0.696103</td>\n",
              "      <td>0.378425</td>\n",
              "      <td>0.726623</td>\n",
              "      <td>0.840830</td>\n",
              "      <td>0.771020</td>\n",
              "      <td>0.388281</td>\n",
              "      <td>0.070420</td>\n",
              "      <td>0.077821</td>\n",
              "      <td>0.140447</td>\n",
              "      <td>0.189135</td>\n",
              "      <td>...</td>\n",
              "      <td>0.316014</td>\n",
              "      <td>0.306317</td>\n",
              "      <td>0.480409</td>\n",
              "      <td>0.036040</td>\n",
              "      <td>0.091339</td>\n",
              "      <td>0.011044</td>\n",
              "      <td>0.024080</td>\n",
              "      <td>0.367595</td>\n",
              "      <td>0.348075</td>\n",
              "      <td>0.337083</td>\n",
              "      <td>0.523092</td>\n",
              "      <td>0.072915</td>\n",
              "      <td>0.047083</td>\n",
              "      <td>0.059317</td>\n",
              "      <td>0.342587</td>\n",
              "      <td>0.325369</td>\n",
              "      <td>0.315623</td>\n",
              "      <td>0.488236</td>\n",
              "      <td>0.098981</td>\n",
              "      <td>0.102791</td>\n",
              "      <td>0.383284</td>\n",
              "      <td>0.371268</td>\n",
              "      <td>0.364060</td>\n",
              "      <td>0.488672</td>\n",
              "      <td>0.014147</td>\n",
              "      <td>0.375583</td>\n",
              "      <td>0.355437</td>\n",
              "      <td>0.344108</td>\n",
              "      <td>0.533792</td>\n",
              "      <td>0.389574</td>\n",
              "      <td>0.369229</td>\n",
              "      <td>0.357770</td>\n",
              "      <td>0.547088</td>\n",
              "      <td>0.034734</td>\n",
              "      <td>0.052466</td>\n",
              "      <td>0.273859</td>\n",
              "      <td>0.017829</td>\n",
              "      <td>0.307068</td>\n",
              "      <td>0.323504</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.169271</td>\n",
              "      <td>0.126485</td>\n",
              "      <td>0.385130</td>\n",
              "      <td>0.230463</td>\n",
              "      <td>0.317255</td>\n",
              "      <td>0.533089</td>\n",
              "      <td>0.748044</td>\n",
              "      <td>0.664228</td>\n",
              "      <td>0.743196</td>\n",
              "      <td>1.106701</td>\n",
              "      <td>0.028413</td>\n",
              "      <td>0.046252</td>\n",
              "      <td>0.049930</td>\n",
              "      <td>0.063039</td>\n",
              "      <td>0.087407</td>\n",
              "      <td>0.118559</td>\n",
              "      <td>0.152797</td>\n",
              "      <td>0.220146</td>\n",
              "      <td>0.142418</td>\n",
              "      <td>0.164354</td>\n",
              "      <td>1.124805</td>\n",
              "      <td>0.593084</td>\n",
              "      <td>0.623172</td>\n",
              "      <td>0.663476</td>\n",
              "      <td>0.749090</td>\n",
              "      <td>0.581652</td>\n",
              "      <td>0.748947</td>\n",
              "      <td>0.715505</td>\n",
              "      <td>0.777167</td>\n",
              "      <td>0.791096</td>\n",
              "      <td>0.760509</td>\n",
              "      <td>0.409146</td>\n",
              "      <td>0.775943</td>\n",
              "      <td>0.954549</td>\n",
              "      <td>0.847544</td>\n",
              "      <td>0.423438</td>\n",
              "      <td>0.084630</td>\n",
              "      <td>0.086811</td>\n",
              "      <td>0.170919</td>\n",
              "      <td>0.227653</td>\n",
              "      <td>...</td>\n",
              "      <td>0.366696</td>\n",
              "      <td>0.351569</td>\n",
              "      <td>0.553719</td>\n",
              "      <td>0.040489</td>\n",
              "      <td>0.096791</td>\n",
              "      <td>0.013174</td>\n",
              "      <td>0.024401</td>\n",
              "      <td>0.418736</td>\n",
              "      <td>0.394968</td>\n",
              "      <td>0.378423</td>\n",
              "      <td>0.597067</td>\n",
              "      <td>0.062927</td>\n",
              "      <td>0.053452</td>\n",
              "      <td>0.064736</td>\n",
              "      <td>0.393140</td>\n",
              "      <td>0.371993</td>\n",
              "      <td>0.356768</td>\n",
              "      <td>0.559273</td>\n",
              "      <td>0.107512</td>\n",
              "      <td>0.117794</td>\n",
              "      <td>0.403877</td>\n",
              "      <td>0.388160</td>\n",
              "      <td>0.375618</td>\n",
              "      <td>0.534734</td>\n",
              "      <td>0.011285</td>\n",
              "      <td>0.429354</td>\n",
              "      <td>0.404976</td>\n",
              "      <td>0.388124</td>\n",
              "      <td>0.610098</td>\n",
              "      <td>0.437590</td>\n",
              "      <td>0.412636</td>\n",
              "      <td>0.395503</td>\n",
              "      <td>0.620943</td>\n",
              "      <td>0.039031</td>\n",
              "      <td>0.060149</td>\n",
              "      <td>0.302577</td>\n",
              "      <td>0.021634</td>\n",
              "      <td>0.339729</td>\n",
              "      <td>0.358177</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 108812 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3  ...    108808    108809    108810  output\n",
              "0  0.187956  0.135271  0.419206  0.254075  ...  0.023774  0.325599  0.346695   Anger\n",
              "1  0.207567  0.149162  0.413281  0.268064  ...  0.020054  0.329249  0.346610   Anger\n",
              "2  0.209710  0.151796  0.425649  0.272657  ...  0.020728  0.320051  0.338464   Anger\n",
              "3  0.220117  0.154567  0.419507  0.281169  ...  0.017829  0.307068  0.323504   Anger\n",
              "4  0.169271  0.126485  0.385130  0.230463  ...  0.021634  0.339729  0.358177   Anger\n",
              "\n",
              "[5 rows x 108812 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LojMwG4lWz7K",
        "outputId": "f6dd3f47-3f64-42ff-bfd8-755a3030105d"
      },
      "source": [
        "sentiment_data_small_version['output'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Surprise    82\n",
              "Happy       69\n",
              "Disgust     59\n",
              "Neutral     56\n",
              "Anger       45\n",
              "Sad         28\n",
              "Fear        25\n",
              "Name: output, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvDgkKUsYy2D"
      },
      "source": [
        "## Mapping The Output Column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JmeYUMXY16u"
      },
      "source": [
        "input_df_copy = sentiment_data_small_version"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekyhnB5HY_Eb"
      },
      "source": [
        "uniqueValues = input_df_copy['output'].unique()\n",
        "input_df_copy['output'] = input_df_copy['output'].map({uniqueValues[0]:0,uniqueValues[1]:1,uniqueValues[2]:2,\n",
        "                                                       uniqueValues[3]:3,uniqueValues[4]:4,uniqueValues[5]:5,\n",
        "                                                       uniqueValues[6]:6})"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWoeBw72ZKUa",
        "outputId": "1f83df73-75d4-4a32-bef9-c04ffa89a511"
      },
      "source": [
        "uniqueValues"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Anger', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK1LdxEXZTRI"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wynE83nGZaAN"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56PAsc3mZbhG"
      },
      "source": [
        "# Create X & y\n",
        "X = input_df_copy.drop(\"output\", axis=1)\n",
        "y = input_df_copy[\"output\"]\n",
        "\n",
        "# Build our train and test sets (use random state to ensure same split as before)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKTrYiSkZfwM"
      },
      "source": [
        "# Model Declaration and Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GeMq8iWZjza"
      },
      "source": [
        "## Model 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrAdvUFIcsuY"
      },
      "source": [
        "### Declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLDNxnFAZhXs"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(256, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(128, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate = .0003),\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    patience=250,\n",
        "    min_delta=0.0001,\n",
        "    restore_best_weights=True,\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt7Sb_fNcvWu"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGPlkzWGZpww",
        "outputId": "500a4206-2f8a-4b83-a1f3-6f153de17648"
      },
      "source": [
        "history_1 = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=2000,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1, \n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "10/10 [==============================] - 3s 191ms/step - loss: 11.3272 - accuracy: 0.1821 - val_loss: 3.3533 - val_accuracy: 0.2192\n",
            "Epoch 2/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 8.5894 - accuracy: 0.2096 - val_loss: 3.0615 - val_accuracy: 0.2466\n",
            "Epoch 3/2000\n",
            "10/10 [==============================] - 1s 146ms/step - loss: 5.2449 - accuracy: 0.1615 - val_loss: 2.3593 - val_accuracy: 0.2466\n",
            "Epoch 4/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 2.8560 - accuracy: 0.1615 - val_loss: 1.8821 - val_accuracy: 0.2466\n",
            "Epoch 5/2000\n",
            "10/10 [==============================] - 1s 147ms/step - loss: 2.1016 - accuracy: 0.1478 - val_loss: 1.9631 - val_accuracy: 0.1233\n",
            "Epoch 6/2000\n",
            "10/10 [==============================] - 1s 147ms/step - loss: 1.9434 - accuracy: 0.1409 - val_loss: 1.8854 - val_accuracy: 0.2192\n",
            "Epoch 7/2000\n",
            "10/10 [==============================] - 1s 146ms/step - loss: 1.9273 - accuracy: 0.1924 - val_loss: 1.8663 - val_accuracy: 0.1370\n",
            "Epoch 8/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.9317 - accuracy: 0.2027 - val_loss: 1.9439 - val_accuracy: 0.2466\n",
            "Epoch 9/2000\n",
            "10/10 [==============================] - 1s 149ms/step - loss: 1.9426 - accuracy: 0.2199 - val_loss: 1.9429 - val_accuracy: 0.2466\n",
            "Epoch 10/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.9413 - accuracy: 0.2199 - val_loss: 1.9415 - val_accuracy: 0.2466\n",
            "Epoch 11/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.9398 - accuracy: 0.2199 - val_loss: 1.9399 - val_accuracy: 0.2466\n",
            "Epoch 12/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.9384 - accuracy: 0.2199 - val_loss: 1.9386 - val_accuracy: 0.2466\n",
            "Epoch 13/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.9369 - accuracy: 0.2199 - val_loss: 1.9372 - val_accuracy: 0.2466\n",
            "Epoch 14/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.9358 - accuracy: 0.2199 - val_loss: 1.9361 - val_accuracy: 0.2466\n",
            "Epoch 15/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.9343 - accuracy: 0.2199 - val_loss: 1.9344 - val_accuracy: 0.2466\n",
            "Epoch 16/2000\n",
            "10/10 [==============================] - 1s 149ms/step - loss: 1.9326 - accuracy: 0.2199 - val_loss: 1.9327 - val_accuracy: 0.2466\n",
            "Epoch 17/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.9310 - accuracy: 0.2199 - val_loss: 1.9312 - val_accuracy: 0.2466\n",
            "Epoch 18/2000\n",
            "10/10 [==============================] - 1s 148ms/step - loss: 1.9297 - accuracy: 0.2199 - val_loss: 1.9297 - val_accuracy: 0.2466\n",
            "Epoch 19/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.9281 - accuracy: 0.2199 - val_loss: 1.9285 - val_accuracy: 0.2466\n",
            "Epoch 20/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.9266 - accuracy: 0.2199 - val_loss: 1.9272 - val_accuracy: 0.2466\n",
            "Epoch 21/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.9256 - accuracy: 0.2199 - val_loss: 1.9260 - val_accuracy: 0.2466\n",
            "Epoch 22/2000\n",
            "10/10 [==============================] - 1s 149ms/step - loss: 1.9243 - accuracy: 0.2199 - val_loss: 1.9246 - val_accuracy: 0.2466\n",
            "Epoch 23/2000\n",
            "10/10 [==============================] - 1s 149ms/step - loss: 1.9229 - accuracy: 0.2199 - val_loss: 1.9235 - val_accuracy: 0.2466\n",
            "Epoch 24/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.9216 - accuracy: 0.2199 - val_loss: 1.9223 - val_accuracy: 0.2466\n",
            "Epoch 25/2000\n",
            "10/10 [==============================] - 1s 148ms/step - loss: 1.9207 - accuracy: 0.2199 - val_loss: 1.9212 - val_accuracy: 0.2466\n",
            "Epoch 26/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.9195 - accuracy: 0.2199 - val_loss: 1.9203 - val_accuracy: 0.2466\n",
            "Epoch 27/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.9184 - accuracy: 0.2199 - val_loss: 1.9190 - val_accuracy: 0.2466\n",
            "Epoch 28/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.9170 - accuracy: 0.2199 - val_loss: 1.9177 - val_accuracy: 0.2466\n",
            "Epoch 29/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.9159 - accuracy: 0.2199 - val_loss: 1.9169 - val_accuracy: 0.2466\n",
            "Epoch 30/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.9151 - accuracy: 0.2199 - val_loss: 1.9158 - val_accuracy: 0.2466\n",
            "Epoch 31/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.9139 - accuracy: 0.2199 - val_loss: 1.9145 - val_accuracy: 0.2466\n",
            "Epoch 32/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.9127 - accuracy: 0.2199 - val_loss: 1.9135 - val_accuracy: 0.2466\n",
            "Epoch 33/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.9116 - accuracy: 0.2199 - val_loss: 1.9127 - val_accuracy: 0.2466\n",
            "Epoch 34/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.9103 - accuracy: 0.2199 - val_loss: 1.9117 - val_accuracy: 0.2466\n",
            "Epoch 35/2000\n",
            "10/10 [==============================] - 1s 149ms/step - loss: 1.9091 - accuracy: 0.2199 - val_loss: 1.9106 - val_accuracy: 0.2466\n",
            "Epoch 36/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.9079 - accuracy: 0.2199 - val_loss: 1.9098 - val_accuracy: 0.2466\n",
            "Epoch 37/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.9067 - accuracy: 0.2199 - val_loss: 1.9090 - val_accuracy: 0.2466\n",
            "Epoch 38/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.9059 - accuracy: 0.2199 - val_loss: 1.9086 - val_accuracy: 0.2466\n",
            "Epoch 39/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.9054 - accuracy: 0.2199 - val_loss: 1.9083 - val_accuracy: 0.2466\n",
            "Epoch 40/2000\n",
            "10/10 [==============================] - 2s 150ms/step - loss: 1.9043 - accuracy: 0.2199 - val_loss: 1.9074 - val_accuracy: 0.2466\n",
            "Epoch 41/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.9034 - accuracy: 0.2199 - val_loss: 1.9067 - val_accuracy: 0.2466\n",
            "Epoch 42/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.9028 - accuracy: 0.2199 - val_loss: 1.9057 - val_accuracy: 0.2466\n",
            "Epoch 43/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.9016 - accuracy: 0.2199 - val_loss: 1.9048 - val_accuracy: 0.2466\n",
            "Epoch 44/2000\n",
            "10/10 [==============================] - 1s 149ms/step - loss: 1.9011 - accuracy: 0.2199 - val_loss: 1.9038 - val_accuracy: 0.2466\n",
            "Epoch 45/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.9011 - accuracy: 0.2199 - val_loss: 1.9031 - val_accuracy: 0.2466\n",
            "Epoch 46/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8998 - accuracy: 0.2199 - val_loss: 1.9024 - val_accuracy: 0.2466\n",
            "Epoch 47/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.8984 - accuracy: 0.2199 - val_loss: 1.9021 - val_accuracy: 0.2466\n",
            "Epoch 48/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.8978 - accuracy: 0.2199 - val_loss: 1.9016 - val_accuracy: 0.2466\n",
            "Epoch 49/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8971 - accuracy: 0.2199 - val_loss: 1.9008 - val_accuracy: 0.2466\n",
            "Epoch 50/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8950 - accuracy: 0.2199 - val_loss: 1.9003 - val_accuracy: 0.2466\n",
            "Epoch 51/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8955 - accuracy: 0.2199 - val_loss: 1.8998 - val_accuracy: 0.2466\n",
            "Epoch 52/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.8953 - accuracy: 0.2199 - val_loss: 1.8993 - val_accuracy: 0.2466\n",
            "Epoch 53/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.8950 - accuracy: 0.2199 - val_loss: 1.8990 - val_accuracy: 0.2466\n",
            "Epoch 54/2000\n",
            "10/10 [==============================] - 1s 149ms/step - loss: 1.8941 - accuracy: 0.2199 - val_loss: 1.8988 - val_accuracy: 0.2466\n",
            "Epoch 55/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8934 - accuracy: 0.2199 - val_loss: 1.8985 - val_accuracy: 0.2466\n",
            "Epoch 56/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.8934 - accuracy: 0.2199 - val_loss: 1.8982 - val_accuracy: 0.2466\n",
            "Epoch 57/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.8904 - accuracy: 0.2199 - val_loss: 1.8979 - val_accuracy: 0.2466\n",
            "Epoch 58/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.8914 - accuracy: 0.2199 - val_loss: 1.8976 - val_accuracy: 0.2466\n",
            "Epoch 59/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8926 - accuracy: 0.2199 - val_loss: 1.8969 - val_accuracy: 0.2466\n",
            "Epoch 60/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.8915 - accuracy: 0.2199 - val_loss: 1.8964 - val_accuracy: 0.2466\n",
            "Epoch 61/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8898 - accuracy: 0.2199 - val_loss: 1.8962 - val_accuracy: 0.2466\n",
            "Epoch 62/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.8902 - accuracy: 0.2199 - val_loss: 1.8960 - val_accuracy: 0.2466\n",
            "Epoch 63/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8898 - accuracy: 0.2199 - val_loss: 1.8957 - val_accuracy: 0.2466\n",
            "Epoch 64/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.8881 - accuracy: 0.2199 - val_loss: 1.8957 - val_accuracy: 0.2466\n",
            "Epoch 65/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.8886 - accuracy: 0.2199 - val_loss: 1.8957 - val_accuracy: 0.2466\n",
            "Epoch 66/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8884 - accuracy: 0.2199 - val_loss: 1.8956 - val_accuracy: 0.2466\n",
            "Epoch 67/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8861 - accuracy: 0.2199 - val_loss: 1.8952 - val_accuracy: 0.2466\n",
            "Epoch 68/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8866 - accuracy: 0.2199 - val_loss: 1.8949 - val_accuracy: 0.2466\n",
            "Epoch 69/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8875 - accuracy: 0.2199 - val_loss: 1.8945 - val_accuracy: 0.2466\n",
            "Epoch 70/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8870 - accuracy: 0.2199 - val_loss: 1.8944 - val_accuracy: 0.2466\n",
            "Epoch 71/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8846 - accuracy: 0.2199 - val_loss: 1.8939 - val_accuracy: 0.2466\n",
            "Epoch 72/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.8834 - accuracy: 0.2199 - val_loss: 1.8935 - val_accuracy: 0.2466\n",
            "Epoch 73/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.8858 - accuracy: 0.2199 - val_loss: 1.8932 - val_accuracy: 0.2466\n",
            "Epoch 74/2000\n",
            "10/10 [==============================] - 2s 150ms/step - loss: 1.8843 - accuracy: 0.2199 - val_loss: 1.8928 - val_accuracy: 0.2466\n",
            "Epoch 75/2000\n",
            "10/10 [==============================] - 1s 149ms/step - loss: 1.8844 - accuracy: 0.2199 - val_loss: 1.8927 - val_accuracy: 0.2466\n",
            "Epoch 76/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8834 - accuracy: 0.2199 - val_loss: 1.8926 - val_accuracy: 0.2466\n",
            "Epoch 77/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8819 - accuracy: 0.2199 - val_loss: 1.8924 - val_accuracy: 0.2466\n",
            "Epoch 78/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8840 - accuracy: 0.2199 - val_loss: 1.8926 - val_accuracy: 0.2466\n",
            "Epoch 79/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8823 - accuracy: 0.2199 - val_loss: 1.8926 - val_accuracy: 0.2466\n",
            "Epoch 80/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8823 - accuracy: 0.2199 - val_loss: 1.8923 - val_accuracy: 0.2466\n",
            "Epoch 81/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8827 - accuracy: 0.2199 - val_loss: 1.8919 - val_accuracy: 0.2466\n",
            "Epoch 82/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8817 - accuracy: 0.2199 - val_loss: 1.8917 - val_accuracy: 0.2466\n",
            "Epoch 83/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.8811 - accuracy: 0.2199 - val_loss: 1.8911 - val_accuracy: 0.2466\n",
            "Epoch 84/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.8812 - accuracy: 0.2199 - val_loss: 1.8909 - val_accuracy: 0.2466\n",
            "Epoch 85/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.8813 - accuracy: 0.2199 - val_loss: 1.8907 - val_accuracy: 0.2466\n",
            "Epoch 86/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.8803 - accuracy: 0.2199 - val_loss: 1.8904 - val_accuracy: 0.2466\n",
            "Epoch 87/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8822 - accuracy: 0.2199 - val_loss: 1.8899 - val_accuracy: 0.2466\n",
            "Epoch 88/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.8819 - accuracy: 0.2199 - val_loss: 1.8894 - val_accuracy: 0.2466\n",
            "Epoch 89/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8791 - accuracy: 0.2199 - val_loss: 1.8891 - val_accuracy: 0.2466\n",
            "Epoch 90/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8796 - accuracy: 0.2199 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 91/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8803 - accuracy: 0.2199 - val_loss: 1.8883 - val_accuracy: 0.2466\n",
            "Epoch 92/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8783 - accuracy: 0.2199 - val_loss: 1.8880 - val_accuracy: 0.2466\n",
            "Epoch 93/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.8786 - accuracy: 0.2199 - val_loss: 1.8876 - val_accuracy: 0.2466\n",
            "Epoch 94/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8777 - accuracy: 0.2199 - val_loss: 1.8877 - val_accuracy: 0.2466\n",
            "Epoch 95/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8786 - accuracy: 0.2199 - val_loss: 1.8876 - val_accuracy: 0.2466\n",
            "Epoch 96/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8784 - accuracy: 0.2199 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 97/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8752 - accuracy: 0.2199 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 98/2000\n",
            "10/10 [==============================] - 1s 149ms/step - loss: 1.8782 - accuracy: 0.2199 - val_loss: 1.8867 - val_accuracy: 0.2466\n",
            "Epoch 99/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8786 - accuracy: 0.2199 - val_loss: 1.8864 - val_accuracy: 0.2466\n",
            "Epoch 100/2000\n",
            "10/10 [==============================] - 2s 150ms/step - loss: 1.8777 - accuracy: 0.2199 - val_loss: 1.8862 - val_accuracy: 0.2466\n",
            "Epoch 101/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.8763 - accuracy: 0.2199 - val_loss: 1.8859 - val_accuracy: 0.2466\n",
            "Epoch 102/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.8766 - accuracy: 0.2199 - val_loss: 1.8858 - val_accuracy: 0.2466\n",
            "Epoch 103/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8773 - accuracy: 0.2199 - val_loss: 1.8856 - val_accuracy: 0.2466\n",
            "Epoch 104/2000\n",
            "10/10 [==============================] - 1s 149ms/step - loss: 1.8790 - accuracy: 0.2199 - val_loss: 1.8851 - val_accuracy: 0.2466\n",
            "Epoch 105/2000\n",
            "10/10 [==============================] - 1s 149ms/step - loss: 1.8755 - accuracy: 0.2199 - val_loss: 1.8845 - val_accuracy: 0.2466\n",
            "Epoch 106/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.8768 - accuracy: 0.2199 - val_loss: 1.8845 - val_accuracy: 0.2466\n",
            "Epoch 107/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.8755 - accuracy: 0.2199 - val_loss: 1.8843 - val_accuracy: 0.2466\n",
            "Epoch 108/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.8745 - accuracy: 0.2199 - val_loss: 1.8842 - val_accuracy: 0.2466\n",
            "Epoch 109/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8779 - accuracy: 0.2199 - val_loss: 1.8840 - val_accuracy: 0.2466\n",
            "Epoch 110/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8756 - accuracy: 0.2199 - val_loss: 1.8836 - val_accuracy: 0.2466\n",
            "Epoch 111/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.8770 - accuracy: 0.2199 - val_loss: 1.8832 - val_accuracy: 0.2466\n",
            "Epoch 112/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.8756 - accuracy: 0.2199 - val_loss: 1.8831 - val_accuracy: 0.2466\n",
            "Epoch 113/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8782 - accuracy: 0.2199 - val_loss: 1.8832 - val_accuracy: 0.2466\n",
            "Epoch 114/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8751 - accuracy: 0.2199 - val_loss: 1.8837 - val_accuracy: 0.2466\n",
            "Epoch 115/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8750 - accuracy: 0.2199 - val_loss: 1.8839 - val_accuracy: 0.2466\n",
            "Epoch 116/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.8754 - accuracy: 0.2199 - val_loss: 1.8839 - val_accuracy: 0.2466\n",
            "Epoch 117/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8741 - accuracy: 0.2199 - val_loss: 1.8841 - val_accuracy: 0.2466\n",
            "Epoch 118/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8754 - accuracy: 0.2199 - val_loss: 1.8849 - val_accuracy: 0.2466\n",
            "Epoch 119/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8755 - accuracy: 0.2199 - val_loss: 1.8852 - val_accuracy: 0.2466\n",
            "Epoch 120/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8755 - accuracy: 0.2199 - val_loss: 1.8851 - val_accuracy: 0.2466\n",
            "Epoch 121/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8760 - accuracy: 0.2199 - val_loss: 1.8853 - val_accuracy: 0.2466\n",
            "Epoch 122/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8735 - accuracy: 0.2199 - val_loss: 1.8856 - val_accuracy: 0.2466\n",
            "Epoch 123/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8734 - accuracy: 0.2199 - val_loss: 1.8858 - val_accuracy: 0.2466\n",
            "Epoch 124/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8727 - accuracy: 0.2199 - val_loss: 1.8859 - val_accuracy: 0.2466\n",
            "Epoch 125/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.8716 - accuracy: 0.2199 - val_loss: 1.8855 - val_accuracy: 0.2466\n",
            "Epoch 126/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8736 - accuracy: 0.2199 - val_loss: 1.8855 - val_accuracy: 0.2466\n",
            "Epoch 127/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8733 - accuracy: 0.2199 - val_loss: 1.8859 - val_accuracy: 0.2466\n",
            "Epoch 128/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8743 - accuracy: 0.2199 - val_loss: 1.8858 - val_accuracy: 0.2466\n",
            "Epoch 129/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8755 - accuracy: 0.2199 - val_loss: 1.8852 - val_accuracy: 0.2466\n",
            "Epoch 130/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8754 - accuracy: 0.2199 - val_loss: 1.8851 - val_accuracy: 0.2466\n",
            "Epoch 131/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8728 - accuracy: 0.2199 - val_loss: 1.8856 - val_accuracy: 0.2466\n",
            "Epoch 132/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8734 - accuracy: 0.2199 - val_loss: 1.8857 - val_accuracy: 0.2466\n",
            "Epoch 133/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8757 - accuracy: 0.2199 - val_loss: 1.8855 - val_accuracy: 0.2466\n",
            "Epoch 134/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8717 - accuracy: 0.2199 - val_loss: 1.8854 - val_accuracy: 0.2466\n",
            "Epoch 135/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8718 - accuracy: 0.2199 - val_loss: 1.8853 - val_accuracy: 0.2466\n",
            "Epoch 136/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8709 - accuracy: 0.2199 - val_loss: 1.8852 - val_accuracy: 0.2466\n",
            "Epoch 137/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8724 - accuracy: 0.2199 - val_loss: 1.8854 - val_accuracy: 0.2466\n",
            "Epoch 138/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8742 - accuracy: 0.2199 - val_loss: 1.8856 - val_accuracy: 0.2466\n",
            "Epoch 139/2000\n",
            "10/10 [==============================] - 1s 152ms/step - loss: 1.8753 - accuracy: 0.2199 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 140/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8763 - accuracy: 0.2199 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 141/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8740 - accuracy: 0.2199 - val_loss: 1.8873 - val_accuracy: 0.2466\n",
            "Epoch 142/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8725 - accuracy: 0.2199 - val_loss: 1.8872 - val_accuracy: 0.2466\n",
            "Epoch 143/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8763 - accuracy: 0.2199 - val_loss: 1.8873 - val_accuracy: 0.2466\n",
            "Epoch 144/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8755 - accuracy: 0.2199 - val_loss: 1.8873 - val_accuracy: 0.2466\n",
            "Epoch 145/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8724 - accuracy: 0.2199 - val_loss: 1.8877 - val_accuracy: 0.2466\n",
            "Epoch 146/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8769 - accuracy: 0.2199 - val_loss: 1.8879 - val_accuracy: 0.2466\n",
            "Epoch 147/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8730 - accuracy: 0.2199 - val_loss: 1.8879 - val_accuracy: 0.2466\n",
            "Epoch 148/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8738 - accuracy: 0.2199 - val_loss: 1.8881 - val_accuracy: 0.2466\n",
            "Epoch 149/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8730 - accuracy: 0.2199 - val_loss: 1.8877 - val_accuracy: 0.2466\n",
            "Epoch 150/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8746 - accuracy: 0.2199 - val_loss: 1.8871 - val_accuracy: 0.2466\n",
            "Epoch 151/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8751 - accuracy: 0.2199 - val_loss: 1.8869 - val_accuracy: 0.2466\n",
            "Epoch 152/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8738 - accuracy: 0.2199 - val_loss: 1.8871 - val_accuracy: 0.2466\n",
            "Epoch 153/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8770 - accuracy: 0.2199 - val_loss: 1.8871 - val_accuracy: 0.2466\n",
            "Epoch 154/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8714 - accuracy: 0.2199 - val_loss: 1.8869 - val_accuracy: 0.2466\n",
            "Epoch 155/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8745 - accuracy: 0.2199 - val_loss: 1.8872 - val_accuracy: 0.2466\n",
            "Epoch 156/2000\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 1.8751 - accuracy: 0.2199 - val_loss: 1.8877 - val_accuracy: 0.2466\n",
            "Epoch 157/2000\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 1.8736 - accuracy: 0.2199 - val_loss: 1.8881 - val_accuracy: 0.2466\n",
            "Epoch 158/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8725 - accuracy: 0.2199 - val_loss: 1.8879 - val_accuracy: 0.2466\n",
            "Epoch 159/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8714 - accuracy: 0.2199 - val_loss: 1.8874 - val_accuracy: 0.2466\n",
            "Epoch 160/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8748 - accuracy: 0.2199 - val_loss: 1.8869 - val_accuracy: 0.2466\n",
            "Epoch 161/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8739 - accuracy: 0.2199 - val_loss: 1.8861 - val_accuracy: 0.2466\n",
            "Epoch 162/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8758 - accuracy: 0.2199 - val_loss: 1.8857 - val_accuracy: 0.2466\n",
            "Epoch 163/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8729 - accuracy: 0.2199 - val_loss: 1.8854 - val_accuracy: 0.2466\n",
            "Epoch 164/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8745 - accuracy: 0.2199 - val_loss: 1.8856 - val_accuracy: 0.2466\n",
            "Epoch 165/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8757 - accuracy: 0.2199 - val_loss: 1.8852 - val_accuracy: 0.2466\n",
            "Epoch 166/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8748 - accuracy: 0.2199 - val_loss: 1.8848 - val_accuracy: 0.2466\n",
            "Epoch 167/2000\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 1.8742 - accuracy: 0.2199 - val_loss: 1.8847 - val_accuracy: 0.2466\n",
            "Epoch 168/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8753 - accuracy: 0.2199 - val_loss: 1.8846 - val_accuracy: 0.2466\n",
            "Epoch 169/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8726 - accuracy: 0.2199 - val_loss: 1.8842 - val_accuracy: 0.2466\n",
            "Epoch 170/2000\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 1.8739 - accuracy: 0.2199 - val_loss: 1.8840 - val_accuracy: 0.2466\n",
            "Epoch 171/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8746 - accuracy: 0.2199 - val_loss: 1.8840 - val_accuracy: 0.2466\n",
            "Epoch 172/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8727 - accuracy: 0.2199 - val_loss: 1.8838 - val_accuracy: 0.2466\n",
            "Epoch 173/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8735 - accuracy: 0.2199 - val_loss: 1.8837 - val_accuracy: 0.2466\n",
            "Epoch 174/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8731 - accuracy: 0.2199 - val_loss: 1.8839 - val_accuracy: 0.2466\n",
            "Epoch 175/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8719 - accuracy: 0.2199 - val_loss: 1.8845 - val_accuracy: 0.2466\n",
            "Epoch 176/2000\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 1.8750 - accuracy: 0.2199 - val_loss: 1.8847 - val_accuracy: 0.2466\n",
            "Epoch 177/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8745 - accuracy: 0.2199 - val_loss: 1.8850 - val_accuracy: 0.2466\n",
            "Epoch 178/2000\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 1.8753 - accuracy: 0.2199 - val_loss: 1.8850 - val_accuracy: 0.2466\n",
            "Epoch 179/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8730 - accuracy: 0.2199 - val_loss: 1.8853 - val_accuracy: 0.2466\n",
            "Epoch 180/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8743 - accuracy: 0.2199 - val_loss: 1.8851 - val_accuracy: 0.2466\n",
            "Epoch 181/2000\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 1.8751 - accuracy: 0.2199 - val_loss: 1.8851 - val_accuracy: 0.2466\n",
            "Epoch 182/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8751 - accuracy: 0.2199 - val_loss: 1.8849 - val_accuracy: 0.2466\n",
            "Epoch 183/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8733 - accuracy: 0.2199 - val_loss: 1.8849 - val_accuracy: 0.2466\n",
            "Epoch 184/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8738 - accuracy: 0.2199 - val_loss: 1.8847 - val_accuracy: 0.2466\n",
            "Epoch 185/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8723 - accuracy: 0.2199 - val_loss: 1.8848 - val_accuracy: 0.2466\n",
            "Epoch 186/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8768 - accuracy: 0.2199 - val_loss: 1.8847 - val_accuracy: 0.2466\n",
            "Epoch 187/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8742 - accuracy: 0.2199 - val_loss: 1.8848 - val_accuracy: 0.2466\n",
            "Epoch 188/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8761 - accuracy: 0.2199 - val_loss: 1.8849 - val_accuracy: 0.2466\n",
            "Epoch 189/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8745 - accuracy: 0.2199 - val_loss: 1.8845 - val_accuracy: 0.2466\n",
            "Epoch 190/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8755 - accuracy: 0.2199 - val_loss: 1.8846 - val_accuracy: 0.2466\n",
            "Epoch 191/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8739 - accuracy: 0.2199 - val_loss: 1.8848 - val_accuracy: 0.2466\n",
            "Epoch 192/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8743 - accuracy: 0.2199 - val_loss: 1.8851 - val_accuracy: 0.2466\n",
            "Epoch 193/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8748 - accuracy: 0.2199 - val_loss: 1.8848 - val_accuracy: 0.2466\n",
            "Epoch 194/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8754 - accuracy: 0.2199 - val_loss: 1.8851 - val_accuracy: 0.2466\n",
            "Epoch 195/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8730 - accuracy: 0.2199 - val_loss: 1.8849 - val_accuracy: 0.2466\n",
            "Epoch 196/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8732 - accuracy: 0.2199 - val_loss: 1.8847 - val_accuracy: 0.2466\n",
            "Epoch 197/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8732 - accuracy: 0.2199 - val_loss: 1.8849 - val_accuracy: 0.2466\n",
            "Epoch 198/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8721 - accuracy: 0.2199 - val_loss: 1.8851 - val_accuracy: 0.2466\n",
            "Epoch 199/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8724 - accuracy: 0.2199 - val_loss: 1.8854 - val_accuracy: 0.2466\n",
            "Epoch 200/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8716 - accuracy: 0.2199 - val_loss: 1.8851 - val_accuracy: 0.2466\n",
            "Epoch 201/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8720 - accuracy: 0.2199 - val_loss: 1.8851 - val_accuracy: 0.2466\n",
            "Epoch 202/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8742 - accuracy: 0.2199 - val_loss: 1.8855 - val_accuracy: 0.2466\n",
            "Epoch 203/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8724 - accuracy: 0.2199 - val_loss: 1.8860 - val_accuracy: 0.2466\n",
            "Epoch 204/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8730 - accuracy: 0.2199 - val_loss: 1.8858 - val_accuracy: 0.2466\n",
            "Epoch 205/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8736 - accuracy: 0.2199 - val_loss: 1.8855 - val_accuracy: 0.2466\n",
            "Epoch 206/2000\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 1.8766 - accuracy: 0.2199 - val_loss: 1.8853 - val_accuracy: 0.2466\n",
            "Epoch 207/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8726 - accuracy: 0.2199 - val_loss: 1.8849 - val_accuracy: 0.2466\n",
            "Epoch 208/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8743 - accuracy: 0.2199 - val_loss: 1.8849 - val_accuracy: 0.2466\n",
            "Epoch 209/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8715 - accuracy: 0.2199 - val_loss: 1.8850 - val_accuracy: 0.2466\n",
            "Epoch 210/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8748 - accuracy: 0.2199 - val_loss: 1.8853 - val_accuracy: 0.2466\n",
            "Epoch 211/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8758 - accuracy: 0.2199 - val_loss: 1.8856 - val_accuracy: 0.2466\n",
            "Epoch 212/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8734 - accuracy: 0.2199 - val_loss: 1.8859 - val_accuracy: 0.2466\n",
            "Epoch 213/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8720 - accuracy: 0.2199 - val_loss: 1.8859 - val_accuracy: 0.2466\n",
            "Epoch 214/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8732 - accuracy: 0.2199 - val_loss: 1.8861 - val_accuracy: 0.2466\n",
            "Epoch 215/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8713 - accuracy: 0.2199 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 216/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8736 - accuracy: 0.2199 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 217/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8713 - accuracy: 0.2199 - val_loss: 1.8871 - val_accuracy: 0.2466\n",
            "Epoch 218/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8712 - accuracy: 0.2199 - val_loss: 1.8874 - val_accuracy: 0.2466\n",
            "Epoch 219/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8719 - accuracy: 0.2199 - val_loss: 1.8871 - val_accuracy: 0.2466\n",
            "Epoch 220/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8734 - accuracy: 0.2199 - val_loss: 1.8867 - val_accuracy: 0.2466\n",
            "Epoch 221/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8728 - accuracy: 0.2199 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 222/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8740 - accuracy: 0.2199 - val_loss: 1.8866 - val_accuracy: 0.2466\n",
            "Epoch 223/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8726 - accuracy: 0.2199 - val_loss: 1.8871 - val_accuracy: 0.2466\n",
            "Epoch 224/2000\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 1.8739 - accuracy: 0.2199 - val_loss: 1.8874 - val_accuracy: 0.2466\n",
            "Epoch 225/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8733 - accuracy: 0.2199 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 226/2000\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 1.8734 - accuracy: 0.2199 - val_loss: 1.8873 - val_accuracy: 0.2466\n",
            "Epoch 227/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8706 - accuracy: 0.2199 - val_loss: 1.8874 - val_accuracy: 0.2466\n",
            "Epoch 228/2000\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 1.8738 - accuracy: 0.2199 - val_loss: 1.8873 - val_accuracy: 0.2466\n",
            "Epoch 229/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8768 - accuracy: 0.2199 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 230/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8707 - accuracy: 0.2199 - val_loss: 1.8868 - val_accuracy: 0.2466\n",
            "Epoch 231/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8735 - accuracy: 0.2199 - val_loss: 1.8872 - val_accuracy: 0.2466\n",
            "Epoch 232/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8737 - accuracy: 0.2199 - val_loss: 1.8876 - val_accuracy: 0.2466\n",
            "Epoch 233/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8745 - accuracy: 0.2199 - val_loss: 1.8880 - val_accuracy: 0.2466\n",
            "Epoch 234/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8749 - accuracy: 0.2199 - val_loss: 1.8885 - val_accuracy: 0.2466\n",
            "Epoch 235/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8754 - accuracy: 0.2199 - val_loss: 1.8890 - val_accuracy: 0.2466\n",
            "Epoch 236/2000\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 1.8690 - accuracy: 0.2199 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 237/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8724 - accuracy: 0.2199 - val_loss: 1.8890 - val_accuracy: 0.2466\n",
            "Epoch 238/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8730 - accuracy: 0.2199 - val_loss: 1.8891 - val_accuracy: 0.2466\n",
            "Epoch 239/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8710 - accuracy: 0.2199 - val_loss: 1.8892 - val_accuracy: 0.2466\n",
            "Epoch 240/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8729 - accuracy: 0.2165 - val_loss: 1.8888 - val_accuracy: 0.2466\n",
            "Epoch 241/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8712 - accuracy: 0.2199 - val_loss: 1.8886 - val_accuracy: 0.2466\n",
            "Epoch 242/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8743 - accuracy: 0.2199 - val_loss: 1.8885 - val_accuracy: 0.2466\n",
            "Epoch 243/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8741 - accuracy: 0.2199 - val_loss: 1.8882 - val_accuracy: 0.2466\n",
            "Epoch 244/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8719 - accuracy: 0.2199 - val_loss: 1.8876 - val_accuracy: 0.2466\n",
            "Epoch 245/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8715 - accuracy: 0.2199 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 246/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8748 - accuracy: 0.2199 - val_loss: 1.8873 - val_accuracy: 0.2466\n",
            "Epoch 247/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8742 - accuracy: 0.2199 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 248/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8732 - accuracy: 0.2199 - val_loss: 1.8873 - val_accuracy: 0.2466\n",
            "Epoch 249/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8708 - accuracy: 0.2199 - val_loss: 1.8876 - val_accuracy: 0.2466\n",
            "Epoch 250/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8722 - accuracy: 0.2199 - val_loss: 1.8877 - val_accuracy: 0.2466\n",
            "Epoch 251/2000\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 1.8761 - accuracy: 0.2199 - val_loss: 1.8880 - val_accuracy: 0.2466\n",
            "Epoch 252/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8739 - accuracy: 0.2199 - val_loss: 1.8877 - val_accuracy: 0.2466\n",
            "Epoch 253/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8709 - accuracy: 0.2199 - val_loss: 1.8877 - val_accuracy: 0.2466\n",
            "Epoch 254/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8727 - accuracy: 0.2199 - val_loss: 1.8877 - val_accuracy: 0.2466\n",
            "Epoch 255/2000\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 1.8738 - accuracy: 0.2199 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 256/2000\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 1.8752 - accuracy: 0.2199 - val_loss: 1.8871 - val_accuracy: 0.2466\n",
            "Epoch 257/2000\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 1.8739 - accuracy: 0.2199 - val_loss: 1.8868 - val_accuracy: 0.2466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuhTbiRh-_BF"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6V3fBm--8D0"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUPEhyKc_3FT"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtI3WUpk--cl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        },
        "outputId": "60971970-bcad-405d-ae5d-cc50a09c6bcb"
      },
      "source": [
        "np.set_printoptions(precision=2)\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "class newmodel(MLPClassifier):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "    def predict(self, X):\n",
        "        y = self.model.predict(X)\n",
        "        return np.argmax(y,axis=1)\n",
        "\n",
        "model1 = newmodel(model)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
        "                  (\"Normalized confusion matrix\", 'true')]\n",
        "\n",
        "for title, normalize in titles_options:\n",
        "    disp = plot_confusion_matrix(model1, X_test, y_test,\n",
        "                                 display_labels=uniqueValues,\n",
        "                                 cmap=plt.cm.Blues,\n",
        "                                 normalize=normalize)\n",
        "    disp.ax_.set_title(title)\n",
        "\n",
        "    print(title)\n",
        "    print(disp.confusion_matrix)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[ 0  0  0  0 11  0  0]\n",
            " [ 0  0  0  0 16  0  0]\n",
            " [ 0  0  0  0  6  0  0]\n",
            " [ 0  0  0  0  9  0  0]\n",
            " [ 0  0  0  0 10  0  0]\n",
            " [ 0  0  0  0  3  0  0]\n",
            " [ 0  0  0  0 18  0  0]]\n",
            "Normalized confusion matrix\n",
            "[[0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hdE6EQfZ6tU"
      },
      "source": [
        "### Evaluation and Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gLH2mdEZ74z",
        "outputId": "c227952d-b860-4063-9df1-95e480dbc20b"
      },
      "source": [
        "# Evaluate our model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Model loss on the test set: {loss}\")\n",
        "print(f\"Model accuracy on the test set: {100*accuracy:.2f}%\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 31ms/step - loss: 1.8663 - accuracy: 0.1370\n",
            "Model loss on the test set: 1.8663477897644043\n",
            "Model accuracy on the test set: 13.70%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Zr5zUN7waFYr",
        "outputId": "5a198084-0f5e-4e9e-b769-5ab6ff58ca00"
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history_1.history['loss'])#[5:])\n",
        "plt.plot(history_1.history['val_loss'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Ol8la_eiaHBH",
        "outputId": "58e38ffe-13ce-4535-fc90-27e28942448e"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history_1.history['accuracy'])#[5:])\n",
        "plt.plot(history_1.history['val_accuracy'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Binary Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvLBB1x4c9g2"
      },
      "source": [
        "## Model 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTEe3fbAc9g3"
      },
      "source": [
        "### Declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd08u9vRc9g3"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model_2 = keras.Sequential([\n",
        "    layers.Dense(512, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(256, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(128, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "model_2.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate = .0003),\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    patience=250,\n",
        "    min_delta=0.0001,\n",
        "    restore_best_weights=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUgoNB_Ic9g3"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHPgDrOyc9g4",
        "outputId": "8e05d1ae-8ff4-4871-9f55-316fb9543263"
      },
      "source": [
        "history_2 = model_2.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=2000,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1, \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "10/10 [==============================] - 1s 36ms/step - loss: 1.9899 - accuracy: 0.1856 - val_loss: 1.9204 - val_accuracy: 0.2466\n",
            "Epoch 2/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9459 - accuracy: 0.2027 - val_loss: 1.9368 - val_accuracy: 0.2466\n",
            "Epoch 3/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9410 - accuracy: 0.1787 - val_loss: 1.9181 - val_accuracy: 0.2466\n",
            "Epoch 4/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9096 - accuracy: 0.2131 - val_loss: 1.9360 - val_accuracy: 0.1233\n",
            "Epoch 5/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8897 - accuracy: 0.2199 - val_loss: 1.8801 - val_accuracy: 0.2466\n",
            "Epoch 6/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9329 - accuracy: 0.2027 - val_loss: 1.8763 - val_accuracy: 0.2466\n",
            "Epoch 7/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9016 - accuracy: 0.2268 - val_loss: 1.8795 - val_accuracy: 0.2466\n",
            "Epoch 8/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9305 - accuracy: 0.1753 - val_loss: 1.9101 - val_accuracy: 0.1233\n",
            "Epoch 9/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9260 - accuracy: 0.1718 - val_loss: 1.8958 - val_accuracy: 0.2466\n",
            "Epoch 10/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8918 - accuracy: 0.2096 - val_loss: 1.8782 - val_accuracy: 0.2466\n",
            "Epoch 11/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9363 - accuracy: 0.1753 - val_loss: 1.8799 - val_accuracy: 0.2466\n",
            "Epoch 12/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8866 - accuracy: 0.2371 - val_loss: 1.8970 - val_accuracy: 0.2466\n",
            "Epoch 13/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8847 - accuracy: 0.1924 - val_loss: 1.9108 - val_accuracy: 0.1233\n",
            "Epoch 14/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8944 - accuracy: 0.2165 - val_loss: 1.9101 - val_accuracy: 0.1233\n",
            "Epoch 15/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9024 - accuracy: 0.1959 - val_loss: 1.8947 - val_accuracy: 0.2466\n",
            "Epoch 16/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8828 - accuracy: 0.2027 - val_loss: 1.8896 - val_accuracy: 0.1233\n",
            "Epoch 17/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9034 - accuracy: 0.2096 - val_loss: 1.8771 - val_accuracy: 0.1233\n",
            "Epoch 18/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8941 - accuracy: 0.1959 - val_loss: 1.8752 - val_accuracy: 0.2466\n",
            "Epoch 19/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8893 - accuracy: 0.2302 - val_loss: 1.8800 - val_accuracy: 0.2466\n",
            "Epoch 20/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8753 - accuracy: 0.1890 - val_loss: 1.8747 - val_accuracy: 0.2466\n",
            "Epoch 21/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8979 - accuracy: 0.2234 - val_loss: 1.8790 - val_accuracy: 0.2466\n",
            "Epoch 22/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8821 - accuracy: 0.2199 - val_loss: 1.8932 - val_accuracy: 0.2466\n",
            "Epoch 23/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9011 - accuracy: 0.2371 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 24/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9011 - accuracy: 0.2096 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 25/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9074 - accuracy: 0.1787 - val_loss: 1.8949 - val_accuracy: 0.2466\n",
            "Epoch 26/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8808 - accuracy: 0.2131 - val_loss: 1.9126 - val_accuracy: 0.2466\n",
            "Epoch 27/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9201 - accuracy: 0.2199 - val_loss: 1.9098 - val_accuracy: 0.2466\n",
            "Epoch 28/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8885 - accuracy: 0.2131 - val_loss: 1.9039 - val_accuracy: 0.2466\n",
            "Epoch 29/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8855 - accuracy: 0.2509 - val_loss: 1.8972 - val_accuracy: 0.3562\n",
            "Epoch 30/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8860 - accuracy: 0.2337 - val_loss: 1.8975 - val_accuracy: 0.1233\n",
            "Epoch 31/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8821 - accuracy: 0.2062 - val_loss: 1.8960 - val_accuracy: 0.1233\n",
            "Epoch 32/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8973 - accuracy: 0.2371 - val_loss: 1.8950 - val_accuracy: 0.2466\n",
            "Epoch 33/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8902 - accuracy: 0.2268 - val_loss: 1.8961 - val_accuracy: 0.2466\n",
            "Epoch 34/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8844 - accuracy: 0.2096 - val_loss: 1.8946 - val_accuracy: 0.2466\n",
            "Epoch 35/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8891 - accuracy: 0.2440 - val_loss: 1.8858 - val_accuracy: 0.2466\n",
            "Epoch 36/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8807 - accuracy: 0.2062 - val_loss: 1.8804 - val_accuracy: 0.2466\n",
            "Epoch 37/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8853 - accuracy: 0.2371 - val_loss: 1.8881 - val_accuracy: 0.2466\n",
            "Epoch 38/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8821 - accuracy: 0.2268 - val_loss: 1.8911 - val_accuracy: 0.2466\n",
            "Epoch 39/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8837 - accuracy: 0.2199 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 40/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8928 - accuracy: 0.2165 - val_loss: 1.8885 - val_accuracy: 0.2466\n",
            "Epoch 41/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8911 - accuracy: 0.2165 - val_loss: 1.8946 - val_accuracy: 0.2466\n",
            "Epoch 42/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8800 - accuracy: 0.1924 - val_loss: 1.8916 - val_accuracy: 0.2466\n",
            "Epoch 43/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8843 - accuracy: 0.2302 - val_loss: 1.8945 - val_accuracy: 0.3562\n",
            "Epoch 44/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8892 - accuracy: 0.2199 - val_loss: 1.8834 - val_accuracy: 0.2466\n",
            "Epoch 45/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8869 - accuracy: 0.1959 - val_loss: 1.8808 - val_accuracy: 0.2466\n",
            "Epoch 46/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8688 - accuracy: 0.2131 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 47/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8814 - accuracy: 0.2268 - val_loss: 1.8844 - val_accuracy: 0.2466\n",
            "Epoch 48/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8763 - accuracy: 0.2234 - val_loss: 1.8920 - val_accuracy: 0.2466\n",
            "Epoch 49/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8739 - accuracy: 0.2268 - val_loss: 1.8892 - val_accuracy: 0.2466\n",
            "Epoch 50/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8921 - accuracy: 0.2165 - val_loss: 1.8885 - val_accuracy: 0.2466\n",
            "Epoch 51/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8732 - accuracy: 0.2131 - val_loss: 1.8922 - val_accuracy: 0.2466\n",
            "Epoch 52/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8901 - accuracy: 0.1959 - val_loss: 1.8917 - val_accuracy: 0.2466\n",
            "Epoch 53/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8679 - accuracy: 0.2268 - val_loss: 1.8833 - val_accuracy: 0.2603\n",
            "Epoch 54/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8815 - accuracy: 0.2612 - val_loss: 1.8858 - val_accuracy: 0.3425\n",
            "Epoch 55/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8697 - accuracy: 0.2096 - val_loss: 1.8915 - val_accuracy: 0.1233\n",
            "Epoch 56/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8940 - accuracy: 0.2302 - val_loss: 1.8944 - val_accuracy: 0.1233\n",
            "Epoch 57/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8772 - accuracy: 0.2405 - val_loss: 1.8920 - val_accuracy: 0.1233\n",
            "Epoch 58/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8817 - accuracy: 0.2474 - val_loss: 1.8773 - val_accuracy: 0.2055\n",
            "Epoch 59/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8686 - accuracy: 0.2337 - val_loss: 1.8713 - val_accuracy: 0.2466\n",
            "Epoch 60/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8725 - accuracy: 0.2474 - val_loss: 1.8746 - val_accuracy: 0.2466\n",
            "Epoch 61/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8848 - accuracy: 0.2268 - val_loss: 1.8704 - val_accuracy: 0.2466\n",
            "Epoch 62/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8717 - accuracy: 0.2199 - val_loss: 1.8659 - val_accuracy: 0.2466\n",
            "Epoch 63/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8711 - accuracy: 0.2302 - val_loss: 1.8706 - val_accuracy: 0.2466\n",
            "Epoch 64/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8657 - accuracy: 0.2302 - val_loss: 1.8716 - val_accuracy: 0.2466\n",
            "Epoch 65/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8808 - accuracy: 0.2199 - val_loss: 1.8668 - val_accuracy: 0.3151\n",
            "Epoch 66/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8627 - accuracy: 0.2955 - val_loss: 1.8673 - val_accuracy: 0.3699\n",
            "Epoch 67/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8618 - accuracy: 0.2405 - val_loss: 1.8599 - val_accuracy: 0.2603\n",
            "Epoch 68/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8636 - accuracy: 0.2337 - val_loss: 1.8594 - val_accuracy: 0.2466\n",
            "Epoch 69/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8568 - accuracy: 0.2749 - val_loss: 1.8560 - val_accuracy: 0.2466\n",
            "Epoch 70/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8708 - accuracy: 0.2405 - val_loss: 1.8617 - val_accuracy: 0.2466\n",
            "Epoch 71/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8825 - accuracy: 0.2199 - val_loss: 1.8641 - val_accuracy: 0.2466\n",
            "Epoch 72/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8636 - accuracy: 0.2474 - val_loss: 1.8614 - val_accuracy: 0.2466\n",
            "Epoch 73/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8518 - accuracy: 0.2715 - val_loss: 1.8505 - val_accuracy: 0.2466\n",
            "Epoch 74/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8640 - accuracy: 0.2440 - val_loss: 1.8424 - val_accuracy: 0.2466\n",
            "Epoch 75/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8583 - accuracy: 0.2577 - val_loss: 1.8431 - val_accuracy: 0.3151\n",
            "Epoch 76/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8643 - accuracy: 0.3024 - val_loss: 1.8264 - val_accuracy: 0.2603\n",
            "Epoch 77/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8422 - accuracy: 0.2543 - val_loss: 1.8283 - val_accuracy: 0.2466\n",
            "Epoch 78/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8396 - accuracy: 0.2680 - val_loss: 1.8355 - val_accuracy: 0.3699\n",
            "Epoch 79/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8536 - accuracy: 0.2749 - val_loss: 1.8157 - val_accuracy: 0.2603\n",
            "Epoch 80/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8442 - accuracy: 0.2921 - val_loss: 1.8048 - val_accuracy: 0.3699\n",
            "Epoch 81/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8426 - accuracy: 0.2887 - val_loss: 1.7915 - val_accuracy: 0.3014\n",
            "Epoch 82/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8248 - accuracy: 0.2818 - val_loss: 1.7868 - val_accuracy: 0.3699\n",
            "Epoch 83/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8128 - accuracy: 0.2749 - val_loss: 1.7792 - val_accuracy: 0.3014\n",
            "Epoch 84/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8568 - accuracy: 0.2818 - val_loss: 1.7522 - val_accuracy: 0.3288\n",
            "Epoch 85/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8098 - accuracy: 0.2784 - val_loss: 1.7504 - val_accuracy: 0.3699\n",
            "Epoch 86/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8059 - accuracy: 0.2990 - val_loss: 1.7585 - val_accuracy: 0.3014\n",
            "Epoch 87/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7903 - accuracy: 0.3368 - val_loss: 1.7446 - val_accuracy: 0.2603\n",
            "Epoch 88/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7793 - accuracy: 0.3196 - val_loss: 1.7001 - val_accuracy: 0.3699\n",
            "Epoch 89/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7744 - accuracy: 0.3127 - val_loss: 1.7828 - val_accuracy: 0.2740\n",
            "Epoch 90/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7713 - accuracy: 0.3127 - val_loss: 1.6506 - val_accuracy: 0.3562\n",
            "Epoch 91/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7496 - accuracy: 0.3333 - val_loss: 1.6615 - val_accuracy: 0.3562\n",
            "Epoch 92/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7074 - accuracy: 0.3986 - val_loss: 1.6254 - val_accuracy: 0.3562\n",
            "Epoch 93/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6802 - accuracy: 0.3814 - val_loss: 1.6550 - val_accuracy: 0.3151\n",
            "Epoch 94/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6708 - accuracy: 0.3780 - val_loss: 1.5539 - val_accuracy: 0.3699\n",
            "Epoch 95/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6138 - accuracy: 0.4158 - val_loss: 1.5708 - val_accuracy: 0.3699\n",
            "Epoch 96/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5997 - accuracy: 0.4227 - val_loss: 1.5482 - val_accuracy: 0.3699\n",
            "Epoch 97/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5853 - accuracy: 0.4089 - val_loss: 1.5999 - val_accuracy: 0.3151\n",
            "Epoch 98/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6466 - accuracy: 0.3608 - val_loss: 1.5208 - val_accuracy: 0.3699\n",
            "Epoch 99/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6461 - accuracy: 0.3711 - val_loss: 1.4938 - val_accuracy: 0.3699\n",
            "Epoch 100/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.5707 - accuracy: 0.4021 - val_loss: 1.4876 - val_accuracy: 0.3699\n",
            "Epoch 101/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5520 - accuracy: 0.4055 - val_loss: 1.4994 - val_accuracy: 0.3699\n",
            "Epoch 102/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5216 - accuracy: 0.4261 - val_loss: 1.4598 - val_accuracy: 0.3699\n",
            "Epoch 103/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5297 - accuracy: 0.4055 - val_loss: 1.5262 - val_accuracy: 0.3151\n",
            "Epoch 104/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5750 - accuracy: 0.3883 - val_loss: 1.5114 - val_accuracy: 0.3288\n",
            "Epoch 105/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5508 - accuracy: 0.3883 - val_loss: 1.5118 - val_accuracy: 0.3425\n",
            "Epoch 106/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5417 - accuracy: 0.3986 - val_loss: 1.4639 - val_accuracy: 0.3699\n",
            "Epoch 107/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5699 - accuracy: 0.3849 - val_loss: 1.5327 - val_accuracy: 0.3151\n",
            "Epoch 108/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6745 - accuracy: 0.3471 - val_loss: 1.4863 - val_accuracy: 0.3699\n",
            "Epoch 109/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6007 - accuracy: 0.3883 - val_loss: 1.5419 - val_accuracy: 0.3562\n",
            "Epoch 110/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5367 - accuracy: 0.4124 - val_loss: 1.4456 - val_accuracy: 0.3699\n",
            "Epoch 111/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4900 - accuracy: 0.4192 - val_loss: 1.4315 - val_accuracy: 0.3699\n",
            "Epoch 112/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4631 - accuracy: 0.4192 - val_loss: 1.4273 - val_accuracy: 0.3699\n",
            "Epoch 113/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4590 - accuracy: 0.4227 - val_loss: 1.4204 - val_accuracy: 0.3699\n",
            "Epoch 114/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4291 - accuracy: 0.4124 - val_loss: 1.4287 - val_accuracy: 0.3699\n",
            "Epoch 115/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5105 - accuracy: 0.4089 - val_loss: 1.5691 - val_accuracy: 0.3973\n",
            "Epoch 116/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5738 - accuracy: 0.3883 - val_loss: 1.4225 - val_accuracy: 0.3699\n",
            "Epoch 117/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5680 - accuracy: 0.3608 - val_loss: 1.4041 - val_accuracy: 0.3699\n",
            "Epoch 118/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4379 - accuracy: 0.4192 - val_loss: 1.4097 - val_accuracy: 0.3699\n",
            "Epoch 119/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4349 - accuracy: 0.4261 - val_loss: 1.4596 - val_accuracy: 0.3699\n",
            "Epoch 120/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4335 - accuracy: 0.4227 - val_loss: 1.4252 - val_accuracy: 0.3699\n",
            "Epoch 121/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4498 - accuracy: 0.4261 - val_loss: 1.4304 - val_accuracy: 0.3699\n",
            "Epoch 122/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4132 - accuracy: 0.4330 - val_loss: 1.4163 - val_accuracy: 0.3836\n",
            "Epoch 123/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4246 - accuracy: 0.4124 - val_loss: 1.4043 - val_accuracy: 0.3699\n",
            "Epoch 124/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4146 - accuracy: 0.4261 - val_loss: 1.3995 - val_accuracy: 0.3699\n",
            "Epoch 125/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.3998 - accuracy: 0.4261 - val_loss: 1.4017 - val_accuracy: 0.3836\n",
            "Epoch 126/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5168 - accuracy: 0.4055 - val_loss: 1.3963 - val_accuracy: 0.3699\n",
            "Epoch 127/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4652 - accuracy: 0.4158 - val_loss: 1.4320 - val_accuracy: 0.3836\n",
            "Epoch 128/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4557 - accuracy: 0.4158 - val_loss: 1.4748 - val_accuracy: 0.3562\n",
            "Epoch 129/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4595 - accuracy: 0.4158 - val_loss: 1.3975 - val_accuracy: 0.3699\n",
            "Epoch 130/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4252 - accuracy: 0.4364 - val_loss: 1.4105 - val_accuracy: 0.3836\n",
            "Epoch 131/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.3960 - accuracy: 0.4261 - val_loss: 1.3769 - val_accuracy: 0.3699\n",
            "Epoch 132/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.3824 - accuracy: 0.4296 - val_loss: 1.3752 - val_accuracy: 0.3699\n",
            "Epoch 133/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.3816 - accuracy: 0.4330 - val_loss: 1.4003 - val_accuracy: 0.3973\n",
            "Epoch 134/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5426 - accuracy: 0.3746 - val_loss: 1.4770 - val_accuracy: 0.3562\n",
            "Epoch 135/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5766 - accuracy: 0.3814 - val_loss: 1.5091 - val_accuracy: 0.3425\n",
            "Epoch 136/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5559 - accuracy: 0.3986 - val_loss: 1.6507 - val_accuracy: 0.2877\n",
            "Epoch 137/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6260 - accuracy: 0.3505 - val_loss: 1.4669 - val_accuracy: 0.3699\n",
            "Epoch 138/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5609 - accuracy: 0.3918 - val_loss: 1.4552 - val_accuracy: 0.3836\n",
            "Epoch 139/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5279 - accuracy: 0.4055 - val_loss: 1.4913 - val_accuracy: 0.3425\n",
            "Epoch 140/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4824 - accuracy: 0.3952 - val_loss: 1.4373 - val_accuracy: 0.3699\n",
            "Epoch 141/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5070 - accuracy: 0.4158 - val_loss: 1.4143 - val_accuracy: 0.3699\n",
            "Epoch 142/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4711 - accuracy: 0.3986 - val_loss: 1.5481 - val_accuracy: 0.3014\n",
            "Epoch 143/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5735 - accuracy: 0.3883 - val_loss: 1.3915 - val_accuracy: 0.3699\n",
            "Epoch 144/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5413 - accuracy: 0.3814 - val_loss: 1.4892 - val_accuracy: 0.3425\n",
            "Epoch 145/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6841 - accuracy: 0.3677 - val_loss: 1.5847 - val_accuracy: 0.3699\n",
            "Epoch 146/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6338 - accuracy: 0.3849 - val_loss: 1.5018 - val_accuracy: 0.3836\n",
            "Epoch 147/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5606 - accuracy: 0.3952 - val_loss: 1.4390 - val_accuracy: 0.3699\n",
            "Epoch 148/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5776 - accuracy: 0.4192 - val_loss: 1.4371 - val_accuracy: 0.3699\n",
            "Epoch 149/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5698 - accuracy: 0.4021 - val_loss: 1.4448 - val_accuracy: 0.3836\n",
            "Epoch 150/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5869 - accuracy: 0.3849 - val_loss: 1.5571 - val_accuracy: 0.3973\n",
            "Epoch 151/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5844 - accuracy: 0.3986 - val_loss: 1.4521 - val_accuracy: 0.3699\n",
            "Epoch 152/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5289 - accuracy: 0.3986 - val_loss: 1.4434 - val_accuracy: 0.3699\n",
            "Epoch 153/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5071 - accuracy: 0.4055 - val_loss: 1.4571 - val_accuracy: 0.3699\n",
            "Epoch 154/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5112 - accuracy: 0.4192 - val_loss: 1.4071 - val_accuracy: 0.3699\n",
            "Epoch 155/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6443 - accuracy: 0.3849 - val_loss: 1.4160 - val_accuracy: 0.3699\n",
            "Epoch 156/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6746 - accuracy: 0.3918 - val_loss: 1.4664 - val_accuracy: 0.3699\n",
            "Epoch 157/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6231 - accuracy: 0.3883 - val_loss: 1.5041 - val_accuracy: 0.3836\n",
            "Epoch 158/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6702 - accuracy: 0.3677 - val_loss: 1.4954 - val_accuracy: 0.3836\n",
            "Epoch 159/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6224 - accuracy: 0.4055 - val_loss: 1.4845 - val_accuracy: 0.3836\n",
            "Epoch 160/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6435 - accuracy: 0.3780 - val_loss: 1.4620 - val_accuracy: 0.3699\n",
            "Epoch 161/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6286 - accuracy: 0.3952 - val_loss: 1.4654 - val_accuracy: 0.3836\n",
            "Epoch 162/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6495 - accuracy: 0.3849 - val_loss: 1.4561 - val_accuracy: 0.3699\n",
            "Epoch 163/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6136 - accuracy: 0.3883 - val_loss: 1.4539 - val_accuracy: 0.3699\n",
            "Epoch 164/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5855 - accuracy: 0.4021 - val_loss: 1.5132 - val_accuracy: 0.3699\n",
            "Epoch 165/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6258 - accuracy: 0.3711 - val_loss: 1.4591 - val_accuracy: 0.3699\n",
            "Epoch 166/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6223 - accuracy: 0.3746 - val_loss: 1.5393 - val_accuracy: 0.3288\n",
            "Epoch 167/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6432 - accuracy: 0.3849 - val_loss: 1.4433 - val_accuracy: 0.3699\n",
            "Epoch 168/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6296 - accuracy: 0.3814 - val_loss: 1.4378 - val_accuracy: 0.3699\n",
            "Epoch 169/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5721 - accuracy: 0.4261 - val_loss: 1.4459 - val_accuracy: 0.3836\n",
            "Epoch 170/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5976 - accuracy: 0.3918 - val_loss: 1.4422 - val_accuracy: 0.3699\n",
            "Epoch 171/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5989 - accuracy: 0.4021 - val_loss: 1.5012 - val_accuracy: 0.3425\n",
            "Epoch 172/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6919 - accuracy: 0.3643 - val_loss: 1.4357 - val_accuracy: 0.3699\n",
            "Epoch 173/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6760 - accuracy: 0.3574 - val_loss: 1.4876 - val_accuracy: 0.3836\n",
            "Epoch 174/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6150 - accuracy: 0.3883 - val_loss: 1.4540 - val_accuracy: 0.3699\n",
            "Epoch 175/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5560 - accuracy: 0.4021 - val_loss: 1.4447 - val_accuracy: 0.3699\n",
            "Epoch 176/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6318 - accuracy: 0.3814 - val_loss: 1.4482 - val_accuracy: 0.3699\n",
            "Epoch 177/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6200 - accuracy: 0.3711 - val_loss: 1.4619 - val_accuracy: 0.3836\n",
            "Epoch 178/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6123 - accuracy: 0.4158 - val_loss: 1.4757 - val_accuracy: 0.3836\n",
            "Epoch 179/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6252 - accuracy: 0.3986 - val_loss: 1.5221 - val_accuracy: 0.3562\n",
            "Epoch 180/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6370 - accuracy: 0.3849 - val_loss: 1.5217 - val_accuracy: 0.3836\n",
            "Epoch 181/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6251 - accuracy: 0.3814 - val_loss: 1.5450 - val_accuracy: 0.3836\n",
            "Epoch 182/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6276 - accuracy: 0.3883 - val_loss: 1.5438 - val_accuracy: 0.3425\n",
            "Epoch 183/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6207 - accuracy: 0.3849 - val_loss: 1.5142 - val_accuracy: 0.3836\n",
            "Epoch 184/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6528 - accuracy: 0.3711 - val_loss: 1.4686 - val_accuracy: 0.3836\n",
            "Epoch 185/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5756 - accuracy: 0.4089 - val_loss: 1.4622 - val_accuracy: 0.3836\n",
            "Epoch 186/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6148 - accuracy: 0.3883 - val_loss: 1.4719 - val_accuracy: 0.3836\n",
            "Epoch 187/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6193 - accuracy: 0.3849 - val_loss: 1.4379 - val_accuracy: 0.3699\n",
            "Epoch 188/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6281 - accuracy: 0.3883 - val_loss: 1.4710 - val_accuracy: 0.3836\n",
            "Epoch 189/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5727 - accuracy: 0.4021 - val_loss: 1.4391 - val_accuracy: 0.3836\n",
            "Epoch 190/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6099 - accuracy: 0.3918 - val_loss: 1.4453 - val_accuracy: 0.3836\n",
            "Epoch 191/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5355 - accuracy: 0.4021 - val_loss: 1.4375 - val_accuracy: 0.3699\n",
            "Epoch 192/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6291 - accuracy: 0.3849 - val_loss: 1.4525 - val_accuracy: 0.3836\n",
            "Epoch 193/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6145 - accuracy: 0.3711 - val_loss: 1.4879 - val_accuracy: 0.3973\n",
            "Epoch 194/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6236 - accuracy: 0.3883 - val_loss: 1.4701 - val_accuracy: 0.3973\n",
            "Epoch 195/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5522 - accuracy: 0.4124 - val_loss: 1.4654 - val_accuracy: 0.3836\n",
            "Epoch 196/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6429 - accuracy: 0.3746 - val_loss: 1.4531 - val_accuracy: 0.3699\n",
            "Epoch 197/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6070 - accuracy: 0.4021 - val_loss: 1.4529 - val_accuracy: 0.3836\n",
            "Epoch 198/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6246 - accuracy: 0.3883 - val_loss: 1.5108 - val_accuracy: 0.4110\n",
            "Epoch 199/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5944 - accuracy: 0.3883 - val_loss: 1.4446 - val_accuracy: 0.3699\n",
            "Epoch 200/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6287 - accuracy: 0.3780 - val_loss: 1.4480 - val_accuracy: 0.3836\n",
            "Epoch 201/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5787 - accuracy: 0.3986 - val_loss: 1.4416 - val_accuracy: 0.3836\n",
            "Epoch 202/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5727 - accuracy: 0.3986 - val_loss: 1.4311 - val_accuracy: 0.3836\n",
            "Epoch 203/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5717 - accuracy: 0.3849 - val_loss: 1.4265 - val_accuracy: 0.3836\n",
            "Epoch 204/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5574 - accuracy: 0.4089 - val_loss: 1.4197 - val_accuracy: 0.3836\n",
            "Epoch 205/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5845 - accuracy: 0.4055 - val_loss: 1.4149 - val_accuracy: 0.3836\n",
            "Epoch 206/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6064 - accuracy: 0.3849 - val_loss: 1.4314 - val_accuracy: 0.4247\n",
            "Epoch 207/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6527 - accuracy: 0.3952 - val_loss: 1.4482 - val_accuracy: 0.3973\n",
            "Epoch 208/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5939 - accuracy: 0.4055 - val_loss: 1.4561 - val_accuracy: 0.4247\n",
            "Epoch 209/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6040 - accuracy: 0.4192 - val_loss: 1.4499 - val_accuracy: 0.4384\n",
            "Epoch 210/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6243 - accuracy: 0.3952 - val_loss: 1.4407 - val_accuracy: 0.3973\n",
            "Epoch 211/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6216 - accuracy: 0.3986 - val_loss: 1.4297 - val_accuracy: 0.3836\n",
            "Epoch 212/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5885 - accuracy: 0.4089 - val_loss: 1.4355 - val_accuracy: 0.3836\n",
            "Epoch 213/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6493 - accuracy: 0.3505 - val_loss: 1.4694 - val_accuracy: 0.4247\n",
            "Epoch 214/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5856 - accuracy: 0.3986 - val_loss: 1.4322 - val_accuracy: 0.3973\n",
            "Epoch 215/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5986 - accuracy: 0.3986 - val_loss: 1.4586 - val_accuracy: 0.4247\n",
            "Epoch 216/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5546 - accuracy: 0.4124 - val_loss: 1.4883 - val_accuracy: 0.3699\n",
            "Epoch 217/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7074 - accuracy: 0.3608 - val_loss: 1.6052 - val_accuracy: 0.3425\n",
            "Epoch 218/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6284 - accuracy: 0.3952 - val_loss: 1.4416 - val_accuracy: 0.3836\n",
            "Epoch 219/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6051 - accuracy: 0.3986 - val_loss: 1.4478 - val_accuracy: 0.3836\n",
            "Epoch 220/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6093 - accuracy: 0.4055 - val_loss: 1.4514 - val_accuracy: 0.3973\n",
            "Epoch 221/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5991 - accuracy: 0.3952 - val_loss: 1.4553 - val_accuracy: 0.4110\n",
            "Epoch 222/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5980 - accuracy: 0.4021 - val_loss: 1.4233 - val_accuracy: 0.3973\n",
            "Epoch 223/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5683 - accuracy: 0.3986 - val_loss: 1.4303 - val_accuracy: 0.3836\n",
            "Epoch 224/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5798 - accuracy: 0.4089 - val_loss: 1.4336 - val_accuracy: 0.3836\n",
            "Epoch 225/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5395 - accuracy: 0.4158 - val_loss: 1.4612 - val_accuracy: 0.4247\n",
            "Epoch 226/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6147 - accuracy: 0.3918 - val_loss: 1.4810 - val_accuracy: 0.4110\n",
            "Epoch 227/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5945 - accuracy: 0.3780 - val_loss: 1.4236 - val_accuracy: 0.3836\n",
            "Epoch 228/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6257 - accuracy: 0.4021 - val_loss: 1.4710 - val_accuracy: 0.4384\n",
            "Epoch 229/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5921 - accuracy: 0.3986 - val_loss: 1.4181 - val_accuracy: 0.3836\n",
            "Epoch 230/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5600 - accuracy: 0.4158 - val_loss: 1.4152 - val_accuracy: 0.3973\n",
            "Epoch 231/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5883 - accuracy: 0.3814 - val_loss: 1.4418 - val_accuracy: 0.4247\n",
            "Epoch 232/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5528 - accuracy: 0.3918 - val_loss: 1.4574 - val_accuracy: 0.4384\n",
            "Epoch 233/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6315 - accuracy: 0.4055 - val_loss: 1.4270 - val_accuracy: 0.3973\n",
            "Epoch 234/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6085 - accuracy: 0.4055 - val_loss: 1.4370 - val_accuracy: 0.4247\n",
            "Epoch 235/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5757 - accuracy: 0.4089 - val_loss: 1.5057 - val_accuracy: 0.4110\n",
            "Epoch 236/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5349 - accuracy: 0.4158 - val_loss: 1.4238 - val_accuracy: 0.4110\n",
            "Epoch 237/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5640 - accuracy: 0.4158 - val_loss: 1.4098 - val_accuracy: 0.4110\n",
            "Epoch 238/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5792 - accuracy: 0.4158 - val_loss: 1.5072 - val_accuracy: 0.4110\n",
            "Epoch 239/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6284 - accuracy: 0.3918 - val_loss: 1.4182 - val_accuracy: 0.4110\n",
            "Epoch 240/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5926 - accuracy: 0.3814 - val_loss: 1.4051 - val_accuracy: 0.3973\n",
            "Epoch 241/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5259 - accuracy: 0.4021 - val_loss: 1.4333 - val_accuracy: 0.4384\n",
            "Epoch 242/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5765 - accuracy: 0.4192 - val_loss: 1.3916 - val_accuracy: 0.4247\n",
            "Epoch 243/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5981 - accuracy: 0.3883 - val_loss: 1.5059 - val_accuracy: 0.3699\n",
            "Epoch 244/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5737 - accuracy: 0.3952 - val_loss: 1.4027 - val_accuracy: 0.4247\n",
            "Epoch 245/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6438 - accuracy: 0.3952 - val_loss: 1.4006 - val_accuracy: 0.4110\n",
            "Epoch 246/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6214 - accuracy: 0.3986 - val_loss: 1.4334 - val_accuracy: 0.3973\n",
            "Epoch 247/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6817 - accuracy: 0.3711 - val_loss: 1.5306 - val_accuracy: 0.4110\n",
            "Epoch 248/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5675 - accuracy: 0.4227 - val_loss: 1.4289 - val_accuracy: 0.3973\n",
            "Epoch 249/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5912 - accuracy: 0.3746 - val_loss: 1.4645 - val_accuracy: 0.4384\n",
            "Epoch 250/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5651 - accuracy: 0.4055 - val_loss: 1.4458 - val_accuracy: 0.4247\n",
            "Epoch 251/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5619 - accuracy: 0.4089 - val_loss: 1.4158 - val_accuracy: 0.4110\n",
            "Epoch 252/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5871 - accuracy: 0.3849 - val_loss: 1.4871 - val_accuracy: 0.4384\n",
            "Epoch 253/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5728 - accuracy: 0.4330 - val_loss: 1.4238 - val_accuracy: 0.4247\n",
            "Epoch 254/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6334 - accuracy: 0.4192 - val_loss: 1.4473 - val_accuracy: 0.3836\n",
            "Epoch 255/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6013 - accuracy: 0.4192 - val_loss: 1.4341 - val_accuracy: 0.4247\n",
            "Epoch 256/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5996 - accuracy: 0.3918 - val_loss: 1.5103 - val_accuracy: 0.4247\n",
            "Epoch 257/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6116 - accuracy: 0.4158 - val_loss: 1.4582 - val_accuracy: 0.4658\n",
            "Epoch 258/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5838 - accuracy: 0.4261 - val_loss: 1.4767 - val_accuracy: 0.4384\n",
            "Epoch 259/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5886 - accuracy: 0.4021 - val_loss: 1.4449 - val_accuracy: 0.4521\n",
            "Epoch 260/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5471 - accuracy: 0.4124 - val_loss: 1.4246 - val_accuracy: 0.3973\n",
            "Epoch 261/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5903 - accuracy: 0.3952 - val_loss: 1.4241 - val_accuracy: 0.4247\n",
            "Epoch 262/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5858 - accuracy: 0.3986 - val_loss: 1.4262 - val_accuracy: 0.4384\n",
            "Epoch 263/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5683 - accuracy: 0.4055 - val_loss: 1.4385 - val_accuracy: 0.4384\n",
            "Epoch 264/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5704 - accuracy: 0.4158 - val_loss: 1.3964 - val_accuracy: 0.4110\n",
            "Epoch 265/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5628 - accuracy: 0.4261 - val_loss: 1.4013 - val_accuracy: 0.4521\n",
            "Epoch 266/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5460 - accuracy: 0.4399 - val_loss: 1.4087 - val_accuracy: 0.4521\n",
            "Epoch 267/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5633 - accuracy: 0.3986 - val_loss: 1.4162 - val_accuracy: 0.4521\n",
            "Epoch 268/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5411 - accuracy: 0.4261 - val_loss: 1.4312 - val_accuracy: 0.4384\n",
            "Epoch 269/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5780 - accuracy: 0.4261 - val_loss: 1.4028 - val_accuracy: 0.4384\n",
            "Epoch 270/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5425 - accuracy: 0.4021 - val_loss: 1.4066 - val_accuracy: 0.4247\n",
            "Epoch 271/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5222 - accuracy: 0.4364 - val_loss: 1.5809 - val_accuracy: 0.3836\n",
            "Epoch 272/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6618 - accuracy: 0.3780 - val_loss: 1.4260 - val_accuracy: 0.4110\n",
            "Epoch 273/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6362 - accuracy: 0.3711 - val_loss: 1.4639 - val_accuracy: 0.4384\n",
            "Epoch 274/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6125 - accuracy: 0.3952 - val_loss: 1.4880 - val_accuracy: 0.4247\n",
            "Epoch 275/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5576 - accuracy: 0.4089 - val_loss: 1.4526 - val_accuracy: 0.4384\n",
            "Epoch 276/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6301 - accuracy: 0.4158 - val_loss: 1.4345 - val_accuracy: 0.4384\n",
            "Epoch 277/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5623 - accuracy: 0.4330 - val_loss: 1.4397 - val_accuracy: 0.4384\n",
            "Epoch 278/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5536 - accuracy: 0.4330 - val_loss: 1.4325 - val_accuracy: 0.4384\n",
            "Epoch 279/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6104 - accuracy: 0.4055 - val_loss: 1.4823 - val_accuracy: 0.4384\n",
            "Epoch 280/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5956 - accuracy: 0.3746 - val_loss: 1.4761 - val_accuracy: 0.4384\n",
            "Epoch 281/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5880 - accuracy: 0.4261 - val_loss: 1.4070 - val_accuracy: 0.4384\n",
            "Epoch 282/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5988 - accuracy: 0.3711 - val_loss: 1.4372 - val_accuracy: 0.4658\n",
            "Epoch 283/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5437 - accuracy: 0.4192 - val_loss: 1.5251 - val_accuracy: 0.4110\n",
            "Epoch 284/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5628 - accuracy: 0.4124 - val_loss: 1.4068 - val_accuracy: 0.4658\n",
            "Epoch 285/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5538 - accuracy: 0.4124 - val_loss: 1.4058 - val_accuracy: 0.4384\n",
            "Epoch 286/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5576 - accuracy: 0.4433 - val_loss: 1.4304 - val_accuracy: 0.4521\n",
            "Epoch 287/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5381 - accuracy: 0.4261 - val_loss: 1.4627 - val_accuracy: 0.4247\n",
            "Epoch 288/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5773 - accuracy: 0.4124 - val_loss: 1.3875 - val_accuracy: 0.4384\n",
            "Epoch 289/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5588 - accuracy: 0.4261 - val_loss: 1.4000 - val_accuracy: 0.4658\n",
            "Epoch 290/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5998 - accuracy: 0.3986 - val_loss: 1.4824 - val_accuracy: 0.4110\n",
            "Epoch 291/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5223 - accuracy: 0.4261 - val_loss: 1.5353 - val_accuracy: 0.3973\n",
            "Epoch 292/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6120 - accuracy: 0.4261 - val_loss: 1.3959 - val_accuracy: 0.4384\n",
            "Epoch 293/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5954 - accuracy: 0.4227 - val_loss: 1.4192 - val_accuracy: 0.4658\n",
            "Epoch 294/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5634 - accuracy: 0.4296 - val_loss: 1.5257 - val_accuracy: 0.4247\n",
            "Epoch 295/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5372 - accuracy: 0.4433 - val_loss: 1.4238 - val_accuracy: 0.4658\n",
            "Epoch 296/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5483 - accuracy: 0.4399 - val_loss: 1.3994 - val_accuracy: 0.4384\n",
            "Epoch 297/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5689 - accuracy: 0.4227 - val_loss: 1.4482 - val_accuracy: 0.4247\n",
            "Epoch 298/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5350 - accuracy: 0.4433 - val_loss: 1.5410 - val_accuracy: 0.3973\n",
            "Epoch 299/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6311 - accuracy: 0.4158 - val_loss: 1.4608 - val_accuracy: 0.4247\n",
            "Epoch 300/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0148 - accuracy: 0.2680 - val_loss: 1.9967 - val_accuracy: 0.2466\n",
            "Epoch 301/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7931 - accuracy: 0.3196 - val_loss: 1.5967 - val_accuracy: 0.3288\n",
            "Epoch 302/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6718 - accuracy: 0.3643 - val_loss: 1.6305 - val_accuracy: 0.3836\n",
            "Epoch 303/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6287 - accuracy: 0.3986 - val_loss: 1.4896 - val_accuracy: 0.4521\n",
            "Epoch 304/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6154 - accuracy: 0.4399 - val_loss: 1.4781 - val_accuracy: 0.4110\n",
            "Epoch 305/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7089 - accuracy: 0.3505 - val_loss: 1.7087 - val_accuracy: 0.3288\n",
            "Epoch 306/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6514 - accuracy: 0.3746 - val_loss: 1.5372 - val_accuracy: 0.3425\n",
            "Epoch 307/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6168 - accuracy: 0.4021 - val_loss: 1.5750 - val_accuracy: 0.3973\n",
            "Epoch 308/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5953 - accuracy: 0.4192 - val_loss: 1.4433 - val_accuracy: 0.4384\n",
            "Epoch 309/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5521 - accuracy: 0.4330 - val_loss: 1.4536 - val_accuracy: 0.4521\n",
            "Epoch 310/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5439 - accuracy: 0.4467 - val_loss: 1.5132 - val_accuracy: 0.4110\n",
            "Epoch 311/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5950 - accuracy: 0.4330 - val_loss: 1.4403 - val_accuracy: 0.4521\n",
            "Epoch 312/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5920 - accuracy: 0.4227 - val_loss: 1.4280 - val_accuracy: 0.4521\n",
            "Epoch 313/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5509 - accuracy: 0.4399 - val_loss: 1.4167 - val_accuracy: 0.4795\n",
            "Epoch 314/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5704 - accuracy: 0.4192 - val_loss: 1.4930 - val_accuracy: 0.3973\n",
            "Epoch 315/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5472 - accuracy: 0.4261 - val_loss: 1.3878 - val_accuracy: 0.4795\n",
            "Epoch 316/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5497 - accuracy: 0.4399 - val_loss: 1.4822 - val_accuracy: 0.3973\n",
            "Epoch 317/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5681 - accuracy: 0.4124 - val_loss: 1.3800 - val_accuracy: 0.4658\n",
            "Epoch 318/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5304 - accuracy: 0.4502 - val_loss: 1.4087 - val_accuracy: 0.4384\n",
            "Epoch 319/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5414 - accuracy: 0.4399 - val_loss: 1.4194 - val_accuracy: 0.4384\n",
            "Epoch 320/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5475 - accuracy: 0.4296 - val_loss: 1.3869 - val_accuracy: 0.4521\n",
            "Epoch 321/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6043 - accuracy: 0.3986 - val_loss: 1.4578 - val_accuracy: 0.4247\n",
            "Epoch 322/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5450 - accuracy: 0.4227 - val_loss: 1.4952 - val_accuracy: 0.3973\n",
            "Epoch 323/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8172 - accuracy: 0.3024 - val_loss: 1.4217 - val_accuracy: 0.4521\n",
            "Epoch 324/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5732 - accuracy: 0.4055 - val_loss: 1.5212 - val_accuracy: 0.3973\n",
            "Epoch 325/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5756 - accuracy: 0.4124 - val_loss: 1.4286 - val_accuracy: 0.4521\n",
            "Epoch 326/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5585 - accuracy: 0.4261 - val_loss: 1.4170 - val_accuracy: 0.4795\n",
            "Epoch 327/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5705 - accuracy: 0.4158 - val_loss: 1.4560 - val_accuracy: 0.4384\n",
            "Epoch 328/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5348 - accuracy: 0.4399 - val_loss: 1.4723 - val_accuracy: 0.4247\n",
            "Epoch 329/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5391 - accuracy: 0.4502 - val_loss: 1.4141 - val_accuracy: 0.4795\n",
            "Epoch 330/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4821 - accuracy: 0.4708 - val_loss: 1.4007 - val_accuracy: 0.4795\n",
            "Epoch 331/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5495 - accuracy: 0.3918 - val_loss: 1.5552 - val_accuracy: 0.3973\n",
            "Epoch 332/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5986 - accuracy: 0.4192 - val_loss: 1.4082 - val_accuracy: 0.4658\n",
            "Epoch 333/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5134 - accuracy: 0.4502 - val_loss: 1.4135 - val_accuracy: 0.4521\n",
            "Epoch 334/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5194 - accuracy: 0.4467 - val_loss: 1.4871 - val_accuracy: 0.3973\n",
            "Epoch 335/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.6058 - accuracy: 0.3883 - val_loss: 1.4845 - val_accuracy: 0.4110\n",
            "Epoch 336/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5994 - accuracy: 0.4192 - val_loss: 1.4499 - val_accuracy: 0.4247\n",
            "Epoch 337/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5911 - accuracy: 0.4330 - val_loss: 1.4028 - val_accuracy: 0.4932\n",
            "Epoch 338/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5764 - accuracy: 0.4296 - val_loss: 1.5705 - val_accuracy: 0.3973\n",
            "Epoch 339/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6605 - accuracy: 0.3746 - val_loss: 1.4414 - val_accuracy: 0.3973\n",
            "Epoch 340/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6300 - accuracy: 0.4055 - val_loss: 1.5742 - val_accuracy: 0.3699\n",
            "Epoch 341/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5563 - accuracy: 0.3986 - val_loss: 1.5095 - val_accuracy: 0.3973\n",
            "Epoch 342/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5889 - accuracy: 0.3986 - val_loss: 1.3822 - val_accuracy: 0.4795\n",
            "Epoch 343/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5664 - accuracy: 0.4089 - val_loss: 1.4896 - val_accuracy: 0.4110\n",
            "Epoch 344/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5756 - accuracy: 0.4089 - val_loss: 1.4747 - val_accuracy: 0.4247\n",
            "Epoch 345/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5652 - accuracy: 0.4261 - val_loss: 1.3963 - val_accuracy: 0.4795\n",
            "Epoch 346/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5208 - accuracy: 0.4399 - val_loss: 1.5834 - val_accuracy: 0.3699\n",
            "Epoch 347/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5796 - accuracy: 0.4158 - val_loss: 1.3857 - val_accuracy: 0.4932\n",
            "Epoch 348/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5405 - accuracy: 0.4467 - val_loss: 1.4179 - val_accuracy: 0.4384\n",
            "Epoch 349/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5478 - accuracy: 0.4296 - val_loss: 1.4113 - val_accuracy: 0.4384\n",
            "Epoch 350/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5567 - accuracy: 0.4124 - val_loss: 1.5152 - val_accuracy: 0.3973\n",
            "Epoch 351/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5519 - accuracy: 0.4261 - val_loss: 1.3832 - val_accuracy: 0.4795\n",
            "Epoch 352/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4765 - accuracy: 0.4570 - val_loss: 1.4621 - val_accuracy: 0.4110\n",
            "Epoch 353/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5318 - accuracy: 0.4364 - val_loss: 1.4105 - val_accuracy: 0.4384\n",
            "Epoch 354/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5097 - accuracy: 0.4433 - val_loss: 1.4281 - val_accuracy: 0.4384\n",
            "Epoch 355/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5829 - accuracy: 0.4399 - val_loss: 1.3859 - val_accuracy: 0.4658\n",
            "Epoch 356/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4942 - accuracy: 0.4605 - val_loss: 1.3938 - val_accuracy: 0.4384\n",
            "Epoch 357/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5017 - accuracy: 0.4742 - val_loss: 1.5256 - val_accuracy: 0.3973\n",
            "Epoch 358/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4891 - accuracy: 0.4639 - val_loss: 1.3576 - val_accuracy: 0.4932\n",
            "Epoch 359/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5369 - accuracy: 0.4570 - val_loss: 1.4455 - val_accuracy: 0.4384\n",
            "Epoch 360/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5066 - accuracy: 0.4536 - val_loss: 1.3684 - val_accuracy: 0.4932\n",
            "Epoch 361/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5835 - accuracy: 0.4330 - val_loss: 1.5085 - val_accuracy: 0.3973\n",
            "Epoch 362/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5544 - accuracy: 0.4467 - val_loss: 1.4219 - val_accuracy: 0.4384\n",
            "Epoch 363/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6366 - accuracy: 0.4055 - val_loss: 1.3781 - val_accuracy: 0.4521\n",
            "Epoch 364/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5624 - accuracy: 0.4089 - val_loss: 1.5660 - val_accuracy: 0.3973\n",
            "Epoch 365/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5097 - accuracy: 0.4433 - val_loss: 1.3956 - val_accuracy: 0.4384\n",
            "Epoch 366/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5661 - accuracy: 0.4399 - val_loss: 1.3681 - val_accuracy: 0.4932\n",
            "Epoch 367/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5038 - accuracy: 0.4639 - val_loss: 1.4376 - val_accuracy: 0.4384\n",
            "Epoch 368/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5123 - accuracy: 0.4502 - val_loss: 1.4764 - val_accuracy: 0.4247\n",
            "Epoch 369/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5281 - accuracy: 0.4399 - val_loss: 1.4190 - val_accuracy: 0.4384\n",
            "Epoch 370/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5502 - accuracy: 0.4399 - val_loss: 1.4144 - val_accuracy: 0.4384\n",
            "Epoch 371/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5833 - accuracy: 0.4261 - val_loss: 1.3895 - val_accuracy: 0.4795\n",
            "Epoch 372/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5782 - accuracy: 0.4296 - val_loss: 1.6534 - val_accuracy: 0.3699\n",
            "Epoch 373/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5901 - accuracy: 0.4192 - val_loss: 1.4188 - val_accuracy: 0.4384\n",
            "Epoch 374/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5275 - accuracy: 0.4364 - val_loss: 1.3832 - val_accuracy: 0.4795\n",
            "Epoch 375/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5333 - accuracy: 0.4605 - val_loss: 1.4660 - val_accuracy: 0.4247\n",
            "Epoch 376/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5386 - accuracy: 0.4124 - val_loss: 1.4789 - val_accuracy: 0.4110\n",
            "Epoch 377/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5751 - accuracy: 0.4364 - val_loss: 1.5597 - val_accuracy: 0.3836\n",
            "Epoch 378/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5667 - accuracy: 0.4330 - val_loss: 1.3558 - val_accuracy: 0.4932\n",
            "Epoch 379/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5296 - accuracy: 0.4433 - val_loss: 1.4757 - val_accuracy: 0.4247\n",
            "Epoch 380/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5420 - accuracy: 0.4433 - val_loss: 1.4049 - val_accuracy: 0.4384\n",
            "Epoch 381/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5140 - accuracy: 0.4433 - val_loss: 1.4853 - val_accuracy: 0.4110\n",
            "Epoch 382/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4992 - accuracy: 0.4364 - val_loss: 1.4220 - val_accuracy: 0.4521\n",
            "Epoch 383/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5048 - accuracy: 0.4433 - val_loss: 1.3756 - val_accuracy: 0.4795\n",
            "Epoch 384/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5259 - accuracy: 0.4364 - val_loss: 1.4375 - val_accuracy: 0.4384\n",
            "Epoch 385/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5057 - accuracy: 0.4570 - val_loss: 1.4140 - val_accuracy: 0.4384\n",
            "Epoch 386/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4870 - accuracy: 0.4674 - val_loss: 1.5340 - val_accuracy: 0.3973\n",
            "Epoch 387/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5166 - accuracy: 0.4399 - val_loss: 1.3938 - val_accuracy: 0.4521\n",
            "Epoch 388/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5016 - accuracy: 0.4536 - val_loss: 1.3452 - val_accuracy: 0.4932\n",
            "Epoch 389/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5137 - accuracy: 0.4364 - val_loss: 1.5538 - val_accuracy: 0.3973\n",
            "Epoch 390/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5607 - accuracy: 0.4330 - val_loss: 1.3763 - val_accuracy: 0.4521\n",
            "Epoch 391/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5033 - accuracy: 0.4570 - val_loss: 1.4139 - val_accuracy: 0.4384\n",
            "Epoch 392/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5080 - accuracy: 0.4674 - val_loss: 1.4564 - val_accuracy: 0.4247\n",
            "Epoch 393/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4789 - accuracy: 0.4502 - val_loss: 1.4121 - val_accuracy: 0.4384\n",
            "Epoch 394/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4937 - accuracy: 0.4742 - val_loss: 1.5024 - val_accuracy: 0.3973\n",
            "Epoch 395/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5313 - accuracy: 0.4261 - val_loss: 1.3897 - val_accuracy: 0.4521\n",
            "Epoch 396/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5337 - accuracy: 0.4502 - val_loss: 1.3516 - val_accuracy: 0.4795\n",
            "Epoch 397/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5697 - accuracy: 0.4192 - val_loss: 1.4906 - val_accuracy: 0.4247\n",
            "Epoch 398/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5116 - accuracy: 0.4261 - val_loss: 1.4720 - val_accuracy: 0.4247\n",
            "Epoch 399/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5326 - accuracy: 0.4364 - val_loss: 1.4237 - val_accuracy: 0.4384\n",
            "Epoch 400/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5466 - accuracy: 0.4227 - val_loss: 1.3719 - val_accuracy: 0.4658\n",
            "Epoch 401/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5892 - accuracy: 0.4433 - val_loss: 1.3730 - val_accuracy: 0.4795\n",
            "Epoch 402/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.5297 - accuracy: 0.4364 - val_loss: 1.4102 - val_accuracy: 0.4384\n",
            "Epoch 403/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5686 - accuracy: 0.4055 - val_loss: 1.6397 - val_accuracy: 0.3699\n",
            "Epoch 404/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5205 - accuracy: 0.4399 - val_loss: 1.4452 - val_accuracy: 0.4384\n",
            "Epoch 405/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5251 - accuracy: 0.4055 - val_loss: 1.4065 - val_accuracy: 0.4384\n",
            "Epoch 406/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5241 - accuracy: 0.4777 - val_loss: 1.3574 - val_accuracy: 0.4795\n",
            "Epoch 407/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4594 - accuracy: 0.4399 - val_loss: 1.4238 - val_accuracy: 0.4384\n",
            "Epoch 408/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4598 - accuracy: 0.4674 - val_loss: 1.3359 - val_accuracy: 0.4795\n",
            "Epoch 409/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4905 - accuracy: 0.4399 - val_loss: 1.4189 - val_accuracy: 0.4384\n",
            "Epoch 410/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5052 - accuracy: 0.4399 - val_loss: 1.3741 - val_accuracy: 0.4521\n",
            "Epoch 411/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5299 - accuracy: 0.4364 - val_loss: 1.3198 - val_accuracy: 0.4932\n",
            "Epoch 412/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5605 - accuracy: 0.4330 - val_loss: 1.3427 - val_accuracy: 0.4932\n",
            "Epoch 413/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5795 - accuracy: 0.4055 - val_loss: 1.5585 - val_accuracy: 0.3973\n",
            "Epoch 414/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5800 - accuracy: 0.4124 - val_loss: 1.4967 - val_accuracy: 0.4110\n",
            "Epoch 415/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4736 - accuracy: 0.4570 - val_loss: 1.4171 - val_accuracy: 0.4384\n",
            "Epoch 416/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5564 - accuracy: 0.4330 - val_loss: 1.4102 - val_accuracy: 0.4384\n",
            "Epoch 417/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5298 - accuracy: 0.4467 - val_loss: 1.5698 - val_accuracy: 0.3973\n",
            "Epoch 418/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5238 - accuracy: 0.4399 - val_loss: 1.3789 - val_accuracy: 0.4658\n",
            "Epoch 419/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4930 - accuracy: 0.4467 - val_loss: 1.3761 - val_accuracy: 0.4658\n",
            "Epoch 420/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4707 - accuracy: 0.4777 - val_loss: 1.5258 - val_accuracy: 0.3973\n",
            "Epoch 421/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5025 - accuracy: 0.4639 - val_loss: 1.3804 - val_accuracy: 0.4658\n",
            "Epoch 422/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5618 - accuracy: 0.4296 - val_loss: 1.3394 - val_accuracy: 0.4932\n",
            "Epoch 423/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5480 - accuracy: 0.4089 - val_loss: 1.4167 - val_accuracy: 0.4521\n",
            "Epoch 424/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5272 - accuracy: 0.4399 - val_loss: 1.4882 - val_accuracy: 0.4384\n",
            "Epoch 425/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4625 - accuracy: 0.4777 - val_loss: 1.4601 - val_accuracy: 0.4384\n",
            "Epoch 426/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4676 - accuracy: 0.4570 - val_loss: 1.3417 - val_accuracy: 0.4795\n",
            "Epoch 427/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4946 - accuracy: 0.4261 - val_loss: 1.5530 - val_accuracy: 0.3973\n",
            "Epoch 428/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5280 - accuracy: 0.4467 - val_loss: 1.5396 - val_accuracy: 0.4110\n",
            "Epoch 429/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4847 - accuracy: 0.4777 - val_loss: 1.4440 - val_accuracy: 0.4384\n",
            "Epoch 430/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5714 - accuracy: 0.4055 - val_loss: 1.3332 - val_accuracy: 0.4932\n",
            "Epoch 431/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5351 - accuracy: 0.4296 - val_loss: 1.3907 - val_accuracy: 0.4521\n",
            "Epoch 432/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5067 - accuracy: 0.4330 - val_loss: 1.4505 - val_accuracy: 0.4384\n",
            "Epoch 433/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4954 - accuracy: 0.4605 - val_loss: 1.4577 - val_accuracy: 0.4247\n",
            "Epoch 434/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5157 - accuracy: 0.4330 - val_loss: 1.3746 - val_accuracy: 0.4384\n",
            "Epoch 435/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5413 - accuracy: 0.4536 - val_loss: 1.6445 - val_accuracy: 0.3699\n",
            "Epoch 436/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5594 - accuracy: 0.4261 - val_loss: 1.5570 - val_accuracy: 0.3973\n",
            "Epoch 437/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5807 - accuracy: 0.4089 - val_loss: 1.3478 - val_accuracy: 0.4932\n",
            "Epoch 438/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6106 - accuracy: 0.4158 - val_loss: 1.3751 - val_accuracy: 0.4658\n",
            "Epoch 439/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5567 - accuracy: 0.4296 - val_loss: 1.5701 - val_accuracy: 0.3973\n",
            "Epoch 440/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5008 - accuracy: 0.4364 - val_loss: 1.4740 - val_accuracy: 0.4384\n",
            "Epoch 441/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4979 - accuracy: 0.4502 - val_loss: 1.5054 - val_accuracy: 0.4384\n",
            "Epoch 442/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5225 - accuracy: 0.4330 - val_loss: 1.4062 - val_accuracy: 0.4658\n",
            "Epoch 443/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5528 - accuracy: 0.4296 - val_loss: 1.3995 - val_accuracy: 0.4795\n",
            "Epoch 444/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5471 - accuracy: 0.4227 - val_loss: 1.6560 - val_accuracy: 0.3836\n",
            "Epoch 445/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5683 - accuracy: 0.4055 - val_loss: 1.4332 - val_accuracy: 0.4384\n",
            "Epoch 446/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4881 - accuracy: 0.4399 - val_loss: 1.3669 - val_accuracy: 0.4795\n",
            "Epoch 447/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4832 - accuracy: 0.4330 - val_loss: 1.4024 - val_accuracy: 0.4384\n",
            "Epoch 448/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4793 - accuracy: 0.4433 - val_loss: 1.4831 - val_accuracy: 0.4110\n",
            "Epoch 449/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5082 - accuracy: 0.4502 - val_loss: 1.3615 - val_accuracy: 0.4658\n",
            "Epoch 450/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4756 - accuracy: 0.4742 - val_loss: 1.4669 - val_accuracy: 0.4384\n",
            "Epoch 451/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4700 - accuracy: 0.4674 - val_loss: 1.4761 - val_accuracy: 0.4384\n",
            "Epoch 452/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4996 - accuracy: 0.4536 - val_loss: 1.4399 - val_accuracy: 0.4384\n",
            "Epoch 453/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5200 - accuracy: 0.4467 - val_loss: 1.4536 - val_accuracy: 0.4384\n",
            "Epoch 454/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4557 - accuracy: 0.4570 - val_loss: 1.3963 - val_accuracy: 0.4521\n",
            "Epoch 455/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5204 - accuracy: 0.4433 - val_loss: 1.5133 - val_accuracy: 0.4110\n",
            "Epoch 456/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5122 - accuracy: 0.4467 - val_loss: 1.6028 - val_accuracy: 0.3973\n",
            "Epoch 457/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5865 - accuracy: 0.4089 - val_loss: 1.3701 - val_accuracy: 0.4384\n",
            "Epoch 458/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5117 - accuracy: 0.4399 - val_loss: 1.3867 - val_accuracy: 0.4521\n",
            "Epoch 459/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5402 - accuracy: 0.4433 - val_loss: 1.5448 - val_accuracy: 0.4110\n",
            "Epoch 460/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5197 - accuracy: 0.4467 - val_loss: 1.4551 - val_accuracy: 0.4384\n",
            "Epoch 461/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4750 - accuracy: 0.4502 - val_loss: 1.3233 - val_accuracy: 0.4932\n",
            "Epoch 462/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5058 - accuracy: 0.4674 - val_loss: 1.4299 - val_accuracy: 0.4384\n",
            "Epoch 463/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4813 - accuracy: 0.4433 - val_loss: 1.4207 - val_accuracy: 0.4384\n",
            "Epoch 464/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4437 - accuracy: 0.4742 - val_loss: 1.3696 - val_accuracy: 0.4795\n",
            "Epoch 465/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4522 - accuracy: 0.4674 - val_loss: 1.3282 - val_accuracy: 0.4932\n",
            "Epoch 466/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5264 - accuracy: 0.4502 - val_loss: 1.4002 - val_accuracy: 0.4384\n",
            "Epoch 467/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4473 - accuracy: 0.4708 - val_loss: 1.4180 - val_accuracy: 0.4384\n",
            "Epoch 468/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5068 - accuracy: 0.4261 - val_loss: 1.4842 - val_accuracy: 0.4384\n",
            "Epoch 469/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4915 - accuracy: 0.4639 - val_loss: 1.7290 - val_accuracy: 0.3562\n",
            "Epoch 470/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5420 - accuracy: 0.4433 - val_loss: 1.3611 - val_accuracy: 0.4795\n",
            "Epoch 471/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4660 - accuracy: 0.4811 - val_loss: 1.4506 - val_accuracy: 0.4384\n",
            "Epoch 472/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5007 - accuracy: 0.4777 - val_loss: 1.4595 - val_accuracy: 0.4384\n",
            "Epoch 473/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5318 - accuracy: 0.4399 - val_loss: 1.3256 - val_accuracy: 0.4932\n",
            "Epoch 474/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5731 - accuracy: 0.4261 - val_loss: 1.3735 - val_accuracy: 0.4795\n",
            "Epoch 475/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4726 - accuracy: 0.4845 - val_loss: 1.5279 - val_accuracy: 0.4110\n",
            "Epoch 476/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4789 - accuracy: 0.4605 - val_loss: 1.3638 - val_accuracy: 0.4795\n",
            "Epoch 477/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5268 - accuracy: 0.4330 - val_loss: 1.3368 - val_accuracy: 0.4932\n",
            "Epoch 478/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4921 - accuracy: 0.4433 - val_loss: 1.5036 - val_accuracy: 0.4110\n",
            "Epoch 479/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5013 - accuracy: 0.4467 - val_loss: 1.4901 - val_accuracy: 0.4384\n",
            "Epoch 480/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4925 - accuracy: 0.4742 - val_loss: 1.3440 - val_accuracy: 0.4932\n",
            "Epoch 481/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5241 - accuracy: 0.4605 - val_loss: 1.3341 - val_accuracy: 0.4932\n",
            "Epoch 482/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5225 - accuracy: 0.4433 - val_loss: 1.5460 - val_accuracy: 0.3973\n",
            "Epoch 483/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4812 - accuracy: 0.4674 - val_loss: 1.4087 - val_accuracy: 0.4384\n",
            "Epoch 484/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4392 - accuracy: 0.4639 - val_loss: 1.4700 - val_accuracy: 0.4110\n",
            "Epoch 485/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4846 - accuracy: 0.4777 - val_loss: 1.5394 - val_accuracy: 0.4110\n",
            "Epoch 486/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4410 - accuracy: 0.4708 - val_loss: 1.3590 - val_accuracy: 0.4521\n",
            "Epoch 487/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4709 - accuracy: 0.4742 - val_loss: 1.3864 - val_accuracy: 0.4521\n",
            "Epoch 488/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4674 - accuracy: 0.4570 - val_loss: 1.5084 - val_accuracy: 0.4110\n",
            "Epoch 489/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4673 - accuracy: 0.4536 - val_loss: 1.3717 - val_accuracy: 0.4521\n",
            "Epoch 490/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4624 - accuracy: 0.4742 - val_loss: 1.3655 - val_accuracy: 0.4658\n",
            "Epoch 491/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4682 - accuracy: 0.4811 - val_loss: 1.4850 - val_accuracy: 0.4110\n",
            "Epoch 492/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4223 - accuracy: 0.4708 - val_loss: 1.4010 - val_accuracy: 0.4384\n",
            "Epoch 493/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4609 - accuracy: 0.4433 - val_loss: 1.3048 - val_accuracy: 0.5068\n",
            "Epoch 494/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4751 - accuracy: 0.4605 - val_loss: 1.2860 - val_accuracy: 0.4932\n",
            "Epoch 495/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.5952 - accuracy: 0.4158 - val_loss: 1.5932 - val_accuracy: 0.4110\n",
            "Epoch 496/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5145 - accuracy: 0.4330 - val_loss: 1.5584 - val_accuracy: 0.3973\n",
            "Epoch 497/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5048 - accuracy: 0.4364 - val_loss: 1.3277 - val_accuracy: 0.4795\n",
            "Epoch 498/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4955 - accuracy: 0.4742 - val_loss: 1.2930 - val_accuracy: 0.4932\n",
            "Epoch 499/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5838 - accuracy: 0.4364 - val_loss: 1.5844 - val_accuracy: 0.3973\n",
            "Epoch 500/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4652 - accuracy: 0.4845 - val_loss: 1.5468 - val_accuracy: 0.4110\n",
            "Epoch 501/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5012 - accuracy: 0.4399 - val_loss: 1.5196 - val_accuracy: 0.4110\n",
            "Epoch 502/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0206 - accuracy: 0.2646 - val_loss: 2.0544 - val_accuracy: 0.2466\n",
            "Epoch 503/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 2.0117 - accuracy: 0.2199 - val_loss: 1.9519 - val_accuracy: 0.2466\n",
            "Epoch 504/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9291 - accuracy: 0.2199 - val_loss: 1.9164 - val_accuracy: 0.2466\n",
            "Epoch 505/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9163 - accuracy: 0.2199 - val_loss: 1.9061 - val_accuracy: 0.2466\n",
            "Epoch 506/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8933 - accuracy: 0.2199 - val_loss: 1.8986 - val_accuracy: 0.2466\n",
            "Epoch 507/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8940 - accuracy: 0.2199 - val_loss: 1.8952 - val_accuracy: 0.2466\n",
            "Epoch 508/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8869 - accuracy: 0.2199 - val_loss: 1.8912 - val_accuracy: 0.2466\n",
            "Epoch 509/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8910 - accuracy: 0.2199 - val_loss: 1.8901 - val_accuracy: 0.2466\n",
            "Epoch 510/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8831 - accuracy: 0.2199 - val_loss: 1.8890 - val_accuracy: 0.2466\n",
            "Epoch 511/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8827 - accuracy: 0.2199 - val_loss: 1.8880 - val_accuracy: 0.2466\n",
            "Epoch 512/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8788 - accuracy: 0.2199 - val_loss: 1.8882 - val_accuracy: 0.2466\n",
            "Epoch 513/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8798 - accuracy: 0.2199 - val_loss: 1.8876 - val_accuracy: 0.2466\n",
            "Epoch 514/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8863 - accuracy: 0.2165 - val_loss: 1.8876 - val_accuracy: 0.2466\n",
            "Epoch 515/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8814 - accuracy: 0.2199 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 516/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8820 - accuracy: 0.2165 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 517/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8821 - accuracy: 0.2199 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 518/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8836 - accuracy: 0.2268 - val_loss: 1.8860 - val_accuracy: 0.2466\n",
            "Epoch 519/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8761 - accuracy: 0.2199 - val_loss: 1.8858 - val_accuracy: 0.2466\n",
            "Epoch 520/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8842 - accuracy: 0.2131 - val_loss: 1.8864 - val_accuracy: 0.2466\n",
            "Epoch 521/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8757 - accuracy: 0.2234 - val_loss: 1.8862 - val_accuracy: 0.2466\n",
            "Epoch 522/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8820 - accuracy: 0.2165 - val_loss: 1.8868 - val_accuracy: 0.2466\n",
            "Epoch 523/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8814 - accuracy: 0.2234 - val_loss: 1.8868 - val_accuracy: 0.2466\n",
            "Epoch 524/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8776 - accuracy: 0.2165 - val_loss: 1.8877 - val_accuracy: 0.2466\n",
            "Epoch 525/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8840 - accuracy: 0.2234 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 526/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8766 - accuracy: 0.2440 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 527/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8779 - accuracy: 0.2131 - val_loss: 1.8889 - val_accuracy: 0.2466\n",
            "Epoch 528/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8718 - accuracy: 0.2371 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 529/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8794 - accuracy: 0.2062 - val_loss: 1.8900 - val_accuracy: 0.2466\n",
            "Epoch 530/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8810 - accuracy: 0.2165 - val_loss: 1.8910 - val_accuracy: 0.2466\n",
            "Epoch 531/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8825 - accuracy: 0.2062 - val_loss: 1.8904 - val_accuracy: 0.2466\n",
            "Epoch 532/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8752 - accuracy: 0.2199 - val_loss: 1.8892 - val_accuracy: 0.2466\n",
            "Epoch 533/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8808 - accuracy: 0.2096 - val_loss: 1.8893 - val_accuracy: 0.2466\n",
            "Epoch 534/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8763 - accuracy: 0.2234 - val_loss: 1.8895 - val_accuracy: 0.2466\n",
            "Epoch 535/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8848 - accuracy: 0.2096 - val_loss: 1.8899 - val_accuracy: 0.2466\n",
            "Epoch 536/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8718 - accuracy: 0.2234 - val_loss: 1.8905 - val_accuracy: 0.2466\n",
            "Epoch 537/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8814 - accuracy: 0.1821 - val_loss: 1.8908 - val_accuracy: 0.2466\n",
            "Epoch 538/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8781 - accuracy: 0.2062 - val_loss: 1.8912 - val_accuracy: 0.2466\n",
            "Epoch 539/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8771 - accuracy: 0.2268 - val_loss: 1.8913 - val_accuracy: 0.2466\n",
            "Epoch 540/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8826 - accuracy: 0.2165 - val_loss: 1.8918 - val_accuracy: 0.2466\n",
            "Epoch 541/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8745 - accuracy: 0.2337 - val_loss: 1.8921 - val_accuracy: 0.2466\n",
            "Epoch 542/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8751 - accuracy: 0.2234 - val_loss: 1.8906 - val_accuracy: 0.2466\n",
            "Epoch 543/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8718 - accuracy: 0.2199 - val_loss: 1.8895 - val_accuracy: 0.2466\n",
            "Epoch 544/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8790 - accuracy: 0.2199 - val_loss: 1.8888 - val_accuracy: 0.2466\n",
            "Epoch 545/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8749 - accuracy: 0.2062 - val_loss: 1.8890 - val_accuracy: 0.2466\n",
            "Epoch 546/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8755 - accuracy: 0.2337 - val_loss: 1.8879 - val_accuracy: 0.2466\n",
            "Epoch 547/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8735 - accuracy: 0.2131 - val_loss: 1.8873 - val_accuracy: 0.2466\n",
            "Epoch 548/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8824 - accuracy: 0.1856 - val_loss: 1.8866 - val_accuracy: 0.2466\n",
            "Epoch 549/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8751 - accuracy: 0.2199 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 550/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8822 - accuracy: 0.1959 - val_loss: 1.8859 - val_accuracy: 0.2466\n",
            "Epoch 551/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8775 - accuracy: 0.2268 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 552/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8757 - accuracy: 0.2062 - val_loss: 1.8884 - val_accuracy: 0.2466\n",
            "Epoch 553/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8753 - accuracy: 0.1959 - val_loss: 1.8891 - val_accuracy: 0.2466\n",
            "Epoch 554/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8749 - accuracy: 0.2165 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 555/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8732 - accuracy: 0.2268 - val_loss: 1.8886 - val_accuracy: 0.2466\n",
            "Epoch 556/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8791 - accuracy: 0.2096 - val_loss: 1.8904 - val_accuracy: 0.2466\n",
            "Epoch 557/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8748 - accuracy: 0.2096 - val_loss: 1.8921 - val_accuracy: 0.2466\n",
            "Epoch 558/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8697 - accuracy: 0.2096 - val_loss: 1.8920 - val_accuracy: 0.2466\n",
            "Epoch 559/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8828 - accuracy: 0.2302 - val_loss: 1.8909 - val_accuracy: 0.2466\n",
            "Epoch 560/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8765 - accuracy: 0.2337 - val_loss: 1.8897 - val_accuracy: 0.2466\n",
            "Epoch 561/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8740 - accuracy: 0.2131 - val_loss: 1.8891 - val_accuracy: 0.2466\n",
            "Epoch 562/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8820 - accuracy: 0.2199 - val_loss: 1.8885 - val_accuracy: 0.2466\n",
            "Epoch 563/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8764 - accuracy: 0.2234 - val_loss: 1.8852 - val_accuracy: 0.2466\n",
            "Epoch 564/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8766 - accuracy: 0.2234 - val_loss: 1.8840 - val_accuracy: 0.2466\n",
            "Epoch 565/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8761 - accuracy: 0.2131 - val_loss: 1.8846 - val_accuracy: 0.2466\n",
            "Epoch 566/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8768 - accuracy: 0.2131 - val_loss: 1.8864 - val_accuracy: 0.2466\n",
            "Epoch 567/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8738 - accuracy: 0.2096 - val_loss: 1.8868 - val_accuracy: 0.2466\n",
            "Epoch 568/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8737 - accuracy: 0.2062 - val_loss: 1.8868 - val_accuracy: 0.2466\n",
            "Epoch 569/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8775 - accuracy: 0.2199 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 570/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8731 - accuracy: 0.2131 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 571/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8786 - accuracy: 0.2062 - val_loss: 1.8867 - val_accuracy: 0.2466\n",
            "Epoch 572/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8763 - accuracy: 0.2062 - val_loss: 1.8866 - val_accuracy: 0.2466\n",
            "Epoch 573/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8725 - accuracy: 0.2165 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 574/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8753 - accuracy: 0.2131 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 575/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8753 - accuracy: 0.2096 - val_loss: 1.8882 - val_accuracy: 0.2466\n",
            "Epoch 576/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8719 - accuracy: 0.2199 - val_loss: 1.8888 - val_accuracy: 0.2466\n",
            "Epoch 577/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8712 - accuracy: 0.2027 - val_loss: 1.8886 - val_accuracy: 0.2466\n",
            "Epoch 578/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8706 - accuracy: 0.2165 - val_loss: 1.8904 - val_accuracy: 0.2466\n",
            "Epoch 579/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8793 - accuracy: 0.2199 - val_loss: 1.8907 - val_accuracy: 0.2466\n",
            "Epoch 580/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8789 - accuracy: 0.2165 - val_loss: 1.8909 - val_accuracy: 0.2466\n",
            "Epoch 581/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8749 - accuracy: 0.2268 - val_loss: 1.8908 - val_accuracy: 0.2466\n",
            "Epoch 582/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8729 - accuracy: 0.2234 - val_loss: 1.8890 - val_accuracy: 0.2466\n",
            "Epoch 583/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8751 - accuracy: 0.2405 - val_loss: 1.8880 - val_accuracy: 0.2466\n",
            "Epoch 584/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8748 - accuracy: 0.2199 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 585/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8749 - accuracy: 0.2096 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 586/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8723 - accuracy: 0.2268 - val_loss: 1.8854 - val_accuracy: 0.2466\n",
            "Epoch 587/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.8779 - accuracy: 0.2096 - val_loss: 1.8849 - val_accuracy: 0.2466\n",
            "Epoch 588/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8742 - accuracy: 0.2096 - val_loss: 1.8849 - val_accuracy: 0.2466\n",
            "Epoch 589/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8833 - accuracy: 0.2096 - val_loss: 1.8853 - val_accuracy: 0.2466\n",
            "Epoch 590/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8767 - accuracy: 0.2234 - val_loss: 1.8864 - val_accuracy: 0.2466\n",
            "Epoch 591/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8766 - accuracy: 0.2199 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 592/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8827 - accuracy: 0.2165 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 593/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8801 - accuracy: 0.2302 - val_loss: 1.8861 - val_accuracy: 0.2466\n",
            "Epoch 594/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8759 - accuracy: 0.2027 - val_loss: 1.8869 - val_accuracy: 0.2466\n",
            "Epoch 595/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8761 - accuracy: 0.2302 - val_loss: 1.8886 - val_accuracy: 0.2466\n",
            "Epoch 596/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8778 - accuracy: 0.1959 - val_loss: 1.8883 - val_accuracy: 0.2466\n",
            "Epoch 597/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8794 - accuracy: 0.2234 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 598/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8760 - accuracy: 0.2165 - val_loss: 1.8860 - val_accuracy: 0.2466\n",
            "Epoch 599/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8710 - accuracy: 0.2199 - val_loss: 1.8860 - val_accuracy: 0.2466\n",
            "Epoch 600/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8741 - accuracy: 0.2165 - val_loss: 1.8857 - val_accuracy: 0.2466\n",
            "Epoch 601/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8783 - accuracy: 0.2096 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 602/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8764 - accuracy: 0.2165 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 603/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8799 - accuracy: 0.2234 - val_loss: 1.8862 - val_accuracy: 0.2466\n",
            "Epoch 604/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8743 - accuracy: 0.2199 - val_loss: 1.8846 - val_accuracy: 0.2466\n",
            "Epoch 605/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8774 - accuracy: 0.2131 - val_loss: 1.8837 - val_accuracy: 0.2466\n",
            "Epoch 606/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8739 - accuracy: 0.2234 - val_loss: 1.8833 - val_accuracy: 0.2466\n",
            "Epoch 607/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8747 - accuracy: 0.2234 - val_loss: 1.8836 - val_accuracy: 0.2466\n",
            "Epoch 608/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8760 - accuracy: 0.2234 - val_loss: 1.8832 - val_accuracy: 0.2466\n",
            "Epoch 609/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8755 - accuracy: 0.2268 - val_loss: 1.8834 - val_accuracy: 0.2466\n",
            "Epoch 610/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8788 - accuracy: 0.2131 - val_loss: 1.8835 - val_accuracy: 0.2466\n",
            "Epoch 611/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8778 - accuracy: 0.2131 - val_loss: 1.8847 - val_accuracy: 0.2466\n",
            "Epoch 612/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8704 - accuracy: 0.2302 - val_loss: 1.8862 - val_accuracy: 0.2466\n",
            "Epoch 613/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8840 - accuracy: 0.2302 - val_loss: 1.8876 - val_accuracy: 0.2466\n",
            "Epoch 614/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8759 - accuracy: 0.1959 - val_loss: 1.8890 - val_accuracy: 0.2466\n",
            "Epoch 615/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8786 - accuracy: 0.2165 - val_loss: 1.8905 - val_accuracy: 0.2466\n",
            "Epoch 616/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8831 - accuracy: 0.1993 - val_loss: 1.8909 - val_accuracy: 0.2466\n",
            "Epoch 617/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8793 - accuracy: 0.2165 - val_loss: 1.8909 - val_accuracy: 0.2466\n",
            "Epoch 618/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8731 - accuracy: 0.2509 - val_loss: 1.8903 - val_accuracy: 0.2466\n",
            "Epoch 619/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8749 - accuracy: 0.1890 - val_loss: 1.8889 - val_accuracy: 0.2466\n",
            "Epoch 620/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8772 - accuracy: 0.2234 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 621/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8678 - accuracy: 0.2337 - val_loss: 1.8884 - val_accuracy: 0.2466\n",
            "Epoch 622/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8793 - accuracy: 0.1993 - val_loss: 1.8879 - val_accuracy: 0.2466\n",
            "Epoch 623/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8796 - accuracy: 0.2062 - val_loss: 1.8864 - val_accuracy: 0.2466\n",
            "Epoch 624/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8814 - accuracy: 0.2096 - val_loss: 1.8856 - val_accuracy: 0.2466\n",
            "Epoch 625/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8726 - accuracy: 0.2165 - val_loss: 1.8847 - val_accuracy: 0.2466\n",
            "Epoch 626/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8726 - accuracy: 0.2337 - val_loss: 1.8839 - val_accuracy: 0.2466\n",
            "Epoch 627/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8805 - accuracy: 0.2234 - val_loss: 1.8834 - val_accuracy: 0.2466\n",
            "Epoch 628/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8779 - accuracy: 0.2268 - val_loss: 1.8827 - val_accuracy: 0.2466\n",
            "Epoch 629/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8722 - accuracy: 0.2096 - val_loss: 1.8826 - val_accuracy: 0.2466\n",
            "Epoch 630/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8711 - accuracy: 0.2199 - val_loss: 1.8831 - val_accuracy: 0.2466\n",
            "Epoch 631/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8725 - accuracy: 0.2199 - val_loss: 1.8835 - val_accuracy: 0.2466\n",
            "Epoch 632/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8728 - accuracy: 0.2268 - val_loss: 1.8835 - val_accuracy: 0.2466\n",
            "Epoch 633/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8751 - accuracy: 0.2234 - val_loss: 1.8829 - val_accuracy: 0.2466\n",
            "Epoch 634/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8707 - accuracy: 0.2096 - val_loss: 1.8823 - val_accuracy: 0.2466\n",
            "Epoch 635/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8733 - accuracy: 0.2131 - val_loss: 1.8824 - val_accuracy: 0.2466\n",
            "Epoch 636/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8800 - accuracy: 0.2302 - val_loss: 1.8839 - val_accuracy: 0.2466\n",
            "Epoch 637/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8751 - accuracy: 0.2131 - val_loss: 1.8864 - val_accuracy: 0.2466\n",
            "Epoch 638/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8787 - accuracy: 0.2027 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 639/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8731 - accuracy: 0.2199 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 640/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8699 - accuracy: 0.2096 - val_loss: 1.8861 - val_accuracy: 0.2466\n",
            "Epoch 641/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8780 - accuracy: 0.2199 - val_loss: 1.8850 - val_accuracy: 0.2466\n",
            "Epoch 642/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8708 - accuracy: 0.2199 - val_loss: 1.8848 - val_accuracy: 0.2466\n",
            "Epoch 643/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8799 - accuracy: 0.2131 - val_loss: 1.8856 - val_accuracy: 0.2466\n",
            "Epoch 644/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8745 - accuracy: 0.1993 - val_loss: 1.8857 - val_accuracy: 0.2466\n",
            "Epoch 645/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8739 - accuracy: 0.2199 - val_loss: 1.8845 - val_accuracy: 0.2466\n",
            "Epoch 646/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8746 - accuracy: 0.2096 - val_loss: 1.8840 - val_accuracy: 0.2466\n",
            "Epoch 647/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8772 - accuracy: 0.2268 - val_loss: 1.8832 - val_accuracy: 0.2466\n",
            "Epoch 648/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8733 - accuracy: 0.1993 - val_loss: 1.8833 - val_accuracy: 0.2466\n",
            "Epoch 649/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8751 - accuracy: 0.2027 - val_loss: 1.8834 - val_accuracy: 0.2466\n",
            "Epoch 650/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8783 - accuracy: 0.1959 - val_loss: 1.8829 - val_accuracy: 0.2466\n",
            "Epoch 651/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8749 - accuracy: 0.2165 - val_loss: 1.8827 - val_accuracy: 0.2466\n",
            "Epoch 652/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8747 - accuracy: 0.2199 - val_loss: 1.8836 - val_accuracy: 0.2466\n",
            "Epoch 653/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8810 - accuracy: 0.1993 - val_loss: 1.8838 - val_accuracy: 0.2466\n",
            "Epoch 654/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8761 - accuracy: 0.2234 - val_loss: 1.8834 - val_accuracy: 0.2466\n",
            "Epoch 655/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8736 - accuracy: 0.2199 - val_loss: 1.8823 - val_accuracy: 0.2466\n",
            "Epoch 656/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8731 - accuracy: 0.2131 - val_loss: 1.8824 - val_accuracy: 0.2466\n",
            "Epoch 657/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8760 - accuracy: 0.2027 - val_loss: 1.8819 - val_accuracy: 0.2466\n",
            "Epoch 658/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8789 - accuracy: 0.2062 - val_loss: 1.8820 - val_accuracy: 0.2466\n",
            "Epoch 659/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8714 - accuracy: 0.2302 - val_loss: 1.8819 - val_accuracy: 0.2466\n",
            "Epoch 660/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8747 - accuracy: 0.2131 - val_loss: 1.8816 - val_accuracy: 0.2466\n",
            "Epoch 661/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8700 - accuracy: 0.2165 - val_loss: 1.8816 - val_accuracy: 0.2466\n",
            "Epoch 662/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8702 - accuracy: 0.2234 - val_loss: 1.8814 - val_accuracy: 0.2466\n",
            "Epoch 663/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8797 - accuracy: 0.2199 - val_loss: 1.8815 - val_accuracy: 0.2466\n",
            "Epoch 664/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8661 - accuracy: 0.2199 - val_loss: 1.8806 - val_accuracy: 0.2466\n",
            "Epoch 665/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8756 - accuracy: 0.2268 - val_loss: 1.8814 - val_accuracy: 0.2466\n",
            "Epoch 666/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8792 - accuracy: 0.2199 - val_loss: 1.8816 - val_accuracy: 0.2466\n",
            "Epoch 667/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8784 - accuracy: 0.2165 - val_loss: 1.8822 - val_accuracy: 0.2466\n",
            "Epoch 668/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8716 - accuracy: 0.2234 - val_loss: 1.8835 - val_accuracy: 0.2466\n",
            "Epoch 669/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8709 - accuracy: 0.2096 - val_loss: 1.8829 - val_accuracy: 0.2466\n",
            "Epoch 670/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8736 - accuracy: 0.2165 - val_loss: 1.8824 - val_accuracy: 0.2466\n",
            "Epoch 671/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8707 - accuracy: 0.2268 - val_loss: 1.8830 - val_accuracy: 0.2466\n",
            "Epoch 672/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8795 - accuracy: 0.2199 - val_loss: 1.8832 - val_accuracy: 0.2466\n",
            "Epoch 673/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8644 - accuracy: 0.2199 - val_loss: 1.8838 - val_accuracy: 0.2466\n",
            "Epoch 674/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8716 - accuracy: 0.2096 - val_loss: 1.8841 - val_accuracy: 0.2466\n",
            "Epoch 675/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8743 - accuracy: 0.2371 - val_loss: 1.8859 - val_accuracy: 0.2466\n",
            "Epoch 676/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8781 - accuracy: 0.2302 - val_loss: 1.8857 - val_accuracy: 0.2466\n",
            "Epoch 677/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8705 - accuracy: 0.2234 - val_loss: 1.8854 - val_accuracy: 0.2466\n",
            "Epoch 678/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8770 - accuracy: 0.2199 - val_loss: 1.8857 - val_accuracy: 0.2466\n",
            "Epoch 679/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8799 - accuracy: 0.2131 - val_loss: 1.8860 - val_accuracy: 0.2466\n",
            "Epoch 680/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8743 - accuracy: 0.2337 - val_loss: 1.8861 - val_accuracy: 0.2466\n",
            "Epoch 681/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8668 - accuracy: 0.2131 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 682/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8739 - accuracy: 0.2131 - val_loss: 1.8873 - val_accuracy: 0.2466\n",
            "Epoch 683/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8753 - accuracy: 0.2062 - val_loss: 1.8884 - val_accuracy: 0.2466\n",
            "Epoch 684/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8750 - accuracy: 0.2199 - val_loss: 1.8880 - val_accuracy: 0.2466\n",
            "Epoch 685/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8805 - accuracy: 0.2096 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 686/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8745 - accuracy: 0.2405 - val_loss: 1.8901 - val_accuracy: 0.2466\n",
            "Epoch 687/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8740 - accuracy: 0.2062 - val_loss: 1.8893 - val_accuracy: 0.2466\n",
            "Epoch 688/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8739 - accuracy: 0.2096 - val_loss: 1.8880 - val_accuracy: 0.2466\n",
            "Epoch 689/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8701 - accuracy: 0.2096 - val_loss: 1.8881 - val_accuracy: 0.2466\n",
            "Epoch 690/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8748 - accuracy: 0.2062 - val_loss: 1.8883 - val_accuracy: 0.2466\n",
            "Epoch 691/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8775 - accuracy: 0.2405 - val_loss: 1.8880 - val_accuracy: 0.2466\n",
            "Epoch 692/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8748 - accuracy: 0.2131 - val_loss: 1.8878 - val_accuracy: 0.2466\n",
            "Epoch 693/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8728 - accuracy: 0.2027 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 694/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8758 - accuracy: 0.2234 - val_loss: 1.8877 - val_accuracy: 0.2466\n",
            "Epoch 695/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8765 - accuracy: 0.2131 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 696/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8797 - accuracy: 0.2131 - val_loss: 1.8869 - val_accuracy: 0.2466\n",
            "Epoch 697/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8728 - accuracy: 0.2062 - val_loss: 1.8859 - val_accuracy: 0.2466\n",
            "Epoch 698/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8745 - accuracy: 0.2268 - val_loss: 1.8859 - val_accuracy: 0.2466\n",
            "Epoch 699/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8780 - accuracy: 0.2199 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 700/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8751 - accuracy: 0.2268 - val_loss: 1.8858 - val_accuracy: 0.2466\n",
            "Epoch 701/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8799 - accuracy: 0.2096 - val_loss: 1.8854 - val_accuracy: 0.2466\n",
            "Epoch 702/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8701 - accuracy: 0.2234 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 703/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8718 - accuracy: 0.2268 - val_loss: 1.8872 - val_accuracy: 0.2466\n",
            "Epoch 704/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8785 - accuracy: 0.2268 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 705/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8730 - accuracy: 0.2302 - val_loss: 1.8857 - val_accuracy: 0.2466\n",
            "Epoch 706/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8722 - accuracy: 0.2131 - val_loss: 1.8851 - val_accuracy: 0.2466\n",
            "Epoch 707/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8696 - accuracy: 0.2165 - val_loss: 1.8847 - val_accuracy: 0.2466\n",
            "Epoch 708/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8842 - accuracy: 0.1993 - val_loss: 1.8836 - val_accuracy: 0.2466\n",
            "Epoch 709/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8812 - accuracy: 0.2234 - val_loss: 1.8836 - val_accuracy: 0.2466\n",
            "Epoch 710/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8760 - accuracy: 0.2199 - val_loss: 1.8841 - val_accuracy: 0.2466\n",
            "Epoch 711/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8754 - accuracy: 0.2199 - val_loss: 1.8839 - val_accuracy: 0.2466\n",
            "Epoch 712/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8808 - accuracy: 0.2199 - val_loss: 1.8851 - val_accuracy: 0.2466\n",
            "Epoch 713/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8743 - accuracy: 0.2302 - val_loss: 1.8867 - val_accuracy: 0.2466\n",
            "Epoch 714/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8745 - accuracy: 0.2096 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 715/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8740 - accuracy: 0.2474 - val_loss: 1.8873 - val_accuracy: 0.2466\n",
            "Epoch 716/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8769 - accuracy: 0.2096 - val_loss: 1.8872 - val_accuracy: 0.2466\n",
            "Epoch 717/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8747 - accuracy: 0.2062 - val_loss: 1.8866 - val_accuracy: 0.2466\n",
            "Epoch 718/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8791 - accuracy: 0.1993 - val_loss: 1.8862 - val_accuracy: 0.2466\n",
            "Epoch 719/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8730 - accuracy: 0.2096 - val_loss: 1.8872 - val_accuracy: 0.2466\n",
            "Epoch 720/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8808 - accuracy: 0.2062 - val_loss: 1.8867 - val_accuracy: 0.2466\n",
            "Epoch 721/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8786 - accuracy: 0.2337 - val_loss: 1.8867 - val_accuracy: 0.2466\n",
            "Epoch 722/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8782 - accuracy: 0.2268 - val_loss: 1.8862 - val_accuracy: 0.2466\n",
            "Epoch 723/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8702 - accuracy: 0.2440 - val_loss: 1.8862 - val_accuracy: 0.2466\n",
            "Epoch 724/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8759 - accuracy: 0.2131 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 725/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8703 - accuracy: 0.2268 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 726/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8705 - accuracy: 0.2268 - val_loss: 1.8885 - val_accuracy: 0.2466\n",
            "Epoch 727/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8731 - accuracy: 0.2199 - val_loss: 1.8893 - val_accuracy: 0.2466\n",
            "Epoch 728/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8725 - accuracy: 0.2165 - val_loss: 1.8903 - val_accuracy: 0.2466\n",
            "Epoch 729/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8746 - accuracy: 0.2268 - val_loss: 1.8911 - val_accuracy: 0.2466\n",
            "Epoch 730/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8711 - accuracy: 0.2131 - val_loss: 1.8915 - val_accuracy: 0.2466\n",
            "Epoch 731/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8788 - accuracy: 0.1993 - val_loss: 1.8925 - val_accuracy: 0.2466\n",
            "Epoch 732/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8722 - accuracy: 0.2027 - val_loss: 1.8928 - val_accuracy: 0.2466\n",
            "Epoch 733/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8752 - accuracy: 0.2302 - val_loss: 1.8923 - val_accuracy: 0.2466\n",
            "Epoch 734/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8745 - accuracy: 0.2337 - val_loss: 1.8924 - val_accuracy: 0.2466\n",
            "Epoch 735/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8761 - accuracy: 0.2268 - val_loss: 1.8917 - val_accuracy: 0.2466\n",
            "Epoch 736/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8720 - accuracy: 0.2096 - val_loss: 1.8910 - val_accuracy: 0.2466\n",
            "Epoch 737/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8761 - accuracy: 0.2509 - val_loss: 1.8903 - val_accuracy: 0.2466\n",
            "Epoch 738/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8754 - accuracy: 0.2062 - val_loss: 1.8899 - val_accuracy: 0.2466\n",
            "Epoch 739/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8736 - accuracy: 0.2234 - val_loss: 1.8899 - val_accuracy: 0.2466\n",
            "Epoch 740/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8742 - accuracy: 0.2337 - val_loss: 1.8902 - val_accuracy: 0.2466\n",
            "Epoch 741/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8839 - accuracy: 0.1787 - val_loss: 1.8902 - val_accuracy: 0.2466\n",
            "Epoch 742/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8800 - accuracy: 0.2302 - val_loss: 1.8896 - val_accuracy: 0.2466\n",
            "Epoch 743/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8748 - accuracy: 0.2199 - val_loss: 1.8896 - val_accuracy: 0.2466\n",
            "Epoch 744/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8735 - accuracy: 0.2199 - val_loss: 1.8899 - val_accuracy: 0.2466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJR5pfQ1c9g4"
      },
      "source": [
        "### Evaluation and Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "413JtwURc9g5",
        "outputId": "4725b60f-af5e-4113-9da3-031d483b06ea"
      },
      "source": [
        "# Evaluate our model on the test set\n",
        "loss, accuracy = model_2.evaluate(X_test, y_test)\n",
        "print(f\"Model loss on the test set: {loss}\")\n",
        "print(f\"Model accuracy on the test set: {100*accuracy:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 5ms/step - loss: 0.7995 - accuracy: 0.6410\n",
            "Model loss on the test set: 0.7994661927223206\n",
            "Model accuracy on the test set: 64.10%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "OJB0Jvw9c9g5",
        "outputId": "124252bd-a206-48f1-edaa-5107209b8409"
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history_2.history['loss'])#[5:])\n",
        "plt.plot(history_2.history['val_loss'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "NOjoGnLic9g6",
        "outputId": "671609fd-bb22-48e4-f317-16e0fa7a3e45"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history_2.history['accuracy'])#[5:])\n",
        "plt.plot(history_2.history['val_accuracy'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Binary Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}