{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "distance ck+.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koushikroy/facial_sentiment_analysis/blob/main/07_distance_jaffee_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCXyx8lD8yuD"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZyNQK_p6gU3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvwNzEk69PpW"
      },
      "source": [
        "# Dateset Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLGsT1ORYjId"
      },
      "source": [
        "## Downloading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8-iDzOLIQtD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c463111d-aaab-4675-fdc3-2c7d2fb07f54"
      },
      "source": [
        "!wget -cO - 'https://s3.us-west-2.amazonaws.com/secure.notion-static.com/8d717e17-7c5d-47cd-b556-5bd7d6bb1273/distance_dataset.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210910%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210910T143237Z&X-Amz-Expires=86400&X-Amz-Signature=9f9bc5d1c4af979a21b54d81781caea2ef2395fd09188df307734c5d93fbebf4&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%20%3D%22distance_dataset.csv%22'> ck_dist.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-10 14:34:43--  https://s3.us-west-2.amazonaws.com/secure.notion-static.com/8d717e17-7c5d-47cd-b556-5bd7d6bb1273/distance_dataset.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20210910%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20210910T143237Z&X-Amz-Expires=86400&X-Amz-Signature=9f9bc5d1c4af979a21b54d81781caea2ef2395fd09188df307734c5d93fbebf4&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%20%3D%22distance_dataset.csv%22\n",
            "Resolving s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)... 52.92.131.0\n",
            "Connecting to s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)|52.92.131.0|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1797668726 (1.7G) [text/csv]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.67G  34.2MB/s    in 50s     \n",
            "\n",
            "2021-09-10 14:35:34 (34.0 MB/s) - written to stdout [1797668726/1797668726]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQnuCiaCYs2W"
      },
      "source": [
        "## Exploring and Cleaning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9COVLEMgBPcf"
      },
      "source": [
        "sentiment_data_original = pd.read_csv('/content/ck_dist.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "YUft2RE7BX-6",
        "outputId": "b261e0aa-ecbe-4ec3-8b39-63b3e9cedf28"
      },
      "source": [
        "sentiment_data_original.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>108772</th>\n",
              "      <th>108773</th>\n",
              "      <th>108774</th>\n",
              "      <th>108775</th>\n",
              "      <th>108776</th>\n",
              "      <th>108777</th>\n",
              "      <th>108778</th>\n",
              "      <th>108779</th>\n",
              "      <th>108780</th>\n",
              "      <th>108781</th>\n",
              "      <th>108782</th>\n",
              "      <th>108783</th>\n",
              "      <th>108784</th>\n",
              "      <th>108785</th>\n",
              "      <th>108786</th>\n",
              "      <th>108787</th>\n",
              "      <th>108788</th>\n",
              "      <th>108789</th>\n",
              "      <th>108790</th>\n",
              "      <th>108791</th>\n",
              "      <th>108792</th>\n",
              "      <th>108793</th>\n",
              "      <th>108794</th>\n",
              "      <th>108795</th>\n",
              "      <th>108796</th>\n",
              "      <th>108797</th>\n",
              "      <th>108798</th>\n",
              "      <th>108799</th>\n",
              "      <th>108800</th>\n",
              "      <th>108801</th>\n",
              "      <th>108802</th>\n",
              "      <th>108803</th>\n",
              "      <th>108804</th>\n",
              "      <th>108805</th>\n",
              "      <th>108806</th>\n",
              "      <th>108807</th>\n",
              "      <th>108808</th>\n",
              "      <th>108809</th>\n",
              "      <th>108810</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.187956</td>\n",
              "      <td>0.135271</td>\n",
              "      <td>0.419206</td>\n",
              "      <td>0.254075</td>\n",
              "      <td>0.346495</td>\n",
              "      <td>0.571146</td>\n",
              "      <td>0.738945</td>\n",
              "      <td>0.723141</td>\n",
              "      <td>0.806195</td>\n",
              "      <td>1.116449</td>\n",
              "      <td>0.029100</td>\n",
              "      <td>0.048255</td>\n",
              "      <td>0.054430</td>\n",
              "      <td>0.058375</td>\n",
              "      <td>0.081279</td>\n",
              "      <td>0.109907</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>0.191198</td>\n",
              "      <td>0.157580</td>\n",
              "      <td>0.179609</td>\n",
              "      <td>1.046170</td>\n",
              "      <td>0.608358</td>\n",
              "      <td>0.629658</td>\n",
              "      <td>0.659367</td>\n",
              "      <td>0.730874</td>\n",
              "      <td>0.603732</td>\n",
              "      <td>0.768399</td>\n",
              "      <td>0.740817</td>\n",
              "      <td>0.788229</td>\n",
              "      <td>0.793099</td>\n",
              "      <td>0.727295</td>\n",
              "      <td>0.351643</td>\n",
              "      <td>0.763274</td>\n",
              "      <td>0.868677</td>\n",
              "      <td>0.803198</td>\n",
              "      <td>0.403602</td>\n",
              "      <td>0.071373</td>\n",
              "      <td>0.072551</td>\n",
              "      <td>0.140190</td>\n",
              "      <td>0.182667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.383090</td>\n",
              "      <td>0.367822</td>\n",
              "      <td>0.555479</td>\n",
              "      <td>0.038096</td>\n",
              "      <td>0.096757</td>\n",
              "      <td>0.013857</td>\n",
              "      <td>0.023125</td>\n",
              "      <td>0.439093</td>\n",
              "      <td>0.414083</td>\n",
              "      <td>0.397515</td>\n",
              "      <td>0.596772</td>\n",
              "      <td>0.068370</td>\n",
              "      <td>0.051937</td>\n",
              "      <td>0.060741</td>\n",
              "      <td>0.412759</td>\n",
              "      <td>0.390038</td>\n",
              "      <td>0.374819</td>\n",
              "      <td>0.560521</td>\n",
              "      <td>0.108174</td>\n",
              "      <td>0.113428</td>\n",
              "      <td>0.429644</td>\n",
              "      <td>0.412602</td>\n",
              "      <td>0.400537</td>\n",
              "      <td>0.541059</td>\n",
              "      <td>0.009956</td>\n",
              "      <td>0.449599</td>\n",
              "      <td>0.423889</td>\n",
              "      <td>0.406911</td>\n",
              "      <td>0.610217</td>\n",
              "      <td>0.459337</td>\n",
              "      <td>0.433453</td>\n",
              "      <td>0.416359</td>\n",
              "      <td>0.619876</td>\n",
              "      <td>0.040861</td>\n",
              "      <td>0.064414</td>\n",
              "      <td>0.287163</td>\n",
              "      <td>0.023774</td>\n",
              "      <td>0.325599</td>\n",
              "      <td>0.346695</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.207567</td>\n",
              "      <td>0.149162</td>\n",
              "      <td>0.413281</td>\n",
              "      <td>0.268064</td>\n",
              "      <td>0.350784</td>\n",
              "      <td>0.550446</td>\n",
              "      <td>0.729772</td>\n",
              "      <td>0.661067</td>\n",
              "      <td>0.733735</td>\n",
              "      <td>1.052325</td>\n",
              "      <td>0.029055</td>\n",
              "      <td>0.048058</td>\n",
              "      <td>0.054046</td>\n",
              "      <td>0.052564</td>\n",
              "      <td>0.073975</td>\n",
              "      <td>0.102124</td>\n",
              "      <td>0.133495</td>\n",
              "      <td>0.196838</td>\n",
              "      <td>0.178358</td>\n",
              "      <td>0.193430</td>\n",
              "      <td>1.071643</td>\n",
              "      <td>0.590631</td>\n",
              "      <td>0.617111</td>\n",
              "      <td>0.652965</td>\n",
              "      <td>0.726510</td>\n",
              "      <td>0.583013</td>\n",
              "      <td>0.725266</td>\n",
              "      <td>0.698325</td>\n",
              "      <td>0.749550</td>\n",
              "      <td>0.762678</td>\n",
              "      <td>0.737213</td>\n",
              "      <td>0.403877</td>\n",
              "      <td>0.753039</td>\n",
              "      <td>0.920617</td>\n",
              "      <td>0.821129</td>\n",
              "      <td>0.411357</td>\n",
              "      <td>0.072746</td>\n",
              "      <td>0.077174</td>\n",
              "      <td>0.147522</td>\n",
              "      <td>0.198965</td>\n",
              "      <td>...</td>\n",
              "      <td>0.334787</td>\n",
              "      <td>0.322138</td>\n",
              "      <td>0.507045</td>\n",
              "      <td>0.038844</td>\n",
              "      <td>0.088166</td>\n",
              "      <td>0.011825</td>\n",
              "      <td>0.025459</td>\n",
              "      <td>0.388988</td>\n",
              "      <td>0.365276</td>\n",
              "      <td>0.351106</td>\n",
              "      <td>0.552140</td>\n",
              "      <td>0.063657</td>\n",
              "      <td>0.050616</td>\n",
              "      <td>0.063830</td>\n",
              "      <td>0.363319</td>\n",
              "      <td>0.342413</td>\n",
              "      <td>0.329606</td>\n",
              "      <td>0.514974</td>\n",
              "      <td>0.096696</td>\n",
              "      <td>0.105036</td>\n",
              "      <td>0.393837</td>\n",
              "      <td>0.378244</td>\n",
              "      <td>0.367825</td>\n",
              "      <td>0.508859</td>\n",
              "      <td>0.013846</td>\n",
              "      <td>0.398088</td>\n",
              "      <td>0.373699</td>\n",
              "      <td>0.359201</td>\n",
              "      <td>0.563786</td>\n",
              "      <td>0.410744</td>\n",
              "      <td>0.385853</td>\n",
              "      <td>0.371103</td>\n",
              "      <td>0.577582</td>\n",
              "      <td>0.040470</td>\n",
              "      <td>0.060192</td>\n",
              "      <td>0.291065</td>\n",
              "      <td>0.020054</td>\n",
              "      <td>0.329249</td>\n",
              "      <td>0.346610</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.209710</td>\n",
              "      <td>0.151796</td>\n",
              "      <td>0.425649</td>\n",
              "      <td>0.272657</td>\n",
              "      <td>0.358480</td>\n",
              "      <td>0.568503</td>\n",
              "      <td>0.729258</td>\n",
              "      <td>0.702382</td>\n",
              "      <td>0.781597</td>\n",
              "      <td>1.093249</td>\n",
              "      <td>0.029604</td>\n",
              "      <td>0.048569</td>\n",
              "      <td>0.053562</td>\n",
              "      <td>0.059927</td>\n",
              "      <td>0.081331</td>\n",
              "      <td>0.108687</td>\n",
              "      <td>0.138396</td>\n",
              "      <td>0.192105</td>\n",
              "      <td>0.180009</td>\n",
              "      <td>0.198394</td>\n",
              "      <td>1.054637</td>\n",
              "      <td>0.598924</td>\n",
              "      <td>0.621862</td>\n",
              "      <td>0.654303</td>\n",
              "      <td>0.723751</td>\n",
              "      <td>0.593897</td>\n",
              "      <td>0.747247</td>\n",
              "      <td>0.722203</td>\n",
              "      <td>0.766800</td>\n",
              "      <td>0.773796</td>\n",
              "      <td>0.727711</td>\n",
              "      <td>0.367211</td>\n",
              "      <td>0.751856</td>\n",
              "      <td>0.886812</td>\n",
              "      <td>0.806554</td>\n",
              "      <td>0.410377</td>\n",
              "      <td>0.075550</td>\n",
              "      <td>0.076730</td>\n",
              "      <td>0.150007</td>\n",
              "      <td>0.198634</td>\n",
              "      <td>...</td>\n",
              "      <td>0.351177</td>\n",
              "      <td>0.338624</td>\n",
              "      <td>0.516268</td>\n",
              "      <td>0.039003</td>\n",
              "      <td>0.102248</td>\n",
              "      <td>0.013609</td>\n",
              "      <td>0.024207</td>\n",
              "      <td>0.404742</td>\n",
              "      <td>0.382472</td>\n",
              "      <td>0.368544</td>\n",
              "      <td>0.559361</td>\n",
              "      <td>0.075464</td>\n",
              "      <td>0.052612</td>\n",
              "      <td>0.062633</td>\n",
              "      <td>0.378595</td>\n",
              "      <td>0.358844</td>\n",
              "      <td>0.346298</td>\n",
              "      <td>0.522152</td>\n",
              "      <td>0.113270</td>\n",
              "      <td>0.118113</td>\n",
              "      <td>0.406730</td>\n",
              "      <td>0.393133</td>\n",
              "      <td>0.383738</td>\n",
              "      <td>0.507482</td>\n",
              "      <td>0.011729</td>\n",
              "      <td>0.414348</td>\n",
              "      <td>0.391303</td>\n",
              "      <td>0.376955</td>\n",
              "      <td>0.572403</td>\n",
              "      <td>0.425904</td>\n",
              "      <td>0.402678</td>\n",
              "      <td>0.388212</td>\n",
              "      <td>0.583566</td>\n",
              "      <td>0.038252</td>\n",
              "      <td>0.058773</td>\n",
              "      <td>0.283944</td>\n",
              "      <td>0.020728</td>\n",
              "      <td>0.320051</td>\n",
              "      <td>0.338464</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.220117</td>\n",
              "      <td>0.154567</td>\n",
              "      <td>0.419507</td>\n",
              "      <td>0.281169</td>\n",
              "      <td>0.360029</td>\n",
              "      <td>0.550323</td>\n",
              "      <td>0.703096</td>\n",
              "      <td>0.681569</td>\n",
              "      <td>0.758550</td>\n",
              "      <td>1.051571</td>\n",
              "      <td>0.031128</td>\n",
              "      <td>0.053641</td>\n",
              "      <td>0.062343</td>\n",
              "      <td>0.080691</td>\n",
              "      <td>0.106775</td>\n",
              "      <td>0.139166</td>\n",
              "      <td>0.173484</td>\n",
              "      <td>0.226350</td>\n",
              "      <td>0.188956</td>\n",
              "      <td>0.200879</td>\n",
              "      <td>1.006257</td>\n",
              "      <td>0.570464</td>\n",
              "      <td>0.593828</td>\n",
              "      <td>0.626521</td>\n",
              "      <td>0.696045</td>\n",
              "      <td>0.565623</td>\n",
              "      <td>0.727810</td>\n",
              "      <td>0.700437</td>\n",
              "      <td>0.747852</td>\n",
              "      <td>0.753084</td>\n",
              "      <td>0.696103</td>\n",
              "      <td>0.378425</td>\n",
              "      <td>0.726623</td>\n",
              "      <td>0.840830</td>\n",
              "      <td>0.771020</td>\n",
              "      <td>0.388281</td>\n",
              "      <td>0.070420</td>\n",
              "      <td>0.077821</td>\n",
              "      <td>0.140447</td>\n",
              "      <td>0.189135</td>\n",
              "      <td>...</td>\n",
              "      <td>0.316014</td>\n",
              "      <td>0.306317</td>\n",
              "      <td>0.480409</td>\n",
              "      <td>0.036040</td>\n",
              "      <td>0.091339</td>\n",
              "      <td>0.011044</td>\n",
              "      <td>0.024080</td>\n",
              "      <td>0.367595</td>\n",
              "      <td>0.348075</td>\n",
              "      <td>0.337083</td>\n",
              "      <td>0.523092</td>\n",
              "      <td>0.072915</td>\n",
              "      <td>0.047083</td>\n",
              "      <td>0.059317</td>\n",
              "      <td>0.342587</td>\n",
              "      <td>0.325369</td>\n",
              "      <td>0.315623</td>\n",
              "      <td>0.488236</td>\n",
              "      <td>0.098981</td>\n",
              "      <td>0.102791</td>\n",
              "      <td>0.383284</td>\n",
              "      <td>0.371268</td>\n",
              "      <td>0.364060</td>\n",
              "      <td>0.488672</td>\n",
              "      <td>0.014147</td>\n",
              "      <td>0.375583</td>\n",
              "      <td>0.355437</td>\n",
              "      <td>0.344108</td>\n",
              "      <td>0.533792</td>\n",
              "      <td>0.389574</td>\n",
              "      <td>0.369229</td>\n",
              "      <td>0.357770</td>\n",
              "      <td>0.547088</td>\n",
              "      <td>0.034734</td>\n",
              "      <td>0.052466</td>\n",
              "      <td>0.273859</td>\n",
              "      <td>0.017829</td>\n",
              "      <td>0.307068</td>\n",
              "      <td>0.323504</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.169271</td>\n",
              "      <td>0.126485</td>\n",
              "      <td>0.385130</td>\n",
              "      <td>0.230463</td>\n",
              "      <td>0.317255</td>\n",
              "      <td>0.533089</td>\n",
              "      <td>0.748044</td>\n",
              "      <td>0.664228</td>\n",
              "      <td>0.743196</td>\n",
              "      <td>1.106701</td>\n",
              "      <td>0.028413</td>\n",
              "      <td>0.046252</td>\n",
              "      <td>0.049930</td>\n",
              "      <td>0.063039</td>\n",
              "      <td>0.087407</td>\n",
              "      <td>0.118559</td>\n",
              "      <td>0.152797</td>\n",
              "      <td>0.220146</td>\n",
              "      <td>0.142418</td>\n",
              "      <td>0.164354</td>\n",
              "      <td>1.124805</td>\n",
              "      <td>0.593084</td>\n",
              "      <td>0.623172</td>\n",
              "      <td>0.663476</td>\n",
              "      <td>0.749090</td>\n",
              "      <td>0.581652</td>\n",
              "      <td>0.748947</td>\n",
              "      <td>0.715505</td>\n",
              "      <td>0.777167</td>\n",
              "      <td>0.791096</td>\n",
              "      <td>0.760509</td>\n",
              "      <td>0.409146</td>\n",
              "      <td>0.775943</td>\n",
              "      <td>0.954549</td>\n",
              "      <td>0.847544</td>\n",
              "      <td>0.423438</td>\n",
              "      <td>0.084630</td>\n",
              "      <td>0.086811</td>\n",
              "      <td>0.170919</td>\n",
              "      <td>0.227653</td>\n",
              "      <td>...</td>\n",
              "      <td>0.366696</td>\n",
              "      <td>0.351569</td>\n",
              "      <td>0.553719</td>\n",
              "      <td>0.040489</td>\n",
              "      <td>0.096791</td>\n",
              "      <td>0.013174</td>\n",
              "      <td>0.024401</td>\n",
              "      <td>0.418736</td>\n",
              "      <td>0.394968</td>\n",
              "      <td>0.378423</td>\n",
              "      <td>0.597067</td>\n",
              "      <td>0.062927</td>\n",
              "      <td>0.053452</td>\n",
              "      <td>0.064736</td>\n",
              "      <td>0.393140</td>\n",
              "      <td>0.371993</td>\n",
              "      <td>0.356768</td>\n",
              "      <td>0.559273</td>\n",
              "      <td>0.107512</td>\n",
              "      <td>0.117794</td>\n",
              "      <td>0.403877</td>\n",
              "      <td>0.388160</td>\n",
              "      <td>0.375618</td>\n",
              "      <td>0.534734</td>\n",
              "      <td>0.011285</td>\n",
              "      <td>0.429354</td>\n",
              "      <td>0.404976</td>\n",
              "      <td>0.388124</td>\n",
              "      <td>0.610098</td>\n",
              "      <td>0.437590</td>\n",
              "      <td>0.412636</td>\n",
              "      <td>0.395503</td>\n",
              "      <td>0.620943</td>\n",
              "      <td>0.039031</td>\n",
              "      <td>0.060149</td>\n",
              "      <td>0.302577</td>\n",
              "      <td>0.021634</td>\n",
              "      <td>0.339729</td>\n",
              "      <td>0.358177</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.201214</td>\n",
              "      <td>0.151782</td>\n",
              "      <td>0.421794</td>\n",
              "      <td>0.263214</td>\n",
              "      <td>0.350937</td>\n",
              "      <td>0.567104</td>\n",
              "      <td>0.778336</td>\n",
              "      <td>0.695609</td>\n",
              "      <td>0.772108</td>\n",
              "      <td>1.107092</td>\n",
              "      <td>0.028564</td>\n",
              "      <td>0.044086</td>\n",
              "      <td>0.045230</td>\n",
              "      <td>0.049422</td>\n",
              "      <td>0.071696</td>\n",
              "      <td>0.099870</td>\n",
              "      <td>0.131883</td>\n",
              "      <td>0.193947</td>\n",
              "      <td>0.173874</td>\n",
              "      <td>0.198542</td>\n",
              "      <td>1.119847</td>\n",
              "      <td>0.628621</td>\n",
              "      <td>0.656638</td>\n",
              "      <td>0.693945</td>\n",
              "      <td>0.774810</td>\n",
              "      <td>0.618773</td>\n",
              "      <td>0.780738</td>\n",
              "      <td>0.748902</td>\n",
              "      <td>0.806958</td>\n",
              "      <td>0.819018</td>\n",
              "      <td>0.781056</td>\n",
              "      <td>0.385107</td>\n",
              "      <td>0.805113</td>\n",
              "      <td>0.956332</td>\n",
              "      <td>0.862971</td>\n",
              "      <td>0.445626</td>\n",
              "      <td>0.084873</td>\n",
              "      <td>0.083246</td>\n",
              "      <td>0.169230</td>\n",
              "      <td>0.224749</td>\n",
              "      <td>...</td>\n",
              "      <td>0.363406</td>\n",
              "      <td>0.348437</td>\n",
              "      <td>0.548580</td>\n",
              "      <td>0.040810</td>\n",
              "      <td>0.104221</td>\n",
              "      <td>0.014204</td>\n",
              "      <td>0.024438</td>\n",
              "      <td>0.417262</td>\n",
              "      <td>0.392878</td>\n",
              "      <td>0.376410</td>\n",
              "      <td>0.592104</td>\n",
              "      <td>0.071560</td>\n",
              "      <td>0.054951</td>\n",
              "      <td>0.064953</td>\n",
              "      <td>0.390691</td>\n",
              "      <td>0.369076</td>\n",
              "      <td>0.354074</td>\n",
              "      <td>0.553403</td>\n",
              "      <td>0.116046</td>\n",
              "      <td>0.123771</td>\n",
              "      <td>0.406107</td>\n",
              "      <td>0.390981</td>\n",
              "      <td>0.379279</td>\n",
              "      <td>0.527054</td>\n",
              "      <td>0.010362</td>\n",
              "      <td>0.428094</td>\n",
              "      <td>0.402946</td>\n",
              "      <td>0.386077</td>\n",
              "      <td>0.606026</td>\n",
              "      <td>0.437283</td>\n",
              "      <td>0.411742</td>\n",
              "      <td>0.394661</td>\n",
              "      <td>0.616388</td>\n",
              "      <td>0.040926</td>\n",
              "      <td>0.063137</td>\n",
              "      <td>0.306602</td>\n",
              "      <td>0.022623</td>\n",
              "      <td>0.345332</td>\n",
              "      <td>0.364837</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.201445</td>\n",
              "      <td>0.142092</td>\n",
              "      <td>0.402971</td>\n",
              "      <td>0.262329</td>\n",
              "      <td>0.342025</td>\n",
              "      <td>0.531263</td>\n",
              "      <td>0.713764</td>\n",
              "      <td>0.648947</td>\n",
              "      <td>0.722268</td>\n",
              "      <td>1.035393</td>\n",
              "      <td>0.030960</td>\n",
              "      <td>0.056085</td>\n",
              "      <td>0.068495</td>\n",
              "      <td>0.114359</td>\n",
              "      <td>0.143733</td>\n",
              "      <td>0.179653</td>\n",
              "      <td>0.215819</td>\n",
              "      <td>0.265837</td>\n",
              "      <td>0.171497</td>\n",
              "      <td>0.187828</td>\n",
              "      <td>1.014264</td>\n",
              "      <td>0.573812</td>\n",
              "      <td>0.601036</td>\n",
              "      <td>0.636922</td>\n",
              "      <td>0.710729</td>\n",
              "      <td>0.564168</td>\n",
              "      <td>0.718312</td>\n",
              "      <td>0.687400</td>\n",
              "      <td>0.744814</td>\n",
              "      <td>0.756857</td>\n",
              "      <td>0.718459</td>\n",
              "      <td>0.413091</td>\n",
              "      <td>0.736380</td>\n",
              "      <td>0.869702</td>\n",
              "      <td>0.794389</td>\n",
              "      <td>0.405554</td>\n",
              "      <td>0.077319</td>\n",
              "      <td>0.082075</td>\n",
              "      <td>0.152301</td>\n",
              "      <td>0.199589</td>\n",
              "      <td>...</td>\n",
              "      <td>0.325847</td>\n",
              "      <td>0.311424</td>\n",
              "      <td>0.533286</td>\n",
              "      <td>0.041044</td>\n",
              "      <td>0.108038</td>\n",
              "      <td>0.013479</td>\n",
              "      <td>0.024760</td>\n",
              "      <td>0.387766</td>\n",
              "      <td>0.360072</td>\n",
              "      <td>0.343858</td>\n",
              "      <td>0.578735</td>\n",
              "      <td>0.080488</td>\n",
              "      <td>0.054518</td>\n",
              "      <td>0.065088</td>\n",
              "      <td>0.358947</td>\n",
              "      <td>0.334179</td>\n",
              "      <td>0.319822</td>\n",
              "      <td>0.538894</td>\n",
              "      <td>0.119029</td>\n",
              "      <td>0.123410</td>\n",
              "      <td>0.388418</td>\n",
              "      <td>0.371290</td>\n",
              "      <td>0.361279</td>\n",
              "      <td>0.520165</td>\n",
              "      <td>0.012824</td>\n",
              "      <td>0.397418</td>\n",
              "      <td>0.368870</td>\n",
              "      <td>0.352118</td>\n",
              "      <td>0.591755</td>\n",
              "      <td>0.410210</td>\n",
              "      <td>0.381542</td>\n",
              "      <td>0.364677</td>\n",
              "      <td>0.603436</td>\n",
              "      <td>0.043291</td>\n",
              "      <td>0.067886</td>\n",
              "      <td>0.309477</td>\n",
              "      <td>0.024666</td>\n",
              "      <td>0.350341</td>\n",
              "      <td>0.373090</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.229665</td>\n",
              "      <td>0.162953</td>\n",
              "      <td>0.423904</td>\n",
              "      <td>0.289620</td>\n",
              "      <td>0.366386</td>\n",
              "      <td>0.554114</td>\n",
              "      <td>0.695700</td>\n",
              "      <td>0.669631</td>\n",
              "      <td>0.743736</td>\n",
              "      <td>1.070072</td>\n",
              "      <td>0.032345</td>\n",
              "      <td>0.055883</td>\n",
              "      <td>0.066026</td>\n",
              "      <td>0.083836</td>\n",
              "      <td>0.109215</td>\n",
              "      <td>0.141375</td>\n",
              "      <td>0.175506</td>\n",
              "      <td>0.229806</td>\n",
              "      <td>0.199053</td>\n",
              "      <td>0.209095</td>\n",
              "      <td>0.984146</td>\n",
              "      <td>0.566460</td>\n",
              "      <td>0.589285</td>\n",
              "      <td>0.621117</td>\n",
              "      <td>0.688129</td>\n",
              "      <td>0.562217</td>\n",
              "      <td>0.715803</td>\n",
              "      <td>0.689945</td>\n",
              "      <td>0.735879</td>\n",
              "      <td>0.742015</td>\n",
              "      <td>0.689711</td>\n",
              "      <td>0.380862</td>\n",
              "      <td>0.716315</td>\n",
              "      <td>0.819460</td>\n",
              "      <td>0.759189</td>\n",
              "      <td>0.389090</td>\n",
              "      <td>0.072795</td>\n",
              "      <td>0.079407</td>\n",
              "      <td>0.142314</td>\n",
              "      <td>0.188936</td>\n",
              "      <td>...</td>\n",
              "      <td>0.318474</td>\n",
              "      <td>0.304276</td>\n",
              "      <td>0.534882</td>\n",
              "      <td>0.039581</td>\n",
              "      <td>0.114430</td>\n",
              "      <td>0.014209</td>\n",
              "      <td>0.024212</td>\n",
              "      <td>0.382200</td>\n",
              "      <td>0.355067</td>\n",
              "      <td>0.339385</td>\n",
              "      <td>0.578492</td>\n",
              "      <td>0.090986</td>\n",
              "      <td>0.053709</td>\n",
              "      <td>0.062717</td>\n",
              "      <td>0.352041</td>\n",
              "      <td>0.327375</td>\n",
              "      <td>0.313412</td>\n",
              "      <td>0.539565</td>\n",
              "      <td>0.125921</td>\n",
              "      <td>0.125901</td>\n",
              "      <td>0.386563</td>\n",
              "      <td>0.370149</td>\n",
              "      <td>0.361212</td>\n",
              "      <td>0.521859</td>\n",
              "      <td>0.013623</td>\n",
              "      <td>0.392283</td>\n",
              "      <td>0.364286</td>\n",
              "      <td>0.348014</td>\n",
              "      <td>0.592079</td>\n",
              "      <td>0.405454</td>\n",
              "      <td>0.377692</td>\n",
              "      <td>0.361526</td>\n",
              "      <td>0.602225</td>\n",
              "      <td>0.041439</td>\n",
              "      <td>0.066086</td>\n",
              "      <td>0.302470</td>\n",
              "      <td>0.024663</td>\n",
              "      <td>0.342028</td>\n",
              "      <td>0.365451</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.202947</td>\n",
              "      <td>0.136122</td>\n",
              "      <td>0.403073</td>\n",
              "      <td>0.265638</td>\n",
              "      <td>0.345050</td>\n",
              "      <td>0.527880</td>\n",
              "      <td>0.659657</td>\n",
              "      <td>0.636934</td>\n",
              "      <td>0.708961</td>\n",
              "      <td>0.999804</td>\n",
              "      <td>0.028783</td>\n",
              "      <td>0.050522</td>\n",
              "      <td>0.059664</td>\n",
              "      <td>0.065190</td>\n",
              "      <td>0.084318</td>\n",
              "      <td>0.111167</td>\n",
              "      <td>0.143145</td>\n",
              "      <td>0.212148</td>\n",
              "      <td>0.169972</td>\n",
              "      <td>0.182799</td>\n",
              "      <td>0.921014</td>\n",
              "      <td>0.539363</td>\n",
              "      <td>0.560920</td>\n",
              "      <td>0.590740</td>\n",
              "      <td>0.652537</td>\n",
              "      <td>0.534494</td>\n",
              "      <td>0.674838</td>\n",
              "      <td>0.650788</td>\n",
              "      <td>0.694318</td>\n",
              "      <td>0.700837</td>\n",
              "      <td>0.655022</td>\n",
              "      <td>0.388863</td>\n",
              "      <td>0.678553</td>\n",
              "      <td>0.777336</td>\n",
              "      <td>0.721673</td>\n",
              "      <td>0.372380</td>\n",
              "      <td>0.072174</td>\n",
              "      <td>0.075148</td>\n",
              "      <td>0.142220</td>\n",
              "      <td>0.188177</td>\n",
              "      <td>...</td>\n",
              "      <td>0.311425</td>\n",
              "      <td>0.300645</td>\n",
              "      <td>0.494920</td>\n",
              "      <td>0.038747</td>\n",
              "      <td>0.107794</td>\n",
              "      <td>0.013411</td>\n",
              "      <td>0.024303</td>\n",
              "      <td>0.370802</td>\n",
              "      <td>0.346829</td>\n",
              "      <td>0.334400</td>\n",
              "      <td>0.538421</td>\n",
              "      <td>0.082576</td>\n",
              "      <td>0.052078</td>\n",
              "      <td>0.062079</td>\n",
              "      <td>0.342569</td>\n",
              "      <td>0.321431</td>\n",
              "      <td>0.310854</td>\n",
              "      <td>0.500563</td>\n",
              "      <td>0.119173</td>\n",
              "      <td>0.121215</td>\n",
              "      <td>0.371764</td>\n",
              "      <td>0.358866</td>\n",
              "      <td>0.352982</td>\n",
              "      <td>0.481096</td>\n",
              "      <td>0.013947</td>\n",
              "      <td>0.379843</td>\n",
              "      <td>0.354911</td>\n",
              "      <td>0.341864</td>\n",
              "      <td>0.551111</td>\n",
              "      <td>0.393665</td>\n",
              "      <td>0.368844</td>\n",
              "      <td>0.355811</td>\n",
              "      <td>0.562447</td>\n",
              "      <td>0.041660</td>\n",
              "      <td>0.064933</td>\n",
              "      <td>0.281306</td>\n",
              "      <td>0.023279</td>\n",
              "      <td>0.321330</td>\n",
              "      <td>0.343704</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.190090</td>\n",
              "      <td>0.134454</td>\n",
              "      <td>0.397736</td>\n",
              "      <td>0.252823</td>\n",
              "      <td>0.335747</td>\n",
              "      <td>0.533425</td>\n",
              "      <td>0.699587</td>\n",
              "      <td>0.659145</td>\n",
              "      <td>0.737174</td>\n",
              "      <td>1.055481</td>\n",
              "      <td>0.028178</td>\n",
              "      <td>0.045347</td>\n",
              "      <td>0.048341</td>\n",
              "      <td>0.066484</td>\n",
              "      <td>0.086756</td>\n",
              "      <td>0.113838</td>\n",
              "      <td>0.146531</td>\n",
              "      <td>0.214499</td>\n",
              "      <td>0.159292</td>\n",
              "      <td>0.177222</td>\n",
              "      <td>1.017778</td>\n",
              "      <td>0.566561</td>\n",
              "      <td>0.592075</td>\n",
              "      <td>0.626114</td>\n",
              "      <td>0.698645</td>\n",
              "      <td>0.558526</td>\n",
              "      <td>0.713824</td>\n",
              "      <td>0.686168</td>\n",
              "      <td>0.736074</td>\n",
              "      <td>0.744427</td>\n",
              "      <td>0.706240</td>\n",
              "      <td>0.397103</td>\n",
              "      <td>0.721832</td>\n",
              "      <td>0.860965</td>\n",
              "      <td>0.780058</td>\n",
              "      <td>0.408079</td>\n",
              "      <td>0.085810</td>\n",
              "      <td>0.088344</td>\n",
              "      <td>0.173263</td>\n",
              "      <td>0.231297</td>\n",
              "      <td>...</td>\n",
              "      <td>0.329700</td>\n",
              "      <td>0.319722</td>\n",
              "      <td>0.477639</td>\n",
              "      <td>0.038850</td>\n",
              "      <td>0.100831</td>\n",
              "      <td>0.012174</td>\n",
              "      <td>0.023939</td>\n",
              "      <td>0.379498</td>\n",
              "      <td>0.360818</td>\n",
              "      <td>0.349367</td>\n",
              "      <td>0.521613</td>\n",
              "      <td>0.071357</td>\n",
              "      <td>0.051015</td>\n",
              "      <td>0.062335</td>\n",
              "      <td>0.354211</td>\n",
              "      <td>0.338137</td>\n",
              "      <td>0.328119</td>\n",
              "      <td>0.484586</td>\n",
              "      <td>0.110986</td>\n",
              "      <td>0.118454</td>\n",
              "      <td>0.375262</td>\n",
              "      <td>0.365304</td>\n",
              "      <td>0.358435</td>\n",
              "      <td>0.462950</td>\n",
              "      <td>0.012266</td>\n",
              "      <td>0.388259</td>\n",
              "      <td>0.368885</td>\n",
              "      <td>0.357053</td>\n",
              "      <td>0.533411</td>\n",
              "      <td>0.399802</td>\n",
              "      <td>0.380080</td>\n",
              "      <td>0.368042</td>\n",
              "      <td>0.545525</td>\n",
              "      <td>0.035131</td>\n",
              "      <td>0.053746</td>\n",
              "      <td>0.271671</td>\n",
              "      <td>0.018766</td>\n",
              "      <td>0.305077</td>\n",
              "      <td>0.322051</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 108812 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3  ...    108808    108809    108810  output\n",
              "0  0.187956  0.135271  0.419206  0.254075  ...  0.023774  0.325599  0.346695   Anger\n",
              "1  0.207567  0.149162  0.413281  0.268064  ...  0.020054  0.329249  0.346610   Anger\n",
              "2  0.209710  0.151796  0.425649  0.272657  ...  0.020728  0.320051  0.338464   Anger\n",
              "3  0.220117  0.154567  0.419507  0.281169  ...  0.017829  0.307068  0.323504   Anger\n",
              "4  0.169271  0.126485  0.385130  0.230463  ...  0.021634  0.339729  0.358177   Anger\n",
              "5  0.201214  0.151782  0.421794  0.263214  ...  0.022623  0.345332  0.364837   Anger\n",
              "6  0.201445  0.142092  0.402971  0.262329  ...  0.024666  0.350341  0.373090   Anger\n",
              "7  0.229665  0.162953  0.423904  0.289620  ...  0.024663  0.342028  0.365451   Anger\n",
              "8  0.202947  0.136122  0.403073  0.265638  ...  0.023279  0.321330  0.343704   Anger\n",
              "9  0.190090  0.134454  0.397736  0.252823  ...  0.018766  0.305077  0.322051   Anger\n",
              "\n",
              "[10 rows x 108812 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDKwZJvdoX1o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7f55_uZCFEG"
      },
      "source": [
        "\n",
        "**From the dataset, we can see that:**\n",
        "*   There are in total 937 Columns excluding the index column \n",
        "*   The first 936 columns represents the landmark points in the face and the 'output' column represnts the emotion\n",
        "*   The face has been cropped and resized thus no need for further normalization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQZ4VOKCBdTM",
        "outputId": "eca133fa-692a-4e05-8d51-a6453e012412"
      },
      "source": [
        "sentiment_data_original.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 863 entries, 0 to 862\n",
            "Columns: 108812 entries, 0 to output\n",
            "dtypes: float64(108811), object(1)\n",
            "memory usage: 716.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcv0dQIABi8O",
        "outputId": "b5450b56-0437-47fe-ef7d-37b68223c3c1"
      },
      "source": [
        "#value_count in the output column \n",
        "sentiment_data_original['output'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Neutral     555\n",
              "Surprise     82\n",
              "Happy        69\n",
              "Disgust      59\n",
              "Anger        45\n",
              "Sad          28\n",
              "Fear         25\n",
              "Name: output, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh4iA1inDAXi"
      },
      "source": [
        "\n",
        "\n",
        "> So you can see that the neutral category has a staggering number of input compared to othet categories. This can be a later as the model might be overflitted. So, we need to take care of this.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqHvZrsMC_4a"
      },
      "source": [
        "all_neutral = sentiment_data_original['output'] == 'Neutral' \n",
        "list_of_neutral_index = []   \n",
        "for i in range (len(all_neutral)):\n",
        "    if all_neutral[i]:\n",
        "        list_of_neutral_index.append(i)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCcvMUQuhDpP"
      },
      "source": [
        "# Here we need to generate a list of random number\n",
        "import random\n",
        "random.shuffle(list_of_neutral_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1DK8UOGpc8F"
      },
      "source": [
        "# Dropping the random values\n",
        "sentiment_data_small_version = sentiment_data_original.drop(list_of_neutral_index[1:500])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "csLqjscvWdWt",
        "outputId": "e97f6497-dc2a-45d4-c499-777219ce7512"
      },
      "source": [
        "sentiment_data_small_version.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>108772</th>\n",
              "      <th>108773</th>\n",
              "      <th>108774</th>\n",
              "      <th>108775</th>\n",
              "      <th>108776</th>\n",
              "      <th>108777</th>\n",
              "      <th>108778</th>\n",
              "      <th>108779</th>\n",
              "      <th>108780</th>\n",
              "      <th>108781</th>\n",
              "      <th>108782</th>\n",
              "      <th>108783</th>\n",
              "      <th>108784</th>\n",
              "      <th>108785</th>\n",
              "      <th>108786</th>\n",
              "      <th>108787</th>\n",
              "      <th>108788</th>\n",
              "      <th>108789</th>\n",
              "      <th>108790</th>\n",
              "      <th>108791</th>\n",
              "      <th>108792</th>\n",
              "      <th>108793</th>\n",
              "      <th>108794</th>\n",
              "      <th>108795</th>\n",
              "      <th>108796</th>\n",
              "      <th>108797</th>\n",
              "      <th>108798</th>\n",
              "      <th>108799</th>\n",
              "      <th>108800</th>\n",
              "      <th>108801</th>\n",
              "      <th>108802</th>\n",
              "      <th>108803</th>\n",
              "      <th>108804</th>\n",
              "      <th>108805</th>\n",
              "      <th>108806</th>\n",
              "      <th>108807</th>\n",
              "      <th>108808</th>\n",
              "      <th>108809</th>\n",
              "      <th>108810</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.187956</td>\n",
              "      <td>0.135271</td>\n",
              "      <td>0.419206</td>\n",
              "      <td>0.254075</td>\n",
              "      <td>0.346495</td>\n",
              "      <td>0.571146</td>\n",
              "      <td>0.738945</td>\n",
              "      <td>0.723141</td>\n",
              "      <td>0.806195</td>\n",
              "      <td>1.116449</td>\n",
              "      <td>0.029100</td>\n",
              "      <td>0.048255</td>\n",
              "      <td>0.054430</td>\n",
              "      <td>0.058375</td>\n",
              "      <td>0.081279</td>\n",
              "      <td>0.109907</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>0.191198</td>\n",
              "      <td>0.157580</td>\n",
              "      <td>0.179609</td>\n",
              "      <td>1.046170</td>\n",
              "      <td>0.608358</td>\n",
              "      <td>0.629658</td>\n",
              "      <td>0.659367</td>\n",
              "      <td>0.730874</td>\n",
              "      <td>0.603732</td>\n",
              "      <td>0.768399</td>\n",
              "      <td>0.740817</td>\n",
              "      <td>0.788229</td>\n",
              "      <td>0.793099</td>\n",
              "      <td>0.727295</td>\n",
              "      <td>0.351643</td>\n",
              "      <td>0.763274</td>\n",
              "      <td>0.868677</td>\n",
              "      <td>0.803198</td>\n",
              "      <td>0.403602</td>\n",
              "      <td>0.071373</td>\n",
              "      <td>0.072551</td>\n",
              "      <td>0.140190</td>\n",
              "      <td>0.182667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.383090</td>\n",
              "      <td>0.367822</td>\n",
              "      <td>0.555479</td>\n",
              "      <td>0.038096</td>\n",
              "      <td>0.096757</td>\n",
              "      <td>0.013857</td>\n",
              "      <td>0.023125</td>\n",
              "      <td>0.439093</td>\n",
              "      <td>0.414083</td>\n",
              "      <td>0.397515</td>\n",
              "      <td>0.596772</td>\n",
              "      <td>0.068370</td>\n",
              "      <td>0.051937</td>\n",
              "      <td>0.060741</td>\n",
              "      <td>0.412759</td>\n",
              "      <td>0.390038</td>\n",
              "      <td>0.374819</td>\n",
              "      <td>0.560521</td>\n",
              "      <td>0.108174</td>\n",
              "      <td>0.113428</td>\n",
              "      <td>0.429644</td>\n",
              "      <td>0.412602</td>\n",
              "      <td>0.400537</td>\n",
              "      <td>0.541059</td>\n",
              "      <td>0.009956</td>\n",
              "      <td>0.449599</td>\n",
              "      <td>0.423889</td>\n",
              "      <td>0.406911</td>\n",
              "      <td>0.610217</td>\n",
              "      <td>0.459337</td>\n",
              "      <td>0.433453</td>\n",
              "      <td>0.416359</td>\n",
              "      <td>0.619876</td>\n",
              "      <td>0.040861</td>\n",
              "      <td>0.064414</td>\n",
              "      <td>0.287163</td>\n",
              "      <td>0.023774</td>\n",
              "      <td>0.325599</td>\n",
              "      <td>0.346695</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.207567</td>\n",
              "      <td>0.149162</td>\n",
              "      <td>0.413281</td>\n",
              "      <td>0.268064</td>\n",
              "      <td>0.350784</td>\n",
              "      <td>0.550446</td>\n",
              "      <td>0.729772</td>\n",
              "      <td>0.661067</td>\n",
              "      <td>0.733735</td>\n",
              "      <td>1.052325</td>\n",
              "      <td>0.029055</td>\n",
              "      <td>0.048058</td>\n",
              "      <td>0.054046</td>\n",
              "      <td>0.052564</td>\n",
              "      <td>0.073975</td>\n",
              "      <td>0.102124</td>\n",
              "      <td>0.133495</td>\n",
              "      <td>0.196838</td>\n",
              "      <td>0.178358</td>\n",
              "      <td>0.193430</td>\n",
              "      <td>1.071643</td>\n",
              "      <td>0.590631</td>\n",
              "      <td>0.617111</td>\n",
              "      <td>0.652965</td>\n",
              "      <td>0.726510</td>\n",
              "      <td>0.583013</td>\n",
              "      <td>0.725266</td>\n",
              "      <td>0.698325</td>\n",
              "      <td>0.749550</td>\n",
              "      <td>0.762678</td>\n",
              "      <td>0.737213</td>\n",
              "      <td>0.403877</td>\n",
              "      <td>0.753039</td>\n",
              "      <td>0.920617</td>\n",
              "      <td>0.821129</td>\n",
              "      <td>0.411357</td>\n",
              "      <td>0.072746</td>\n",
              "      <td>0.077174</td>\n",
              "      <td>0.147522</td>\n",
              "      <td>0.198965</td>\n",
              "      <td>...</td>\n",
              "      <td>0.334787</td>\n",
              "      <td>0.322138</td>\n",
              "      <td>0.507045</td>\n",
              "      <td>0.038844</td>\n",
              "      <td>0.088166</td>\n",
              "      <td>0.011825</td>\n",
              "      <td>0.025459</td>\n",
              "      <td>0.388988</td>\n",
              "      <td>0.365276</td>\n",
              "      <td>0.351106</td>\n",
              "      <td>0.552140</td>\n",
              "      <td>0.063657</td>\n",
              "      <td>0.050616</td>\n",
              "      <td>0.063830</td>\n",
              "      <td>0.363319</td>\n",
              "      <td>0.342413</td>\n",
              "      <td>0.329606</td>\n",
              "      <td>0.514974</td>\n",
              "      <td>0.096696</td>\n",
              "      <td>0.105036</td>\n",
              "      <td>0.393837</td>\n",
              "      <td>0.378244</td>\n",
              "      <td>0.367825</td>\n",
              "      <td>0.508859</td>\n",
              "      <td>0.013846</td>\n",
              "      <td>0.398088</td>\n",
              "      <td>0.373699</td>\n",
              "      <td>0.359201</td>\n",
              "      <td>0.563786</td>\n",
              "      <td>0.410744</td>\n",
              "      <td>0.385853</td>\n",
              "      <td>0.371103</td>\n",
              "      <td>0.577582</td>\n",
              "      <td>0.040470</td>\n",
              "      <td>0.060192</td>\n",
              "      <td>0.291065</td>\n",
              "      <td>0.020054</td>\n",
              "      <td>0.329249</td>\n",
              "      <td>0.346610</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.209710</td>\n",
              "      <td>0.151796</td>\n",
              "      <td>0.425649</td>\n",
              "      <td>0.272657</td>\n",
              "      <td>0.358480</td>\n",
              "      <td>0.568503</td>\n",
              "      <td>0.729258</td>\n",
              "      <td>0.702382</td>\n",
              "      <td>0.781597</td>\n",
              "      <td>1.093249</td>\n",
              "      <td>0.029604</td>\n",
              "      <td>0.048569</td>\n",
              "      <td>0.053562</td>\n",
              "      <td>0.059927</td>\n",
              "      <td>0.081331</td>\n",
              "      <td>0.108687</td>\n",
              "      <td>0.138396</td>\n",
              "      <td>0.192105</td>\n",
              "      <td>0.180009</td>\n",
              "      <td>0.198394</td>\n",
              "      <td>1.054637</td>\n",
              "      <td>0.598924</td>\n",
              "      <td>0.621862</td>\n",
              "      <td>0.654303</td>\n",
              "      <td>0.723751</td>\n",
              "      <td>0.593897</td>\n",
              "      <td>0.747247</td>\n",
              "      <td>0.722203</td>\n",
              "      <td>0.766800</td>\n",
              "      <td>0.773796</td>\n",
              "      <td>0.727711</td>\n",
              "      <td>0.367211</td>\n",
              "      <td>0.751856</td>\n",
              "      <td>0.886812</td>\n",
              "      <td>0.806554</td>\n",
              "      <td>0.410377</td>\n",
              "      <td>0.075550</td>\n",
              "      <td>0.076730</td>\n",
              "      <td>0.150007</td>\n",
              "      <td>0.198634</td>\n",
              "      <td>...</td>\n",
              "      <td>0.351177</td>\n",
              "      <td>0.338624</td>\n",
              "      <td>0.516268</td>\n",
              "      <td>0.039003</td>\n",
              "      <td>0.102248</td>\n",
              "      <td>0.013609</td>\n",
              "      <td>0.024207</td>\n",
              "      <td>0.404742</td>\n",
              "      <td>0.382472</td>\n",
              "      <td>0.368544</td>\n",
              "      <td>0.559361</td>\n",
              "      <td>0.075464</td>\n",
              "      <td>0.052612</td>\n",
              "      <td>0.062633</td>\n",
              "      <td>0.378595</td>\n",
              "      <td>0.358844</td>\n",
              "      <td>0.346298</td>\n",
              "      <td>0.522152</td>\n",
              "      <td>0.113270</td>\n",
              "      <td>0.118113</td>\n",
              "      <td>0.406730</td>\n",
              "      <td>0.393133</td>\n",
              "      <td>0.383738</td>\n",
              "      <td>0.507482</td>\n",
              "      <td>0.011729</td>\n",
              "      <td>0.414348</td>\n",
              "      <td>0.391303</td>\n",
              "      <td>0.376955</td>\n",
              "      <td>0.572403</td>\n",
              "      <td>0.425904</td>\n",
              "      <td>0.402678</td>\n",
              "      <td>0.388212</td>\n",
              "      <td>0.583566</td>\n",
              "      <td>0.038252</td>\n",
              "      <td>0.058773</td>\n",
              "      <td>0.283944</td>\n",
              "      <td>0.020728</td>\n",
              "      <td>0.320051</td>\n",
              "      <td>0.338464</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.220117</td>\n",
              "      <td>0.154567</td>\n",
              "      <td>0.419507</td>\n",
              "      <td>0.281169</td>\n",
              "      <td>0.360029</td>\n",
              "      <td>0.550323</td>\n",
              "      <td>0.703096</td>\n",
              "      <td>0.681569</td>\n",
              "      <td>0.758550</td>\n",
              "      <td>1.051571</td>\n",
              "      <td>0.031128</td>\n",
              "      <td>0.053641</td>\n",
              "      <td>0.062343</td>\n",
              "      <td>0.080691</td>\n",
              "      <td>0.106775</td>\n",
              "      <td>0.139166</td>\n",
              "      <td>0.173484</td>\n",
              "      <td>0.226350</td>\n",
              "      <td>0.188956</td>\n",
              "      <td>0.200879</td>\n",
              "      <td>1.006257</td>\n",
              "      <td>0.570464</td>\n",
              "      <td>0.593828</td>\n",
              "      <td>0.626521</td>\n",
              "      <td>0.696045</td>\n",
              "      <td>0.565623</td>\n",
              "      <td>0.727810</td>\n",
              "      <td>0.700437</td>\n",
              "      <td>0.747852</td>\n",
              "      <td>0.753084</td>\n",
              "      <td>0.696103</td>\n",
              "      <td>0.378425</td>\n",
              "      <td>0.726623</td>\n",
              "      <td>0.840830</td>\n",
              "      <td>0.771020</td>\n",
              "      <td>0.388281</td>\n",
              "      <td>0.070420</td>\n",
              "      <td>0.077821</td>\n",
              "      <td>0.140447</td>\n",
              "      <td>0.189135</td>\n",
              "      <td>...</td>\n",
              "      <td>0.316014</td>\n",
              "      <td>0.306317</td>\n",
              "      <td>0.480409</td>\n",
              "      <td>0.036040</td>\n",
              "      <td>0.091339</td>\n",
              "      <td>0.011044</td>\n",
              "      <td>0.024080</td>\n",
              "      <td>0.367595</td>\n",
              "      <td>0.348075</td>\n",
              "      <td>0.337083</td>\n",
              "      <td>0.523092</td>\n",
              "      <td>0.072915</td>\n",
              "      <td>0.047083</td>\n",
              "      <td>0.059317</td>\n",
              "      <td>0.342587</td>\n",
              "      <td>0.325369</td>\n",
              "      <td>0.315623</td>\n",
              "      <td>0.488236</td>\n",
              "      <td>0.098981</td>\n",
              "      <td>0.102791</td>\n",
              "      <td>0.383284</td>\n",
              "      <td>0.371268</td>\n",
              "      <td>0.364060</td>\n",
              "      <td>0.488672</td>\n",
              "      <td>0.014147</td>\n",
              "      <td>0.375583</td>\n",
              "      <td>0.355437</td>\n",
              "      <td>0.344108</td>\n",
              "      <td>0.533792</td>\n",
              "      <td>0.389574</td>\n",
              "      <td>0.369229</td>\n",
              "      <td>0.357770</td>\n",
              "      <td>0.547088</td>\n",
              "      <td>0.034734</td>\n",
              "      <td>0.052466</td>\n",
              "      <td>0.273859</td>\n",
              "      <td>0.017829</td>\n",
              "      <td>0.307068</td>\n",
              "      <td>0.323504</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.169271</td>\n",
              "      <td>0.126485</td>\n",
              "      <td>0.385130</td>\n",
              "      <td>0.230463</td>\n",
              "      <td>0.317255</td>\n",
              "      <td>0.533089</td>\n",
              "      <td>0.748044</td>\n",
              "      <td>0.664228</td>\n",
              "      <td>0.743196</td>\n",
              "      <td>1.106701</td>\n",
              "      <td>0.028413</td>\n",
              "      <td>0.046252</td>\n",
              "      <td>0.049930</td>\n",
              "      <td>0.063039</td>\n",
              "      <td>0.087407</td>\n",
              "      <td>0.118559</td>\n",
              "      <td>0.152797</td>\n",
              "      <td>0.220146</td>\n",
              "      <td>0.142418</td>\n",
              "      <td>0.164354</td>\n",
              "      <td>1.124805</td>\n",
              "      <td>0.593084</td>\n",
              "      <td>0.623172</td>\n",
              "      <td>0.663476</td>\n",
              "      <td>0.749090</td>\n",
              "      <td>0.581652</td>\n",
              "      <td>0.748947</td>\n",
              "      <td>0.715505</td>\n",
              "      <td>0.777167</td>\n",
              "      <td>0.791096</td>\n",
              "      <td>0.760509</td>\n",
              "      <td>0.409146</td>\n",
              "      <td>0.775943</td>\n",
              "      <td>0.954549</td>\n",
              "      <td>0.847544</td>\n",
              "      <td>0.423438</td>\n",
              "      <td>0.084630</td>\n",
              "      <td>0.086811</td>\n",
              "      <td>0.170919</td>\n",
              "      <td>0.227653</td>\n",
              "      <td>...</td>\n",
              "      <td>0.366696</td>\n",
              "      <td>0.351569</td>\n",
              "      <td>0.553719</td>\n",
              "      <td>0.040489</td>\n",
              "      <td>0.096791</td>\n",
              "      <td>0.013174</td>\n",
              "      <td>0.024401</td>\n",
              "      <td>0.418736</td>\n",
              "      <td>0.394968</td>\n",
              "      <td>0.378423</td>\n",
              "      <td>0.597067</td>\n",
              "      <td>0.062927</td>\n",
              "      <td>0.053452</td>\n",
              "      <td>0.064736</td>\n",
              "      <td>0.393140</td>\n",
              "      <td>0.371993</td>\n",
              "      <td>0.356768</td>\n",
              "      <td>0.559273</td>\n",
              "      <td>0.107512</td>\n",
              "      <td>0.117794</td>\n",
              "      <td>0.403877</td>\n",
              "      <td>0.388160</td>\n",
              "      <td>0.375618</td>\n",
              "      <td>0.534734</td>\n",
              "      <td>0.011285</td>\n",
              "      <td>0.429354</td>\n",
              "      <td>0.404976</td>\n",
              "      <td>0.388124</td>\n",
              "      <td>0.610098</td>\n",
              "      <td>0.437590</td>\n",
              "      <td>0.412636</td>\n",
              "      <td>0.395503</td>\n",
              "      <td>0.620943</td>\n",
              "      <td>0.039031</td>\n",
              "      <td>0.060149</td>\n",
              "      <td>0.302577</td>\n",
              "      <td>0.021634</td>\n",
              "      <td>0.339729</td>\n",
              "      <td>0.358177</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 108812 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3  ...    108808    108809    108810  output\n",
              "0  0.187956  0.135271  0.419206  0.254075  ...  0.023774  0.325599  0.346695   Anger\n",
              "1  0.207567  0.149162  0.413281  0.268064  ...  0.020054  0.329249  0.346610   Anger\n",
              "2  0.209710  0.151796  0.425649  0.272657  ...  0.020728  0.320051  0.338464   Anger\n",
              "3  0.220117  0.154567  0.419507  0.281169  ...  0.017829  0.307068  0.323504   Anger\n",
              "4  0.169271  0.126485  0.385130  0.230463  ...  0.021634  0.339729  0.358177   Anger\n",
              "\n",
              "[5 rows x 108812 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LojMwG4lWz7K",
        "outputId": "625cdc6c-92b3-45b6-9f50-7b9d84775d7b"
      },
      "source": [
        "sentiment_data_small_version['output'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Surprise    82\n",
              "Happy       69\n",
              "Disgust     59\n",
              "Neutral     56\n",
              "Anger       45\n",
              "Sad         28\n",
              "Fear        25\n",
              "Name: output, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvDgkKUsYy2D"
      },
      "source": [
        "## Mapping The Output Column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JmeYUMXY16u"
      },
      "source": [
        "input_df_copy = sentiment_data_small_version.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1vrnHdxh84x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f67bd7-3fe4-4e41-fd7a-ce8f88443b96"
      },
      "source": [
        "input_df_copy.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(364, 108812)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekyhnB5HY_Eb"
      },
      "source": [
        "uniqueValues = input_df_copy['output'].unique()\n",
        "input_df_copy['output'] = input_df_copy['output'].map({uniqueValues[0]:0,uniqueValues[1]:1,uniqueValues[2]:2,\n",
        "                                                       uniqueValues[3]:3,uniqueValues[4]:4,uniqueValues[5]:5,\n",
        "                                                       uniqueValues[6]:6})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWoeBw72ZKUa",
        "outputId": "8aaaeb86-68f4-4b58-b89e-98db27731b9e"
      },
      "source": [
        "uniqueValues"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK1LdxEXZTRI"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP0eYcREKUw2"
      },
      "source": [
        "X = input_df_copy.drop(['output'],axis=1)\n",
        "y=input_df_copy['output']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLt1vOYnKtZ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9377a757-95db-4541-c385-d9614cce988a"
      },
      "source": [
        "y.head(86)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0\n",
              "1     0\n",
              "2     0\n",
              "3     0\n",
              "4     0\n",
              "     ..\n",
              "81    1\n",
              "82    1\n",
              "83    1\n",
              "84    1\n",
              "85    1\n",
              "Name: output, Length: 86, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csdkIMLcGYP5"
      },
      "source": [
        "#apply SelectKBest class to extract top 10 best features\n",
        "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
        "fit = bestfeatures.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li17BU2zLPD4"
      },
      "source": [
        "dfscores = pd.DataFrame(fit.scores_)\n",
        "dfcolumns = pd.DataFrame(X.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKJ323D9LRVR"
      },
      "source": [
        "#concat two dataframes for better visualization \n",
        "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "featureScores.columns = ['Specs','Score']  #naming the dataframe columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygrSgRidLVJP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "93077047-ea58-4204-d609-46b82ada1a90"
      },
      "source": [
        "featureScores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Specs</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.464170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.396295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.247906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.340175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.258935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108806</th>\n",
              "      <td>108806</td>\n",
              "      <td>0.133161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108807</th>\n",
              "      <td>108807</td>\n",
              "      <td>0.189749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108808</th>\n",
              "      <td>108808</td>\n",
              "      <td>0.033036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108809</th>\n",
              "      <td>108809</td>\n",
              "      <td>0.261581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108810</th>\n",
              "      <td>108810</td>\n",
              "      <td>0.278889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>108811 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Specs     Score\n",
              "0            0  0.464170\n",
              "1            1  0.396295\n",
              "2            2  0.247906\n",
              "3            3  0.340175\n",
              "4            4  0.258935\n",
              "...        ...       ...\n",
              "108806  108806  0.133161\n",
              "108807  108807  0.189749\n",
              "108808  108808  0.033036\n",
              "108809  108809  0.261581\n",
              "108810  108810  0.278889\n",
              "\n",
              "[108811 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Geqrz3uFLgu_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d96c9ff4-f5db-4154-931a-d8c39a303a2c"
      },
      "source": [
        "important_feature= featureScores.nlargest(100,'Score')[\"Specs\"]\n",
        "important_feature"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5980      5980\n",
              "5527      5527\n",
              "34895    34895\n",
              "96880    96880\n",
              "89158    89158\n",
              "         ...  \n",
              "15          15\n",
              "96877    96877\n",
              "5376      5376\n",
              "34128    34128\n",
              "7171      7171\n",
              "Name: Specs, Length: 100, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czzd2M-igr03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef77279-5492-4826-a18f-56edd0fff8aa"
      },
      "source": [
        "imp_fea_dataset = input_df_copy[important_feature].join(input_df_copy[\"output\"])\n",
        "imp_fea_dataset.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(364, 101)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wynE83nGZaAN"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56PAsc3mZbhG"
      },
      "source": [
        "# Create X & y\n",
        "X = imp_fea_dataset.drop(\"output\", axis=1)\n",
        "y = imp_fea_dataset[\"output\"]\n",
        "\n",
        "# Build our train and test sets (use random state to ensure same split as before)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKTrYiSkZfwM"
      },
      "source": [
        "# Model Declaration and Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GeMq8iWZjza"
      },
      "source": [
        "## Model 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrAdvUFIcsuY"
      },
      "source": [
        "### Declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLDNxnFAZhXs"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(256, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(128, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate = .0003),\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    patience=250,\n",
        "    min_delta=0.0001,\n",
        "    restore_best_weights=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt7Sb_fNcvWu"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGPlkzWGZpww",
        "outputId": "2bf12e23-1a1f-4d9f-9a1c-2566022198ee"
      },
      "source": [
        "history_1 = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=2000,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1, \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "10/10 [==============================] - 1s 34ms/step - loss: 1.8551 - accuracy: 0.2234 - val_loss: 1.7706 - val_accuracy: 0.2466\n",
            "Epoch 2/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.7712 - accuracy: 0.2199 - val_loss: 1.7058 - val_accuracy: 0.2466\n",
            "Epoch 3/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.7245 - accuracy: 0.2199 - val_loss: 1.6678 - val_accuracy: 0.2466\n",
            "Epoch 4/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.7071 - accuracy: 0.2199 - val_loss: 1.6503 - val_accuracy: 0.2466\n",
            "Epoch 5/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.6653 - accuracy: 0.2199 - val_loss: 1.6343 - val_accuracy: 0.2466\n",
            "Epoch 6/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.6556 - accuracy: 0.2199 - val_loss: 1.6213 - val_accuracy: 0.2466\n",
            "Epoch 7/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.6285 - accuracy: 0.2199 - val_loss: 1.6048 - val_accuracy: 0.2466\n",
            "Epoch 8/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.6024 - accuracy: 0.2234 - val_loss: 1.5836 - val_accuracy: 0.2466\n",
            "Epoch 9/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.5829 - accuracy: 0.2302 - val_loss: 1.5526 - val_accuracy: 0.2603\n",
            "Epoch 10/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5567 - accuracy: 0.2612 - val_loss: 1.5222 - val_accuracy: 0.3288\n",
            "Epoch 11/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5392 - accuracy: 0.3230 - val_loss: 1.5078 - val_accuracy: 0.3288\n",
            "Epoch 12/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.5187 - accuracy: 0.3402 - val_loss: 1.4924 - val_accuracy: 0.3699\n",
            "Epoch 13/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4852 - accuracy: 0.3677 - val_loss: 1.4572 - val_accuracy: 0.3836\n",
            "Epoch 14/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4709 - accuracy: 0.3952 - val_loss: 1.4300 - val_accuracy: 0.3836\n",
            "Epoch 15/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4493 - accuracy: 0.3986 - val_loss: 1.4049 - val_accuracy: 0.3836\n",
            "Epoch 16/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.4214 - accuracy: 0.4124 - val_loss: 1.3893 - val_accuracy: 0.3973\n",
            "Epoch 17/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.4192 - accuracy: 0.4467 - val_loss: 1.3831 - val_accuracy: 0.4247\n",
            "Epoch 18/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3926 - accuracy: 0.4570 - val_loss: 1.3455 - val_accuracy: 0.3973\n",
            "Epoch 19/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3720 - accuracy: 0.4330 - val_loss: 1.3199 - val_accuracy: 0.4795\n",
            "Epoch 20/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3676 - accuracy: 0.4296 - val_loss: 1.2897 - val_accuracy: 0.4384\n",
            "Epoch 21/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3349 - accuracy: 0.4467 - val_loss: 1.2751 - val_accuracy: 0.4658\n",
            "Epoch 22/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.3407 - accuracy: 0.4605 - val_loss: 1.2541 - val_accuracy: 0.4658\n",
            "Epoch 23/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3053 - accuracy: 0.4605 - val_loss: 1.2275 - val_accuracy: 0.5068\n",
            "Epoch 24/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3001 - accuracy: 0.4811 - val_loss: 1.2127 - val_accuracy: 0.4932\n",
            "Epoch 25/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2879 - accuracy: 0.4742 - val_loss: 1.2073 - val_accuracy: 0.4932\n",
            "Epoch 26/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2983 - accuracy: 0.4639 - val_loss: 1.1892 - val_accuracy: 0.4521\n",
            "Epoch 27/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2813 - accuracy: 0.4880 - val_loss: 1.1759 - val_accuracy: 0.5068\n",
            "Epoch 28/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2535 - accuracy: 0.4811 - val_loss: 1.1584 - val_accuracy: 0.4932\n",
            "Epoch 29/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2732 - accuracy: 0.4467 - val_loss: 1.1565 - val_accuracy: 0.4521\n",
            "Epoch 30/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2676 - accuracy: 0.4536 - val_loss: 1.1512 - val_accuracy: 0.4658\n",
            "Epoch 31/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2400 - accuracy: 0.5120 - val_loss: 1.1242 - val_accuracy: 0.5342\n",
            "Epoch 32/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2529 - accuracy: 0.4880 - val_loss: 1.1151 - val_accuracy: 0.5205\n",
            "Epoch 33/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2239 - accuracy: 0.5361 - val_loss: 1.1262 - val_accuracy: 0.5342\n",
            "Epoch 34/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2111 - accuracy: 0.5464 - val_loss: 1.1076 - val_accuracy: 0.5205\n",
            "Epoch 35/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2208 - accuracy: 0.5258 - val_loss: 1.1045 - val_accuracy: 0.4932\n",
            "Epoch 36/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2058 - accuracy: 0.5052 - val_loss: 1.0931 - val_accuracy: 0.5479\n",
            "Epoch 37/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1982 - accuracy: 0.5292 - val_loss: 1.0956 - val_accuracy: 0.5205\n",
            "Epoch 38/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2124 - accuracy: 0.5223 - val_loss: 1.0882 - val_accuracy: 0.5342\n",
            "Epoch 39/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1953 - accuracy: 0.5292 - val_loss: 1.0895 - val_accuracy: 0.4932\n",
            "Epoch 40/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2084 - accuracy: 0.4914 - val_loss: 1.1006 - val_accuracy: 0.4795\n",
            "Epoch 41/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2020 - accuracy: 0.5017 - val_loss: 1.0872 - val_accuracy: 0.4932\n",
            "Epoch 42/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2022 - accuracy: 0.5017 - val_loss: 1.0722 - val_accuracy: 0.5342\n",
            "Epoch 43/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1847 - accuracy: 0.5155 - val_loss: 1.0621 - val_accuracy: 0.5342\n",
            "Epoch 44/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1738 - accuracy: 0.5155 - val_loss: 1.0771 - val_accuracy: 0.5479\n",
            "Epoch 45/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1700 - accuracy: 0.5292 - val_loss: 1.0756 - val_accuracy: 0.5205\n",
            "Epoch 46/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2176 - accuracy: 0.5086 - val_loss: 1.0876 - val_accuracy: 0.5205\n",
            "Epoch 47/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1766 - accuracy: 0.5086 - val_loss: 1.0798 - val_accuracy: 0.5068\n",
            "Epoch 48/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1859 - accuracy: 0.5017 - val_loss: 1.0699 - val_accuracy: 0.5068\n",
            "Epoch 49/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1890 - accuracy: 0.5189 - val_loss: 1.0698 - val_accuracy: 0.5068\n",
            "Epoch 50/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1793 - accuracy: 0.5361 - val_loss: 1.0631 - val_accuracy: 0.4932\n",
            "Epoch 51/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1933 - accuracy: 0.5086 - val_loss: 1.0602 - val_accuracy: 0.5205\n",
            "Epoch 52/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.1687 - accuracy: 0.5361 - val_loss: 1.0584 - val_accuracy: 0.5342\n",
            "Epoch 53/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1628 - accuracy: 0.5326 - val_loss: 1.0523 - val_accuracy: 0.5068\n",
            "Epoch 54/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1796 - accuracy: 0.5120 - val_loss: 1.0487 - val_accuracy: 0.5342\n",
            "Epoch 55/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1915 - accuracy: 0.5326 - val_loss: 1.0531 - val_accuracy: 0.5068\n",
            "Epoch 56/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1546 - accuracy: 0.5258 - val_loss: 1.0527 - val_accuracy: 0.5068\n",
            "Epoch 57/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1739 - accuracy: 0.5120 - val_loss: 1.0533 - val_accuracy: 0.4932\n",
            "Epoch 58/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1703 - accuracy: 0.5155 - val_loss: 1.0550 - val_accuracy: 0.5205\n",
            "Epoch 59/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1723 - accuracy: 0.5189 - val_loss: 1.0427 - val_accuracy: 0.5479\n",
            "Epoch 60/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1925 - accuracy: 0.5086 - val_loss: 1.0367 - val_accuracy: 0.5342\n",
            "Epoch 61/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1545 - accuracy: 0.5361 - val_loss: 1.0380 - val_accuracy: 0.5342\n",
            "Epoch 62/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1410 - accuracy: 0.5464 - val_loss: 1.0340 - val_accuracy: 0.4932\n",
            "Epoch 63/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1275 - accuracy: 0.5533 - val_loss: 1.0380 - val_accuracy: 0.5342\n",
            "Epoch 64/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1575 - accuracy: 0.5086 - val_loss: 1.0487 - val_accuracy: 0.5068\n",
            "Epoch 65/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1642 - accuracy: 0.5120 - val_loss: 1.0416 - val_accuracy: 0.5479\n",
            "Epoch 66/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1416 - accuracy: 0.5498 - val_loss: 1.0301 - val_accuracy: 0.5479\n",
            "Epoch 67/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1458 - accuracy: 0.5430 - val_loss: 1.0296 - val_accuracy: 0.5342\n",
            "Epoch 68/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1457 - accuracy: 0.5258 - val_loss: 1.0305 - val_accuracy: 0.5342\n",
            "Epoch 69/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1383 - accuracy: 0.5533 - val_loss: 1.0209 - val_accuracy: 0.5205\n",
            "Epoch 70/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1637 - accuracy: 0.5361 - val_loss: 1.0394 - val_accuracy: 0.5205\n",
            "Epoch 71/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1295 - accuracy: 0.5498 - val_loss: 1.0295 - val_accuracy: 0.5068\n",
            "Epoch 72/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1609 - accuracy: 0.5326 - val_loss: 1.0318 - val_accuracy: 0.5068\n",
            "Epoch 73/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1362 - accuracy: 0.5361 - val_loss: 1.0352 - val_accuracy: 0.5342\n",
            "Epoch 74/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1791 - accuracy: 0.5017 - val_loss: 1.0372 - val_accuracy: 0.4795\n",
            "Epoch 75/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1232 - accuracy: 0.5567 - val_loss: 1.0553 - val_accuracy: 0.5068\n",
            "Epoch 76/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1440 - accuracy: 0.5292 - val_loss: 1.0311 - val_accuracy: 0.5068\n",
            "Epoch 77/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1240 - accuracy: 0.5326 - val_loss: 1.0438 - val_accuracy: 0.5205\n",
            "Epoch 78/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1607 - accuracy: 0.5155 - val_loss: 1.0264 - val_accuracy: 0.5342\n",
            "Epoch 79/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1206 - accuracy: 0.5430 - val_loss: 1.0434 - val_accuracy: 0.5342\n",
            "Epoch 80/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1479 - accuracy: 0.5017 - val_loss: 1.0216 - val_accuracy: 0.5479\n",
            "Epoch 81/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1280 - accuracy: 0.5258 - val_loss: 1.0203 - val_accuracy: 0.5479\n",
            "Epoch 82/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1455 - accuracy: 0.5464 - val_loss: 1.0264 - val_accuracy: 0.5479\n",
            "Epoch 83/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1207 - accuracy: 0.5498 - val_loss: 1.0306 - val_accuracy: 0.4932\n",
            "Epoch 84/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1161 - accuracy: 0.5120 - val_loss: 1.0392 - val_accuracy: 0.5205\n",
            "Epoch 85/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1214 - accuracy: 0.5395 - val_loss: 1.0338 - val_accuracy: 0.5205\n",
            "Epoch 86/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0777 - accuracy: 0.5601 - val_loss: 1.0271 - val_accuracy: 0.5205\n",
            "Epoch 87/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1136 - accuracy: 0.5567 - val_loss: 1.0270 - val_accuracy: 0.5205\n",
            "Epoch 88/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1291 - accuracy: 0.5189 - val_loss: 1.0300 - val_accuracy: 0.5205\n",
            "Epoch 89/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1159 - accuracy: 0.5395 - val_loss: 1.0348 - val_accuracy: 0.4932\n",
            "Epoch 90/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1009 - accuracy: 0.5430 - val_loss: 1.0246 - val_accuracy: 0.4795\n",
            "Epoch 91/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1019 - accuracy: 0.5292 - val_loss: 1.0236 - val_accuracy: 0.5205\n",
            "Epoch 92/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1012 - accuracy: 0.5430 - val_loss: 1.0271 - val_accuracy: 0.4795\n",
            "Epoch 93/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1135 - accuracy: 0.5567 - val_loss: 1.0140 - val_accuracy: 0.4932\n",
            "Epoch 94/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1133 - accuracy: 0.5326 - val_loss: 1.0096 - val_accuracy: 0.4932\n",
            "Epoch 95/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0886 - accuracy: 0.5430 - val_loss: 1.0052 - val_accuracy: 0.5205\n",
            "Epoch 96/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0981 - accuracy: 0.5567 - val_loss: 1.0080 - val_accuracy: 0.5068\n",
            "Epoch 97/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.1059 - accuracy: 0.5739 - val_loss: 1.0003 - val_accuracy: 0.5479\n",
            "Epoch 98/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0875 - accuracy: 0.5704 - val_loss: 0.9921 - val_accuracy: 0.5479\n",
            "Epoch 99/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.5670 - val_loss: 0.9985 - val_accuracy: 0.5479\n",
            "Epoch 100/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0911 - accuracy: 0.5704 - val_loss: 1.0050 - val_accuracy: 0.5479\n",
            "Epoch 101/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0818 - accuracy: 0.5498 - val_loss: 1.0095 - val_accuracy: 0.5205\n",
            "Epoch 102/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0879 - accuracy: 0.5498 - val_loss: 1.0142 - val_accuracy: 0.5068\n",
            "Epoch 103/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0770 - accuracy: 0.5533 - val_loss: 1.0048 - val_accuracy: 0.5068\n",
            "Epoch 104/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0810 - accuracy: 0.5636 - val_loss: 1.0054 - val_accuracy: 0.5616\n",
            "Epoch 105/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0747 - accuracy: 0.5567 - val_loss: 1.0056 - val_accuracy: 0.5479\n",
            "Epoch 106/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0642 - accuracy: 0.5567 - val_loss: 1.0022 - val_accuracy: 0.5479\n",
            "Epoch 107/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0937 - accuracy: 0.5464 - val_loss: 1.0074 - val_accuracy: 0.5342\n",
            "Epoch 108/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0641 - accuracy: 0.5739 - val_loss: 1.0184 - val_accuracy: 0.5342\n",
            "Epoch 109/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0599 - accuracy: 0.5395 - val_loss: 0.9976 - val_accuracy: 0.5342\n",
            "Epoch 110/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0588 - accuracy: 0.5704 - val_loss: 0.9906 - val_accuracy: 0.5342\n",
            "Epoch 111/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0931 - accuracy: 0.5704 - val_loss: 0.9757 - val_accuracy: 0.5342\n",
            "Epoch 112/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0622 - accuracy: 0.5808 - val_loss: 0.9733 - val_accuracy: 0.5890\n",
            "Epoch 113/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0830 - accuracy: 0.5739 - val_loss: 0.9704 - val_accuracy: 0.5616\n",
            "Epoch 114/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0456 - accuracy: 0.5636 - val_loss: 0.9843 - val_accuracy: 0.5479\n",
            "Epoch 115/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0778 - accuracy: 0.5601 - val_loss: 0.9796 - val_accuracy: 0.5342\n",
            "Epoch 116/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0691 - accuracy: 0.5430 - val_loss: 0.9870 - val_accuracy: 0.5342\n",
            "Epoch 117/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0408 - accuracy: 0.5533 - val_loss: 0.9865 - val_accuracy: 0.5479\n",
            "Epoch 118/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0632 - accuracy: 0.5636 - val_loss: 0.9819 - val_accuracy: 0.5342\n",
            "Epoch 119/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0379 - accuracy: 0.5876 - val_loss: 0.9712 - val_accuracy: 0.5479\n",
            "Epoch 120/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0546 - accuracy: 0.5876 - val_loss: 0.9693 - val_accuracy: 0.5753\n",
            "Epoch 121/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0337 - accuracy: 0.5979 - val_loss: 0.9618 - val_accuracy: 0.5890\n",
            "Epoch 122/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0307 - accuracy: 0.5876 - val_loss: 0.9599 - val_accuracy: 0.5479\n",
            "Epoch 123/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0450 - accuracy: 0.5739 - val_loss: 0.9700 - val_accuracy: 0.5342\n",
            "Epoch 124/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0401 - accuracy: 0.5911 - val_loss: 0.9624 - val_accuracy: 0.5479\n",
            "Epoch 125/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0347 - accuracy: 0.5808 - val_loss: 0.9548 - val_accuracy: 0.5890\n",
            "Epoch 126/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0278 - accuracy: 0.5842 - val_loss: 0.9466 - val_accuracy: 0.6027\n",
            "Epoch 127/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0303 - accuracy: 0.5739 - val_loss: 0.9513 - val_accuracy: 0.6027\n",
            "Epoch 128/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0481 - accuracy: 0.5842 - val_loss: 0.9429 - val_accuracy: 0.5890\n",
            "Epoch 129/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0242 - accuracy: 0.5704 - val_loss: 0.9480 - val_accuracy: 0.6027\n",
            "Epoch 130/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0303 - accuracy: 0.5979 - val_loss: 0.9407 - val_accuracy: 0.6027\n",
            "Epoch 131/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0397 - accuracy: 0.5704 - val_loss: 0.9336 - val_accuracy: 0.6301\n",
            "Epoch 132/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0185 - accuracy: 0.5911 - val_loss: 0.9369 - val_accuracy: 0.5890\n",
            "Epoch 133/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0485 - accuracy: 0.5636 - val_loss: 0.9428 - val_accuracy: 0.5616\n",
            "Epoch 134/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0101 - accuracy: 0.5773 - val_loss: 0.9424 - val_accuracy: 0.6027\n",
            "Epoch 135/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0035 - accuracy: 0.5842 - val_loss: 0.9473 - val_accuracy: 0.5342\n",
            "Epoch 136/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0169 - accuracy: 0.5601 - val_loss: 0.9381 - val_accuracy: 0.5479\n",
            "Epoch 137/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0096 - accuracy: 0.5601 - val_loss: 0.9393 - val_accuracy: 0.5890\n",
            "Epoch 138/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0127 - accuracy: 0.5945 - val_loss: 0.9452 - val_accuracy: 0.5479\n",
            "Epoch 139/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9940 - accuracy: 0.6014 - val_loss: 0.9279 - val_accuracy: 0.5753\n",
            "Epoch 140/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0000 - accuracy: 0.6117 - val_loss: 0.9138 - val_accuracy: 0.6027\n",
            "Epoch 141/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0154 - accuracy: 0.5979 - val_loss: 0.9296 - val_accuracy: 0.6027\n",
            "Epoch 142/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0079 - accuracy: 0.5911 - val_loss: 0.9182 - val_accuracy: 0.6438\n",
            "Epoch 143/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0045 - accuracy: 0.6117 - val_loss: 0.9121 - val_accuracy: 0.6301\n",
            "Epoch 144/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9967 - accuracy: 0.5979 - val_loss: 0.9117 - val_accuracy: 0.6164\n",
            "Epoch 145/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.0110 - accuracy: 0.5979 - val_loss: 0.9022 - val_accuracy: 0.6164\n",
            "Epoch 146/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9897 - accuracy: 0.6082 - val_loss: 0.8997 - val_accuracy: 0.6027\n",
            "Epoch 147/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9887 - accuracy: 0.5979 - val_loss: 0.9050 - val_accuracy: 0.6027\n",
            "Epoch 148/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9882 - accuracy: 0.6048 - val_loss: 0.9086 - val_accuracy: 0.5890\n",
            "Epoch 149/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0289 - accuracy: 0.5567 - val_loss: 0.9101 - val_accuracy: 0.5890\n",
            "Epoch 150/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9924 - accuracy: 0.5945 - val_loss: 0.9154 - val_accuracy: 0.6027\n",
            "Epoch 151/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9821 - accuracy: 0.5945 - val_loss: 0.8979 - val_accuracy: 0.6027\n",
            "Epoch 152/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9739 - accuracy: 0.6014 - val_loss: 0.9000 - val_accuracy: 0.5890\n",
            "Epoch 153/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9990 - accuracy: 0.6289 - val_loss: 0.8926 - val_accuracy: 0.6164\n",
            "Epoch 154/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9830 - accuracy: 0.5979 - val_loss: 0.8988 - val_accuracy: 0.6164\n",
            "Epoch 155/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9989 - accuracy: 0.6186 - val_loss: 0.8965 - val_accuracy: 0.6575\n",
            "Epoch 156/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9663 - accuracy: 0.6254 - val_loss: 0.9036 - val_accuracy: 0.6301\n",
            "Epoch 157/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9658 - accuracy: 0.6014 - val_loss: 0.8888 - val_accuracy: 0.6164\n",
            "Epoch 158/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9845 - accuracy: 0.6220 - val_loss: 0.8930 - val_accuracy: 0.6164\n",
            "Epoch 159/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9805 - accuracy: 0.5945 - val_loss: 0.8914 - val_accuracy: 0.6027\n",
            "Epoch 160/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9836 - accuracy: 0.6082 - val_loss: 0.8902 - val_accuracy: 0.6027\n",
            "Epoch 161/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9681 - accuracy: 0.6048 - val_loss: 0.8937 - val_accuracy: 0.6164\n",
            "Epoch 162/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9575 - accuracy: 0.5945 - val_loss: 0.8969 - val_accuracy: 0.6164\n",
            "Epoch 163/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9592 - accuracy: 0.6048 - val_loss: 0.8814 - val_accuracy: 0.6027\n",
            "Epoch 164/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9688 - accuracy: 0.5945 - val_loss: 0.8974 - val_accuracy: 0.5890\n",
            "Epoch 165/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9723 - accuracy: 0.5842 - val_loss: 0.8765 - val_accuracy: 0.6164\n",
            "Epoch 166/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9705 - accuracy: 0.6357 - val_loss: 0.8788 - val_accuracy: 0.6438\n",
            "Epoch 167/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9675 - accuracy: 0.5945 - val_loss: 0.8746 - val_accuracy: 0.6712\n",
            "Epoch 168/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9546 - accuracy: 0.6082 - val_loss: 0.8757 - val_accuracy: 0.6301\n",
            "Epoch 169/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9554 - accuracy: 0.6289 - val_loss: 0.8696 - val_accuracy: 0.6575\n",
            "Epoch 170/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9871 - accuracy: 0.6048 - val_loss: 0.8638 - val_accuracy: 0.6712\n",
            "Epoch 171/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9589 - accuracy: 0.6014 - val_loss: 0.8642 - val_accuracy: 0.6575\n",
            "Epoch 172/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9618 - accuracy: 0.6048 - val_loss: 0.8587 - val_accuracy: 0.6438\n",
            "Epoch 173/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9410 - accuracy: 0.5979 - val_loss: 0.8566 - val_accuracy: 0.6575\n",
            "Epoch 174/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9313 - accuracy: 0.6323 - val_loss: 0.8670 - val_accuracy: 0.6575\n",
            "Epoch 175/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9572 - accuracy: 0.5979 - val_loss: 0.8558 - val_accuracy: 0.6438\n",
            "Epoch 176/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9541 - accuracy: 0.6151 - val_loss: 0.8501 - val_accuracy: 0.6438\n",
            "Epoch 177/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9588 - accuracy: 0.6254 - val_loss: 0.8525 - val_accuracy: 0.6575\n",
            "Epoch 178/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9478 - accuracy: 0.6048 - val_loss: 0.8463 - val_accuracy: 0.6438\n",
            "Epoch 179/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9375 - accuracy: 0.6289 - val_loss: 0.8462 - val_accuracy: 0.6575\n",
            "Epoch 180/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9470 - accuracy: 0.6426 - val_loss: 0.8581 - val_accuracy: 0.6575\n",
            "Epoch 181/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9298 - accuracy: 0.6323 - val_loss: 0.8575 - val_accuracy: 0.6575\n",
            "Epoch 182/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9389 - accuracy: 0.6014 - val_loss: 0.8526 - val_accuracy: 0.6575\n",
            "Epoch 183/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9261 - accuracy: 0.6289 - val_loss: 0.8515 - val_accuracy: 0.6575\n",
            "Epoch 184/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9335 - accuracy: 0.6220 - val_loss: 0.8529 - val_accuracy: 0.6438\n",
            "Epoch 185/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9443 - accuracy: 0.6117 - val_loss: 0.8344 - val_accuracy: 0.6301\n",
            "Epoch 186/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9313 - accuracy: 0.6254 - val_loss: 0.8322 - val_accuracy: 0.6438\n",
            "Epoch 187/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9460 - accuracy: 0.6082 - val_loss: 0.8355 - val_accuracy: 0.6438\n",
            "Epoch 188/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9310 - accuracy: 0.6254 - val_loss: 0.8336 - val_accuracy: 0.6712\n",
            "Epoch 189/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9022 - accuracy: 0.6289 - val_loss: 0.8327 - val_accuracy: 0.6712\n",
            "Epoch 190/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9005 - accuracy: 0.6426 - val_loss: 0.8468 - val_accuracy: 0.6575\n",
            "Epoch 191/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9118 - accuracy: 0.6186 - val_loss: 0.8368 - val_accuracy: 0.6712\n",
            "Epoch 192/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9353 - accuracy: 0.6151 - val_loss: 0.8349 - val_accuracy: 0.6301\n",
            "Epoch 193/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9422 - accuracy: 0.6117 - val_loss: 0.8283 - val_accuracy: 0.6438\n",
            "Epoch 194/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9291 - accuracy: 0.6564 - val_loss: 0.8303 - val_accuracy: 0.6438\n",
            "Epoch 195/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9462 - accuracy: 0.6082 - val_loss: 0.8363 - val_accuracy: 0.6575\n",
            "Epoch 196/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9285 - accuracy: 0.6392 - val_loss: 0.8276 - val_accuracy: 0.6849\n",
            "Epoch 197/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9431 - accuracy: 0.6495 - val_loss: 0.8253 - val_accuracy: 0.6575\n",
            "Epoch 198/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9219 - accuracy: 0.6220 - val_loss: 0.8227 - val_accuracy: 0.6575\n",
            "Epoch 199/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9151 - accuracy: 0.6426 - val_loss: 0.8238 - val_accuracy: 0.6849\n",
            "Epoch 200/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9175 - accuracy: 0.6357 - val_loss: 0.8447 - val_accuracy: 0.6849\n",
            "Epoch 201/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9038 - accuracy: 0.6289 - val_loss: 0.8246 - val_accuracy: 0.6438\n",
            "Epoch 202/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9086 - accuracy: 0.6151 - val_loss: 0.8280 - val_accuracy: 0.6575\n",
            "Epoch 203/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8912 - accuracy: 0.6495 - val_loss: 0.8279 - val_accuracy: 0.6712\n",
            "Epoch 204/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9060 - accuracy: 0.6289 - val_loss: 0.8144 - val_accuracy: 0.6986\n",
            "Epoch 205/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9293 - accuracy: 0.5979 - val_loss: 0.8135 - val_accuracy: 0.6575\n",
            "Epoch 206/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9132 - accuracy: 0.6082 - val_loss: 0.8152 - val_accuracy: 0.6712\n",
            "Epoch 207/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9056 - accuracy: 0.6323 - val_loss: 0.8147 - val_accuracy: 0.6301\n",
            "Epoch 208/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9187 - accuracy: 0.6426 - val_loss: 0.8083 - val_accuracy: 0.6301\n",
            "Epoch 209/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9106 - accuracy: 0.6254 - val_loss: 0.8169 - val_accuracy: 0.6575\n",
            "Epoch 210/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8740 - accuracy: 0.6460 - val_loss: 0.8112 - val_accuracy: 0.6438\n",
            "Epoch 211/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9018 - accuracy: 0.6220 - val_loss: 0.8089 - val_accuracy: 0.6301\n",
            "Epoch 212/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8933 - accuracy: 0.6254 - val_loss: 0.8084 - val_accuracy: 0.6438\n",
            "Epoch 213/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9025 - accuracy: 0.6357 - val_loss: 0.8164 - val_accuracy: 0.6712\n",
            "Epoch 214/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8950 - accuracy: 0.6289 - val_loss: 0.8283 - val_accuracy: 0.6712\n",
            "Epoch 215/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8918 - accuracy: 0.6289 - val_loss: 0.8070 - val_accuracy: 0.6438\n",
            "Epoch 216/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9132 - accuracy: 0.6392 - val_loss: 0.8086 - val_accuracy: 0.6438\n",
            "Epoch 217/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9141 - accuracy: 0.6220 - val_loss: 0.8129 - val_accuracy: 0.6438\n",
            "Epoch 218/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8903 - accuracy: 0.6598 - val_loss: 0.8058 - val_accuracy: 0.6575\n",
            "Epoch 219/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8959 - accuracy: 0.6254 - val_loss: 0.8183 - val_accuracy: 0.6986\n",
            "Epoch 220/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8912 - accuracy: 0.6460 - val_loss: 0.7874 - val_accuracy: 0.6438\n",
            "Epoch 221/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9077 - accuracy: 0.6460 - val_loss: 0.8149 - val_accuracy: 0.6438\n",
            "Epoch 222/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9081 - accuracy: 0.6082 - val_loss: 0.7967 - val_accuracy: 0.6575\n",
            "Epoch 223/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9086 - accuracy: 0.6392 - val_loss: 0.8019 - val_accuracy: 0.6712\n",
            "Epoch 224/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8998 - accuracy: 0.6323 - val_loss: 0.8051 - val_accuracy: 0.6438\n",
            "Epoch 225/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8839 - accuracy: 0.6460 - val_loss: 0.8146 - val_accuracy: 0.6575\n",
            "Epoch 226/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8975 - accuracy: 0.6426 - val_loss: 0.7989 - val_accuracy: 0.6301\n",
            "Epoch 227/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8831 - accuracy: 0.6529 - val_loss: 0.8119 - val_accuracy: 0.6438\n",
            "Epoch 228/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8960 - accuracy: 0.6564 - val_loss: 0.8014 - val_accuracy: 0.6438\n",
            "Epoch 229/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8774 - accuracy: 0.6460 - val_loss: 0.8062 - val_accuracy: 0.6438\n",
            "Epoch 230/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9132 - accuracy: 0.6220 - val_loss: 0.8063 - val_accuracy: 0.6849\n",
            "Epoch 231/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8903 - accuracy: 0.6289 - val_loss: 0.7993 - val_accuracy: 0.6575\n",
            "Epoch 232/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9092 - accuracy: 0.6460 - val_loss: 0.7973 - val_accuracy: 0.6575\n",
            "Epoch 233/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9193 - accuracy: 0.6220 - val_loss: 0.8102 - val_accuracy: 0.6575\n",
            "Epoch 234/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8886 - accuracy: 0.6357 - val_loss: 0.7903 - val_accuracy: 0.6301\n",
            "Epoch 235/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9069 - accuracy: 0.6460 - val_loss: 0.7899 - val_accuracy: 0.6712\n",
            "Epoch 236/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8702 - accuracy: 0.6564 - val_loss: 0.7995 - val_accuracy: 0.6438\n",
            "Epoch 237/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8900 - accuracy: 0.6357 - val_loss: 0.7929 - val_accuracy: 0.6849\n",
            "Epoch 238/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.9325 - accuracy: 0.6392 - val_loss: 0.7975 - val_accuracy: 0.6301\n",
            "Epoch 239/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8891 - accuracy: 0.6460 - val_loss: 0.8022 - val_accuracy: 0.6438\n",
            "Epoch 240/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9046 - accuracy: 0.6151 - val_loss: 0.8518 - val_accuracy: 0.6301\n",
            "Epoch 241/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9035 - accuracy: 0.6426 - val_loss: 0.8019 - val_accuracy: 0.6164\n",
            "Epoch 242/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9007 - accuracy: 0.6632 - val_loss: 0.8141 - val_accuracy: 0.6438\n",
            "Epoch 243/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8797 - accuracy: 0.6495 - val_loss: 0.8029 - val_accuracy: 0.6438\n",
            "Epoch 244/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8790 - accuracy: 0.6392 - val_loss: 0.8255 - val_accuracy: 0.6301\n",
            "Epoch 245/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8872 - accuracy: 0.6495 - val_loss: 0.7987 - val_accuracy: 0.6438\n",
            "Epoch 246/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8660 - accuracy: 0.6357 - val_loss: 0.7925 - val_accuracy: 0.6438\n",
            "Epoch 247/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8655 - accuracy: 0.6495 - val_loss: 0.7978 - val_accuracy: 0.6438\n",
            "Epoch 248/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8782 - accuracy: 0.6598 - val_loss: 0.8065 - val_accuracy: 0.6438\n",
            "Epoch 249/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8844 - accuracy: 0.6254 - val_loss: 0.7936 - val_accuracy: 0.6849\n",
            "Epoch 250/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8784 - accuracy: 0.6495 - val_loss: 0.7923 - val_accuracy: 0.6575\n",
            "Epoch 251/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8812 - accuracy: 0.6289 - val_loss: 0.8046 - val_accuracy: 0.6438\n",
            "Epoch 252/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8741 - accuracy: 0.6632 - val_loss: 0.7906 - val_accuracy: 0.6438\n",
            "Epoch 253/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8792 - accuracy: 0.6460 - val_loss: 0.8233 - val_accuracy: 0.6164\n",
            "Epoch 254/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8822 - accuracy: 0.6426 - val_loss: 0.8017 - val_accuracy: 0.6438\n",
            "Epoch 255/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8782 - accuracy: 0.6460 - val_loss: 0.7931 - val_accuracy: 0.6438\n",
            "Epoch 256/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8929 - accuracy: 0.6392 - val_loss: 0.7987 - val_accuracy: 0.6438\n",
            "Epoch 257/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8873 - accuracy: 0.6701 - val_loss: 0.8004 - val_accuracy: 0.6438\n",
            "Epoch 258/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8993 - accuracy: 0.6392 - val_loss: 0.7914 - val_accuracy: 0.6575\n",
            "Epoch 259/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8986 - accuracy: 0.6392 - val_loss: 0.7971 - val_accuracy: 0.6712\n",
            "Epoch 260/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8688 - accuracy: 0.6495 - val_loss: 0.8139 - val_accuracy: 0.6712\n",
            "Epoch 261/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8509 - accuracy: 0.6632 - val_loss: 0.7918 - val_accuracy: 0.6849\n",
            "Epoch 262/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8605 - accuracy: 0.6564 - val_loss: 0.7932 - val_accuracy: 0.6438\n",
            "Epoch 263/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8665 - accuracy: 0.6632 - val_loss: 0.7932 - val_accuracy: 0.6986\n",
            "Epoch 264/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8633 - accuracy: 0.6529 - val_loss: 0.7902 - val_accuracy: 0.6575\n",
            "Epoch 265/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8567 - accuracy: 0.6701 - val_loss: 0.7750 - val_accuracy: 0.6575\n",
            "Epoch 266/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8769 - accuracy: 0.6598 - val_loss: 0.7944 - val_accuracy: 0.6438\n",
            "Epoch 267/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8870 - accuracy: 0.6289 - val_loss: 0.7944 - val_accuracy: 0.6027\n",
            "Epoch 268/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8744 - accuracy: 0.6426 - val_loss: 0.7986 - val_accuracy: 0.6438\n",
            "Epoch 269/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9071 - accuracy: 0.6151 - val_loss: 0.8236 - val_accuracy: 0.6301\n",
            "Epoch 270/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9156 - accuracy: 0.6323 - val_loss: 0.7932 - val_accuracy: 0.6438\n",
            "Epoch 271/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8810 - accuracy: 0.6460 - val_loss: 0.7768 - val_accuracy: 0.6712\n",
            "Epoch 272/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8712 - accuracy: 0.6254 - val_loss: 0.7989 - val_accuracy: 0.6301\n",
            "Epoch 273/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8455 - accuracy: 0.6770 - val_loss: 0.7957 - val_accuracy: 0.6301\n",
            "Epoch 274/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8721 - accuracy: 0.6495 - val_loss: 0.7821 - val_accuracy: 0.6438\n",
            "Epoch 275/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8923 - accuracy: 0.6598 - val_loss: 0.7854 - val_accuracy: 0.6986\n",
            "Epoch 276/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9228 - accuracy: 0.6151 - val_loss: 0.8251 - val_accuracy: 0.6712\n",
            "Epoch 277/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8951 - accuracy: 0.6186 - val_loss: 0.8104 - val_accuracy: 0.6575\n",
            "Epoch 278/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8804 - accuracy: 0.6426 - val_loss: 0.7956 - val_accuracy: 0.6438\n",
            "Epoch 279/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8767 - accuracy: 0.6392 - val_loss: 0.7752 - val_accuracy: 0.6712\n",
            "Epoch 280/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8870 - accuracy: 0.6667 - val_loss: 0.7865 - val_accuracy: 0.6986\n",
            "Epoch 281/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8805 - accuracy: 0.6254 - val_loss: 0.7925 - val_accuracy: 0.6986\n",
            "Epoch 282/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8439 - accuracy: 0.6598 - val_loss: 0.7751 - val_accuracy: 0.6849\n",
            "Epoch 283/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8547 - accuracy: 0.6598 - val_loss: 0.7814 - val_accuracy: 0.6849\n",
            "Epoch 284/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8686 - accuracy: 0.6598 - val_loss: 0.7748 - val_accuracy: 0.6575\n",
            "Epoch 285/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8511 - accuracy: 0.6495 - val_loss: 0.7857 - val_accuracy: 0.6712\n",
            "Epoch 286/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8581 - accuracy: 0.6117 - val_loss: 0.7855 - val_accuracy: 0.6575\n",
            "Epoch 287/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8674 - accuracy: 0.6529 - val_loss: 0.7879 - val_accuracy: 0.6438\n",
            "Epoch 288/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8417 - accuracy: 0.6598 - val_loss: 0.7948 - val_accuracy: 0.6438\n",
            "Epoch 289/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8598 - accuracy: 0.6392 - val_loss: 0.7755 - val_accuracy: 0.6301\n",
            "Epoch 290/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8510 - accuracy: 0.6495 - val_loss: 0.7932 - val_accuracy: 0.6438\n",
            "Epoch 291/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8556 - accuracy: 0.6598 - val_loss: 0.7845 - val_accuracy: 0.6438\n",
            "Epoch 292/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8548 - accuracy: 0.6564 - val_loss: 0.7831 - val_accuracy: 0.6164\n",
            "Epoch 293/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8410 - accuracy: 0.6804 - val_loss: 0.7694 - val_accuracy: 0.6301\n",
            "Epoch 294/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8750 - accuracy: 0.6564 - val_loss: 0.7744 - val_accuracy: 0.6712\n",
            "Epoch 295/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8705 - accuracy: 0.6323 - val_loss: 0.7927 - val_accuracy: 0.6712\n",
            "Epoch 296/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8740 - accuracy: 0.6426 - val_loss: 0.8100 - val_accuracy: 0.6575\n",
            "Epoch 297/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8336 - accuracy: 0.6701 - val_loss: 0.7928 - val_accuracy: 0.6712\n",
            "Epoch 298/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8537 - accuracy: 0.6873 - val_loss: 0.7861 - val_accuracy: 0.6849\n",
            "Epoch 299/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8560 - accuracy: 0.6392 - val_loss: 0.8010 - val_accuracy: 0.6712\n",
            "Epoch 300/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8497 - accuracy: 0.6392 - val_loss: 0.7994 - val_accuracy: 0.6575\n",
            "Epoch 301/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8701 - accuracy: 0.6392 - val_loss: 0.7893 - val_accuracy: 0.6575\n",
            "Epoch 302/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8352 - accuracy: 0.6598 - val_loss: 0.7689 - val_accuracy: 0.6301\n",
            "Epoch 303/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8637 - accuracy: 0.6392 - val_loss: 0.7661 - val_accuracy: 0.6301\n",
            "Epoch 304/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8409 - accuracy: 0.6632 - val_loss: 0.7834 - val_accuracy: 0.6438\n",
            "Epoch 305/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8594 - accuracy: 0.6220 - val_loss: 0.7971 - val_accuracy: 0.6438\n",
            "Epoch 306/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8728 - accuracy: 0.6460 - val_loss: 0.7807 - val_accuracy: 0.6164\n",
            "Epoch 307/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8458 - accuracy: 0.6323 - val_loss: 0.7696 - val_accuracy: 0.6712\n",
            "Epoch 308/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8572 - accuracy: 0.6564 - val_loss: 0.7849 - val_accuracy: 0.6575\n",
            "Epoch 309/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8320 - accuracy: 0.6564 - val_loss: 0.7844 - val_accuracy: 0.6301\n",
            "Epoch 310/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8366 - accuracy: 0.6632 - val_loss: 0.7695 - val_accuracy: 0.6301\n",
            "Epoch 311/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8417 - accuracy: 0.6564 - val_loss: 0.7814 - val_accuracy: 0.6712\n",
            "Epoch 312/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8805 - accuracy: 0.6495 - val_loss: 0.7745 - val_accuracy: 0.6712\n",
            "Epoch 313/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8365 - accuracy: 0.6667 - val_loss: 0.7778 - val_accuracy: 0.6849\n",
            "Epoch 314/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8639 - accuracy: 0.6426 - val_loss: 0.7841 - val_accuracy: 0.6301\n",
            "Epoch 315/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8489 - accuracy: 0.6529 - val_loss: 0.7713 - val_accuracy: 0.6712\n",
            "Epoch 316/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8381 - accuracy: 0.6632 - val_loss: 0.7689 - val_accuracy: 0.6849\n",
            "Epoch 317/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8489 - accuracy: 0.6701 - val_loss: 0.7860 - val_accuracy: 0.6438\n",
            "Epoch 318/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8641 - accuracy: 0.6529 - val_loss: 0.7801 - val_accuracy: 0.6712\n",
            "Epoch 319/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8337 - accuracy: 0.6495 - val_loss: 0.7878 - val_accuracy: 0.6712\n",
            "Epoch 320/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8376 - accuracy: 0.6426 - val_loss: 0.7815 - val_accuracy: 0.6712\n",
            "Epoch 321/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8473 - accuracy: 0.6460 - val_loss: 0.7825 - val_accuracy: 0.6712\n",
            "Epoch 322/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8343 - accuracy: 0.6804 - val_loss: 0.7994 - val_accuracy: 0.6712\n",
            "Epoch 323/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8433 - accuracy: 0.6529 - val_loss: 0.7856 - val_accuracy: 0.6575\n",
            "Epoch 324/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8519 - accuracy: 0.6426 - val_loss: 0.7869 - val_accuracy: 0.6712\n",
            "Epoch 325/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8498 - accuracy: 0.6804 - val_loss: 0.8020 - val_accuracy: 0.6849\n",
            "Epoch 326/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8674 - accuracy: 0.6392 - val_loss: 0.7616 - val_accuracy: 0.6712\n",
            "Epoch 327/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8289 - accuracy: 0.6667 - val_loss: 0.7936 - val_accuracy: 0.6712\n",
            "Epoch 328/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8411 - accuracy: 0.6701 - val_loss: 0.7664 - val_accuracy: 0.6575\n",
            "Epoch 329/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8374 - accuracy: 0.6735 - val_loss: 0.7824 - val_accuracy: 0.6712\n",
            "Epoch 330/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8425 - accuracy: 0.6598 - val_loss: 0.7856 - val_accuracy: 0.6438\n",
            "Epoch 331/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8223 - accuracy: 0.6770 - val_loss: 0.7862 - val_accuracy: 0.6575\n",
            "Epoch 332/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8465 - accuracy: 0.6495 - val_loss: 0.7611 - val_accuracy: 0.6575\n",
            "Epoch 333/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8558 - accuracy: 0.6529 - val_loss: 0.7983 - val_accuracy: 0.6575\n",
            "Epoch 334/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8427 - accuracy: 0.6701 - val_loss: 0.7653 - val_accuracy: 0.6575\n",
            "Epoch 335/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8591 - accuracy: 0.6460 - val_loss: 0.7779 - val_accuracy: 0.6849\n",
            "Epoch 336/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8567 - accuracy: 0.6770 - val_loss: 0.7618 - val_accuracy: 0.6438\n",
            "Epoch 337/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8459 - accuracy: 0.6564 - val_loss: 0.7648 - val_accuracy: 0.6301\n",
            "Epoch 338/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8594 - accuracy: 0.6529 - val_loss: 0.7771 - val_accuracy: 0.6712\n",
            "Epoch 339/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8540 - accuracy: 0.6598 - val_loss: 0.7840 - val_accuracy: 0.6849\n",
            "Epoch 340/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8408 - accuracy: 0.6564 - val_loss: 0.7780 - val_accuracy: 0.6438\n",
            "Epoch 341/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8367 - accuracy: 0.6529 - val_loss: 0.7740 - val_accuracy: 0.6712\n",
            "Epoch 342/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8387 - accuracy: 0.6838 - val_loss: 0.7919 - val_accuracy: 0.6712\n",
            "Epoch 343/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8462 - accuracy: 0.6495 - val_loss: 0.8092 - val_accuracy: 0.6712\n",
            "Epoch 344/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8601 - accuracy: 0.6495 - val_loss: 0.7793 - val_accuracy: 0.6575\n",
            "Epoch 345/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8642 - accuracy: 0.6426 - val_loss: 0.7920 - val_accuracy: 0.6849\n",
            "Epoch 346/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8449 - accuracy: 0.6426 - val_loss: 0.8018 - val_accuracy: 0.6849\n",
            "Epoch 347/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8691 - accuracy: 0.6529 - val_loss: 0.7557 - val_accuracy: 0.6849\n",
            "Epoch 348/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8515 - accuracy: 0.6460 - val_loss: 0.7913 - val_accuracy: 0.6849\n",
            "Epoch 349/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8554 - accuracy: 0.6529 - val_loss: 0.8079 - val_accuracy: 0.6438\n",
            "Epoch 350/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8804 - accuracy: 0.6598 - val_loss: 0.7692 - val_accuracy: 0.7123\n",
            "Epoch 351/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8927 - accuracy: 0.6392 - val_loss: 0.8229 - val_accuracy: 0.6712\n",
            "Epoch 352/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8420 - accuracy: 0.6598 - val_loss: 0.7994 - val_accuracy: 0.6712\n",
            "Epoch 353/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8180 - accuracy: 0.6804 - val_loss: 0.7952 - val_accuracy: 0.6712\n",
            "Epoch 354/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8220 - accuracy: 0.6598 - val_loss: 0.7914 - val_accuracy: 0.6712\n",
            "Epoch 355/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8453 - accuracy: 0.6667 - val_loss: 0.7684 - val_accuracy: 0.6575\n",
            "Epoch 356/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8934 - accuracy: 0.6529 - val_loss: 0.8250 - val_accuracy: 0.6301\n",
            "Epoch 357/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9015 - accuracy: 0.6254 - val_loss: 0.8156 - val_accuracy: 0.6712\n",
            "Epoch 358/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8686 - accuracy: 0.6598 - val_loss: 0.7709 - val_accuracy: 0.7260\n",
            "Epoch 359/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8470 - accuracy: 0.6735 - val_loss: 0.7965 - val_accuracy: 0.6438\n",
            "Epoch 360/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8445 - accuracy: 0.6529 - val_loss: 0.7869 - val_accuracy: 0.6849\n",
            "Epoch 361/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8501 - accuracy: 0.6495 - val_loss: 0.7840 - val_accuracy: 0.6712\n",
            "Epoch 362/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8357 - accuracy: 0.6460 - val_loss: 0.8065 - val_accuracy: 0.6301\n",
            "Epoch 363/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8527 - accuracy: 0.6564 - val_loss: 0.7812 - val_accuracy: 0.6849\n",
            "Epoch 364/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8236 - accuracy: 0.6426 - val_loss: 0.7982 - val_accuracy: 0.6712\n",
            "Epoch 365/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8552 - accuracy: 0.6632 - val_loss: 0.7805 - val_accuracy: 0.6712\n",
            "Epoch 366/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8364 - accuracy: 0.6564 - val_loss: 0.7891 - val_accuracy: 0.6575\n",
            "Epoch 367/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8452 - accuracy: 0.6495 - val_loss: 0.7690 - val_accuracy: 0.6712\n",
            "Epoch 368/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8509 - accuracy: 0.6564 - val_loss: 0.7884 - val_accuracy: 0.6712\n",
            "Epoch 369/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8211 - accuracy: 0.6701 - val_loss: 0.7752 - val_accuracy: 0.6575\n",
            "Epoch 370/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8503 - accuracy: 0.6460 - val_loss: 0.7744 - val_accuracy: 0.6575\n",
            "Epoch 371/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8581 - accuracy: 0.6426 - val_loss: 0.7879 - val_accuracy: 0.6712\n",
            "Epoch 372/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8516 - accuracy: 0.6495 - val_loss: 0.7787 - val_accuracy: 0.6438\n",
            "Epoch 373/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8366 - accuracy: 0.6564 - val_loss: 0.7853 - val_accuracy: 0.6712\n",
            "Epoch 374/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8564 - accuracy: 0.6564 - val_loss: 0.7725 - val_accuracy: 0.6712\n",
            "Epoch 375/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8489 - accuracy: 0.6667 - val_loss: 0.7630 - val_accuracy: 0.6712\n",
            "Epoch 376/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8762 - accuracy: 0.6495 - val_loss: 0.7751 - val_accuracy: 0.6849\n",
            "Epoch 377/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8445 - accuracy: 0.6564 - val_loss: 0.8048 - val_accuracy: 0.6712\n",
            "Epoch 378/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8445 - accuracy: 0.6667 - val_loss: 0.7641 - val_accuracy: 0.6575\n",
            "Epoch 379/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8229 - accuracy: 0.6701 - val_loss: 0.7807 - val_accuracy: 0.6438\n",
            "Epoch 380/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8255 - accuracy: 0.6701 - val_loss: 0.8389 - val_accuracy: 0.6712\n",
            "Epoch 381/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8354 - accuracy: 0.6460 - val_loss: 0.7737 - val_accuracy: 0.6712\n",
            "Epoch 382/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8021 - accuracy: 0.6667 - val_loss: 0.7880 - val_accuracy: 0.6575\n",
            "Epoch 383/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8515 - accuracy: 0.6495 - val_loss: 0.7634 - val_accuracy: 0.6712\n",
            "Epoch 384/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8784 - accuracy: 0.6357 - val_loss: 0.7860 - val_accuracy: 0.6301\n",
            "Epoch 385/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9044 - accuracy: 0.6598 - val_loss: 0.8032 - val_accuracy: 0.6301\n",
            "Epoch 386/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8541 - accuracy: 0.6598 - val_loss: 0.7559 - val_accuracy: 0.6575\n",
            "Epoch 387/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8493 - accuracy: 0.6701 - val_loss: 0.7940 - val_accuracy: 0.6438\n",
            "Epoch 388/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8464 - accuracy: 0.6357 - val_loss: 0.7678 - val_accuracy: 0.6438\n",
            "Epoch 389/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8156 - accuracy: 0.6770 - val_loss: 0.7660 - val_accuracy: 0.6438\n",
            "Epoch 390/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8370 - accuracy: 0.6735 - val_loss: 0.7744 - val_accuracy: 0.6712\n",
            "Epoch 391/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8260 - accuracy: 0.6735 - val_loss: 0.7664 - val_accuracy: 0.6712\n",
            "Epoch 392/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8490 - accuracy: 0.6529 - val_loss: 0.7723 - val_accuracy: 0.6712\n",
            "Epoch 393/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8469 - accuracy: 0.6529 - val_loss: 0.8169 - val_accuracy: 0.6712\n",
            "Epoch 394/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8352 - accuracy: 0.6598 - val_loss: 0.7820 - val_accuracy: 0.6712\n",
            "Epoch 395/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8348 - accuracy: 0.6495 - val_loss: 0.7723 - val_accuracy: 0.6712\n",
            "Epoch 396/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8328 - accuracy: 0.6667 - val_loss: 0.8053 - val_accuracy: 0.6575\n",
            "Epoch 397/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8104 - accuracy: 0.6667 - val_loss: 0.7597 - val_accuracy: 0.6849\n",
            "Epoch 398/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8273 - accuracy: 0.6770 - val_loss: 0.7564 - val_accuracy: 0.6849\n",
            "Epoch 399/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8772 - accuracy: 0.6460 - val_loss: 0.8249 - val_accuracy: 0.6575\n",
            "Epoch 400/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8526 - accuracy: 0.6804 - val_loss: 0.7857 - val_accuracy: 0.6575\n",
            "Epoch 401/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8194 - accuracy: 0.6770 - val_loss: 0.7637 - val_accuracy: 0.6438\n",
            "Epoch 402/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8230 - accuracy: 0.6735 - val_loss: 0.7864 - val_accuracy: 0.6575\n",
            "Epoch 403/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8331 - accuracy: 0.6770 - val_loss: 0.7871 - val_accuracy: 0.6712\n",
            "Epoch 404/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8243 - accuracy: 0.6770 - val_loss: 0.7582 - val_accuracy: 0.6575\n",
            "Epoch 405/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8552 - accuracy: 0.6289 - val_loss: 0.7929 - val_accuracy: 0.6712\n",
            "Epoch 406/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8254 - accuracy: 0.6529 - val_loss: 0.8204 - val_accuracy: 0.6438\n",
            "Epoch 407/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8481 - accuracy: 0.6564 - val_loss: 0.7851 - val_accuracy: 0.6849\n",
            "Epoch 408/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8403 - accuracy: 0.6495 - val_loss: 0.7593 - val_accuracy: 0.6849\n",
            "Epoch 409/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8377 - accuracy: 0.6460 - val_loss: 0.8046 - val_accuracy: 0.6712\n",
            "Epoch 410/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8868 - accuracy: 0.6460 - val_loss: 0.8159 - val_accuracy: 0.6575\n",
            "Epoch 411/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8293 - accuracy: 0.6564 - val_loss: 0.7489 - val_accuracy: 0.6712\n",
            "Epoch 412/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8244 - accuracy: 0.6804 - val_loss: 0.7825 - val_accuracy: 0.6849\n",
            "Epoch 413/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8485 - accuracy: 0.6701 - val_loss: 0.7791 - val_accuracy: 0.6712\n",
            "Epoch 414/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8285 - accuracy: 0.6357 - val_loss: 0.7682 - val_accuracy: 0.6712\n",
            "Epoch 415/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8411 - accuracy: 0.6529 - val_loss: 0.7710 - val_accuracy: 0.6849\n",
            "Epoch 416/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8210 - accuracy: 0.6426 - val_loss: 0.7769 - val_accuracy: 0.6849\n",
            "Epoch 417/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8380 - accuracy: 0.6667 - val_loss: 0.7814 - val_accuracy: 0.6712\n",
            "Epoch 418/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8066 - accuracy: 0.6838 - val_loss: 0.7615 - val_accuracy: 0.6575\n",
            "Epoch 419/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8273 - accuracy: 0.6735 - val_loss: 0.7797 - val_accuracy: 0.6849\n",
            "Epoch 420/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8148 - accuracy: 0.6735 - val_loss: 0.7806 - val_accuracy: 0.6438\n",
            "Epoch 421/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8304 - accuracy: 0.6564 - val_loss: 0.7586 - val_accuracy: 0.6438\n",
            "Epoch 422/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8370 - accuracy: 0.6632 - val_loss: 0.7671 - val_accuracy: 0.6712\n",
            "Epoch 423/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8462 - accuracy: 0.6598 - val_loss: 0.7666 - val_accuracy: 0.6712\n",
            "Epoch 424/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8267 - accuracy: 0.6564 - val_loss: 0.8252 - val_accuracy: 0.6712\n",
            "Epoch 425/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8427 - accuracy: 0.6598 - val_loss: 0.7751 - val_accuracy: 0.6849\n",
            "Epoch 426/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8603 - accuracy: 0.6357 - val_loss: 0.8779 - val_accuracy: 0.6438\n",
            "Epoch 427/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8311 - accuracy: 0.6495 - val_loss: 0.7580 - val_accuracy: 0.6712\n",
            "Epoch 428/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8466 - accuracy: 0.6598 - val_loss: 0.8030 - val_accuracy: 0.6712\n",
            "Epoch 429/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8227 - accuracy: 0.6495 - val_loss: 0.7696 - val_accuracy: 0.6575\n",
            "Epoch 430/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8490 - accuracy: 0.6460 - val_loss: 0.8011 - val_accuracy: 0.6849\n",
            "Epoch 431/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8264 - accuracy: 0.6529 - val_loss: 0.7951 - val_accuracy: 0.6575\n",
            "Epoch 432/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8045 - accuracy: 0.6735 - val_loss: 0.7687 - val_accuracy: 0.6712\n",
            "Epoch 433/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8360 - accuracy: 0.6564 - val_loss: 0.7787 - val_accuracy: 0.6986\n",
            "Epoch 434/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8117 - accuracy: 0.6838 - val_loss: 0.7935 - val_accuracy: 0.6712\n",
            "Epoch 435/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8281 - accuracy: 0.6495 - val_loss: 0.7829 - val_accuracy: 0.6849\n",
            "Epoch 436/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8446 - accuracy: 0.6460 - val_loss: 0.7853 - val_accuracy: 0.6438\n",
            "Epoch 437/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8226 - accuracy: 0.6701 - val_loss: 0.7828 - val_accuracy: 0.6575\n",
            "Epoch 438/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8277 - accuracy: 0.6529 - val_loss: 0.7815 - val_accuracy: 0.6712\n",
            "Epoch 439/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8217 - accuracy: 0.6667 - val_loss: 0.7877 - val_accuracy: 0.6849\n",
            "Epoch 440/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8207 - accuracy: 0.6873 - val_loss: 0.7608 - val_accuracy: 0.6712\n",
            "Epoch 441/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8214 - accuracy: 0.6392 - val_loss: 0.7760 - val_accuracy: 0.6712\n",
            "Epoch 442/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8282 - accuracy: 0.6495 - val_loss: 0.7768 - val_accuracy: 0.6849\n",
            "Epoch 443/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8225 - accuracy: 0.6804 - val_loss: 0.7563 - val_accuracy: 0.6849\n",
            "Epoch 444/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8143 - accuracy: 0.6804 - val_loss: 0.7815 - val_accuracy: 0.6849\n",
            "Epoch 445/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8199 - accuracy: 0.6701 - val_loss: 0.7724 - val_accuracy: 0.6712\n",
            "Epoch 446/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8248 - accuracy: 0.6495 - val_loss: 0.7643 - val_accuracy: 0.6575\n",
            "Epoch 447/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8111 - accuracy: 0.6667 - val_loss: 0.7805 - val_accuracy: 0.6849\n",
            "Epoch 448/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8464 - accuracy: 0.6632 - val_loss: 0.8253 - val_accuracy: 0.6575\n",
            "Epoch 449/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8467 - accuracy: 0.6735 - val_loss: 0.7610 - val_accuracy: 0.7123\n",
            "Epoch 450/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8241 - accuracy: 0.6804 - val_loss: 0.7896 - val_accuracy: 0.6986\n",
            "Epoch 451/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8421 - accuracy: 0.6667 - val_loss: 0.7648 - val_accuracy: 0.6712\n",
            "Epoch 452/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8290 - accuracy: 0.6289 - val_loss: 0.7873 - val_accuracy: 0.6849\n",
            "Epoch 453/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8299 - accuracy: 0.6632 - val_loss: 0.7760 - val_accuracy: 0.6575\n",
            "Epoch 454/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7937 - accuracy: 0.6770 - val_loss: 0.7554 - val_accuracy: 0.6712\n",
            "Epoch 455/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8317 - accuracy: 0.6426 - val_loss: 0.7748 - val_accuracy: 0.6712\n",
            "Epoch 456/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8084 - accuracy: 0.6701 - val_loss: 0.7921 - val_accuracy: 0.6849\n",
            "Epoch 457/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8277 - accuracy: 0.6770 - val_loss: 0.7555 - val_accuracy: 0.6712\n",
            "Epoch 458/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8358 - accuracy: 0.6564 - val_loss: 0.7678 - val_accuracy: 0.6575\n",
            "Epoch 459/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8294 - accuracy: 0.6529 - val_loss: 0.8051 - val_accuracy: 0.6712\n",
            "Epoch 460/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8152 - accuracy: 0.6770 - val_loss: 0.7674 - val_accuracy: 0.6986\n",
            "Epoch 461/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8011 - accuracy: 0.6701 - val_loss: 0.7652 - val_accuracy: 0.6712\n",
            "Epoch 462/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8283 - accuracy: 0.6701 - val_loss: 0.7958 - val_accuracy: 0.6849\n",
            "Epoch 463/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8327 - accuracy: 0.6495 - val_loss: 0.7531 - val_accuracy: 0.6712\n",
            "Epoch 464/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8051 - accuracy: 0.6770 - val_loss: 0.8027 - val_accuracy: 0.6849\n",
            "Epoch 465/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8126 - accuracy: 0.6632 - val_loss: 0.7964 - val_accuracy: 0.6849\n",
            "Epoch 466/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8168 - accuracy: 0.6667 - val_loss: 0.7550 - val_accuracy: 0.6849\n",
            "Epoch 467/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8366 - accuracy: 0.6701 - val_loss: 0.7577 - val_accuracy: 0.6986\n",
            "Epoch 468/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8345 - accuracy: 0.6667 - val_loss: 0.7971 - val_accuracy: 0.6849\n",
            "Epoch 469/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8214 - accuracy: 0.6838 - val_loss: 0.7918 - val_accuracy: 0.6986\n",
            "Epoch 470/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8342 - accuracy: 0.6460 - val_loss: 0.8040 - val_accuracy: 0.6986\n",
            "Epoch 471/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8176 - accuracy: 0.6667 - val_loss: 0.7674 - val_accuracy: 0.6438\n",
            "Epoch 472/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8468 - accuracy: 0.6529 - val_loss: 0.7854 - val_accuracy: 0.6986\n",
            "Epoch 473/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8343 - accuracy: 0.6529 - val_loss: 0.7925 - val_accuracy: 0.6712\n",
            "Epoch 474/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8079 - accuracy: 0.6667 - val_loss: 0.7924 - val_accuracy: 0.6575\n",
            "Epoch 475/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8178 - accuracy: 0.6770 - val_loss: 0.7680 - val_accuracy: 0.6712\n",
            "Epoch 476/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8240 - accuracy: 0.6392 - val_loss: 0.7909 - val_accuracy: 0.6986\n",
            "Epoch 477/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8277 - accuracy: 0.6529 - val_loss: 0.7873 - val_accuracy: 0.6849\n",
            "Epoch 478/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8126 - accuracy: 0.6701 - val_loss: 0.7694 - val_accuracy: 0.6575\n",
            "Epoch 479/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8324 - accuracy: 0.6770 - val_loss: 0.7687 - val_accuracy: 0.6849\n",
            "Epoch 480/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8203 - accuracy: 0.6598 - val_loss: 0.8232 - val_accuracy: 0.6575\n",
            "Epoch 481/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8004 - accuracy: 0.6564 - val_loss: 0.7661 - val_accuracy: 0.6849\n",
            "Epoch 482/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8404 - accuracy: 0.6392 - val_loss: 0.7873 - val_accuracy: 0.6849\n",
            "Epoch 483/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8306 - accuracy: 0.6770 - val_loss: 0.8189 - val_accuracy: 0.6712\n",
            "Epoch 484/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8019 - accuracy: 0.6770 - val_loss: 0.7768 - val_accuracy: 0.6712\n",
            "Epoch 485/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8150 - accuracy: 0.6632 - val_loss: 0.7817 - val_accuracy: 0.6849\n",
            "Epoch 486/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8296 - accuracy: 0.6564 - val_loss: 0.7809 - val_accuracy: 0.6849\n",
            "Epoch 487/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8066 - accuracy: 0.6564 - val_loss: 0.7923 - val_accuracy: 0.6986\n",
            "Epoch 488/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8196 - accuracy: 0.6873 - val_loss: 0.8337 - val_accuracy: 0.6986\n",
            "Epoch 489/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8317 - accuracy: 0.6770 - val_loss: 0.7930 - val_accuracy: 0.6849\n",
            "Epoch 490/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8226 - accuracy: 0.6460 - val_loss: 0.7766 - val_accuracy: 0.6986\n",
            "Epoch 491/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8391 - accuracy: 0.6529 - val_loss: 0.8497 - val_accuracy: 0.6575\n",
            "Epoch 492/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7994 - accuracy: 0.6632 - val_loss: 0.7593 - val_accuracy: 0.6849\n",
            "Epoch 493/2000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8335 - accuracy: 0.6598 - val_loss: 0.7914 - val_accuracy: 0.6712\n",
            "Epoch 494/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8280 - accuracy: 0.6667 - val_loss: 0.8372 - val_accuracy: 0.6712\n",
            "Epoch 495/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8469 - accuracy: 0.6564 - val_loss: 0.7716 - val_accuracy: 0.6986\n",
            "Epoch 496/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8209 - accuracy: 0.6632 - val_loss: 0.8120 - val_accuracy: 0.6712\n",
            "Epoch 497/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8134 - accuracy: 0.6770 - val_loss: 0.7633 - val_accuracy: 0.7123\n",
            "Epoch 498/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7945 - accuracy: 0.6770 - val_loss: 0.7926 - val_accuracy: 0.6849\n",
            "Epoch 499/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8217 - accuracy: 0.6564 - val_loss: 0.7608 - val_accuracy: 0.6849\n",
            "Epoch 500/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8246 - accuracy: 0.6564 - val_loss: 0.8057 - val_accuracy: 0.6986\n",
            "Epoch 501/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8116 - accuracy: 0.6770 - val_loss: 0.7720 - val_accuracy: 0.6438\n",
            "Epoch 502/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8068 - accuracy: 0.6426 - val_loss: 0.8043 - val_accuracy: 0.6575\n",
            "Epoch 503/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7906 - accuracy: 0.6529 - val_loss: 0.7792 - val_accuracy: 0.6438\n",
            "Epoch 504/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8281 - accuracy: 0.6667 - val_loss: 0.8046 - val_accuracy: 0.6712\n",
            "Epoch 505/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8084 - accuracy: 0.6838 - val_loss: 0.7500 - val_accuracy: 0.7123\n",
            "Epoch 506/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7939 - accuracy: 0.6495 - val_loss: 0.7836 - val_accuracy: 0.6575\n",
            "Epoch 507/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7948 - accuracy: 0.6838 - val_loss: 0.7685 - val_accuracy: 0.6301\n",
            "Epoch 508/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8021 - accuracy: 0.6735 - val_loss: 0.7520 - val_accuracy: 0.6575\n",
            "Epoch 509/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8324 - accuracy: 0.6495 - val_loss: 0.7907 - val_accuracy: 0.6712\n",
            "Epoch 510/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8297 - accuracy: 0.6564 - val_loss: 0.8164 - val_accuracy: 0.6849\n",
            "Epoch 511/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7855 - accuracy: 0.6873 - val_loss: 0.7714 - val_accuracy: 0.6849\n",
            "Epoch 512/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8220 - accuracy: 0.6598 - val_loss: 0.8090 - val_accuracy: 0.6575\n",
            "Epoch 513/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8375 - accuracy: 0.6529 - val_loss: 0.8305 - val_accuracy: 0.6712\n",
            "Epoch 514/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8244 - accuracy: 0.6460 - val_loss: 0.7662 - val_accuracy: 0.6301\n",
            "Epoch 515/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8242 - accuracy: 0.6460 - val_loss: 0.8247 - val_accuracy: 0.6438\n",
            "Epoch 516/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8120 - accuracy: 0.6701 - val_loss: 0.7836 - val_accuracy: 0.6712\n",
            "Epoch 517/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8119 - accuracy: 0.6701 - val_loss: 0.7741 - val_accuracy: 0.6712\n",
            "Epoch 518/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8059 - accuracy: 0.6770 - val_loss: 0.8467 - val_accuracy: 0.6438\n",
            "Epoch 519/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8218 - accuracy: 0.6598 - val_loss: 0.7825 - val_accuracy: 0.6575\n",
            "Epoch 520/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8281 - accuracy: 0.6873 - val_loss: 0.7516 - val_accuracy: 0.6712\n",
            "Epoch 521/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8052 - accuracy: 0.6873 - val_loss: 0.7890 - val_accuracy: 0.6575\n",
            "Epoch 522/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8008 - accuracy: 0.6701 - val_loss: 0.7818 - val_accuracy: 0.6712\n",
            "Epoch 523/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8111 - accuracy: 0.6838 - val_loss: 0.7955 - val_accuracy: 0.6849\n",
            "Epoch 524/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7876 - accuracy: 0.6735 - val_loss: 0.7825 - val_accuracy: 0.6849\n",
            "Epoch 525/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8008 - accuracy: 0.6667 - val_loss: 0.7840 - val_accuracy: 0.6712\n",
            "Epoch 526/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7948 - accuracy: 0.6804 - val_loss: 0.7894 - val_accuracy: 0.6575\n",
            "Epoch 527/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8198 - accuracy: 0.6942 - val_loss: 0.7614 - val_accuracy: 0.6575\n",
            "Epoch 528/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8324 - accuracy: 0.6529 - val_loss: 0.7729 - val_accuracy: 0.6849\n",
            "Epoch 529/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7985 - accuracy: 0.6942 - val_loss: 0.8087 - val_accuracy: 0.6575\n",
            "Epoch 530/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8180 - accuracy: 0.6838 - val_loss: 0.7675 - val_accuracy: 0.6575\n",
            "Epoch 531/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8242 - accuracy: 0.6701 - val_loss: 0.8051 - val_accuracy: 0.6712\n",
            "Epoch 532/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8007 - accuracy: 0.6701 - val_loss: 0.7797 - val_accuracy: 0.6849\n",
            "Epoch 533/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8281 - accuracy: 0.6460 - val_loss: 0.7609 - val_accuracy: 0.6986\n",
            "Epoch 534/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7900 - accuracy: 0.6907 - val_loss: 0.8023 - val_accuracy: 0.6849\n",
            "Epoch 535/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7888 - accuracy: 0.6701 - val_loss: 0.7781 - val_accuracy: 0.6712\n",
            "Epoch 536/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8056 - accuracy: 0.6632 - val_loss: 0.7901 - val_accuracy: 0.6849\n",
            "Epoch 537/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8003 - accuracy: 0.6564 - val_loss: 0.7848 - val_accuracy: 0.6849\n",
            "Epoch 538/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8213 - accuracy: 0.6632 - val_loss: 0.8067 - val_accuracy: 0.6849\n",
            "Epoch 539/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7947 - accuracy: 0.6770 - val_loss: 0.7972 - val_accuracy: 0.6849\n",
            "Epoch 540/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7990 - accuracy: 0.6701 - val_loss: 0.7577 - val_accuracy: 0.6849\n",
            "Epoch 541/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8044 - accuracy: 0.6735 - val_loss: 0.8188 - val_accuracy: 0.6849\n",
            "Epoch 542/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7990 - accuracy: 0.6667 - val_loss: 0.7838 - val_accuracy: 0.6849\n",
            "Epoch 543/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8068 - accuracy: 0.6735 - val_loss: 0.7802 - val_accuracy: 0.7123\n",
            "Epoch 544/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7963 - accuracy: 0.6942 - val_loss: 0.7777 - val_accuracy: 0.6849\n",
            "Epoch 545/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8290 - accuracy: 0.6392 - val_loss: 0.7741 - val_accuracy: 0.6849\n",
            "Epoch 546/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8047 - accuracy: 0.6804 - val_loss: 0.7900 - val_accuracy: 0.6712\n",
            "Epoch 547/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8223 - accuracy: 0.6667 - val_loss: 0.8106 - val_accuracy: 0.6849\n",
            "Epoch 548/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7941 - accuracy: 0.6770 - val_loss: 0.7699 - val_accuracy: 0.6849\n",
            "Epoch 549/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7969 - accuracy: 0.6976 - val_loss: 0.7808 - val_accuracy: 0.6575\n",
            "Epoch 550/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7946 - accuracy: 0.6976 - val_loss: 0.7875 - val_accuracy: 0.6849\n",
            "Epoch 551/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8122 - accuracy: 0.6701 - val_loss: 0.7900 - val_accuracy: 0.6986\n",
            "Epoch 552/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8204 - accuracy: 0.6598 - val_loss: 0.8223 - val_accuracy: 0.6849\n",
            "Epoch 553/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8185 - accuracy: 0.6735 - val_loss: 0.7606 - val_accuracy: 0.6712\n",
            "Epoch 554/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8001 - accuracy: 0.6701 - val_loss: 0.7677 - val_accuracy: 0.6575\n",
            "Epoch 555/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7979 - accuracy: 0.6701 - val_loss: 0.8198 - val_accuracy: 0.6849\n",
            "Epoch 556/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7863 - accuracy: 0.6838 - val_loss: 0.7876 - val_accuracy: 0.6849\n",
            "Epoch 557/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7959 - accuracy: 0.6701 - val_loss: 0.7707 - val_accuracy: 0.6986\n",
            "Epoch 558/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8274 - accuracy: 0.6804 - val_loss: 0.7872 - val_accuracy: 0.6986\n",
            "Epoch 559/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8059 - accuracy: 0.6701 - val_loss: 0.8278 - val_accuracy: 0.6849\n",
            "Epoch 560/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8298 - accuracy: 0.6426 - val_loss: 0.7965 - val_accuracy: 0.7123\n",
            "Epoch 561/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8206 - accuracy: 0.6495 - val_loss: 0.7914 - val_accuracy: 0.6849\n",
            "Epoch 562/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8478 - accuracy: 0.6701 - val_loss: 0.7563 - val_accuracy: 0.6986\n",
            "Epoch 563/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8096 - accuracy: 0.6667 - val_loss: 0.8598 - val_accuracy: 0.6575\n",
            "Epoch 564/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8445 - accuracy: 0.6667 - val_loss: 0.8204 - val_accuracy: 0.6712\n",
            "Epoch 565/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8156 - accuracy: 0.6460 - val_loss: 0.7662 - val_accuracy: 0.6849\n",
            "Epoch 566/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7923 - accuracy: 0.6701 - val_loss: 0.7776 - val_accuracy: 0.7123\n",
            "Epoch 567/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7900 - accuracy: 0.6632 - val_loss: 0.7899 - val_accuracy: 0.6849\n",
            "Epoch 568/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7994 - accuracy: 0.6735 - val_loss: 0.7881 - val_accuracy: 0.6986\n",
            "Epoch 569/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8023 - accuracy: 0.6632 - val_loss: 0.7992 - val_accuracy: 0.6849\n",
            "Epoch 570/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8222 - accuracy: 0.6564 - val_loss: 0.7926 - val_accuracy: 0.6986\n",
            "Epoch 571/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8112 - accuracy: 0.6735 - val_loss: 0.8346 - val_accuracy: 0.6849\n",
            "Epoch 572/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8058 - accuracy: 0.6667 - val_loss: 0.8018 - val_accuracy: 0.6575\n",
            "Epoch 573/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8001 - accuracy: 0.6495 - val_loss: 0.7841 - val_accuracy: 0.6849\n",
            "Epoch 574/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7841 - accuracy: 0.6804 - val_loss: 0.7908 - val_accuracy: 0.6575\n",
            "Epoch 575/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7959 - accuracy: 0.6667 - val_loss: 0.7778 - val_accuracy: 0.6301\n",
            "Epoch 576/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8018 - accuracy: 0.6667 - val_loss: 0.8132 - val_accuracy: 0.6849\n",
            "Epoch 577/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7742 - accuracy: 0.6598 - val_loss: 0.7844 - val_accuracy: 0.6986\n",
            "Epoch 578/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8082 - accuracy: 0.6735 - val_loss: 0.7904 - val_accuracy: 0.6986\n",
            "Epoch 579/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7988 - accuracy: 0.6838 - val_loss: 0.8131 - val_accuracy: 0.6712\n",
            "Epoch 580/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7980 - accuracy: 0.6976 - val_loss: 0.7824 - val_accuracy: 0.6849\n",
            "Epoch 581/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8126 - accuracy: 0.6357 - val_loss: 0.7724 - val_accuracy: 0.6849\n",
            "Epoch 582/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8199 - accuracy: 0.6598 - val_loss: 0.7807 - val_accuracy: 0.6712\n",
            "Epoch 583/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7799 - accuracy: 0.6804 - val_loss: 0.8143 - val_accuracy: 0.6986\n",
            "Epoch 584/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8093 - accuracy: 0.6598 - val_loss: 0.7863 - val_accuracy: 0.6438\n",
            "Epoch 585/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7985 - accuracy: 0.6701 - val_loss: 0.8036 - val_accuracy: 0.6712\n",
            "Epoch 586/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7903 - accuracy: 0.6701 - val_loss: 0.8344 - val_accuracy: 0.6712\n",
            "Epoch 587/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8009 - accuracy: 0.6529 - val_loss: 0.7861 - val_accuracy: 0.6849\n",
            "Epoch 588/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7953 - accuracy: 0.6667 - val_loss: 0.8004 - val_accuracy: 0.6712\n",
            "Epoch 589/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8071 - accuracy: 0.6735 - val_loss: 0.7701 - val_accuracy: 0.6712\n",
            "Epoch 590/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7875 - accuracy: 0.6770 - val_loss: 0.7946 - val_accuracy: 0.6986\n",
            "Epoch 591/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7953 - accuracy: 0.6804 - val_loss: 0.7620 - val_accuracy: 0.6849\n",
            "Epoch 592/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8151 - accuracy: 0.6598 - val_loss: 0.7910 - val_accuracy: 0.6849\n",
            "Epoch 593/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8034 - accuracy: 0.6495 - val_loss: 0.7924 - val_accuracy: 0.6712\n",
            "Epoch 594/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8033 - accuracy: 0.6804 - val_loss: 0.7702 - val_accuracy: 0.6575\n",
            "Epoch 595/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8136 - accuracy: 0.6667 - val_loss: 0.8145 - val_accuracy: 0.6986\n",
            "Epoch 596/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7894 - accuracy: 0.6873 - val_loss: 0.7702 - val_accuracy: 0.6849\n",
            "Epoch 597/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7774 - accuracy: 0.6735 - val_loss: 0.8349 - val_accuracy: 0.6575\n",
            "Epoch 598/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.6598 - val_loss: 0.7909 - val_accuracy: 0.6849\n",
            "Epoch 599/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8019 - accuracy: 0.6770 - val_loss: 0.8190 - val_accuracy: 0.6575\n",
            "Epoch 600/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7951 - accuracy: 0.6701 - val_loss: 0.8001 - val_accuracy: 0.6438\n",
            "Epoch 601/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7962 - accuracy: 0.6838 - val_loss: 0.7775 - val_accuracy: 0.6712\n",
            "Epoch 602/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7759 - accuracy: 0.6976 - val_loss: 0.8060 - val_accuracy: 0.6712\n",
            "Epoch 603/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7959 - accuracy: 0.6667 - val_loss: 0.8040 - val_accuracy: 0.6849\n",
            "Epoch 604/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8165 - accuracy: 0.6701 - val_loss: 0.8000 - val_accuracy: 0.6849\n",
            "Epoch 605/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8012 - accuracy: 0.6804 - val_loss: 0.8045 - val_accuracy: 0.6849\n",
            "Epoch 606/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7993 - accuracy: 0.6460 - val_loss: 0.7905 - val_accuracy: 0.6849\n",
            "Epoch 607/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7847 - accuracy: 0.6907 - val_loss: 0.8097 - val_accuracy: 0.6849\n",
            "Epoch 608/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8219 - accuracy: 0.6667 - val_loss: 0.7713 - val_accuracy: 0.6849\n",
            "Epoch 609/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7746 - accuracy: 0.6873 - val_loss: 0.7790 - val_accuracy: 0.6849\n",
            "Epoch 610/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8019 - accuracy: 0.6770 - val_loss: 0.8023 - val_accuracy: 0.6986\n",
            "Epoch 611/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8103 - accuracy: 0.6460 - val_loss: 0.8178 - val_accuracy: 0.6849\n",
            "Epoch 612/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7808 - accuracy: 0.6804 - val_loss: 0.7992 - val_accuracy: 0.6712\n",
            "Epoch 613/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8113 - accuracy: 0.6598 - val_loss: 0.7866 - val_accuracy: 0.6849\n",
            "Epoch 614/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7994 - accuracy: 0.6667 - val_loss: 0.8404 - val_accuracy: 0.6575\n",
            "Epoch 615/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7780 - accuracy: 0.6838 - val_loss: 0.7737 - val_accuracy: 0.6986\n",
            "Epoch 616/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7981 - accuracy: 0.6735 - val_loss: 0.7929 - val_accuracy: 0.6986\n",
            "Epoch 617/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7843 - accuracy: 0.6942 - val_loss: 0.7788 - val_accuracy: 0.7123\n",
            "Epoch 618/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8016 - accuracy: 0.6667 - val_loss: 0.8095 - val_accuracy: 0.6986\n",
            "Epoch 619/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7872 - accuracy: 0.6804 - val_loss: 0.8153 - val_accuracy: 0.6986\n",
            "Epoch 620/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7938 - accuracy: 0.6735 - val_loss: 0.7666 - val_accuracy: 0.6712\n",
            "Epoch 621/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8171 - accuracy: 0.6770 - val_loss: 0.7817 - val_accuracy: 0.6712\n",
            "Epoch 622/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7951 - accuracy: 0.6632 - val_loss: 0.8071 - val_accuracy: 0.6849\n",
            "Epoch 623/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7904 - accuracy: 0.6804 - val_loss: 0.7854 - val_accuracy: 0.6849\n",
            "Epoch 624/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8140 - accuracy: 0.6495 - val_loss: 0.8048 - val_accuracy: 0.6849\n",
            "Epoch 625/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8164 - accuracy: 0.6701 - val_loss: 0.7891 - val_accuracy: 0.6986\n",
            "Epoch 626/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7998 - accuracy: 0.6838 - val_loss: 0.8002 - val_accuracy: 0.6849\n",
            "Epoch 627/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7713 - accuracy: 0.6804 - val_loss: 0.8210 - val_accuracy: 0.6575\n",
            "Epoch 628/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7833 - accuracy: 0.6701 - val_loss: 0.7705 - val_accuracy: 0.6849\n",
            "Epoch 629/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7914 - accuracy: 0.6838 - val_loss: 0.7891 - val_accuracy: 0.6986\n",
            "Epoch 630/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8065 - accuracy: 0.6838 - val_loss: 0.8348 - val_accuracy: 0.6712\n",
            "Epoch 631/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8048 - accuracy: 0.6598 - val_loss: 0.8247 - val_accuracy: 0.6849\n",
            "Epoch 632/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8121 - accuracy: 0.6667 - val_loss: 0.7698 - val_accuracy: 0.7123\n",
            "Epoch 633/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7981 - accuracy: 0.6667 - val_loss: 0.7842 - val_accuracy: 0.7123\n",
            "Epoch 634/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7814 - accuracy: 0.6770 - val_loss: 0.8241 - val_accuracy: 0.7123\n",
            "Epoch 635/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7959 - accuracy: 0.6701 - val_loss: 0.7657 - val_accuracy: 0.6986\n",
            "Epoch 636/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8467 - accuracy: 0.6564 - val_loss: 0.8911 - val_accuracy: 0.6575\n",
            "Epoch 637/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8556 - accuracy: 0.6323 - val_loss: 0.7827 - val_accuracy: 0.6712\n",
            "Epoch 638/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8146 - accuracy: 0.6942 - val_loss: 0.8180 - val_accuracy: 0.7123\n",
            "Epoch 639/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8003 - accuracy: 0.6838 - val_loss: 0.8302 - val_accuracy: 0.6712\n",
            "Epoch 640/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8096 - accuracy: 0.6460 - val_loss: 0.7825 - val_accuracy: 0.7123\n",
            "Epoch 641/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8017 - accuracy: 0.6529 - val_loss: 0.7767 - val_accuracy: 0.7123\n",
            "Epoch 642/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7945 - accuracy: 0.6564 - val_loss: 0.8081 - val_accuracy: 0.6849\n",
            "Epoch 643/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7942 - accuracy: 0.6667 - val_loss: 0.8216 - val_accuracy: 0.6712\n",
            "Epoch 644/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8030 - accuracy: 0.6392 - val_loss: 0.7885 - val_accuracy: 0.6849\n",
            "Epoch 645/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8268 - accuracy: 0.6632 - val_loss: 0.7880 - val_accuracy: 0.7260\n",
            "Epoch 646/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7852 - accuracy: 0.6804 - val_loss: 0.8277 - val_accuracy: 0.7123\n",
            "Epoch 647/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7885 - accuracy: 0.6770 - val_loss: 0.8082 - val_accuracy: 0.7123\n",
            "Epoch 648/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8086 - accuracy: 0.6804 - val_loss: 0.7670 - val_accuracy: 0.6986\n",
            "Epoch 649/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7853 - accuracy: 0.6907 - val_loss: 0.8496 - val_accuracy: 0.6712\n",
            "Epoch 650/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7910 - accuracy: 0.6598 - val_loss: 0.7816 - val_accuracy: 0.6986\n",
            "Epoch 651/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7852 - accuracy: 0.6632 - val_loss: 0.8079 - val_accuracy: 0.6849\n",
            "Epoch 652/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8145 - accuracy: 0.6357 - val_loss: 0.7972 - val_accuracy: 0.6986\n",
            "Epoch 653/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7848 - accuracy: 0.6942 - val_loss: 0.7734 - val_accuracy: 0.7123\n",
            "Epoch 654/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7937 - accuracy: 0.6942 - val_loss: 0.8239 - val_accuracy: 0.7123\n",
            "Epoch 655/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7899 - accuracy: 0.6770 - val_loss: 0.7689 - val_accuracy: 0.6986\n",
            "Epoch 656/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7837 - accuracy: 0.6735 - val_loss: 0.7733 - val_accuracy: 0.7123\n",
            "Epoch 657/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8120 - accuracy: 0.6632 - val_loss: 0.7868 - val_accuracy: 0.6986\n",
            "Epoch 658/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8023 - accuracy: 0.6804 - val_loss: 0.8418 - val_accuracy: 0.6849\n",
            "Epoch 659/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7825 - accuracy: 0.6804 - val_loss: 0.7701 - val_accuracy: 0.6986\n",
            "Epoch 660/2000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8018 - accuracy: 0.6838 - val_loss: 0.8333 - val_accuracy: 0.6849\n",
            "Epoch 661/2000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8031 - accuracy: 0.6770 - val_loss: 0.8192 - val_accuracy: 0.6712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AU1rJeJtdqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f060ff-fd7b-4a97-f39c-17b160e4aeb3"
      },
      "source": [
        "np.argmax(model.predict(X_test),axis=1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 1, 4, 6, 1, 3, 1, 1, 3, 6, 4, 4, 6, 4, 3, 6, 0, 0, 6, 1, 1, 3,\n",
              "       0, 6, 4, 3, 0, 0, 6, 6, 0, 2, 1, 6, 3, 1, 4, 0, 6, 6, 6, 4, 0, 0,\n",
              "       3, 4, 4, 1, 0, 4, 4, 4, 6, 6, 3, 6, 1, 4, 6, 1, 6, 0, 1, 1, 6, 4,\n",
              "       1, 1, 4, 1, 1, 3, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD__VauavyE7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2afdc56-a142-483d-fd83-f9f149519d84"
      },
      "source": [
        "np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 0, 0, 6, 1, 3, 1, 2, 3, 2, 4, 0, 6, 1, 3, 6, 0, 4, 6, 1, 0, 3,\n",
              "       1, 6, 4, 3, 4, 4, 6, 6, 0, 2, 0, 6, 3, 2, 1, 0, 6, 6, 6, 4, 0, 5,\n",
              "       2, 4, 1, 1, 0, 1, 4, 5, 6, 6, 3, 6, 1, 0, 6, 1, 6, 5, 1, 1, 6, 1,\n",
              "       4, 2, 4, 1, 1, 3, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7UlpY_fv87b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y56bJyxMtQIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d6a24e-cd55-4033-a98d-e0e1eb54cdab"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, np.argmax(model.predict(X_test),axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.45      0.45        11\n",
            "           1       0.59      0.62      0.61        16\n",
            "           2       1.00      0.17      0.29         6\n",
            "           3       0.90      1.00      0.95         9\n",
            "           4       0.40      0.60      0.48        10\n",
            "           5       0.00      0.00      0.00         3\n",
            "           6       0.95      1.00      0.97        18\n",
            "\n",
            "    accuracy                           0.67        73\n",
            "   macro avg       0.61      0.55      0.54        73\n",
            "weighted avg       0.68      0.67      0.65        73\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBmDRQ7Jwolv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP6qXQWSi-DX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92bb9418-d38d-4c02-da1b-81f9bf1c381b"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 5ms/step - loss: 0.7212 - accuracy: 0.6849\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.721165120601654, 0.6849315166473389]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MBwjeEqw4Fr"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAory2TZw51n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b07b679a-024e-4f6e-8519-76e8442b1588"
      },
      "source": [
        "# training a linear SVM classifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train)\n",
        "svm_predictions = svm_model_linear.predict(X_test)\n",
        "  \n",
        "# model accuracy for X_test  \n",
        "accuracy = svm_model_linear.score(X_test, y_test)\n",
        "\n",
        "# creating a confusion matrix\n",
        "cm = confusion_matrix(y_test, svm_predictions)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0, 11,  0,  0],\n",
              "       [ 0,  5,  0,  0, 11,  0,  0],\n",
              "       [ 0,  0,  0,  5,  1,  0,  0],\n",
              "       [ 0,  0,  0,  9,  0,  0,  0],\n",
              "       [ 0,  0,  0,  0, 10,  0,  0],\n",
              "       [ 0,  0,  0,  0,  3,  0,  0],\n",
              "       [ 0,  0,  0,  4,  0,  0, 14]])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGHlN1CtxTFJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca873fc-65f6-4517-8fa6-eeff67fcba41"
      },
      "source": [
        "accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5205479452054794"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE8u4I-HxXDq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzyVP7opxjl8"
      },
      "source": [
        "GNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T61LNLKExoju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26ad5745-1d1e-41f9-e028-d8412c6405d0"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB().fit(X_train, y_train)\n",
        "gnb_predictions = gnb.predict(X_test)\n",
        "  \n",
        "# accuracy on X_test\n",
        "accuracy = gnb.score(X_test, y_test)\n",
        "\n",
        "  \n",
        "# creating a confusion matrix\n",
        "cm = confusion_matrix(y_test, gnb_predictions)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  1,  0,  0,  3,  7,  0],\n",
              "       [ 0,  1,  4,  0, 10,  1,  0],\n",
              "       [ 0,  0,  4,  1,  1,  0,  0],\n",
              "       [ 0,  0,  1,  7,  0,  0,  1],\n",
              "       [ 0,  0,  0,  0,  4,  6,  0],\n",
              "       [ 0,  0,  0,  0,  0,  3,  0],\n",
              "       [ 0,  0,  0,  4,  0,  0, 14]])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1uBl1C8xugs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1975a97-8b8c-4425-80bd-40e8377e2cca"
      },
      "source": [
        "accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4520547945205479"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKEGwm6Ux3_p"
      },
      "source": [
        "# KNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDvrAGePx3gY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94efd737-d523-4381-a1ea-c2c5cb3706e9"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors = 13).fit(X_train, y_train)\n",
        "  \n",
        "# accuracy on X_test\n",
        "accuracy = knn.score(X_test, y_test)\n",
        "  \n",
        "# creating a confusion matrix\n",
        "knn_predictions = knn.predict(X_test) \n",
        "cm = confusion_matrix(y_test, knn_predictions)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4,  2,  0,  0,  4,  1,  0],\n",
              "       [ 2, 11,  0,  0,  3,  0,  0],\n",
              "       [ 0,  2,  1,  3,  0,  0,  0],\n",
              "       [ 0,  0,  0,  9,  0,  0,  0],\n",
              "       [ 1,  1,  0,  0,  8,  0,  0],\n",
              "       [ 2,  0,  0,  0,  1,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0, 18]])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIkjwDJPx-ht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb9f4f27-0447-4dc0-c41d-99e24bc79f21"
      },
      "source": [
        "accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6986301369863014"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peAK1v3iyy9I"
      },
      "source": [
        "# Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttvj91L9y2jI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2565665c-e33f-48e4-99ce-da64e2bde1a1"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dtree_model = DecisionTreeClassifier(max_depth = 13).fit(X_train, y_train)\n",
        "dtree_predictions = dtree_model.predict(X_test)\n",
        "  \n",
        "# creating a confusion matrix\n",
        "cm = confusion_matrix(y_test, dtree_predictions)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3,  0,  1,  0,  4,  3,  0],\n",
              "       [ 2, 10,  0,  0,  4,  0,  0],\n",
              "       [ 0,  4,  0,  1,  0,  0,  1],\n",
              "       [ 0,  0,  0,  9,  0,  0,  0],\n",
              "       [ 0,  1,  0,  0,  7,  2,  0],\n",
              "       [ 2,  0,  0,  0,  1,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0, 18]])"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yJBPHjmy47M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12fd6afa-509a-4ac2-b0ca-1578ca906b58"
      },
      "source": [
        "dtree_model.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6438356164383562"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuhTbiRh-_BF"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6V3fBm--8D0"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUPEhyKc_3FT"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtI3WUpk--cl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "outputId": "189a6eb9-b541-410f-9a5b-8dbbb1db9472"
      },
      "source": [
        "np.set_printoptions(precision=2)\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "class newmodel(MLPClassifier):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "    def predict(self, X):\n",
        "        y = self.model.predict(X)\n",
        "        return np.argmax(y,axis=1)\n",
        "\n",
        "model1 = newmodel(model)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
        "                  (\"Normalized confusion matrix\", 'true')]\n",
        "\n",
        "for title, normalize in titles_options:\n",
        "    disp = plot_confusion_matrix(model1, X_test, y_test,\n",
        "                                 display_labels=uniqueValues,\n",
        "                                 cmap=plt.cm.Blues,\n",
        "                                 normalize=normalize)\n",
        "    disp.ax_.set_title(title)\n",
        "\n",
        "    print(title)\n",
        "    print(disp.confusion_matrix)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[ 3  3  0  0  5  0  0]\n",
            " [ 1 13  0  0  2  0  0]\n",
            " [ 0  4  0  1  0  0  1]\n",
            " [ 0  0  0  9  0  0  0]\n",
            " [ 1  2  0  0  7  0  0]\n",
            " [ 2  0  0  0  1  0  0]\n",
            " [ 0  0  0  0  0  0 18]]\n",
            "Normalized confusion matrix\n",
            "[[0.27 0.27 0.   0.   0.45 0.   0.  ]\n",
            " [0.06 0.81 0.   0.   0.12 0.   0.  ]\n",
            " [0.   0.67 0.   0.17 0.   0.   0.17]\n",
            " [0.   0.   0.   1.   0.   0.   0.  ]\n",
            " [0.1  0.2  0.   0.   0.7  0.   0.  ]\n",
            " [0.67 0.   0.   0.   0.33 0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   1.  ]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hdE6EQfZ6tU"
      },
      "source": [
        "### Evaluation and Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gLH2mdEZ74z",
        "outputId": "1650ae98-0d6b-4cf4-e02c-362d293ef7d2"
      },
      "source": [
        "# Evaluate our model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Model loss on the test set: {loss}\")\n",
        "print(f\"Model accuracy on the test set: {100*accuracy:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step - loss: 0.7212 - accuracy: 0.6849\n",
            "Model loss on the test set: 0.721165120601654\n",
            "Model accuracy on the test set: 68.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Zr5zUN7waFYr",
        "outputId": "48f1f641-087a-478b-c333-56db09af6cd1"
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history_1.history['loss'])#[5:])\n",
        "plt.plot(history_1.history['val_loss'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Ol8la_eiaHBH",
        "outputId": "94685f26-b36f-4d19-ce94-b790325c15e8"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history_1.history['accuracy'])#[5:])\n",
        "plt.plot(history_1.history['val_accuracy'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Binary Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpFz87FZrNWm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvLBB1x4c9g2"
      },
      "source": [
        "## Model 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTEe3fbAc9g3"
      },
      "source": [
        "### Declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd08u9vRc9g3"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model_2 = keras.Sequential([\n",
        "    layers.Dense(512, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(256, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(128, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "model_2.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate = .0003),\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    patience=250,\n",
        "    min_delta=0.0001,\n",
        "    restore_best_weights=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUgoNB_Ic9g3"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHPgDrOyc9g4",
        "outputId": "8e05d1ae-8ff4-4871-9f55-316fb9543263"
      },
      "source": [
        "history_2 = model_2.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=2000,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1, \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "10/10 [==============================] - 1s 36ms/step - loss: 1.9899 - accuracy: 0.1856 - val_loss: 1.9204 - val_accuracy: 0.2466\n",
            "Epoch 2/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9459 - accuracy: 0.2027 - val_loss: 1.9368 - val_accuracy: 0.2466\n",
            "Epoch 3/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9410 - accuracy: 0.1787 - val_loss: 1.9181 - val_accuracy: 0.2466\n",
            "Epoch 4/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9096 - accuracy: 0.2131 - val_loss: 1.9360 - val_accuracy: 0.1233\n",
            "Epoch 5/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8897 - accuracy: 0.2199 - val_loss: 1.8801 - val_accuracy: 0.2466\n",
            "Epoch 6/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9329 - accuracy: 0.2027 - val_loss: 1.8763 - val_accuracy: 0.2466\n",
            "Epoch 7/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9016 - accuracy: 0.2268 - val_loss: 1.8795 - val_accuracy: 0.2466\n",
            "Epoch 8/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9305 - accuracy: 0.1753 - val_loss: 1.9101 - val_accuracy: 0.1233\n",
            "Epoch 9/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9260 - accuracy: 0.1718 - val_loss: 1.8958 - val_accuracy: 0.2466\n",
            "Epoch 10/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8918 - accuracy: 0.2096 - val_loss: 1.8782 - val_accuracy: 0.2466\n",
            "Epoch 11/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9363 - accuracy: 0.1753 - val_loss: 1.8799 - val_accuracy: 0.2466\n",
            "Epoch 12/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8866 - accuracy: 0.2371 - val_loss: 1.8970 - val_accuracy: 0.2466\n",
            "Epoch 13/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8847 - accuracy: 0.1924 - val_loss: 1.9108 - val_accuracy: 0.1233\n",
            "Epoch 14/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8944 - accuracy: 0.2165 - val_loss: 1.9101 - val_accuracy: 0.1233\n",
            "Epoch 15/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9024 - accuracy: 0.1959 - val_loss: 1.8947 - val_accuracy: 0.2466\n",
            "Epoch 16/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8828 - accuracy: 0.2027 - val_loss: 1.8896 - val_accuracy: 0.1233\n",
            "Epoch 17/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9034 - accuracy: 0.2096 - val_loss: 1.8771 - val_accuracy: 0.1233\n",
            "Epoch 18/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8941 - accuracy: 0.1959 - val_loss: 1.8752 - val_accuracy: 0.2466\n",
            "Epoch 19/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8893 - accuracy: 0.2302 - val_loss: 1.8800 - val_accuracy: 0.2466\n",
            "Epoch 20/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8753 - accuracy: 0.1890 - val_loss: 1.8747 - val_accuracy: 0.2466\n",
            "Epoch 21/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8979 - accuracy: 0.2234 - val_loss: 1.8790 - val_accuracy: 0.2466\n",
            "Epoch 22/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8821 - accuracy: 0.2199 - val_loss: 1.8932 - val_accuracy: 0.2466\n",
            "Epoch 23/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9011 - accuracy: 0.2371 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 24/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9011 - accuracy: 0.2096 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 25/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9074 - accuracy: 0.1787 - val_loss: 1.8949 - val_accuracy: 0.2466\n",
            "Epoch 26/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8808 - accuracy: 0.2131 - val_loss: 1.9126 - val_accuracy: 0.2466\n",
            "Epoch 27/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9201 - accuracy: 0.2199 - val_loss: 1.9098 - val_accuracy: 0.2466\n",
            "Epoch 28/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8885 - accuracy: 0.2131 - val_loss: 1.9039 - val_accuracy: 0.2466\n",
            "Epoch 29/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8855 - accuracy: 0.2509 - val_loss: 1.8972 - val_accuracy: 0.3562\n",
            "Epoch 30/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8860 - accuracy: 0.2337 - val_loss: 1.8975 - val_accuracy: 0.1233\n",
            "Epoch 31/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8821 - accuracy: 0.2062 - val_loss: 1.8960 - val_accuracy: 0.1233\n",
            "Epoch 32/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8973 - accuracy: 0.2371 - val_loss: 1.8950 - val_accuracy: 0.2466\n",
            "Epoch 33/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8902 - accuracy: 0.2268 - val_loss: 1.8961 - val_accuracy: 0.2466\n",
            "Epoch 34/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8844 - accuracy: 0.2096 - val_loss: 1.8946 - val_accuracy: 0.2466\n",
            "Epoch 35/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8891 - accuracy: 0.2440 - val_loss: 1.8858 - val_accuracy: 0.2466\n",
            "Epoch 36/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8807 - accuracy: 0.2062 - val_loss: 1.8804 - val_accuracy: 0.2466\n",
            "Epoch 37/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8853 - accuracy: 0.2371 - val_loss: 1.8881 - val_accuracy: 0.2466\n",
            "Epoch 38/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8821 - accuracy: 0.2268 - val_loss: 1.8911 - val_accuracy: 0.2466\n",
            "Epoch 39/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8837 - accuracy: 0.2199 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 40/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8928 - accuracy: 0.2165 - val_loss: 1.8885 - val_accuracy: 0.2466\n",
            "Epoch 41/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8911 - accuracy: 0.2165 - val_loss: 1.8946 - val_accuracy: 0.2466\n",
            "Epoch 42/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8800 - accuracy: 0.1924 - val_loss: 1.8916 - val_accuracy: 0.2466\n",
            "Epoch 43/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8843 - accuracy: 0.2302 - val_loss: 1.8945 - val_accuracy: 0.3562\n",
            "Epoch 44/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8892 - accuracy: 0.2199 - val_loss: 1.8834 - val_accuracy: 0.2466\n",
            "Epoch 45/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8869 - accuracy: 0.1959 - val_loss: 1.8808 - val_accuracy: 0.2466\n",
            "Epoch 46/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8688 - accuracy: 0.2131 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 47/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8814 - accuracy: 0.2268 - val_loss: 1.8844 - val_accuracy: 0.2466\n",
            "Epoch 48/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8763 - accuracy: 0.2234 - val_loss: 1.8920 - val_accuracy: 0.2466\n",
            "Epoch 49/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8739 - accuracy: 0.2268 - val_loss: 1.8892 - val_accuracy: 0.2466\n",
            "Epoch 50/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8921 - accuracy: 0.2165 - val_loss: 1.8885 - val_accuracy: 0.2466\n",
            "Epoch 51/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8732 - accuracy: 0.2131 - val_loss: 1.8922 - val_accuracy: 0.2466\n",
            "Epoch 52/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8901 - accuracy: 0.1959 - val_loss: 1.8917 - val_accuracy: 0.2466\n",
            "Epoch 53/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8679 - accuracy: 0.2268 - val_loss: 1.8833 - val_accuracy: 0.2603\n",
            "Epoch 54/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8815 - accuracy: 0.2612 - val_loss: 1.8858 - val_accuracy: 0.3425\n",
            "Epoch 55/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8697 - accuracy: 0.2096 - val_loss: 1.8915 - val_accuracy: 0.1233\n",
            "Epoch 56/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8940 - accuracy: 0.2302 - val_loss: 1.8944 - val_accuracy: 0.1233\n",
            "Epoch 57/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8772 - accuracy: 0.2405 - val_loss: 1.8920 - val_accuracy: 0.1233\n",
            "Epoch 58/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8817 - accuracy: 0.2474 - val_loss: 1.8773 - val_accuracy: 0.2055\n",
            "Epoch 59/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8686 - accuracy: 0.2337 - val_loss: 1.8713 - val_accuracy: 0.2466\n",
            "Epoch 60/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8725 - accuracy: 0.2474 - val_loss: 1.8746 - val_accuracy: 0.2466\n",
            "Epoch 61/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8848 - accuracy: 0.2268 - val_loss: 1.8704 - val_accuracy: 0.2466\n",
            "Epoch 62/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8717 - accuracy: 0.2199 - val_loss: 1.8659 - val_accuracy: 0.2466\n",
            "Epoch 63/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8711 - accuracy: 0.2302 - val_loss: 1.8706 - val_accuracy: 0.2466\n",
            "Epoch 64/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8657 - accuracy: 0.2302 - val_loss: 1.8716 - val_accuracy: 0.2466\n",
            "Epoch 65/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8808 - accuracy: 0.2199 - val_loss: 1.8668 - val_accuracy: 0.3151\n",
            "Epoch 66/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8627 - accuracy: 0.2955 - val_loss: 1.8673 - val_accuracy: 0.3699\n",
            "Epoch 67/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8618 - accuracy: 0.2405 - val_loss: 1.8599 - val_accuracy: 0.2603\n",
            "Epoch 68/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8636 - accuracy: 0.2337 - val_loss: 1.8594 - val_accuracy: 0.2466\n",
            "Epoch 69/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8568 - accuracy: 0.2749 - val_loss: 1.8560 - val_accuracy: 0.2466\n",
            "Epoch 70/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8708 - accuracy: 0.2405 - val_loss: 1.8617 - val_accuracy: 0.2466\n",
            "Epoch 71/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8825 - accuracy: 0.2199 - val_loss: 1.8641 - val_accuracy: 0.2466\n",
            "Epoch 72/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8636 - accuracy: 0.2474 - val_loss: 1.8614 - val_accuracy: 0.2466\n",
            "Epoch 73/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8518 - accuracy: 0.2715 - val_loss: 1.8505 - val_accuracy: 0.2466\n",
            "Epoch 74/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8640 - accuracy: 0.2440 - val_loss: 1.8424 - val_accuracy: 0.2466\n",
            "Epoch 75/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8583 - accuracy: 0.2577 - val_loss: 1.8431 - val_accuracy: 0.3151\n",
            "Epoch 76/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8643 - accuracy: 0.3024 - val_loss: 1.8264 - val_accuracy: 0.2603\n",
            "Epoch 77/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8422 - accuracy: 0.2543 - val_loss: 1.8283 - val_accuracy: 0.2466\n",
            "Epoch 78/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8396 - accuracy: 0.2680 - val_loss: 1.8355 - val_accuracy: 0.3699\n",
            "Epoch 79/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8536 - accuracy: 0.2749 - val_loss: 1.8157 - val_accuracy: 0.2603\n",
            "Epoch 80/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8442 - accuracy: 0.2921 - val_loss: 1.8048 - val_accuracy: 0.3699\n",
            "Epoch 81/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8426 - accuracy: 0.2887 - val_loss: 1.7915 - val_accuracy: 0.3014\n",
            "Epoch 82/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8248 - accuracy: 0.2818 - val_loss: 1.7868 - val_accuracy: 0.3699\n",
            "Epoch 83/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8128 - accuracy: 0.2749 - val_loss: 1.7792 - val_accuracy: 0.3014\n",
            "Epoch 84/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8568 - accuracy: 0.2818 - val_loss: 1.7522 - val_accuracy: 0.3288\n",
            "Epoch 85/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8098 - accuracy: 0.2784 - val_loss: 1.7504 - val_accuracy: 0.3699\n",
            "Epoch 86/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8059 - accuracy: 0.2990 - val_loss: 1.7585 - val_accuracy: 0.3014\n",
            "Epoch 87/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7903 - accuracy: 0.3368 - val_loss: 1.7446 - val_accuracy: 0.2603\n",
            "Epoch 88/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7793 - accuracy: 0.3196 - val_loss: 1.7001 - val_accuracy: 0.3699\n",
            "Epoch 89/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7744 - accuracy: 0.3127 - val_loss: 1.7828 - val_accuracy: 0.2740\n",
            "Epoch 90/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7713 - accuracy: 0.3127 - val_loss: 1.6506 - val_accuracy: 0.3562\n",
            "Epoch 91/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7496 - accuracy: 0.3333 - val_loss: 1.6615 - val_accuracy: 0.3562\n",
            "Epoch 92/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7074 - accuracy: 0.3986 - val_loss: 1.6254 - val_accuracy: 0.3562\n",
            "Epoch 93/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6802 - accuracy: 0.3814 - val_loss: 1.6550 - val_accuracy: 0.3151\n",
            "Epoch 94/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6708 - accuracy: 0.3780 - val_loss: 1.5539 - val_accuracy: 0.3699\n",
            "Epoch 95/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6138 - accuracy: 0.4158 - val_loss: 1.5708 - val_accuracy: 0.3699\n",
            "Epoch 96/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5997 - accuracy: 0.4227 - val_loss: 1.5482 - val_accuracy: 0.3699\n",
            "Epoch 97/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5853 - accuracy: 0.4089 - val_loss: 1.5999 - val_accuracy: 0.3151\n",
            "Epoch 98/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6466 - accuracy: 0.3608 - val_loss: 1.5208 - val_accuracy: 0.3699\n",
            "Epoch 99/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6461 - accuracy: 0.3711 - val_loss: 1.4938 - val_accuracy: 0.3699\n",
            "Epoch 100/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.5707 - accuracy: 0.4021 - val_loss: 1.4876 - val_accuracy: 0.3699\n",
            "Epoch 101/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5520 - accuracy: 0.4055 - val_loss: 1.4994 - val_accuracy: 0.3699\n",
            "Epoch 102/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5216 - accuracy: 0.4261 - val_loss: 1.4598 - val_accuracy: 0.3699\n",
            "Epoch 103/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5297 - accuracy: 0.4055 - val_loss: 1.5262 - val_accuracy: 0.3151\n",
            "Epoch 104/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5750 - accuracy: 0.3883 - val_loss: 1.5114 - val_accuracy: 0.3288\n",
            "Epoch 105/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5508 - accuracy: 0.3883 - val_loss: 1.5118 - val_accuracy: 0.3425\n",
            "Epoch 106/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5417 - accuracy: 0.3986 - val_loss: 1.4639 - val_accuracy: 0.3699\n",
            "Epoch 107/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5699 - accuracy: 0.3849 - val_loss: 1.5327 - val_accuracy: 0.3151\n",
            "Epoch 108/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6745 - accuracy: 0.3471 - val_loss: 1.4863 - val_accuracy: 0.3699\n",
            "Epoch 109/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6007 - accuracy: 0.3883 - val_loss: 1.5419 - val_accuracy: 0.3562\n",
            "Epoch 110/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5367 - accuracy: 0.4124 - val_loss: 1.4456 - val_accuracy: 0.3699\n",
            "Epoch 111/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4900 - accuracy: 0.4192 - val_loss: 1.4315 - val_accuracy: 0.3699\n",
            "Epoch 112/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4631 - accuracy: 0.4192 - val_loss: 1.4273 - val_accuracy: 0.3699\n",
            "Epoch 113/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4590 - accuracy: 0.4227 - val_loss: 1.4204 - val_accuracy: 0.3699\n",
            "Epoch 114/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4291 - accuracy: 0.4124 - val_loss: 1.4287 - val_accuracy: 0.3699\n",
            "Epoch 115/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5105 - accuracy: 0.4089 - val_loss: 1.5691 - val_accuracy: 0.3973\n",
            "Epoch 116/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5738 - accuracy: 0.3883 - val_loss: 1.4225 - val_accuracy: 0.3699\n",
            "Epoch 117/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5680 - accuracy: 0.3608 - val_loss: 1.4041 - val_accuracy: 0.3699\n",
            "Epoch 118/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4379 - accuracy: 0.4192 - val_loss: 1.4097 - val_accuracy: 0.3699\n",
            "Epoch 119/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4349 - accuracy: 0.4261 - val_loss: 1.4596 - val_accuracy: 0.3699\n",
            "Epoch 120/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4335 - accuracy: 0.4227 - val_loss: 1.4252 - val_accuracy: 0.3699\n",
            "Epoch 121/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4498 - accuracy: 0.4261 - val_loss: 1.4304 - val_accuracy: 0.3699\n",
            "Epoch 122/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4132 - accuracy: 0.4330 - val_loss: 1.4163 - val_accuracy: 0.3836\n",
            "Epoch 123/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4246 - accuracy: 0.4124 - val_loss: 1.4043 - val_accuracy: 0.3699\n",
            "Epoch 124/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4146 - accuracy: 0.4261 - val_loss: 1.3995 - val_accuracy: 0.3699\n",
            "Epoch 125/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.3998 - accuracy: 0.4261 - val_loss: 1.4017 - val_accuracy: 0.3836\n",
            "Epoch 126/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5168 - accuracy: 0.4055 - val_loss: 1.3963 - val_accuracy: 0.3699\n",
            "Epoch 127/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4652 - accuracy: 0.4158 - val_loss: 1.4320 - val_accuracy: 0.3836\n",
            "Epoch 128/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4557 - accuracy: 0.4158 - val_loss: 1.4748 - val_accuracy: 0.3562\n",
            "Epoch 129/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4595 - accuracy: 0.4158 - val_loss: 1.3975 - val_accuracy: 0.3699\n",
            "Epoch 130/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4252 - accuracy: 0.4364 - val_loss: 1.4105 - val_accuracy: 0.3836\n",
            "Epoch 131/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.3960 - accuracy: 0.4261 - val_loss: 1.3769 - val_accuracy: 0.3699\n",
            "Epoch 132/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.3824 - accuracy: 0.4296 - val_loss: 1.3752 - val_accuracy: 0.3699\n",
            "Epoch 133/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.3816 - accuracy: 0.4330 - val_loss: 1.4003 - val_accuracy: 0.3973\n",
            "Epoch 134/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5426 - accuracy: 0.3746 - val_loss: 1.4770 - val_accuracy: 0.3562\n",
            "Epoch 135/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5766 - accuracy: 0.3814 - val_loss: 1.5091 - val_accuracy: 0.3425\n",
            "Epoch 136/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5559 - accuracy: 0.3986 - val_loss: 1.6507 - val_accuracy: 0.2877\n",
            "Epoch 137/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6260 - accuracy: 0.3505 - val_loss: 1.4669 - val_accuracy: 0.3699\n",
            "Epoch 138/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5609 - accuracy: 0.3918 - val_loss: 1.4552 - val_accuracy: 0.3836\n",
            "Epoch 139/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5279 - accuracy: 0.4055 - val_loss: 1.4913 - val_accuracy: 0.3425\n",
            "Epoch 140/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4824 - accuracy: 0.3952 - val_loss: 1.4373 - val_accuracy: 0.3699\n",
            "Epoch 141/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5070 - accuracy: 0.4158 - val_loss: 1.4143 - val_accuracy: 0.3699\n",
            "Epoch 142/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4711 - accuracy: 0.3986 - val_loss: 1.5481 - val_accuracy: 0.3014\n",
            "Epoch 143/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5735 - accuracy: 0.3883 - val_loss: 1.3915 - val_accuracy: 0.3699\n",
            "Epoch 144/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5413 - accuracy: 0.3814 - val_loss: 1.4892 - val_accuracy: 0.3425\n",
            "Epoch 145/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6841 - accuracy: 0.3677 - val_loss: 1.5847 - val_accuracy: 0.3699\n",
            "Epoch 146/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6338 - accuracy: 0.3849 - val_loss: 1.5018 - val_accuracy: 0.3836\n",
            "Epoch 147/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5606 - accuracy: 0.3952 - val_loss: 1.4390 - val_accuracy: 0.3699\n",
            "Epoch 148/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5776 - accuracy: 0.4192 - val_loss: 1.4371 - val_accuracy: 0.3699\n",
            "Epoch 149/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5698 - accuracy: 0.4021 - val_loss: 1.4448 - val_accuracy: 0.3836\n",
            "Epoch 150/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5869 - accuracy: 0.3849 - val_loss: 1.5571 - val_accuracy: 0.3973\n",
            "Epoch 151/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5844 - accuracy: 0.3986 - val_loss: 1.4521 - val_accuracy: 0.3699\n",
            "Epoch 152/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5289 - accuracy: 0.3986 - val_loss: 1.4434 - val_accuracy: 0.3699\n",
            "Epoch 153/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5071 - accuracy: 0.4055 - val_loss: 1.4571 - val_accuracy: 0.3699\n",
            "Epoch 154/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5112 - accuracy: 0.4192 - val_loss: 1.4071 - val_accuracy: 0.3699\n",
            "Epoch 155/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6443 - accuracy: 0.3849 - val_loss: 1.4160 - val_accuracy: 0.3699\n",
            "Epoch 156/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6746 - accuracy: 0.3918 - val_loss: 1.4664 - val_accuracy: 0.3699\n",
            "Epoch 157/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6231 - accuracy: 0.3883 - val_loss: 1.5041 - val_accuracy: 0.3836\n",
            "Epoch 158/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6702 - accuracy: 0.3677 - val_loss: 1.4954 - val_accuracy: 0.3836\n",
            "Epoch 159/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6224 - accuracy: 0.4055 - val_loss: 1.4845 - val_accuracy: 0.3836\n",
            "Epoch 160/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6435 - accuracy: 0.3780 - val_loss: 1.4620 - val_accuracy: 0.3699\n",
            "Epoch 161/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6286 - accuracy: 0.3952 - val_loss: 1.4654 - val_accuracy: 0.3836\n",
            "Epoch 162/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6495 - accuracy: 0.3849 - val_loss: 1.4561 - val_accuracy: 0.3699\n",
            "Epoch 163/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6136 - accuracy: 0.3883 - val_loss: 1.4539 - val_accuracy: 0.3699\n",
            "Epoch 164/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5855 - accuracy: 0.4021 - val_loss: 1.5132 - val_accuracy: 0.3699\n",
            "Epoch 165/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6258 - accuracy: 0.3711 - val_loss: 1.4591 - val_accuracy: 0.3699\n",
            "Epoch 166/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6223 - accuracy: 0.3746 - val_loss: 1.5393 - val_accuracy: 0.3288\n",
            "Epoch 167/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6432 - accuracy: 0.3849 - val_loss: 1.4433 - val_accuracy: 0.3699\n",
            "Epoch 168/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6296 - accuracy: 0.3814 - val_loss: 1.4378 - val_accuracy: 0.3699\n",
            "Epoch 169/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5721 - accuracy: 0.4261 - val_loss: 1.4459 - val_accuracy: 0.3836\n",
            "Epoch 170/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5976 - accuracy: 0.3918 - val_loss: 1.4422 - val_accuracy: 0.3699\n",
            "Epoch 171/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5989 - accuracy: 0.4021 - val_loss: 1.5012 - val_accuracy: 0.3425\n",
            "Epoch 172/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6919 - accuracy: 0.3643 - val_loss: 1.4357 - val_accuracy: 0.3699\n",
            "Epoch 173/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6760 - accuracy: 0.3574 - val_loss: 1.4876 - val_accuracy: 0.3836\n",
            "Epoch 174/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6150 - accuracy: 0.3883 - val_loss: 1.4540 - val_accuracy: 0.3699\n",
            "Epoch 175/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5560 - accuracy: 0.4021 - val_loss: 1.4447 - val_accuracy: 0.3699\n",
            "Epoch 176/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6318 - accuracy: 0.3814 - val_loss: 1.4482 - val_accuracy: 0.3699\n",
            "Epoch 177/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6200 - accuracy: 0.3711 - val_loss: 1.4619 - val_accuracy: 0.3836\n",
            "Epoch 178/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6123 - accuracy: 0.4158 - val_loss: 1.4757 - val_accuracy: 0.3836\n",
            "Epoch 179/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6252 - accuracy: 0.3986 - val_loss: 1.5221 - val_accuracy: 0.3562\n",
            "Epoch 180/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6370 - accuracy: 0.3849 - val_loss: 1.5217 - val_accuracy: 0.3836\n",
            "Epoch 181/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6251 - accuracy: 0.3814 - val_loss: 1.5450 - val_accuracy: 0.3836\n",
            "Epoch 182/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6276 - accuracy: 0.3883 - val_loss: 1.5438 - val_accuracy: 0.3425\n",
            "Epoch 183/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6207 - accuracy: 0.3849 - val_loss: 1.5142 - val_accuracy: 0.3836\n",
            "Epoch 184/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6528 - accuracy: 0.3711 - val_loss: 1.4686 - val_accuracy: 0.3836\n",
            "Epoch 185/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5756 - accuracy: 0.4089 - val_loss: 1.4622 - val_accuracy: 0.3836\n",
            "Epoch 186/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6148 - accuracy: 0.3883 - val_loss: 1.4719 - val_accuracy: 0.3836\n",
            "Epoch 187/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6193 - accuracy: 0.3849 - val_loss: 1.4379 - val_accuracy: 0.3699\n",
            "Epoch 188/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6281 - accuracy: 0.3883 - val_loss: 1.4710 - val_accuracy: 0.3836\n",
            "Epoch 189/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5727 - accuracy: 0.4021 - val_loss: 1.4391 - val_accuracy: 0.3836\n",
            "Epoch 190/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6099 - accuracy: 0.3918 - val_loss: 1.4453 - val_accuracy: 0.3836\n",
            "Epoch 191/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5355 - accuracy: 0.4021 - val_loss: 1.4375 - val_accuracy: 0.3699\n",
            "Epoch 192/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6291 - accuracy: 0.3849 - val_loss: 1.4525 - val_accuracy: 0.3836\n",
            "Epoch 193/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6145 - accuracy: 0.3711 - val_loss: 1.4879 - val_accuracy: 0.3973\n",
            "Epoch 194/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6236 - accuracy: 0.3883 - val_loss: 1.4701 - val_accuracy: 0.3973\n",
            "Epoch 195/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5522 - accuracy: 0.4124 - val_loss: 1.4654 - val_accuracy: 0.3836\n",
            "Epoch 196/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6429 - accuracy: 0.3746 - val_loss: 1.4531 - val_accuracy: 0.3699\n",
            "Epoch 197/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6070 - accuracy: 0.4021 - val_loss: 1.4529 - val_accuracy: 0.3836\n",
            "Epoch 198/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6246 - accuracy: 0.3883 - val_loss: 1.5108 - val_accuracy: 0.4110\n",
            "Epoch 199/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5944 - accuracy: 0.3883 - val_loss: 1.4446 - val_accuracy: 0.3699\n",
            "Epoch 200/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6287 - accuracy: 0.3780 - val_loss: 1.4480 - val_accuracy: 0.3836\n",
            "Epoch 201/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5787 - accuracy: 0.3986 - val_loss: 1.4416 - val_accuracy: 0.3836\n",
            "Epoch 202/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5727 - accuracy: 0.3986 - val_loss: 1.4311 - val_accuracy: 0.3836\n",
            "Epoch 203/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5717 - accuracy: 0.3849 - val_loss: 1.4265 - val_accuracy: 0.3836\n",
            "Epoch 204/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5574 - accuracy: 0.4089 - val_loss: 1.4197 - val_accuracy: 0.3836\n",
            "Epoch 205/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5845 - accuracy: 0.4055 - val_loss: 1.4149 - val_accuracy: 0.3836\n",
            "Epoch 206/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6064 - accuracy: 0.3849 - val_loss: 1.4314 - val_accuracy: 0.4247\n",
            "Epoch 207/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6527 - accuracy: 0.3952 - val_loss: 1.4482 - val_accuracy: 0.3973\n",
            "Epoch 208/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5939 - accuracy: 0.4055 - val_loss: 1.4561 - val_accuracy: 0.4247\n",
            "Epoch 209/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6040 - accuracy: 0.4192 - val_loss: 1.4499 - val_accuracy: 0.4384\n",
            "Epoch 210/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6243 - accuracy: 0.3952 - val_loss: 1.4407 - val_accuracy: 0.3973\n",
            "Epoch 211/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6216 - accuracy: 0.3986 - val_loss: 1.4297 - val_accuracy: 0.3836\n",
            "Epoch 212/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5885 - accuracy: 0.4089 - val_loss: 1.4355 - val_accuracy: 0.3836\n",
            "Epoch 213/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6493 - accuracy: 0.3505 - val_loss: 1.4694 - val_accuracy: 0.4247\n",
            "Epoch 214/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5856 - accuracy: 0.3986 - val_loss: 1.4322 - val_accuracy: 0.3973\n",
            "Epoch 215/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5986 - accuracy: 0.3986 - val_loss: 1.4586 - val_accuracy: 0.4247\n",
            "Epoch 216/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5546 - accuracy: 0.4124 - val_loss: 1.4883 - val_accuracy: 0.3699\n",
            "Epoch 217/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7074 - accuracy: 0.3608 - val_loss: 1.6052 - val_accuracy: 0.3425\n",
            "Epoch 218/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6284 - accuracy: 0.3952 - val_loss: 1.4416 - val_accuracy: 0.3836\n",
            "Epoch 219/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6051 - accuracy: 0.3986 - val_loss: 1.4478 - val_accuracy: 0.3836\n",
            "Epoch 220/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6093 - accuracy: 0.4055 - val_loss: 1.4514 - val_accuracy: 0.3973\n",
            "Epoch 221/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5991 - accuracy: 0.3952 - val_loss: 1.4553 - val_accuracy: 0.4110\n",
            "Epoch 222/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5980 - accuracy: 0.4021 - val_loss: 1.4233 - val_accuracy: 0.3973\n",
            "Epoch 223/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5683 - accuracy: 0.3986 - val_loss: 1.4303 - val_accuracy: 0.3836\n",
            "Epoch 224/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5798 - accuracy: 0.4089 - val_loss: 1.4336 - val_accuracy: 0.3836\n",
            "Epoch 225/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5395 - accuracy: 0.4158 - val_loss: 1.4612 - val_accuracy: 0.4247\n",
            "Epoch 226/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6147 - accuracy: 0.3918 - val_loss: 1.4810 - val_accuracy: 0.4110\n",
            "Epoch 227/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5945 - accuracy: 0.3780 - val_loss: 1.4236 - val_accuracy: 0.3836\n",
            "Epoch 228/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6257 - accuracy: 0.4021 - val_loss: 1.4710 - val_accuracy: 0.4384\n",
            "Epoch 229/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5921 - accuracy: 0.3986 - val_loss: 1.4181 - val_accuracy: 0.3836\n",
            "Epoch 230/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5600 - accuracy: 0.4158 - val_loss: 1.4152 - val_accuracy: 0.3973\n",
            "Epoch 231/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5883 - accuracy: 0.3814 - val_loss: 1.4418 - val_accuracy: 0.4247\n",
            "Epoch 232/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5528 - accuracy: 0.3918 - val_loss: 1.4574 - val_accuracy: 0.4384\n",
            "Epoch 233/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6315 - accuracy: 0.4055 - val_loss: 1.4270 - val_accuracy: 0.3973\n",
            "Epoch 234/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6085 - accuracy: 0.4055 - val_loss: 1.4370 - val_accuracy: 0.4247\n",
            "Epoch 235/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5757 - accuracy: 0.4089 - val_loss: 1.5057 - val_accuracy: 0.4110\n",
            "Epoch 236/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5349 - accuracy: 0.4158 - val_loss: 1.4238 - val_accuracy: 0.4110\n",
            "Epoch 237/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5640 - accuracy: 0.4158 - val_loss: 1.4098 - val_accuracy: 0.4110\n",
            "Epoch 238/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5792 - accuracy: 0.4158 - val_loss: 1.5072 - val_accuracy: 0.4110\n",
            "Epoch 239/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6284 - accuracy: 0.3918 - val_loss: 1.4182 - val_accuracy: 0.4110\n",
            "Epoch 240/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5926 - accuracy: 0.3814 - val_loss: 1.4051 - val_accuracy: 0.3973\n",
            "Epoch 241/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5259 - accuracy: 0.4021 - val_loss: 1.4333 - val_accuracy: 0.4384\n",
            "Epoch 242/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5765 - accuracy: 0.4192 - val_loss: 1.3916 - val_accuracy: 0.4247\n",
            "Epoch 243/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5981 - accuracy: 0.3883 - val_loss: 1.5059 - val_accuracy: 0.3699\n",
            "Epoch 244/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5737 - accuracy: 0.3952 - val_loss: 1.4027 - val_accuracy: 0.4247\n",
            "Epoch 245/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6438 - accuracy: 0.3952 - val_loss: 1.4006 - val_accuracy: 0.4110\n",
            "Epoch 246/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6214 - accuracy: 0.3986 - val_loss: 1.4334 - val_accuracy: 0.3973\n",
            "Epoch 247/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6817 - accuracy: 0.3711 - val_loss: 1.5306 - val_accuracy: 0.4110\n",
            "Epoch 248/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5675 - accuracy: 0.4227 - val_loss: 1.4289 - val_accuracy: 0.3973\n",
            "Epoch 249/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5912 - accuracy: 0.3746 - val_loss: 1.4645 - val_accuracy: 0.4384\n",
            "Epoch 250/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5651 - accuracy: 0.4055 - val_loss: 1.4458 - val_accuracy: 0.4247\n",
            "Epoch 251/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5619 - accuracy: 0.4089 - val_loss: 1.4158 - val_accuracy: 0.4110\n",
            "Epoch 252/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5871 - accuracy: 0.3849 - val_loss: 1.4871 - val_accuracy: 0.4384\n",
            "Epoch 253/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5728 - accuracy: 0.4330 - val_loss: 1.4238 - val_accuracy: 0.4247\n",
            "Epoch 254/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6334 - accuracy: 0.4192 - val_loss: 1.4473 - val_accuracy: 0.3836\n",
            "Epoch 255/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6013 - accuracy: 0.4192 - val_loss: 1.4341 - val_accuracy: 0.4247\n",
            "Epoch 256/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5996 - accuracy: 0.3918 - val_loss: 1.5103 - val_accuracy: 0.4247\n",
            "Epoch 257/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6116 - accuracy: 0.4158 - val_loss: 1.4582 - val_accuracy: 0.4658\n",
            "Epoch 258/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5838 - accuracy: 0.4261 - val_loss: 1.4767 - val_accuracy: 0.4384\n",
            "Epoch 259/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5886 - accuracy: 0.4021 - val_loss: 1.4449 - val_accuracy: 0.4521\n",
            "Epoch 260/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5471 - accuracy: 0.4124 - val_loss: 1.4246 - val_accuracy: 0.3973\n",
            "Epoch 261/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5903 - accuracy: 0.3952 - val_loss: 1.4241 - val_accuracy: 0.4247\n",
            "Epoch 262/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5858 - accuracy: 0.3986 - val_loss: 1.4262 - val_accuracy: 0.4384\n",
            "Epoch 263/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5683 - accuracy: 0.4055 - val_loss: 1.4385 - val_accuracy: 0.4384\n",
            "Epoch 264/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5704 - accuracy: 0.4158 - val_loss: 1.3964 - val_accuracy: 0.4110\n",
            "Epoch 265/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5628 - accuracy: 0.4261 - val_loss: 1.4013 - val_accuracy: 0.4521\n",
            "Epoch 266/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5460 - accuracy: 0.4399 - val_loss: 1.4087 - val_accuracy: 0.4521\n",
            "Epoch 267/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5633 - accuracy: 0.3986 - val_loss: 1.4162 - val_accuracy: 0.4521\n",
            "Epoch 268/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5411 - accuracy: 0.4261 - val_loss: 1.4312 - val_accuracy: 0.4384\n",
            "Epoch 269/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5780 - accuracy: 0.4261 - val_loss: 1.4028 - val_accuracy: 0.4384\n",
            "Epoch 270/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5425 - accuracy: 0.4021 - val_loss: 1.4066 - val_accuracy: 0.4247\n",
            "Epoch 271/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5222 - accuracy: 0.4364 - val_loss: 1.5809 - val_accuracy: 0.3836\n",
            "Epoch 272/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6618 - accuracy: 0.3780 - val_loss: 1.4260 - val_accuracy: 0.4110\n",
            "Epoch 273/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6362 - accuracy: 0.3711 - val_loss: 1.4639 - val_accuracy: 0.4384\n",
            "Epoch 274/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6125 - accuracy: 0.3952 - val_loss: 1.4880 - val_accuracy: 0.4247\n",
            "Epoch 275/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5576 - accuracy: 0.4089 - val_loss: 1.4526 - val_accuracy: 0.4384\n",
            "Epoch 276/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6301 - accuracy: 0.4158 - val_loss: 1.4345 - val_accuracy: 0.4384\n",
            "Epoch 277/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5623 - accuracy: 0.4330 - val_loss: 1.4397 - val_accuracy: 0.4384\n",
            "Epoch 278/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5536 - accuracy: 0.4330 - val_loss: 1.4325 - val_accuracy: 0.4384\n",
            "Epoch 279/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6104 - accuracy: 0.4055 - val_loss: 1.4823 - val_accuracy: 0.4384\n",
            "Epoch 280/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5956 - accuracy: 0.3746 - val_loss: 1.4761 - val_accuracy: 0.4384\n",
            "Epoch 281/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5880 - accuracy: 0.4261 - val_loss: 1.4070 - val_accuracy: 0.4384\n",
            "Epoch 282/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5988 - accuracy: 0.3711 - val_loss: 1.4372 - val_accuracy: 0.4658\n",
            "Epoch 283/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5437 - accuracy: 0.4192 - val_loss: 1.5251 - val_accuracy: 0.4110\n",
            "Epoch 284/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5628 - accuracy: 0.4124 - val_loss: 1.4068 - val_accuracy: 0.4658\n",
            "Epoch 285/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5538 - accuracy: 0.4124 - val_loss: 1.4058 - val_accuracy: 0.4384\n",
            "Epoch 286/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5576 - accuracy: 0.4433 - val_loss: 1.4304 - val_accuracy: 0.4521\n",
            "Epoch 287/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5381 - accuracy: 0.4261 - val_loss: 1.4627 - val_accuracy: 0.4247\n",
            "Epoch 288/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5773 - accuracy: 0.4124 - val_loss: 1.3875 - val_accuracy: 0.4384\n",
            "Epoch 289/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5588 - accuracy: 0.4261 - val_loss: 1.4000 - val_accuracy: 0.4658\n",
            "Epoch 290/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5998 - accuracy: 0.3986 - val_loss: 1.4824 - val_accuracy: 0.4110\n",
            "Epoch 291/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5223 - accuracy: 0.4261 - val_loss: 1.5353 - val_accuracy: 0.3973\n",
            "Epoch 292/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6120 - accuracy: 0.4261 - val_loss: 1.3959 - val_accuracy: 0.4384\n",
            "Epoch 293/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5954 - accuracy: 0.4227 - val_loss: 1.4192 - val_accuracy: 0.4658\n",
            "Epoch 294/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5634 - accuracy: 0.4296 - val_loss: 1.5257 - val_accuracy: 0.4247\n",
            "Epoch 295/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5372 - accuracy: 0.4433 - val_loss: 1.4238 - val_accuracy: 0.4658\n",
            "Epoch 296/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5483 - accuracy: 0.4399 - val_loss: 1.3994 - val_accuracy: 0.4384\n",
            "Epoch 297/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5689 - accuracy: 0.4227 - val_loss: 1.4482 - val_accuracy: 0.4247\n",
            "Epoch 298/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5350 - accuracy: 0.4433 - val_loss: 1.5410 - val_accuracy: 0.3973\n",
            "Epoch 299/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6311 - accuracy: 0.4158 - val_loss: 1.4608 - val_accuracy: 0.4247\n",
            "Epoch 300/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0148 - accuracy: 0.2680 - val_loss: 1.9967 - val_accuracy: 0.2466\n",
            "Epoch 301/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7931 - accuracy: 0.3196 - val_loss: 1.5967 - val_accuracy: 0.3288\n",
            "Epoch 302/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6718 - accuracy: 0.3643 - val_loss: 1.6305 - val_accuracy: 0.3836\n",
            "Epoch 303/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6287 - accuracy: 0.3986 - val_loss: 1.4896 - val_accuracy: 0.4521\n",
            "Epoch 304/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6154 - accuracy: 0.4399 - val_loss: 1.4781 - val_accuracy: 0.4110\n",
            "Epoch 305/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7089 - accuracy: 0.3505 - val_loss: 1.7087 - val_accuracy: 0.3288\n",
            "Epoch 306/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6514 - accuracy: 0.3746 - val_loss: 1.5372 - val_accuracy: 0.3425\n",
            "Epoch 307/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6168 - accuracy: 0.4021 - val_loss: 1.5750 - val_accuracy: 0.3973\n",
            "Epoch 308/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5953 - accuracy: 0.4192 - val_loss: 1.4433 - val_accuracy: 0.4384\n",
            "Epoch 309/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5521 - accuracy: 0.4330 - val_loss: 1.4536 - val_accuracy: 0.4521\n",
            "Epoch 310/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5439 - accuracy: 0.4467 - val_loss: 1.5132 - val_accuracy: 0.4110\n",
            "Epoch 311/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5950 - accuracy: 0.4330 - val_loss: 1.4403 - val_accuracy: 0.4521\n",
            "Epoch 312/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5920 - accuracy: 0.4227 - val_loss: 1.4280 - val_accuracy: 0.4521\n",
            "Epoch 313/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5509 - accuracy: 0.4399 - val_loss: 1.4167 - val_accuracy: 0.4795\n",
            "Epoch 314/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5704 - accuracy: 0.4192 - val_loss: 1.4930 - val_accuracy: 0.3973\n",
            "Epoch 315/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5472 - accuracy: 0.4261 - val_loss: 1.3878 - val_accuracy: 0.4795\n",
            "Epoch 316/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5497 - accuracy: 0.4399 - val_loss: 1.4822 - val_accuracy: 0.3973\n",
            "Epoch 317/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5681 - accuracy: 0.4124 - val_loss: 1.3800 - val_accuracy: 0.4658\n",
            "Epoch 318/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5304 - accuracy: 0.4502 - val_loss: 1.4087 - val_accuracy: 0.4384\n",
            "Epoch 319/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5414 - accuracy: 0.4399 - val_loss: 1.4194 - val_accuracy: 0.4384\n",
            "Epoch 320/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5475 - accuracy: 0.4296 - val_loss: 1.3869 - val_accuracy: 0.4521\n",
            "Epoch 321/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6043 - accuracy: 0.3986 - val_loss: 1.4578 - val_accuracy: 0.4247\n",
            "Epoch 322/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5450 - accuracy: 0.4227 - val_loss: 1.4952 - val_accuracy: 0.3973\n",
            "Epoch 323/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8172 - accuracy: 0.3024 - val_loss: 1.4217 - val_accuracy: 0.4521\n",
            "Epoch 324/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5732 - accuracy: 0.4055 - val_loss: 1.5212 - val_accuracy: 0.3973\n",
            "Epoch 325/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5756 - accuracy: 0.4124 - val_loss: 1.4286 - val_accuracy: 0.4521\n",
            "Epoch 326/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5585 - accuracy: 0.4261 - val_loss: 1.4170 - val_accuracy: 0.4795\n",
            "Epoch 327/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5705 - accuracy: 0.4158 - val_loss: 1.4560 - val_accuracy: 0.4384\n",
            "Epoch 328/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5348 - accuracy: 0.4399 - val_loss: 1.4723 - val_accuracy: 0.4247\n",
            "Epoch 329/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5391 - accuracy: 0.4502 - val_loss: 1.4141 - val_accuracy: 0.4795\n",
            "Epoch 330/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4821 - accuracy: 0.4708 - val_loss: 1.4007 - val_accuracy: 0.4795\n",
            "Epoch 331/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5495 - accuracy: 0.3918 - val_loss: 1.5552 - val_accuracy: 0.3973\n",
            "Epoch 332/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5986 - accuracy: 0.4192 - val_loss: 1.4082 - val_accuracy: 0.4658\n",
            "Epoch 333/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5134 - accuracy: 0.4502 - val_loss: 1.4135 - val_accuracy: 0.4521\n",
            "Epoch 334/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5194 - accuracy: 0.4467 - val_loss: 1.4871 - val_accuracy: 0.3973\n",
            "Epoch 335/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.6058 - accuracy: 0.3883 - val_loss: 1.4845 - val_accuracy: 0.4110\n",
            "Epoch 336/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5994 - accuracy: 0.4192 - val_loss: 1.4499 - val_accuracy: 0.4247\n",
            "Epoch 337/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5911 - accuracy: 0.4330 - val_loss: 1.4028 - val_accuracy: 0.4932\n",
            "Epoch 338/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5764 - accuracy: 0.4296 - val_loss: 1.5705 - val_accuracy: 0.3973\n",
            "Epoch 339/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6605 - accuracy: 0.3746 - val_loss: 1.4414 - val_accuracy: 0.3973\n",
            "Epoch 340/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6300 - accuracy: 0.4055 - val_loss: 1.5742 - val_accuracy: 0.3699\n",
            "Epoch 341/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5563 - accuracy: 0.3986 - val_loss: 1.5095 - val_accuracy: 0.3973\n",
            "Epoch 342/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5889 - accuracy: 0.3986 - val_loss: 1.3822 - val_accuracy: 0.4795\n",
            "Epoch 343/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5664 - accuracy: 0.4089 - val_loss: 1.4896 - val_accuracy: 0.4110\n",
            "Epoch 344/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5756 - accuracy: 0.4089 - val_loss: 1.4747 - val_accuracy: 0.4247\n",
            "Epoch 345/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5652 - accuracy: 0.4261 - val_loss: 1.3963 - val_accuracy: 0.4795\n",
            "Epoch 346/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5208 - accuracy: 0.4399 - val_loss: 1.5834 - val_accuracy: 0.3699\n",
            "Epoch 347/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5796 - accuracy: 0.4158 - val_loss: 1.3857 - val_accuracy: 0.4932\n",
            "Epoch 348/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5405 - accuracy: 0.4467 - val_loss: 1.4179 - val_accuracy: 0.4384\n",
            "Epoch 349/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5478 - accuracy: 0.4296 - val_loss: 1.4113 - val_accuracy: 0.4384\n",
            "Epoch 350/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5567 - accuracy: 0.4124 - val_loss: 1.5152 - val_accuracy: 0.3973\n",
            "Epoch 351/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5519 - accuracy: 0.4261 - val_loss: 1.3832 - val_accuracy: 0.4795\n",
            "Epoch 352/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4765 - accuracy: 0.4570 - val_loss: 1.4621 - val_accuracy: 0.4110\n",
            "Epoch 353/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5318 - accuracy: 0.4364 - val_loss: 1.4105 - val_accuracy: 0.4384\n",
            "Epoch 354/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5097 - accuracy: 0.4433 - val_loss: 1.4281 - val_accuracy: 0.4384\n",
            "Epoch 355/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5829 - accuracy: 0.4399 - val_loss: 1.3859 - val_accuracy: 0.4658\n",
            "Epoch 356/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4942 - accuracy: 0.4605 - val_loss: 1.3938 - val_accuracy: 0.4384\n",
            "Epoch 357/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5017 - accuracy: 0.4742 - val_loss: 1.5256 - val_accuracy: 0.3973\n",
            "Epoch 358/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4891 - accuracy: 0.4639 - val_loss: 1.3576 - val_accuracy: 0.4932\n",
            "Epoch 359/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5369 - accuracy: 0.4570 - val_loss: 1.4455 - val_accuracy: 0.4384\n",
            "Epoch 360/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5066 - accuracy: 0.4536 - val_loss: 1.3684 - val_accuracy: 0.4932\n",
            "Epoch 361/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5835 - accuracy: 0.4330 - val_loss: 1.5085 - val_accuracy: 0.3973\n",
            "Epoch 362/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5544 - accuracy: 0.4467 - val_loss: 1.4219 - val_accuracy: 0.4384\n",
            "Epoch 363/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6366 - accuracy: 0.4055 - val_loss: 1.3781 - val_accuracy: 0.4521\n",
            "Epoch 364/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5624 - accuracy: 0.4089 - val_loss: 1.5660 - val_accuracy: 0.3973\n",
            "Epoch 365/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5097 - accuracy: 0.4433 - val_loss: 1.3956 - val_accuracy: 0.4384\n",
            "Epoch 366/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5661 - accuracy: 0.4399 - val_loss: 1.3681 - val_accuracy: 0.4932\n",
            "Epoch 367/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5038 - accuracy: 0.4639 - val_loss: 1.4376 - val_accuracy: 0.4384\n",
            "Epoch 368/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5123 - accuracy: 0.4502 - val_loss: 1.4764 - val_accuracy: 0.4247\n",
            "Epoch 369/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5281 - accuracy: 0.4399 - val_loss: 1.4190 - val_accuracy: 0.4384\n",
            "Epoch 370/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5502 - accuracy: 0.4399 - val_loss: 1.4144 - val_accuracy: 0.4384\n",
            "Epoch 371/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5833 - accuracy: 0.4261 - val_loss: 1.3895 - val_accuracy: 0.4795\n",
            "Epoch 372/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5782 - accuracy: 0.4296 - val_loss: 1.6534 - val_accuracy: 0.3699\n",
            "Epoch 373/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5901 - accuracy: 0.4192 - val_loss: 1.4188 - val_accuracy: 0.4384\n",
            "Epoch 374/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5275 - accuracy: 0.4364 - val_loss: 1.3832 - val_accuracy: 0.4795\n",
            "Epoch 375/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5333 - accuracy: 0.4605 - val_loss: 1.4660 - val_accuracy: 0.4247\n",
            "Epoch 376/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5386 - accuracy: 0.4124 - val_loss: 1.4789 - val_accuracy: 0.4110\n",
            "Epoch 377/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5751 - accuracy: 0.4364 - val_loss: 1.5597 - val_accuracy: 0.3836\n",
            "Epoch 378/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5667 - accuracy: 0.4330 - val_loss: 1.3558 - val_accuracy: 0.4932\n",
            "Epoch 379/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5296 - accuracy: 0.4433 - val_loss: 1.4757 - val_accuracy: 0.4247\n",
            "Epoch 380/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5420 - accuracy: 0.4433 - val_loss: 1.4049 - val_accuracy: 0.4384\n",
            "Epoch 381/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5140 - accuracy: 0.4433 - val_loss: 1.4853 - val_accuracy: 0.4110\n",
            "Epoch 382/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4992 - accuracy: 0.4364 - val_loss: 1.4220 - val_accuracy: 0.4521\n",
            "Epoch 383/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5048 - accuracy: 0.4433 - val_loss: 1.3756 - val_accuracy: 0.4795\n",
            "Epoch 384/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5259 - accuracy: 0.4364 - val_loss: 1.4375 - val_accuracy: 0.4384\n",
            "Epoch 385/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5057 - accuracy: 0.4570 - val_loss: 1.4140 - val_accuracy: 0.4384\n",
            "Epoch 386/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4870 - accuracy: 0.4674 - val_loss: 1.5340 - val_accuracy: 0.3973\n",
            "Epoch 387/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5166 - accuracy: 0.4399 - val_loss: 1.3938 - val_accuracy: 0.4521\n",
            "Epoch 388/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5016 - accuracy: 0.4536 - val_loss: 1.3452 - val_accuracy: 0.4932\n",
            "Epoch 389/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5137 - accuracy: 0.4364 - val_loss: 1.5538 - val_accuracy: 0.3973\n",
            "Epoch 390/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5607 - accuracy: 0.4330 - val_loss: 1.3763 - val_accuracy: 0.4521\n",
            "Epoch 391/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5033 - accuracy: 0.4570 - val_loss: 1.4139 - val_accuracy: 0.4384\n",
            "Epoch 392/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5080 - accuracy: 0.4674 - val_loss: 1.4564 - val_accuracy: 0.4247\n",
            "Epoch 393/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4789 - accuracy: 0.4502 - val_loss: 1.4121 - val_accuracy: 0.4384\n",
            "Epoch 394/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4937 - accuracy: 0.4742 - val_loss: 1.5024 - val_accuracy: 0.3973\n",
            "Epoch 395/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5313 - accuracy: 0.4261 - val_loss: 1.3897 - val_accuracy: 0.4521\n",
            "Epoch 396/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5337 - accuracy: 0.4502 - val_loss: 1.3516 - val_accuracy: 0.4795\n",
            "Epoch 397/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5697 - accuracy: 0.4192 - val_loss: 1.4906 - val_accuracy: 0.4247\n",
            "Epoch 398/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5116 - accuracy: 0.4261 - val_loss: 1.4720 - val_accuracy: 0.4247\n",
            "Epoch 399/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5326 - accuracy: 0.4364 - val_loss: 1.4237 - val_accuracy: 0.4384\n",
            "Epoch 400/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5466 - accuracy: 0.4227 - val_loss: 1.3719 - val_accuracy: 0.4658\n",
            "Epoch 401/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5892 - accuracy: 0.4433 - val_loss: 1.3730 - val_accuracy: 0.4795\n",
            "Epoch 402/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.5297 - accuracy: 0.4364 - val_loss: 1.4102 - val_accuracy: 0.4384\n",
            "Epoch 403/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5686 - accuracy: 0.4055 - val_loss: 1.6397 - val_accuracy: 0.3699\n",
            "Epoch 404/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5205 - accuracy: 0.4399 - val_loss: 1.4452 - val_accuracy: 0.4384\n",
            "Epoch 405/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5251 - accuracy: 0.4055 - val_loss: 1.4065 - val_accuracy: 0.4384\n",
            "Epoch 406/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5241 - accuracy: 0.4777 - val_loss: 1.3574 - val_accuracy: 0.4795\n",
            "Epoch 407/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4594 - accuracy: 0.4399 - val_loss: 1.4238 - val_accuracy: 0.4384\n",
            "Epoch 408/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4598 - accuracy: 0.4674 - val_loss: 1.3359 - val_accuracy: 0.4795\n",
            "Epoch 409/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4905 - accuracy: 0.4399 - val_loss: 1.4189 - val_accuracy: 0.4384\n",
            "Epoch 410/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5052 - accuracy: 0.4399 - val_loss: 1.3741 - val_accuracy: 0.4521\n",
            "Epoch 411/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5299 - accuracy: 0.4364 - val_loss: 1.3198 - val_accuracy: 0.4932\n",
            "Epoch 412/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5605 - accuracy: 0.4330 - val_loss: 1.3427 - val_accuracy: 0.4932\n",
            "Epoch 413/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5795 - accuracy: 0.4055 - val_loss: 1.5585 - val_accuracy: 0.3973\n",
            "Epoch 414/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5800 - accuracy: 0.4124 - val_loss: 1.4967 - val_accuracy: 0.4110\n",
            "Epoch 415/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4736 - accuracy: 0.4570 - val_loss: 1.4171 - val_accuracy: 0.4384\n",
            "Epoch 416/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5564 - accuracy: 0.4330 - val_loss: 1.4102 - val_accuracy: 0.4384\n",
            "Epoch 417/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5298 - accuracy: 0.4467 - val_loss: 1.5698 - val_accuracy: 0.3973\n",
            "Epoch 418/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5238 - accuracy: 0.4399 - val_loss: 1.3789 - val_accuracy: 0.4658\n",
            "Epoch 419/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4930 - accuracy: 0.4467 - val_loss: 1.3761 - val_accuracy: 0.4658\n",
            "Epoch 420/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4707 - accuracy: 0.4777 - val_loss: 1.5258 - val_accuracy: 0.3973\n",
            "Epoch 421/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5025 - accuracy: 0.4639 - val_loss: 1.3804 - val_accuracy: 0.4658\n",
            "Epoch 422/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5618 - accuracy: 0.4296 - val_loss: 1.3394 - val_accuracy: 0.4932\n",
            "Epoch 423/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5480 - accuracy: 0.4089 - val_loss: 1.4167 - val_accuracy: 0.4521\n",
            "Epoch 424/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5272 - accuracy: 0.4399 - val_loss: 1.4882 - val_accuracy: 0.4384\n",
            "Epoch 425/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4625 - accuracy: 0.4777 - val_loss: 1.4601 - val_accuracy: 0.4384\n",
            "Epoch 426/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4676 - accuracy: 0.4570 - val_loss: 1.3417 - val_accuracy: 0.4795\n",
            "Epoch 427/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4946 - accuracy: 0.4261 - val_loss: 1.5530 - val_accuracy: 0.3973\n",
            "Epoch 428/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5280 - accuracy: 0.4467 - val_loss: 1.5396 - val_accuracy: 0.4110\n",
            "Epoch 429/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4847 - accuracy: 0.4777 - val_loss: 1.4440 - val_accuracy: 0.4384\n",
            "Epoch 430/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5714 - accuracy: 0.4055 - val_loss: 1.3332 - val_accuracy: 0.4932\n",
            "Epoch 431/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5351 - accuracy: 0.4296 - val_loss: 1.3907 - val_accuracy: 0.4521\n",
            "Epoch 432/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5067 - accuracy: 0.4330 - val_loss: 1.4505 - val_accuracy: 0.4384\n",
            "Epoch 433/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4954 - accuracy: 0.4605 - val_loss: 1.4577 - val_accuracy: 0.4247\n",
            "Epoch 434/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5157 - accuracy: 0.4330 - val_loss: 1.3746 - val_accuracy: 0.4384\n",
            "Epoch 435/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5413 - accuracy: 0.4536 - val_loss: 1.6445 - val_accuracy: 0.3699\n",
            "Epoch 436/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5594 - accuracy: 0.4261 - val_loss: 1.5570 - val_accuracy: 0.3973\n",
            "Epoch 437/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5807 - accuracy: 0.4089 - val_loss: 1.3478 - val_accuracy: 0.4932\n",
            "Epoch 438/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6106 - accuracy: 0.4158 - val_loss: 1.3751 - val_accuracy: 0.4658\n",
            "Epoch 439/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5567 - accuracy: 0.4296 - val_loss: 1.5701 - val_accuracy: 0.3973\n",
            "Epoch 440/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5008 - accuracy: 0.4364 - val_loss: 1.4740 - val_accuracy: 0.4384\n",
            "Epoch 441/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4979 - accuracy: 0.4502 - val_loss: 1.5054 - val_accuracy: 0.4384\n",
            "Epoch 442/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5225 - accuracy: 0.4330 - val_loss: 1.4062 - val_accuracy: 0.4658\n",
            "Epoch 443/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5528 - accuracy: 0.4296 - val_loss: 1.3995 - val_accuracy: 0.4795\n",
            "Epoch 444/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5471 - accuracy: 0.4227 - val_loss: 1.6560 - val_accuracy: 0.3836\n",
            "Epoch 445/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5683 - accuracy: 0.4055 - val_loss: 1.4332 - val_accuracy: 0.4384\n",
            "Epoch 446/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4881 - accuracy: 0.4399 - val_loss: 1.3669 - val_accuracy: 0.4795\n",
            "Epoch 447/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4832 - accuracy: 0.4330 - val_loss: 1.4024 - val_accuracy: 0.4384\n",
            "Epoch 448/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4793 - accuracy: 0.4433 - val_loss: 1.4831 - val_accuracy: 0.4110\n",
            "Epoch 449/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5082 - accuracy: 0.4502 - val_loss: 1.3615 - val_accuracy: 0.4658\n",
            "Epoch 450/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4756 - accuracy: 0.4742 - val_loss: 1.4669 - val_accuracy: 0.4384\n",
            "Epoch 451/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4700 - accuracy: 0.4674 - val_loss: 1.4761 - val_accuracy: 0.4384\n",
            "Epoch 452/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4996 - accuracy: 0.4536 - val_loss: 1.4399 - val_accuracy: 0.4384\n",
            "Epoch 453/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5200 - accuracy: 0.4467 - val_loss: 1.4536 - val_accuracy: 0.4384\n",
            "Epoch 454/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4557 - accuracy: 0.4570 - val_loss: 1.3963 - val_accuracy: 0.4521\n",
            "Epoch 455/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5204 - accuracy: 0.4433 - val_loss: 1.5133 - val_accuracy: 0.4110\n",
            "Epoch 456/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5122 - accuracy: 0.4467 - val_loss: 1.6028 - val_accuracy: 0.3973\n",
            "Epoch 457/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5865 - accuracy: 0.4089 - val_loss: 1.3701 - val_accuracy: 0.4384\n",
            "Epoch 458/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5117 - accuracy: 0.4399 - val_loss: 1.3867 - val_accuracy: 0.4521\n",
            "Epoch 459/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5402 - accuracy: 0.4433 - val_loss: 1.5448 - val_accuracy: 0.4110\n",
            "Epoch 460/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5197 - accuracy: 0.4467 - val_loss: 1.4551 - val_accuracy: 0.4384\n",
            "Epoch 461/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4750 - accuracy: 0.4502 - val_loss: 1.3233 - val_accuracy: 0.4932\n",
            "Epoch 462/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5058 - accuracy: 0.4674 - val_loss: 1.4299 - val_accuracy: 0.4384\n",
            "Epoch 463/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4813 - accuracy: 0.4433 - val_loss: 1.4207 - val_accuracy: 0.4384\n",
            "Epoch 464/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4437 - accuracy: 0.4742 - val_loss: 1.3696 - val_accuracy: 0.4795\n",
            "Epoch 465/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4522 - accuracy: 0.4674 - val_loss: 1.3282 - val_accuracy: 0.4932\n",
            "Epoch 466/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5264 - accuracy: 0.4502 - val_loss: 1.4002 - val_accuracy: 0.4384\n",
            "Epoch 467/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4473 - accuracy: 0.4708 - val_loss: 1.4180 - val_accuracy: 0.4384\n",
            "Epoch 468/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5068 - accuracy: 0.4261 - val_loss: 1.4842 - val_accuracy: 0.4384\n",
            "Epoch 469/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4915 - accuracy: 0.4639 - val_loss: 1.7290 - val_accuracy: 0.3562\n",
            "Epoch 470/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5420 - accuracy: 0.4433 - val_loss: 1.3611 - val_accuracy: 0.4795\n",
            "Epoch 471/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4660 - accuracy: 0.4811 - val_loss: 1.4506 - val_accuracy: 0.4384\n",
            "Epoch 472/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5007 - accuracy: 0.4777 - val_loss: 1.4595 - val_accuracy: 0.4384\n",
            "Epoch 473/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5318 - accuracy: 0.4399 - val_loss: 1.3256 - val_accuracy: 0.4932\n",
            "Epoch 474/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5731 - accuracy: 0.4261 - val_loss: 1.3735 - val_accuracy: 0.4795\n",
            "Epoch 475/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4726 - accuracy: 0.4845 - val_loss: 1.5279 - val_accuracy: 0.4110\n",
            "Epoch 476/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4789 - accuracy: 0.4605 - val_loss: 1.3638 - val_accuracy: 0.4795\n",
            "Epoch 477/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5268 - accuracy: 0.4330 - val_loss: 1.3368 - val_accuracy: 0.4932\n",
            "Epoch 478/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4921 - accuracy: 0.4433 - val_loss: 1.5036 - val_accuracy: 0.4110\n",
            "Epoch 479/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5013 - accuracy: 0.4467 - val_loss: 1.4901 - val_accuracy: 0.4384\n",
            "Epoch 480/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4925 - accuracy: 0.4742 - val_loss: 1.3440 - val_accuracy: 0.4932\n",
            "Epoch 481/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5241 - accuracy: 0.4605 - val_loss: 1.3341 - val_accuracy: 0.4932\n",
            "Epoch 482/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5225 - accuracy: 0.4433 - val_loss: 1.5460 - val_accuracy: 0.3973\n",
            "Epoch 483/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4812 - accuracy: 0.4674 - val_loss: 1.4087 - val_accuracy: 0.4384\n",
            "Epoch 484/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4392 - accuracy: 0.4639 - val_loss: 1.4700 - val_accuracy: 0.4110\n",
            "Epoch 485/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4846 - accuracy: 0.4777 - val_loss: 1.5394 - val_accuracy: 0.4110\n",
            "Epoch 486/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4410 - accuracy: 0.4708 - val_loss: 1.3590 - val_accuracy: 0.4521\n",
            "Epoch 487/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4709 - accuracy: 0.4742 - val_loss: 1.3864 - val_accuracy: 0.4521\n",
            "Epoch 488/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4674 - accuracy: 0.4570 - val_loss: 1.5084 - val_accuracy: 0.4110\n",
            "Epoch 489/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4673 - accuracy: 0.4536 - val_loss: 1.3717 - val_accuracy: 0.4521\n",
            "Epoch 490/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4624 - accuracy: 0.4742 - val_loss: 1.3655 - val_accuracy: 0.4658\n",
            "Epoch 491/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4682 - accuracy: 0.4811 - val_loss: 1.4850 - val_accuracy: 0.4110\n",
            "Epoch 492/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4223 - accuracy: 0.4708 - val_loss: 1.4010 - val_accuracy: 0.4384\n",
            "Epoch 493/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4609 - accuracy: 0.4433 - val_loss: 1.3048 - val_accuracy: 0.5068\n",
            "Epoch 494/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4751 - accuracy: 0.4605 - val_loss: 1.2860 - val_accuracy: 0.4932\n",
            "Epoch 495/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.5952 - accuracy: 0.4158 - val_loss: 1.5932 - val_accuracy: 0.4110\n",
            "Epoch 496/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5145 - accuracy: 0.4330 - val_loss: 1.5584 - val_accuracy: 0.3973\n",
            "Epoch 497/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5048 - accuracy: 0.4364 - val_loss: 1.3277 - val_accuracy: 0.4795\n",
            "Epoch 498/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4955 - accuracy: 0.4742 - val_loss: 1.2930 - val_accuracy: 0.4932\n",
            "Epoch 499/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5838 - accuracy: 0.4364 - val_loss: 1.5844 - val_accuracy: 0.3973\n",
            "Epoch 500/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4652 - accuracy: 0.4845 - val_loss: 1.5468 - val_accuracy: 0.4110\n",
            "Epoch 501/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5012 - accuracy: 0.4399 - val_loss: 1.5196 - val_accuracy: 0.4110\n",
            "Epoch 502/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0206 - accuracy: 0.2646 - val_loss: 2.0544 - val_accuracy: 0.2466\n",
            "Epoch 503/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 2.0117 - accuracy: 0.2199 - val_loss: 1.9519 - val_accuracy: 0.2466\n",
            "Epoch 504/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9291 - accuracy: 0.2199 - val_loss: 1.9164 - val_accuracy: 0.2466\n",
            "Epoch 505/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9163 - accuracy: 0.2199 - val_loss: 1.9061 - val_accuracy: 0.2466\n",
            "Epoch 506/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8933 - accuracy: 0.2199 - val_loss: 1.8986 - val_accuracy: 0.2466\n",
            "Epoch 507/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8940 - accuracy: 0.2199 - val_loss: 1.8952 - val_accuracy: 0.2466\n",
            "Epoch 508/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8869 - accuracy: 0.2199 - val_loss: 1.8912 - val_accuracy: 0.2466\n",
            "Epoch 509/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8910 - accuracy: 0.2199 - val_loss: 1.8901 - val_accuracy: 0.2466\n",
            "Epoch 510/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8831 - accuracy: 0.2199 - val_loss: 1.8890 - val_accuracy: 0.2466\n",
            "Epoch 511/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8827 - accuracy: 0.2199 - val_loss: 1.8880 - val_accuracy: 0.2466\n",
            "Epoch 512/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8788 - accuracy: 0.2199 - val_loss: 1.8882 - val_accuracy: 0.2466\n",
            "Epoch 513/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8798 - accuracy: 0.2199 - val_loss: 1.8876 - val_accuracy: 0.2466\n",
            "Epoch 514/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8863 - accuracy: 0.2165 - val_loss: 1.8876 - val_accuracy: 0.2466\n",
            "Epoch 515/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8814 - accuracy: 0.2199 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 516/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8820 - accuracy: 0.2165 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 517/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8821 - accuracy: 0.2199 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 518/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8836 - accuracy: 0.2268 - val_loss: 1.8860 - val_accuracy: 0.2466\n",
            "Epoch 519/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8761 - accuracy: 0.2199 - val_loss: 1.8858 - val_accuracy: 0.2466\n",
            "Epoch 520/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8842 - accuracy: 0.2131 - val_loss: 1.8864 - val_accuracy: 0.2466\n",
            "Epoch 521/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8757 - accuracy: 0.2234 - val_loss: 1.8862 - val_accuracy: 0.2466\n",
            "Epoch 522/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8820 - accuracy: 0.2165 - val_loss: 1.8868 - val_accuracy: 0.2466\n",
            "Epoch 523/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8814 - accuracy: 0.2234 - val_loss: 1.8868 - val_accuracy: 0.2466\n",
            "Epoch 524/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8776 - accuracy: 0.2165 - val_loss: 1.8877 - val_accuracy: 0.2466\n",
            "Epoch 525/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8840 - accuracy: 0.2234 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 526/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8766 - accuracy: 0.2440 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 527/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8779 - accuracy: 0.2131 - val_loss: 1.8889 - val_accuracy: 0.2466\n",
            "Epoch 528/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8718 - accuracy: 0.2371 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 529/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8794 - accuracy: 0.2062 - val_loss: 1.8900 - val_accuracy: 0.2466\n",
            "Epoch 530/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8810 - accuracy: 0.2165 - val_loss: 1.8910 - val_accuracy: 0.2466\n",
            "Epoch 531/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8825 - accuracy: 0.2062 - val_loss: 1.8904 - val_accuracy: 0.2466\n",
            "Epoch 532/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8752 - accuracy: 0.2199 - val_loss: 1.8892 - val_accuracy: 0.2466\n",
            "Epoch 533/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8808 - accuracy: 0.2096 - val_loss: 1.8893 - val_accuracy: 0.2466\n",
            "Epoch 534/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8763 - accuracy: 0.2234 - val_loss: 1.8895 - val_accuracy: 0.2466\n",
            "Epoch 535/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8848 - accuracy: 0.2096 - val_loss: 1.8899 - val_accuracy: 0.2466\n",
            "Epoch 536/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8718 - accuracy: 0.2234 - val_loss: 1.8905 - val_accuracy: 0.2466\n",
            "Epoch 537/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8814 - accuracy: 0.1821 - val_loss: 1.8908 - val_accuracy: 0.2466\n",
            "Epoch 538/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8781 - accuracy: 0.2062 - val_loss: 1.8912 - val_accuracy: 0.2466\n",
            "Epoch 539/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8771 - accuracy: 0.2268 - val_loss: 1.8913 - val_accuracy: 0.2466\n",
            "Epoch 540/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8826 - accuracy: 0.2165 - val_loss: 1.8918 - val_accuracy: 0.2466\n",
            "Epoch 541/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8745 - accuracy: 0.2337 - val_loss: 1.8921 - val_accuracy: 0.2466\n",
            "Epoch 542/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8751 - accuracy: 0.2234 - val_loss: 1.8906 - val_accuracy: 0.2466\n",
            "Epoch 543/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8718 - accuracy: 0.2199 - val_loss: 1.8895 - val_accuracy: 0.2466\n",
            "Epoch 544/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8790 - accuracy: 0.2199 - val_loss: 1.8888 - val_accuracy: 0.2466\n",
            "Epoch 545/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8749 - accuracy: 0.2062 - val_loss: 1.8890 - val_accuracy: 0.2466\n",
            "Epoch 546/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8755 - accuracy: 0.2337 - val_loss: 1.8879 - val_accuracy: 0.2466\n",
            "Epoch 547/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8735 - accuracy: 0.2131 - val_loss: 1.8873 - val_accuracy: 0.2466\n",
            "Epoch 548/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8824 - accuracy: 0.1856 - val_loss: 1.8866 - val_accuracy: 0.2466\n",
            "Epoch 549/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8751 - accuracy: 0.2199 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 550/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8822 - accuracy: 0.1959 - val_loss: 1.8859 - val_accuracy: 0.2466\n",
            "Epoch 551/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8775 - accuracy: 0.2268 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 552/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8757 - accuracy: 0.2062 - val_loss: 1.8884 - val_accuracy: 0.2466\n",
            "Epoch 553/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8753 - accuracy: 0.1959 - val_loss: 1.8891 - val_accuracy: 0.2466\n",
            "Epoch 554/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8749 - accuracy: 0.2165 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 555/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8732 - accuracy: 0.2268 - val_loss: 1.8886 - val_accuracy: 0.2466\n",
            "Epoch 556/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8791 - accuracy: 0.2096 - val_loss: 1.8904 - val_accuracy: 0.2466\n",
            "Epoch 557/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8748 - accuracy: 0.2096 - val_loss: 1.8921 - val_accuracy: 0.2466\n",
            "Epoch 558/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8697 - accuracy: 0.2096 - val_loss: 1.8920 - val_accuracy: 0.2466\n",
            "Epoch 559/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8828 - accuracy: 0.2302 - val_loss: 1.8909 - val_accuracy: 0.2466\n",
            "Epoch 560/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8765 - accuracy: 0.2337 - val_loss: 1.8897 - val_accuracy: 0.2466\n",
            "Epoch 561/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8740 - accuracy: 0.2131 - val_loss: 1.8891 - val_accuracy: 0.2466\n",
            "Epoch 562/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8820 - accuracy: 0.2199 - val_loss: 1.8885 - val_accuracy: 0.2466\n",
            "Epoch 563/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8764 - accuracy: 0.2234 - val_loss: 1.8852 - val_accuracy: 0.2466\n",
            "Epoch 564/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8766 - accuracy: 0.2234 - val_loss: 1.8840 - val_accuracy: 0.2466\n",
            "Epoch 565/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8761 - accuracy: 0.2131 - val_loss: 1.8846 - val_accuracy: 0.2466\n",
            "Epoch 566/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8768 - accuracy: 0.2131 - val_loss: 1.8864 - val_accuracy: 0.2466\n",
            "Epoch 567/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8738 - accuracy: 0.2096 - val_loss: 1.8868 - val_accuracy: 0.2466\n",
            "Epoch 568/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8737 - accuracy: 0.2062 - val_loss: 1.8868 - val_accuracy: 0.2466\n",
            "Epoch 569/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8775 - accuracy: 0.2199 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 570/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8731 - accuracy: 0.2131 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 571/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8786 - accuracy: 0.2062 - val_loss: 1.8867 - val_accuracy: 0.2466\n",
            "Epoch 572/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8763 - accuracy: 0.2062 - val_loss: 1.8866 - val_accuracy: 0.2466\n",
            "Epoch 573/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8725 - accuracy: 0.2165 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 574/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8753 - accuracy: 0.2131 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 575/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8753 - accuracy: 0.2096 - val_loss: 1.8882 - val_accuracy: 0.2466\n",
            "Epoch 576/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8719 - accuracy: 0.2199 - val_loss: 1.8888 - val_accuracy: 0.2466\n",
            "Epoch 577/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8712 - accuracy: 0.2027 - val_loss: 1.8886 - val_accuracy: 0.2466\n",
            "Epoch 578/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8706 - accuracy: 0.2165 - val_loss: 1.8904 - val_accuracy: 0.2466\n",
            "Epoch 579/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8793 - accuracy: 0.2199 - val_loss: 1.8907 - val_accuracy: 0.2466\n",
            "Epoch 580/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8789 - accuracy: 0.2165 - val_loss: 1.8909 - val_accuracy: 0.2466\n",
            "Epoch 581/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8749 - accuracy: 0.2268 - val_loss: 1.8908 - val_accuracy: 0.2466\n",
            "Epoch 582/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8729 - accuracy: 0.2234 - val_loss: 1.8890 - val_accuracy: 0.2466\n",
            "Epoch 583/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8751 - accuracy: 0.2405 - val_loss: 1.8880 - val_accuracy: 0.2466\n",
            "Epoch 584/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8748 - accuracy: 0.2199 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 585/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8749 - accuracy: 0.2096 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 586/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8723 - accuracy: 0.2268 - val_loss: 1.8854 - val_accuracy: 0.2466\n",
            "Epoch 587/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.8779 - accuracy: 0.2096 - val_loss: 1.8849 - val_accuracy: 0.2466\n",
            "Epoch 588/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8742 - accuracy: 0.2096 - val_loss: 1.8849 - val_accuracy: 0.2466\n",
            "Epoch 589/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8833 - accuracy: 0.2096 - val_loss: 1.8853 - val_accuracy: 0.2466\n",
            "Epoch 590/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8767 - accuracy: 0.2234 - val_loss: 1.8864 - val_accuracy: 0.2466\n",
            "Epoch 591/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8766 - accuracy: 0.2199 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 592/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8827 - accuracy: 0.2165 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 593/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8801 - accuracy: 0.2302 - val_loss: 1.8861 - val_accuracy: 0.2466\n",
            "Epoch 594/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8759 - accuracy: 0.2027 - val_loss: 1.8869 - val_accuracy: 0.2466\n",
            "Epoch 595/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8761 - accuracy: 0.2302 - val_loss: 1.8886 - val_accuracy: 0.2466\n",
            "Epoch 596/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8778 - accuracy: 0.1959 - val_loss: 1.8883 - val_accuracy: 0.2466\n",
            "Epoch 597/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8794 - accuracy: 0.2234 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 598/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8760 - accuracy: 0.2165 - val_loss: 1.8860 - val_accuracy: 0.2466\n",
            "Epoch 599/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8710 - accuracy: 0.2199 - val_loss: 1.8860 - val_accuracy: 0.2466\n",
            "Epoch 600/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8741 - accuracy: 0.2165 - val_loss: 1.8857 - val_accuracy: 0.2466\n",
            "Epoch 601/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8783 - accuracy: 0.2096 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 602/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8764 - accuracy: 0.2165 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 603/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8799 - accuracy: 0.2234 - val_loss: 1.8862 - val_accuracy: 0.2466\n",
            "Epoch 604/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8743 - accuracy: 0.2199 - val_loss: 1.8846 - val_accuracy: 0.2466\n",
            "Epoch 605/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8774 - accuracy: 0.2131 - val_loss: 1.8837 - val_accuracy: 0.2466\n",
            "Epoch 606/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8739 - accuracy: 0.2234 - val_loss: 1.8833 - val_accuracy: 0.2466\n",
            "Epoch 607/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8747 - accuracy: 0.2234 - val_loss: 1.8836 - val_accuracy: 0.2466\n",
            "Epoch 608/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8760 - accuracy: 0.2234 - val_loss: 1.8832 - val_accuracy: 0.2466\n",
            "Epoch 609/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8755 - accuracy: 0.2268 - val_loss: 1.8834 - val_accuracy: 0.2466\n",
            "Epoch 610/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8788 - accuracy: 0.2131 - val_loss: 1.8835 - val_accuracy: 0.2466\n",
            "Epoch 611/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8778 - accuracy: 0.2131 - val_loss: 1.8847 - val_accuracy: 0.2466\n",
            "Epoch 612/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8704 - accuracy: 0.2302 - val_loss: 1.8862 - val_accuracy: 0.2466\n",
            "Epoch 613/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8840 - accuracy: 0.2302 - val_loss: 1.8876 - val_accuracy: 0.2466\n",
            "Epoch 614/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8759 - accuracy: 0.1959 - val_loss: 1.8890 - val_accuracy: 0.2466\n",
            "Epoch 615/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8786 - accuracy: 0.2165 - val_loss: 1.8905 - val_accuracy: 0.2466\n",
            "Epoch 616/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8831 - accuracy: 0.1993 - val_loss: 1.8909 - val_accuracy: 0.2466\n",
            "Epoch 617/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8793 - accuracy: 0.2165 - val_loss: 1.8909 - val_accuracy: 0.2466\n",
            "Epoch 618/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8731 - accuracy: 0.2509 - val_loss: 1.8903 - val_accuracy: 0.2466\n",
            "Epoch 619/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8749 - accuracy: 0.1890 - val_loss: 1.8889 - val_accuracy: 0.2466\n",
            "Epoch 620/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8772 - accuracy: 0.2234 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 621/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8678 - accuracy: 0.2337 - val_loss: 1.8884 - val_accuracy: 0.2466\n",
            "Epoch 622/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8793 - accuracy: 0.1993 - val_loss: 1.8879 - val_accuracy: 0.2466\n",
            "Epoch 623/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8796 - accuracy: 0.2062 - val_loss: 1.8864 - val_accuracy: 0.2466\n",
            "Epoch 624/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8814 - accuracy: 0.2096 - val_loss: 1.8856 - val_accuracy: 0.2466\n",
            "Epoch 625/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8726 - accuracy: 0.2165 - val_loss: 1.8847 - val_accuracy: 0.2466\n",
            "Epoch 626/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8726 - accuracy: 0.2337 - val_loss: 1.8839 - val_accuracy: 0.2466\n",
            "Epoch 627/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8805 - accuracy: 0.2234 - val_loss: 1.8834 - val_accuracy: 0.2466\n",
            "Epoch 628/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8779 - accuracy: 0.2268 - val_loss: 1.8827 - val_accuracy: 0.2466\n",
            "Epoch 629/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8722 - accuracy: 0.2096 - val_loss: 1.8826 - val_accuracy: 0.2466\n",
            "Epoch 630/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8711 - accuracy: 0.2199 - val_loss: 1.8831 - val_accuracy: 0.2466\n",
            "Epoch 631/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8725 - accuracy: 0.2199 - val_loss: 1.8835 - val_accuracy: 0.2466\n",
            "Epoch 632/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8728 - accuracy: 0.2268 - val_loss: 1.8835 - val_accuracy: 0.2466\n",
            "Epoch 633/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8751 - accuracy: 0.2234 - val_loss: 1.8829 - val_accuracy: 0.2466\n",
            "Epoch 634/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8707 - accuracy: 0.2096 - val_loss: 1.8823 - val_accuracy: 0.2466\n",
            "Epoch 635/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8733 - accuracy: 0.2131 - val_loss: 1.8824 - val_accuracy: 0.2466\n",
            "Epoch 636/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8800 - accuracy: 0.2302 - val_loss: 1.8839 - val_accuracy: 0.2466\n",
            "Epoch 637/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8751 - accuracy: 0.2131 - val_loss: 1.8864 - val_accuracy: 0.2466\n",
            "Epoch 638/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8787 - accuracy: 0.2027 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 639/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8731 - accuracy: 0.2199 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 640/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8699 - accuracy: 0.2096 - val_loss: 1.8861 - val_accuracy: 0.2466\n",
            "Epoch 641/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8780 - accuracy: 0.2199 - val_loss: 1.8850 - val_accuracy: 0.2466\n",
            "Epoch 642/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8708 - accuracy: 0.2199 - val_loss: 1.8848 - val_accuracy: 0.2466\n",
            "Epoch 643/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8799 - accuracy: 0.2131 - val_loss: 1.8856 - val_accuracy: 0.2466\n",
            "Epoch 644/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8745 - accuracy: 0.1993 - val_loss: 1.8857 - val_accuracy: 0.2466\n",
            "Epoch 645/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8739 - accuracy: 0.2199 - val_loss: 1.8845 - val_accuracy: 0.2466\n",
            "Epoch 646/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8746 - accuracy: 0.2096 - val_loss: 1.8840 - val_accuracy: 0.2466\n",
            "Epoch 647/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8772 - accuracy: 0.2268 - val_loss: 1.8832 - val_accuracy: 0.2466\n",
            "Epoch 648/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8733 - accuracy: 0.1993 - val_loss: 1.8833 - val_accuracy: 0.2466\n",
            "Epoch 649/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8751 - accuracy: 0.2027 - val_loss: 1.8834 - val_accuracy: 0.2466\n",
            "Epoch 650/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8783 - accuracy: 0.1959 - val_loss: 1.8829 - val_accuracy: 0.2466\n",
            "Epoch 651/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8749 - accuracy: 0.2165 - val_loss: 1.8827 - val_accuracy: 0.2466\n",
            "Epoch 652/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8747 - accuracy: 0.2199 - val_loss: 1.8836 - val_accuracy: 0.2466\n",
            "Epoch 653/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8810 - accuracy: 0.1993 - val_loss: 1.8838 - val_accuracy: 0.2466\n",
            "Epoch 654/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8761 - accuracy: 0.2234 - val_loss: 1.8834 - val_accuracy: 0.2466\n",
            "Epoch 655/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8736 - accuracy: 0.2199 - val_loss: 1.8823 - val_accuracy: 0.2466\n",
            "Epoch 656/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8731 - accuracy: 0.2131 - val_loss: 1.8824 - val_accuracy: 0.2466\n",
            "Epoch 657/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8760 - accuracy: 0.2027 - val_loss: 1.8819 - val_accuracy: 0.2466\n",
            "Epoch 658/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8789 - accuracy: 0.2062 - val_loss: 1.8820 - val_accuracy: 0.2466\n",
            "Epoch 659/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8714 - accuracy: 0.2302 - val_loss: 1.8819 - val_accuracy: 0.2466\n",
            "Epoch 660/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8747 - accuracy: 0.2131 - val_loss: 1.8816 - val_accuracy: 0.2466\n",
            "Epoch 661/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8700 - accuracy: 0.2165 - val_loss: 1.8816 - val_accuracy: 0.2466\n",
            "Epoch 662/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8702 - accuracy: 0.2234 - val_loss: 1.8814 - val_accuracy: 0.2466\n",
            "Epoch 663/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8797 - accuracy: 0.2199 - val_loss: 1.8815 - val_accuracy: 0.2466\n",
            "Epoch 664/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8661 - accuracy: 0.2199 - val_loss: 1.8806 - val_accuracy: 0.2466\n",
            "Epoch 665/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8756 - accuracy: 0.2268 - val_loss: 1.8814 - val_accuracy: 0.2466\n",
            "Epoch 666/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8792 - accuracy: 0.2199 - val_loss: 1.8816 - val_accuracy: 0.2466\n",
            "Epoch 667/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8784 - accuracy: 0.2165 - val_loss: 1.8822 - val_accuracy: 0.2466\n",
            "Epoch 668/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8716 - accuracy: 0.2234 - val_loss: 1.8835 - val_accuracy: 0.2466\n",
            "Epoch 669/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8709 - accuracy: 0.2096 - val_loss: 1.8829 - val_accuracy: 0.2466\n",
            "Epoch 670/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8736 - accuracy: 0.2165 - val_loss: 1.8824 - val_accuracy: 0.2466\n",
            "Epoch 671/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8707 - accuracy: 0.2268 - val_loss: 1.8830 - val_accuracy: 0.2466\n",
            "Epoch 672/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8795 - accuracy: 0.2199 - val_loss: 1.8832 - val_accuracy: 0.2466\n",
            "Epoch 673/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8644 - accuracy: 0.2199 - val_loss: 1.8838 - val_accuracy: 0.2466\n",
            "Epoch 674/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8716 - accuracy: 0.2096 - val_loss: 1.8841 - val_accuracy: 0.2466\n",
            "Epoch 675/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8743 - accuracy: 0.2371 - val_loss: 1.8859 - val_accuracy: 0.2466\n",
            "Epoch 676/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8781 - accuracy: 0.2302 - val_loss: 1.8857 - val_accuracy: 0.2466\n",
            "Epoch 677/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8705 - accuracy: 0.2234 - val_loss: 1.8854 - val_accuracy: 0.2466\n",
            "Epoch 678/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8770 - accuracy: 0.2199 - val_loss: 1.8857 - val_accuracy: 0.2466\n",
            "Epoch 679/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8799 - accuracy: 0.2131 - val_loss: 1.8860 - val_accuracy: 0.2466\n",
            "Epoch 680/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8743 - accuracy: 0.2337 - val_loss: 1.8861 - val_accuracy: 0.2466\n",
            "Epoch 681/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8668 - accuracy: 0.2131 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 682/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8739 - accuracy: 0.2131 - val_loss: 1.8873 - val_accuracy: 0.2466\n",
            "Epoch 683/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8753 - accuracy: 0.2062 - val_loss: 1.8884 - val_accuracy: 0.2466\n",
            "Epoch 684/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8750 - accuracy: 0.2199 - val_loss: 1.8880 - val_accuracy: 0.2466\n",
            "Epoch 685/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8805 - accuracy: 0.2096 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 686/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8745 - accuracy: 0.2405 - val_loss: 1.8901 - val_accuracy: 0.2466\n",
            "Epoch 687/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8740 - accuracy: 0.2062 - val_loss: 1.8893 - val_accuracy: 0.2466\n",
            "Epoch 688/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8739 - accuracy: 0.2096 - val_loss: 1.8880 - val_accuracy: 0.2466\n",
            "Epoch 689/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8701 - accuracy: 0.2096 - val_loss: 1.8881 - val_accuracy: 0.2466\n",
            "Epoch 690/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8748 - accuracy: 0.2062 - val_loss: 1.8883 - val_accuracy: 0.2466\n",
            "Epoch 691/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8775 - accuracy: 0.2405 - val_loss: 1.8880 - val_accuracy: 0.2466\n",
            "Epoch 692/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8748 - accuracy: 0.2131 - val_loss: 1.8878 - val_accuracy: 0.2466\n",
            "Epoch 693/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8728 - accuracy: 0.2027 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 694/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8758 - accuracy: 0.2234 - val_loss: 1.8877 - val_accuracy: 0.2466\n",
            "Epoch 695/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8765 - accuracy: 0.2131 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 696/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8797 - accuracy: 0.2131 - val_loss: 1.8869 - val_accuracy: 0.2466\n",
            "Epoch 697/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8728 - accuracy: 0.2062 - val_loss: 1.8859 - val_accuracy: 0.2466\n",
            "Epoch 698/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8745 - accuracy: 0.2268 - val_loss: 1.8859 - val_accuracy: 0.2466\n",
            "Epoch 699/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8780 - accuracy: 0.2199 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 700/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8751 - accuracy: 0.2268 - val_loss: 1.8858 - val_accuracy: 0.2466\n",
            "Epoch 701/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8799 - accuracy: 0.2096 - val_loss: 1.8854 - val_accuracy: 0.2466\n",
            "Epoch 702/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8701 - accuracy: 0.2234 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 703/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8718 - accuracy: 0.2268 - val_loss: 1.8872 - val_accuracy: 0.2466\n",
            "Epoch 704/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8785 - accuracy: 0.2268 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 705/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8730 - accuracy: 0.2302 - val_loss: 1.8857 - val_accuracy: 0.2466\n",
            "Epoch 706/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8722 - accuracy: 0.2131 - val_loss: 1.8851 - val_accuracy: 0.2466\n",
            "Epoch 707/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8696 - accuracy: 0.2165 - val_loss: 1.8847 - val_accuracy: 0.2466\n",
            "Epoch 708/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8842 - accuracy: 0.1993 - val_loss: 1.8836 - val_accuracy: 0.2466\n",
            "Epoch 709/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8812 - accuracy: 0.2234 - val_loss: 1.8836 - val_accuracy: 0.2466\n",
            "Epoch 710/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8760 - accuracy: 0.2199 - val_loss: 1.8841 - val_accuracy: 0.2466\n",
            "Epoch 711/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8754 - accuracy: 0.2199 - val_loss: 1.8839 - val_accuracy: 0.2466\n",
            "Epoch 712/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8808 - accuracy: 0.2199 - val_loss: 1.8851 - val_accuracy: 0.2466\n",
            "Epoch 713/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8743 - accuracy: 0.2302 - val_loss: 1.8867 - val_accuracy: 0.2466\n",
            "Epoch 714/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8745 - accuracy: 0.2096 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 715/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8740 - accuracy: 0.2474 - val_loss: 1.8873 - val_accuracy: 0.2466\n",
            "Epoch 716/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8769 - accuracy: 0.2096 - val_loss: 1.8872 - val_accuracy: 0.2466\n",
            "Epoch 717/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8747 - accuracy: 0.2062 - val_loss: 1.8866 - val_accuracy: 0.2466\n",
            "Epoch 718/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8791 - accuracy: 0.1993 - val_loss: 1.8862 - val_accuracy: 0.2466\n",
            "Epoch 719/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8730 - accuracy: 0.2096 - val_loss: 1.8872 - val_accuracy: 0.2466\n",
            "Epoch 720/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8808 - accuracy: 0.2062 - val_loss: 1.8867 - val_accuracy: 0.2466\n",
            "Epoch 721/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8786 - accuracy: 0.2337 - val_loss: 1.8867 - val_accuracy: 0.2466\n",
            "Epoch 722/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8782 - accuracy: 0.2268 - val_loss: 1.8862 - val_accuracy: 0.2466\n",
            "Epoch 723/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8702 - accuracy: 0.2440 - val_loss: 1.8862 - val_accuracy: 0.2466\n",
            "Epoch 724/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8759 - accuracy: 0.2131 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 725/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8703 - accuracy: 0.2268 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 726/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8705 - accuracy: 0.2268 - val_loss: 1.8885 - val_accuracy: 0.2466\n",
            "Epoch 727/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8731 - accuracy: 0.2199 - val_loss: 1.8893 - val_accuracy: 0.2466\n",
            "Epoch 728/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8725 - accuracy: 0.2165 - val_loss: 1.8903 - val_accuracy: 0.2466\n",
            "Epoch 729/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8746 - accuracy: 0.2268 - val_loss: 1.8911 - val_accuracy: 0.2466\n",
            "Epoch 730/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8711 - accuracy: 0.2131 - val_loss: 1.8915 - val_accuracy: 0.2466\n",
            "Epoch 731/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8788 - accuracy: 0.1993 - val_loss: 1.8925 - val_accuracy: 0.2466\n",
            "Epoch 732/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8722 - accuracy: 0.2027 - val_loss: 1.8928 - val_accuracy: 0.2466\n",
            "Epoch 733/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8752 - accuracy: 0.2302 - val_loss: 1.8923 - val_accuracy: 0.2466\n",
            "Epoch 734/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8745 - accuracy: 0.2337 - val_loss: 1.8924 - val_accuracy: 0.2466\n",
            "Epoch 735/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8761 - accuracy: 0.2268 - val_loss: 1.8917 - val_accuracy: 0.2466\n",
            "Epoch 736/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8720 - accuracy: 0.2096 - val_loss: 1.8910 - val_accuracy: 0.2466\n",
            "Epoch 737/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8761 - accuracy: 0.2509 - val_loss: 1.8903 - val_accuracy: 0.2466\n",
            "Epoch 738/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8754 - accuracy: 0.2062 - val_loss: 1.8899 - val_accuracy: 0.2466\n",
            "Epoch 739/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8736 - accuracy: 0.2234 - val_loss: 1.8899 - val_accuracy: 0.2466\n",
            "Epoch 740/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8742 - accuracy: 0.2337 - val_loss: 1.8902 - val_accuracy: 0.2466\n",
            "Epoch 741/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8839 - accuracy: 0.1787 - val_loss: 1.8902 - val_accuracy: 0.2466\n",
            "Epoch 742/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8800 - accuracy: 0.2302 - val_loss: 1.8896 - val_accuracy: 0.2466\n",
            "Epoch 743/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8748 - accuracy: 0.2199 - val_loss: 1.8896 - val_accuracy: 0.2466\n",
            "Epoch 744/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8735 - accuracy: 0.2199 - val_loss: 1.8899 - val_accuracy: 0.2466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJR5pfQ1c9g4"
      },
      "source": [
        "### Evaluation and Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "413JtwURc9g5",
        "outputId": "4725b60f-af5e-4113-9da3-031d483b06ea"
      },
      "source": [
        "# Evaluate our model on the test set\n",
        "loss, accuracy = model_2.evaluate(X_test, y_test)\n",
        "print(f\"Model loss on the test set: {loss}\")\n",
        "print(f\"Model accuracy on the test set: {100*accuracy:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 5ms/step - loss: 0.7995 - accuracy: 0.6410\n",
            "Model loss on the test set: 0.7994661927223206\n",
            "Model accuracy on the test set: 64.10%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "OJB0Jvw9c9g5",
        "outputId": "124252bd-a206-48f1-edaa-5107209b8409"
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history_2.history['loss'])#[5:])\n",
        "plt.plot(history_2.history['val_loss'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "NOjoGnLic9g6",
        "outputId": "671609fd-bb22-48e4-f317-16e0fa7a3e45"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history_2.history['accuracy'])#[5:])\n",
        "plt.plot(history_2.history['val_accuracy'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Binary Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}