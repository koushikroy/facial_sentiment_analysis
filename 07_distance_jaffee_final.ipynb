{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "distance ck+.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koushikroy/facial_sentiment_analysis/blob/main/07_distance_jaffee_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCXyx8lD8yuD"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZyNQK_p6gU3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvwNzEk69PpW"
      },
      "source": [
        "# Dateset Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLGsT1ORYjId"
      },
      "source": [
        "## Downloading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8-iDzOLIQtD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a188e573-5a6d-468c-9ec4-98432ea96dbc"
      },
      "source": [
        "!wget -cO - 'https://s3.us-west-2.amazonaws.com/secure.notion-static.com/5b04653e-45c4-4cb3-94a7-44b5728caabf/distance_dataset_jaffe.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20211028%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20211028T180203Z&X-Amz-Expires=86400&X-Amz-Signature=376559b091d929b2e49d513df217fb306cb9425d7fc74fb26b906e23da1476fc&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22distance_dataset_jaffe.csv%22'> jafee_dist.csv"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-28 18:03:12--  https://s3.us-west-2.amazonaws.com/secure.notion-static.com/5b04653e-45c4-4cb3-94a7-44b5728caabf/distance_dataset_jaffe.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20211028%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20211028T180203Z&X-Amz-Expires=86400&X-Amz-Signature=376559b091d929b2e49d513df217fb306cb9425d7fc74fb26b906e23da1476fc&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22distance_dataset_jaffe.csv%22\n",
            "Resolving s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)... 52.218.179.112\n",
            "Connecting to s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)|52.218.179.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 444054580 (423M) [text/csv]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>] 423.48M  45.9MB/s    in 9.8s    \n",
            "\n",
            "2021-10-28 18:03:22 (43.4 MB/s) - written to stdout [444054580/444054580]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQnuCiaCYs2W"
      },
      "source": [
        "## Exploring and Cleaning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9COVLEMgBPcf"
      },
      "source": [
        "sentiment_data_original = pd.read_csv('/content/jafee_dist.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "YUft2RE7BX-6",
        "outputId": "53948993-1191-420e-e4d8-19cf7bce3648"
      },
      "source": [
        "sentiment_data_original"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>108772</th>\n",
              "      <th>108773</th>\n",
              "      <th>108774</th>\n",
              "      <th>108775</th>\n",
              "      <th>108776</th>\n",
              "      <th>108777</th>\n",
              "      <th>108778</th>\n",
              "      <th>108779</th>\n",
              "      <th>108780</th>\n",
              "      <th>108781</th>\n",
              "      <th>108782</th>\n",
              "      <th>108783</th>\n",
              "      <th>108784</th>\n",
              "      <th>108785</th>\n",
              "      <th>108786</th>\n",
              "      <th>108787</th>\n",
              "      <th>108788</th>\n",
              "      <th>108789</th>\n",
              "      <th>108790</th>\n",
              "      <th>108791</th>\n",
              "      <th>108792</th>\n",
              "      <th>108793</th>\n",
              "      <th>108794</th>\n",
              "      <th>108795</th>\n",
              "      <th>108796</th>\n",
              "      <th>108797</th>\n",
              "      <th>108798</th>\n",
              "      <th>108799</th>\n",
              "      <th>108800</th>\n",
              "      <th>108801</th>\n",
              "      <th>108802</th>\n",
              "      <th>108803</th>\n",
              "      <th>108804</th>\n",
              "      <th>108805</th>\n",
              "      <th>108806</th>\n",
              "      <th>108807</th>\n",
              "      <th>108808</th>\n",
              "      <th>108809</th>\n",
              "      <th>108810</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.188870</td>\n",
              "      <td>0.139552</td>\n",
              "      <td>0.413746</td>\n",
              "      <td>0.252479</td>\n",
              "      <td>0.342880</td>\n",
              "      <td>0.568451</td>\n",
              "      <td>0.745820</td>\n",
              "      <td>0.734967</td>\n",
              "      <td>0.819906</td>\n",
              "      <td>1.138686</td>\n",
              "      <td>0.029348</td>\n",
              "      <td>0.049690</td>\n",
              "      <td>0.056483</td>\n",
              "      <td>0.091999</td>\n",
              "      <td>0.119676</td>\n",
              "      <td>0.152183</td>\n",
              "      <td>0.184366</td>\n",
              "      <td>0.224272</td>\n",
              "      <td>0.160967</td>\n",
              "      <td>0.180123</td>\n",
              "      <td>1.077636</td>\n",
              "      <td>0.609256</td>\n",
              "      <td>0.632240</td>\n",
              "      <td>0.664218</td>\n",
              "      <td>0.739089</td>\n",
              "      <td>0.603664</td>\n",
              "      <td>0.784691</td>\n",
              "      <td>0.755164</td>\n",
              "      <td>0.804168</td>\n",
              "      <td>0.807079</td>\n",
              "      <td>0.738092</td>\n",
              "      <td>0.351210</td>\n",
              "      <td>0.771940</td>\n",
              "      <td>0.895301</td>\n",
              "      <td>0.818415</td>\n",
              "      <td>0.407416</td>\n",
              "      <td>0.073571</td>\n",
              "      <td>0.075824</td>\n",
              "      <td>0.145562</td>\n",
              "      <td>0.190383</td>\n",
              "      <td>...</td>\n",
              "      <td>0.384747</td>\n",
              "      <td>0.368571</td>\n",
              "      <td>0.570886</td>\n",
              "      <td>0.037954</td>\n",
              "      <td>0.092726</td>\n",
              "      <td>0.013582</td>\n",
              "      <td>0.023906</td>\n",
              "      <td>0.439593</td>\n",
              "      <td>0.414372</td>\n",
              "      <td>0.396950</td>\n",
              "      <td>0.611811</td>\n",
              "      <td>0.066049</td>\n",
              "      <td>0.051500</td>\n",
              "      <td>0.061493</td>\n",
              "      <td>0.413892</td>\n",
              "      <td>0.390757</td>\n",
              "      <td>0.374562</td>\n",
              "      <td>0.576055</td>\n",
              "      <td>0.103351</td>\n",
              "      <td>0.109879</td>\n",
              "      <td>0.436102</td>\n",
              "      <td>0.417762</td>\n",
              "      <td>0.404249</td>\n",
              "      <td>0.564113</td>\n",
              "      <td>0.010628</td>\n",
              "      <td>0.449975</td>\n",
              "      <td>0.424146</td>\n",
              "      <td>0.406369</td>\n",
              "      <td>0.624988</td>\n",
              "      <td>0.459893</td>\n",
              "      <td>0.433798</td>\n",
              "      <td>0.415857</td>\n",
              "      <td>0.635584</td>\n",
              "      <td>0.038513</td>\n",
              "      <td>0.061488</td>\n",
              "      <td>0.293829</td>\n",
              "      <td>0.023229</td>\n",
              "      <td>0.330004</td>\n",
              "      <td>0.350384</td>\n",
              "      <td>Angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.194171</td>\n",
              "      <td>0.145662</td>\n",
              "      <td>0.412163</td>\n",
              "      <td>0.255991</td>\n",
              "      <td>0.343979</td>\n",
              "      <td>0.572534</td>\n",
              "      <td>0.781107</td>\n",
              "      <td>0.738391</td>\n",
              "      <td>0.823450</td>\n",
              "      <td>1.168052</td>\n",
              "      <td>0.030993</td>\n",
              "      <td>0.054250</td>\n",
              "      <td>0.063533</td>\n",
              "      <td>0.103604</td>\n",
              "      <td>0.134544</td>\n",
              "      <td>0.170189</td>\n",
              "      <td>0.203040</td>\n",
              "      <td>0.231775</td>\n",
              "      <td>0.167263</td>\n",
              "      <td>0.179768</td>\n",
              "      <td>1.172985</td>\n",
              "      <td>0.633388</td>\n",
              "      <td>0.659367</td>\n",
              "      <td>0.695413</td>\n",
              "      <td>0.779511</td>\n",
              "      <td>0.624821</td>\n",
              "      <td>0.817070</td>\n",
              "      <td>0.784487</td>\n",
              "      <td>0.839063</td>\n",
              "      <td>0.845741</td>\n",
              "      <td>0.785286</td>\n",
              "      <td>0.375691</td>\n",
              "      <td>0.811948</td>\n",
              "      <td>0.993557</td>\n",
              "      <td>0.877531</td>\n",
              "      <td>0.424999</td>\n",
              "      <td>0.072671</td>\n",
              "      <td>0.084262</td>\n",
              "      <td>0.151082</td>\n",
              "      <td>0.202608</td>\n",
              "      <td>...</td>\n",
              "      <td>0.391687</td>\n",
              "      <td>0.374922</td>\n",
              "      <td>0.552629</td>\n",
              "      <td>0.038076</td>\n",
              "      <td>0.069752</td>\n",
              "      <td>0.011698</td>\n",
              "      <td>0.026241</td>\n",
              "      <td>0.442472</td>\n",
              "      <td>0.418084</td>\n",
              "      <td>0.400295</td>\n",
              "      <td>0.594460</td>\n",
              "      <td>0.046517</td>\n",
              "      <td>0.049562</td>\n",
              "      <td>0.064251</td>\n",
              "      <td>0.419125</td>\n",
              "      <td>0.396652</td>\n",
              "      <td>0.379718</td>\n",
              "      <td>0.559833</td>\n",
              "      <td>0.077633</td>\n",
              "      <td>0.090508</td>\n",
              "      <td>0.446499</td>\n",
              "      <td>0.426446</td>\n",
              "      <td>0.410576</td>\n",
              "      <td>0.565532</td>\n",
              "      <td>0.014709</td>\n",
              "      <td>0.451784</td>\n",
              "      <td>0.426974</td>\n",
              "      <td>0.409001</td>\n",
              "      <td>0.605936</td>\n",
              "      <td>0.461429</td>\n",
              "      <td>0.435994</td>\n",
              "      <td>0.417759</td>\n",
              "      <td>0.619401</td>\n",
              "      <td>0.035042</td>\n",
              "      <td>0.054765</td>\n",
              "      <td>0.279266</td>\n",
              "      <td>0.020421</td>\n",
              "      <td>0.310904</td>\n",
              "      <td>0.326157</td>\n",
              "      <td>Angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.193976</td>\n",
              "      <td>0.140338</td>\n",
              "      <td>0.409292</td>\n",
              "      <td>0.257180</td>\n",
              "      <td>0.344103</td>\n",
              "      <td>0.560419</td>\n",
              "      <td>0.747891</td>\n",
              "      <td>0.718658</td>\n",
              "      <td>0.802723</td>\n",
              "      <td>1.122104</td>\n",
              "      <td>0.030610</td>\n",
              "      <td>0.053236</td>\n",
              "      <td>0.062003</td>\n",
              "      <td>0.084813</td>\n",
              "      <td>0.113035</td>\n",
              "      <td>0.146651</td>\n",
              "      <td>0.179768</td>\n",
              "      <td>0.219392</td>\n",
              "      <td>0.164628</td>\n",
              "      <td>0.176730</td>\n",
              "      <td>1.107713</td>\n",
              "      <td>0.604852</td>\n",
              "      <td>0.630487</td>\n",
              "      <td>0.665350</td>\n",
              "      <td>0.744258</td>\n",
              "      <td>0.596856</td>\n",
              "      <td>0.780583</td>\n",
              "      <td>0.749276</td>\n",
              "      <td>0.802380</td>\n",
              "      <td>0.808342</td>\n",
              "      <td>0.747216</td>\n",
              "      <td>0.378420</td>\n",
              "      <td>0.776078</td>\n",
              "      <td>0.933321</td>\n",
              "      <td>0.832756</td>\n",
              "      <td>0.408933</td>\n",
              "      <td>0.071856</td>\n",
              "      <td>0.083417</td>\n",
              "      <td>0.149565</td>\n",
              "      <td>0.201695</td>\n",
              "      <td>...</td>\n",
              "      <td>0.368159</td>\n",
              "      <td>0.355050</td>\n",
              "      <td>0.519454</td>\n",
              "      <td>0.036709</td>\n",
              "      <td>0.072590</td>\n",
              "      <td>0.010728</td>\n",
              "      <td>0.025707</td>\n",
              "      <td>0.416847</td>\n",
              "      <td>0.395860</td>\n",
              "      <td>0.381620</td>\n",
              "      <td>0.561690</td>\n",
              "      <td>0.050542</td>\n",
              "      <td>0.047313</td>\n",
              "      <td>0.062251</td>\n",
              "      <td>0.394120</td>\n",
              "      <td>0.375226</td>\n",
              "      <td>0.361949</td>\n",
              "      <td>0.528004</td>\n",
              "      <td>0.079879</td>\n",
              "      <td>0.091585</td>\n",
              "      <td>0.423216</td>\n",
              "      <td>0.407300</td>\n",
              "      <td>0.395332</td>\n",
              "      <td>0.532673</td>\n",
              "      <td>0.014985</td>\n",
              "      <td>0.425138</td>\n",
              "      <td>0.403687</td>\n",
              "      <td>0.389234</td>\n",
              "      <td>0.572157</td>\n",
              "      <td>0.436500</td>\n",
              "      <td>0.414408</td>\n",
              "      <td>0.399670</td>\n",
              "      <td>0.586647</td>\n",
              "      <td>0.034328</td>\n",
              "      <td>0.052012</td>\n",
              "      <td>0.268910</td>\n",
              "      <td>0.018184</td>\n",
              "      <td>0.301104</td>\n",
              "      <td>0.316037</td>\n",
              "      <td>Angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.183828</td>\n",
              "      <td>0.129862</td>\n",
              "      <td>0.393064</td>\n",
              "      <td>0.246627</td>\n",
              "      <td>0.330738</td>\n",
              "      <td>0.535461</td>\n",
              "      <td>0.714582</td>\n",
              "      <td>0.704521</td>\n",
              "      <td>0.794331</td>\n",
              "      <td>1.113810</td>\n",
              "      <td>0.028556</td>\n",
              "      <td>0.048396</td>\n",
              "      <td>0.054191</td>\n",
              "      <td>0.067773</td>\n",
              "      <td>0.092101</td>\n",
              "      <td>0.122651</td>\n",
              "      <td>0.156727</td>\n",
              "      <td>0.212878</td>\n",
              "      <td>0.154051</td>\n",
              "      <td>0.169221</td>\n",
              "      <td>1.064113</td>\n",
              "      <td>0.567222</td>\n",
              "      <td>0.596099</td>\n",
              "      <td>0.635392</td>\n",
              "      <td>0.714738</td>\n",
              "      <td>0.558020</td>\n",
              "      <td>0.747832</td>\n",
              "      <td>0.713886</td>\n",
              "      <td>0.772544</td>\n",
              "      <td>0.779131</td>\n",
              "      <td>0.723172</td>\n",
              "      <td>0.380188</td>\n",
              "      <td>0.740767</td>\n",
              "      <td>0.887196</td>\n",
              "      <td>0.805929</td>\n",
              "      <td>0.406645</td>\n",
              "      <td>0.079488</td>\n",
              "      <td>0.086428</td>\n",
              "      <td>0.162431</td>\n",
              "      <td>0.218118</td>\n",
              "      <td>...</td>\n",
              "      <td>0.341465</td>\n",
              "      <td>0.332136</td>\n",
              "      <td>0.503497</td>\n",
              "      <td>0.038793</td>\n",
              "      <td>0.088967</td>\n",
              "      <td>0.011742</td>\n",
              "      <td>0.024536</td>\n",
              "      <td>0.388474</td>\n",
              "      <td>0.372232</td>\n",
              "      <td>0.361520</td>\n",
              "      <td>0.547270</td>\n",
              "      <td>0.061178</td>\n",
              "      <td>0.050499</td>\n",
              "      <td>0.062996</td>\n",
              "      <td>0.363235</td>\n",
              "      <td>0.349350</td>\n",
              "      <td>0.339958</td>\n",
              "      <td>0.510503</td>\n",
              "      <td>0.098281</td>\n",
              "      <td>0.107286</td>\n",
              "      <td>0.386067</td>\n",
              "      <td>0.376738</td>\n",
              "      <td>0.369738</td>\n",
              "      <td>0.498273</td>\n",
              "      <td>0.012959</td>\n",
              "      <td>0.397263</td>\n",
              "      <td>0.380437</td>\n",
              "      <td>0.369398</td>\n",
              "      <td>0.558724</td>\n",
              "      <td>0.408780</td>\n",
              "      <td>0.391513</td>\n",
              "      <td>0.380220</td>\n",
              "      <td>0.571682</td>\n",
              "      <td>0.032272</td>\n",
              "      <td>0.049967</td>\n",
              "      <td>0.281941</td>\n",
              "      <td>0.017865</td>\n",
              "      <td>0.313363</td>\n",
              "      <td>0.329955</td>\n",
              "      <td>Angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.179609</td>\n",
              "      <td>0.125872</td>\n",
              "      <td>0.390826</td>\n",
              "      <td>0.243227</td>\n",
              "      <td>0.328291</td>\n",
              "      <td>0.535725</td>\n",
              "      <td>0.722110</td>\n",
              "      <td>0.707613</td>\n",
              "      <td>0.798247</td>\n",
              "      <td>1.129097</td>\n",
              "      <td>0.029121</td>\n",
              "      <td>0.049819</td>\n",
              "      <td>0.056390</td>\n",
              "      <td>0.070776</td>\n",
              "      <td>0.095970</td>\n",
              "      <td>0.127128</td>\n",
              "      <td>0.161071</td>\n",
              "      <td>0.214604</td>\n",
              "      <td>0.149467</td>\n",
              "      <td>0.163461</td>\n",
              "      <td>1.080893</td>\n",
              "      <td>0.570448</td>\n",
              "      <td>0.600727</td>\n",
              "      <td>0.641462</td>\n",
              "      <td>0.722283</td>\n",
              "      <td>0.560088</td>\n",
              "      <td>0.753085</td>\n",
              "      <td>0.717342</td>\n",
              "      <td>0.778478</td>\n",
              "      <td>0.786077</td>\n",
              "      <td>0.732294</td>\n",
              "      <td>0.381242</td>\n",
              "      <td>0.748627</td>\n",
              "      <td>0.901391</td>\n",
              "      <td>0.816106</td>\n",
              "      <td>0.409567</td>\n",
              "      <td>0.080588</td>\n",
              "      <td>0.088180</td>\n",
              "      <td>0.164979</td>\n",
              "      <td>0.221590</td>\n",
              "      <td>...</td>\n",
              "      <td>0.350288</td>\n",
              "      <td>0.339783</td>\n",
              "      <td>0.529006</td>\n",
              "      <td>0.039304</td>\n",
              "      <td>0.090758</td>\n",
              "      <td>0.012095</td>\n",
              "      <td>0.024854</td>\n",
              "      <td>0.399809</td>\n",
              "      <td>0.381341</td>\n",
              "      <td>0.369334</td>\n",
              "      <td>0.573240</td>\n",
              "      <td>0.062203</td>\n",
              "      <td>0.051358</td>\n",
              "      <td>0.063798</td>\n",
              "      <td>0.374187</td>\n",
              "      <td>0.358184</td>\n",
              "      <td>0.347603</td>\n",
              "      <td>0.536179</td>\n",
              "      <td>0.100402</td>\n",
              "      <td>0.109366</td>\n",
              "      <td>0.396168</td>\n",
              "      <td>0.385013</td>\n",
              "      <td>0.377055</td>\n",
              "      <td>0.523405</td>\n",
              "      <td>0.012939</td>\n",
              "      <td>0.408904</td>\n",
              "      <td>0.389819</td>\n",
              "      <td>0.377453</td>\n",
              "      <td>0.585009</td>\n",
              "      <td>0.420483</td>\n",
              "      <td>0.400955</td>\n",
              "      <td>0.388324</td>\n",
              "      <td>0.597948</td>\n",
              "      <td>0.034820</td>\n",
              "      <td>0.054339</td>\n",
              "      <td>0.291697</td>\n",
              "      <td>0.019673</td>\n",
              "      <td>0.325700</td>\n",
              "      <td>0.344171</td>\n",
              "      <td>Angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>0.194364</td>\n",
              "      <td>0.130571</td>\n",
              "      <td>0.395174</td>\n",
              "      <td>0.257626</td>\n",
              "      <td>0.338215</td>\n",
              "      <td>0.531247</td>\n",
              "      <td>0.688900</td>\n",
              "      <td>0.709969</td>\n",
              "      <td>0.801085</td>\n",
              "      <td>1.093752</td>\n",
              "      <td>0.029769</td>\n",
              "      <td>0.054575</td>\n",
              "      <td>0.066824</td>\n",
              "      <td>0.084258</td>\n",
              "      <td>0.110426</td>\n",
              "      <td>0.143473</td>\n",
              "      <td>0.176643</td>\n",
              "      <td>0.220999</td>\n",
              "      <td>0.161696</td>\n",
              "      <td>0.167527</td>\n",
              "      <td>1.019442</td>\n",
              "      <td>0.550939</td>\n",
              "      <td>0.575308</td>\n",
              "      <td>0.609399</td>\n",
              "      <td>0.685636</td>\n",
              "      <td>0.545038</td>\n",
              "      <td>0.742985</td>\n",
              "      <td>0.710924</td>\n",
              "      <td>0.762786</td>\n",
              "      <td>0.763287</td>\n",
              "      <td>0.685133</td>\n",
              "      <td>0.363876</td>\n",
              "      <td>0.715496</td>\n",
              "      <td>0.837701</td>\n",
              "      <td>0.764215</td>\n",
              "      <td>0.367850</td>\n",
              "      <td>0.061090</td>\n",
              "      <td>0.076900</td>\n",
              "      <td>0.126918</td>\n",
              "      <td>0.173723</td>\n",
              "      <td>...</td>\n",
              "      <td>0.324629</td>\n",
              "      <td>0.316728</td>\n",
              "      <td>0.465521</td>\n",
              "      <td>0.032884</td>\n",
              "      <td>0.068253</td>\n",
              "      <td>0.008710</td>\n",
              "      <td>0.023942</td>\n",
              "      <td>0.371717</td>\n",
              "      <td>0.356132</td>\n",
              "      <td>0.347053</td>\n",
              "      <td>0.507164</td>\n",
              "      <td>0.056273</td>\n",
              "      <td>0.041595</td>\n",
              "      <td>0.056397</td>\n",
              "      <td>0.348977</td>\n",
              "      <td>0.335207</td>\n",
              "      <td>0.327177</td>\n",
              "      <td>0.475728</td>\n",
              "      <td>0.073634</td>\n",
              "      <td>0.079919</td>\n",
              "      <td>0.388756</td>\n",
              "      <td>0.377867</td>\n",
              "      <td>0.371319</td>\n",
              "      <td>0.489848</td>\n",
              "      <td>0.015669</td>\n",
              "      <td>0.377953</td>\n",
              "      <td>0.361933</td>\n",
              "      <td>0.352602</td>\n",
              "      <td>0.515506</td>\n",
              "      <td>0.392611</td>\n",
              "      <td>0.376189</td>\n",
              "      <td>0.366612</td>\n",
              "      <td>0.531089</td>\n",
              "      <td>0.029908</td>\n",
              "      <td>0.046167</td>\n",
              "      <td>0.249187</td>\n",
              "      <td>0.016309</td>\n",
              "      <td>0.278123</td>\n",
              "      <td>0.293556</td>\n",
              "      <td>Surprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>0.193002</td>\n",
              "      <td>0.129960</td>\n",
              "      <td>0.391881</td>\n",
              "      <td>0.255706</td>\n",
              "      <td>0.335653</td>\n",
              "      <td>0.529323</td>\n",
              "      <td>0.685485</td>\n",
              "      <td>0.715924</td>\n",
              "      <td>0.809770</td>\n",
              "      <td>1.105989</td>\n",
              "      <td>0.030017</td>\n",
              "      <td>0.055586</td>\n",
              "      <td>0.068165</td>\n",
              "      <td>0.088999</td>\n",
              "      <td>0.116653</td>\n",
              "      <td>0.150903</td>\n",
              "      <td>0.184536</td>\n",
              "      <td>0.226873</td>\n",
              "      <td>0.160398</td>\n",
              "      <td>0.165220</td>\n",
              "      <td>1.031087</td>\n",
              "      <td>0.546870</td>\n",
              "      <td>0.571875</td>\n",
              "      <td>0.606843</td>\n",
              "      <td>0.683297</td>\n",
              "      <td>0.540764</td>\n",
              "      <td>0.745041</td>\n",
              "      <td>0.712958</td>\n",
              "      <td>0.764159</td>\n",
              "      <td>0.763859</td>\n",
              "      <td>0.684603</td>\n",
              "      <td>0.361149</td>\n",
              "      <td>0.712334</td>\n",
              "      <td>0.842455</td>\n",
              "      <td>0.765507</td>\n",
              "      <td>0.367743</td>\n",
              "      <td>0.062052</td>\n",
              "      <td>0.078584</td>\n",
              "      <td>0.129389</td>\n",
              "      <td>0.176463</td>\n",
              "      <td>...</td>\n",
              "      <td>0.325237</td>\n",
              "      <td>0.317843</td>\n",
              "      <td>0.467488</td>\n",
              "      <td>0.032817</td>\n",
              "      <td>0.068129</td>\n",
              "      <td>0.008464</td>\n",
              "      <td>0.023783</td>\n",
              "      <td>0.371116</td>\n",
              "      <td>0.356367</td>\n",
              "      <td>0.347808</td>\n",
              "      <td>0.509055</td>\n",
              "      <td>0.055641</td>\n",
              "      <td>0.041281</td>\n",
              "      <td>0.056208</td>\n",
              "      <td>0.348856</td>\n",
              "      <td>0.335906</td>\n",
              "      <td>0.328380</td>\n",
              "      <td>0.477847</td>\n",
              "      <td>0.073424</td>\n",
              "      <td>0.080209</td>\n",
              "      <td>0.388208</td>\n",
              "      <td>0.378040</td>\n",
              "      <td>0.371945</td>\n",
              "      <td>0.491734</td>\n",
              "      <td>0.015692</td>\n",
              "      <td>0.377098</td>\n",
              "      <td>0.361929</td>\n",
              "      <td>0.353129</td>\n",
              "      <td>0.517132</td>\n",
              "      <td>0.391545</td>\n",
              "      <td>0.375946</td>\n",
              "      <td>0.366885</td>\n",
              "      <td>0.532789</td>\n",
              "      <td>0.029012</td>\n",
              "      <td>0.044744</td>\n",
              "      <td>0.251260</td>\n",
              "      <td>0.015777</td>\n",
              "      <td>0.279466</td>\n",
              "      <td>0.294496</td>\n",
              "      <td>Surprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>0.192323</td>\n",
              "      <td>0.136191</td>\n",
              "      <td>0.395251</td>\n",
              "      <td>0.253038</td>\n",
              "      <td>0.334102</td>\n",
              "      <td>0.537788</td>\n",
              "      <td>0.708058</td>\n",
              "      <td>0.749064</td>\n",
              "      <td>0.845055</td>\n",
              "      <td>1.126763</td>\n",
              "      <td>0.028823</td>\n",
              "      <td>0.055219</td>\n",
              "      <td>0.069595</td>\n",
              "      <td>0.223003</td>\n",
              "      <td>0.260577</td>\n",
              "      <td>0.300592</td>\n",
              "      <td>0.333258</td>\n",
              "      <td>0.333968</td>\n",
              "      <td>0.163096</td>\n",
              "      <td>0.172278</td>\n",
              "      <td>1.047998</td>\n",
              "      <td>0.562289</td>\n",
              "      <td>0.585907</td>\n",
              "      <td>0.621655</td>\n",
              "      <td>0.705367</td>\n",
              "      <td>0.558880</td>\n",
              "      <td>0.802916</td>\n",
              "      <td>0.763570</td>\n",
              "      <td>0.821803</td>\n",
              "      <td>0.815345</td>\n",
              "      <td>0.698950</td>\n",
              "      <td>0.360546</td>\n",
              "      <td>0.740167</td>\n",
              "      <td>0.851159</td>\n",
              "      <td>0.784144</td>\n",
              "      <td>0.371017</td>\n",
              "      <td>0.064659</td>\n",
              "      <td>0.076207</td>\n",
              "      <td>0.127280</td>\n",
              "      <td>0.165061</td>\n",
              "      <td>...</td>\n",
              "      <td>0.344798</td>\n",
              "      <td>0.332943</td>\n",
              "      <td>0.517444</td>\n",
              "      <td>0.033438</td>\n",
              "      <td>0.072061</td>\n",
              "      <td>0.010917</td>\n",
              "      <td>0.022984</td>\n",
              "      <td>0.395113</td>\n",
              "      <td>0.376144</td>\n",
              "      <td>0.363111</td>\n",
              "      <td>0.556610</td>\n",
              "      <td>0.057556</td>\n",
              "      <td>0.044340</td>\n",
              "      <td>0.056152</td>\n",
              "      <td>0.370484</td>\n",
              "      <td>0.353101</td>\n",
              "      <td>0.341245</td>\n",
              "      <td>0.524301</td>\n",
              "      <td>0.079762</td>\n",
              "      <td>0.085019</td>\n",
              "      <td>0.404616</td>\n",
              "      <td>0.390425</td>\n",
              "      <td>0.380687</td>\n",
              "      <td>0.531407</td>\n",
              "      <td>0.012738</td>\n",
              "      <td>0.403000</td>\n",
              "      <td>0.383540</td>\n",
              "      <td>0.370147</td>\n",
              "      <td>0.567009</td>\n",
              "      <td>0.415274</td>\n",
              "      <td>0.395585</td>\n",
              "      <td>0.382006</td>\n",
              "      <td>0.579562</td>\n",
              "      <td>0.031144</td>\n",
              "      <td>0.052183</td>\n",
              "      <td>0.268310</td>\n",
              "      <td>0.021067</td>\n",
              "      <td>0.298278</td>\n",
              "      <td>0.318296</td>\n",
              "      <td>Surprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>0.188255</td>\n",
              "      <td>0.130466</td>\n",
              "      <td>0.393286</td>\n",
              "      <td>0.250939</td>\n",
              "      <td>0.332746</td>\n",
              "      <td>0.531236</td>\n",
              "      <td>0.681785</td>\n",
              "      <td>0.731719</td>\n",
              "      <td>0.826289</td>\n",
              "      <td>1.099354</td>\n",
              "      <td>0.028683</td>\n",
              "      <td>0.051724</td>\n",
              "      <td>0.061254</td>\n",
              "      <td>0.151646</td>\n",
              "      <td>0.183040</td>\n",
              "      <td>0.218945</td>\n",
              "      <td>0.253742</td>\n",
              "      <td>0.284575</td>\n",
              "      <td>0.156924</td>\n",
              "      <td>0.170033</td>\n",
              "      <td>0.995253</td>\n",
              "      <td>0.544268</td>\n",
              "      <td>0.567603</td>\n",
              "      <td>0.602399</td>\n",
              "      <td>0.680180</td>\n",
              "      <td>0.540600</td>\n",
              "      <td>0.756884</td>\n",
              "      <td>0.722023</td>\n",
              "      <td>0.776115</td>\n",
              "      <td>0.772399</td>\n",
              "      <td>0.676206</td>\n",
              "      <td>0.361358</td>\n",
              "      <td>0.709528</td>\n",
              "      <td>0.804368</td>\n",
              "      <td>0.752685</td>\n",
              "      <td>0.376844</td>\n",
              "      <td>0.073500</td>\n",
              "      <td>0.079095</td>\n",
              "      <td>0.143741</td>\n",
              "      <td>0.186732</td>\n",
              "      <td>...</td>\n",
              "      <td>0.334184</td>\n",
              "      <td>0.324409</td>\n",
              "      <td>0.503809</td>\n",
              "      <td>0.035848</td>\n",
              "      <td>0.088980</td>\n",
              "      <td>0.011661</td>\n",
              "      <td>0.022684</td>\n",
              "      <td>0.384029</td>\n",
              "      <td>0.367027</td>\n",
              "      <td>0.355980</td>\n",
              "      <td>0.544828</td>\n",
              "      <td>0.066934</td>\n",
              "      <td>0.047496</td>\n",
              "      <td>0.058028</td>\n",
              "      <td>0.357847</td>\n",
              "      <td>0.342765</td>\n",
              "      <td>0.333047</td>\n",
              "      <td>0.510064</td>\n",
              "      <td>0.098299</td>\n",
              "      <td>0.102904</td>\n",
              "      <td>0.384226</td>\n",
              "      <td>0.373958</td>\n",
              "      <td>0.367269</td>\n",
              "      <td>0.500412</td>\n",
              "      <td>0.012206</td>\n",
              "      <td>0.392454</td>\n",
              "      <td>0.374868</td>\n",
              "      <td>0.363418</td>\n",
              "      <td>0.556003</td>\n",
              "      <td>0.404575</td>\n",
              "      <td>0.386864</td>\n",
              "      <td>0.375303</td>\n",
              "      <td>0.567501</td>\n",
              "      <td>0.031694</td>\n",
              "      <td>0.051779</td>\n",
              "      <td>0.270842</td>\n",
              "      <td>0.020118</td>\n",
              "      <td>0.301805</td>\n",
              "      <td>0.321198</td>\n",
              "      <td>Surprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>0.201751</td>\n",
              "      <td>0.138578</td>\n",
              "      <td>0.392877</td>\n",
              "      <td>0.261447</td>\n",
              "      <td>0.337171</td>\n",
              "      <td>0.521926</td>\n",
              "      <td>0.671375</td>\n",
              "      <td>0.722987</td>\n",
              "      <td>0.815678</td>\n",
              "      <td>1.073664</td>\n",
              "      <td>0.028142</td>\n",
              "      <td>0.054426</td>\n",
              "      <td>0.069495</td>\n",
              "      <td>0.270632</td>\n",
              "      <td>0.308670</td>\n",
              "      <td>0.348526</td>\n",
              "      <td>0.381326</td>\n",
              "      <td>0.378715</td>\n",
              "      <td>0.170790</td>\n",
              "      <td>0.178426</td>\n",
              "      <td>0.974414</td>\n",
              "      <td>0.533928</td>\n",
              "      <td>0.555845</td>\n",
              "      <td>0.589446</td>\n",
              "      <td>0.667406</td>\n",
              "      <td>0.532006</td>\n",
              "      <td>0.765184</td>\n",
              "      <td>0.727871</td>\n",
              "      <td>0.782695</td>\n",
              "      <td>0.774953</td>\n",
              "      <td>0.658717</td>\n",
              "      <td>0.377753</td>\n",
              "      <td>0.700194</td>\n",
              "      <td>0.786860</td>\n",
              "      <td>0.736231</td>\n",
              "      <td>0.354262</td>\n",
              "      <td>0.064404</td>\n",
              "      <td>0.072865</td>\n",
              "      <td>0.123187</td>\n",
              "      <td>0.158278</td>\n",
              "      <td>...</td>\n",
              "      <td>0.314881</td>\n",
              "      <td>0.304451</td>\n",
              "      <td>0.488185</td>\n",
              "      <td>0.032539</td>\n",
              "      <td>0.079131</td>\n",
              "      <td>0.010128</td>\n",
              "      <td>0.022590</td>\n",
              "      <td>0.366629</td>\n",
              "      <td>0.348060</td>\n",
              "      <td>0.336471</td>\n",
              "      <td>0.527136</td>\n",
              "      <td>0.067293</td>\n",
              "      <td>0.042589</td>\n",
              "      <td>0.054582</td>\n",
              "      <td>0.341402</td>\n",
              "      <td>0.324407</td>\n",
              "      <td>0.314049</td>\n",
              "      <td>0.495140</td>\n",
              "      <td>0.086114</td>\n",
              "      <td>0.088212</td>\n",
              "      <td>0.381361</td>\n",
              "      <td>0.368390</td>\n",
              "      <td>0.360768</td>\n",
              "      <td>0.501974</td>\n",
              "      <td>0.014028</td>\n",
              "      <td>0.373774</td>\n",
              "      <td>0.354700</td>\n",
              "      <td>0.342723</td>\n",
              "      <td>0.536760</td>\n",
              "      <td>0.387789</td>\n",
              "      <td>0.368646</td>\n",
              "      <td>0.356579</td>\n",
              "      <td>0.549596</td>\n",
              "      <td>0.030922</td>\n",
              "      <td>0.051757</td>\n",
              "      <td>0.262765</td>\n",
              "      <td>0.020836</td>\n",
              "      <td>0.292594</td>\n",
              "      <td>0.312784</td>\n",
              "      <td>Surprise</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>213 rows × 108812 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2  ...    108809    108810    output\n",
              "0    0.188870  0.139552  0.413746  ...  0.330004  0.350384     Angry\n",
              "1    0.194171  0.145662  0.412163  ...  0.310904  0.326157     Angry\n",
              "2    0.193976  0.140338  0.409292  ...  0.301104  0.316037     Angry\n",
              "3    0.183828  0.129862  0.393064  ...  0.313363  0.329955     Angry\n",
              "4    0.179609  0.125872  0.390826  ...  0.325700  0.344171     Angry\n",
              "..        ...       ...       ...  ...       ...       ...       ...\n",
              "208  0.194364  0.130571  0.395174  ...  0.278123  0.293556  Surprise\n",
              "209  0.193002  0.129960  0.391881  ...  0.279466  0.294496  Surprise\n",
              "210  0.192323  0.136191  0.395251  ...  0.298278  0.318296  Surprise\n",
              "211  0.188255  0.130466  0.393286  ...  0.301805  0.321198  Surprise\n",
              "212  0.201751  0.138578  0.392877  ...  0.292594  0.312784  Surprise\n",
              "\n",
              "[213 rows x 108812 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7f55_uZCFEG"
      },
      "source": [
        "\n",
        "**From the dataset, we can see that:**\n",
        "*   There are in total 937 Columns excluding the index column \n",
        "*   The first 936 columns represents the landmark points in the face and the 'output' column represnts the emotion\n",
        "*   The face has been cropped and resized thus no need for further normalization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQZ4VOKCBdTM",
        "outputId": "eca133fa-692a-4e05-8d51-a6453e012412"
      },
      "source": [
        "sentiment_data_original.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 863 entries, 0 to 862\n",
            "Columns: 108812 entries, 0 to output\n",
            "dtypes: float64(108811), object(1)\n",
            "memory usage: 716.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcv0dQIABi8O",
        "outputId": "85c610db-e11c-424a-9e32-e1bea2bab6a4"
      },
      "source": [
        "#value_count in the output column \n",
        "sentiment_data_original['output'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Fear        32\n",
              "Happy       31\n",
              "SAD         31\n",
              "Neutral     30\n",
              "Angry       30\n",
              "Surprise    30\n",
              "Disgust     29\n",
              "Name: output, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh4iA1inDAXi"
      },
      "source": [
        "\n",
        "\n",
        "> So you can see that the neutral category has a staggering number of input compared to othet categories. This can be a later as the model might be overflitted. So, we need to take care of this.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqHvZrsMC_4a"
      },
      "source": [
        "all_neutral = sentiment_data_original['output'] == 'Neutral' \n",
        "list_of_neutral_index = []   \n",
        "for i in range (len(all_neutral)):\n",
        "    if all_neutral[i]:\n",
        "        list_of_neutral_index.append(i)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCcvMUQuhDpP"
      },
      "source": [
        "# Here we need to generate a list of random number\n",
        "import random\n",
        "random.shuffle(list_of_neutral_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1DK8UOGpc8F"
      },
      "source": [
        "# Dropping the random values\n",
        "sentiment_data_small_version = sentiment_data_original.drop(list_of_neutral_index[1:500])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csLqjscvWdWt"
      },
      "source": [
        "sentiment_data_small_version = sentiment_data_original.copy()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LojMwG4lWz7K",
        "outputId": "06b0adbe-c627-405b-ba82-02cd500653e5"
      },
      "source": [
        "sentiment_data_small_version['output'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Fear        32\n",
              "Happy       31\n",
              "SAD         31\n",
              "Neutral     30\n",
              "Angry       30\n",
              "Surprise    30\n",
              "Disgust     29\n",
              "Name: output, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvDgkKUsYy2D"
      },
      "source": [
        "## Mapping The Output Column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JmeYUMXY16u"
      },
      "source": [
        "input_df_copy = sentiment_data_small_version.copy()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1vrnHdxh84x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d9e16e-9e3d-450a-fff3-13fa2106c987"
      },
      "source": [
        "input_df_copy.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(213, 108812)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekyhnB5HY_Eb"
      },
      "source": [
        "uniqueValues = input_df_copy['output'].unique()\n",
        "input_df_copy['output'] = input_df_copy['output'].map({uniqueValues[0]:0,uniqueValues[1]:1,uniqueValues[2]:2,\n",
        "                                                       uniqueValues[3]:3,uniqueValues[4]:4,uniqueValues[5]:5,\n",
        "                                                       uniqueValues[6]:6})"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWoeBw72ZKUa",
        "outputId": "cf05621f-ca7f-4d47-8b1c-cd585b662f57"
      },
      "source": [
        "uniqueValues"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'SAD', 'Surprise'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK1LdxEXZTRI"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP0eYcREKUw2"
      },
      "source": [
        "X = input_df_copy.drop(['output'],axis=1)\n",
        "y=input_df_copy['output']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLt1vOYnKtZ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d86bfed-517f-470b-e5fa-68133d75a912"
      },
      "source": [
        "y.head(86)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0\n",
              "1     0\n",
              "2     0\n",
              "3     0\n",
              "4     0\n",
              "     ..\n",
              "81    2\n",
              "82    2\n",
              "83    2\n",
              "84    2\n",
              "85    2\n",
              "Name: output, Length: 86, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csdkIMLcGYP5"
      },
      "source": [
        "#apply SelectKBest class to extract top 10 best features\n",
        "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
        "fit = bestfeatures.fit(X,y)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li17BU2zLPD4"
      },
      "source": [
        "dfscores = pd.DataFrame(fit.scores_)\n",
        "dfcolumns = pd.DataFrame(X.columns)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKJ323D9LRVR"
      },
      "source": [
        "#concat two dataframes for better visualization \n",
        "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "featureScores.columns = ['Specs','Score']  #naming the dataframe columns"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygrSgRidLVJP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "9b799a50-f3db-46fb-808d-5d1623c3f4c4"
      },
      "source": [
        "featureScores"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Specs</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.124149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.114455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.056266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.084351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.056694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108806</th>\n",
              "      <td>108806</td>\n",
              "      <td>0.033493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108807</th>\n",
              "      <td>108807</td>\n",
              "      <td>0.076810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108808</th>\n",
              "      <td>108808</td>\n",
              "      <td>0.013985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108809</th>\n",
              "      <td>108809</td>\n",
              "      <td>0.092471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108810</th>\n",
              "      <td>108810</td>\n",
              "      <td>0.098125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>108811 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Specs     Score\n",
              "0            0  0.124149\n",
              "1            1  0.114455\n",
              "2            2  0.056266\n",
              "3            3  0.084351\n",
              "4            4  0.056694\n",
              "...        ...       ...\n",
              "108806  108806  0.033493\n",
              "108807  108807  0.076810\n",
              "108808  108808  0.013985\n",
              "108809  108809  0.092471\n",
              "108810  108810  0.098125\n",
              "\n",
              "[108811 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Geqrz3uFLgu_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7be22f0-878e-4510-aa57-a151a4114066"
      },
      "source": [
        "important_feature= featureScores.nlargest(100,'Score')[\"Specs\"]\n",
        "important_feature"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5980      5980\n",
              "34895    34895\n",
              "96880    96880\n",
              "5527      5527\n",
              "17053    17053\n",
              "         ...  \n",
              "31796    31796\n",
              "34128    34128\n",
              "95621    95621\n",
              "89744    89744\n",
              "96813    96813\n",
              "Name: Specs, Length: 100, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czzd2M-igr03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a7195c-4575-4138-923f-a36ea5f56317"
      },
      "source": [
        "imp_fea_dataset = input_df_copy[important_feature].join(input_df_copy[\"output\"])\n",
        "imp_fea_dataset.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(213, 101)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wynE83nGZaAN"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56PAsc3mZbhG"
      },
      "source": [
        "# Create X & y\n",
        "X = imp_fea_dataset.drop(\"output\", axis=1)\n",
        "y = imp_fea_dataset[\"output\"]\n",
        "\n",
        "# Build our train and test sets (use random state to ensure same split as before)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKTrYiSkZfwM"
      },
      "source": [
        "# Model Declaration and Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GeMq8iWZjza"
      },
      "source": [
        "## Model 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrAdvUFIcsuY"
      },
      "source": [
        "### Declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLDNxnFAZhXs"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(256, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(128, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate = .0003),\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    patience=250,\n",
        "    min_delta=0.0001,\n",
        "    restore_best_weights=True,\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt7Sb_fNcvWu"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGPlkzWGZpww",
        "outputId": "c3fc8697-22b8-4a67-8dc2-9b40f0f5e8b9"
      },
      "source": [
        "history_1 = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=2000,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1, \n",
        ")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "6/6 [==============================] - 1s 62ms/step - loss: 1.9533 - accuracy: 0.0882 - val_loss: 1.9431 - val_accuracy: 0.1628\n",
            "Epoch 2/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.9462 - accuracy: 0.1235 - val_loss: 1.9360 - val_accuracy: 0.1628\n",
            "Epoch 3/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.9419 - accuracy: 0.1412 - val_loss: 1.9300 - val_accuracy: 0.1628\n",
            "Epoch 4/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.9364 - accuracy: 0.1353 - val_loss: 1.9228 - val_accuracy: 0.1860\n",
            "Epoch 5/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.9336 - accuracy: 0.1412 - val_loss: 1.9160 - val_accuracy: 0.2093\n",
            "Epoch 6/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.9349 - accuracy: 0.1294 - val_loss: 1.9132 - val_accuracy: 0.2093\n",
            "Epoch 7/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.9319 - accuracy: 0.1176 - val_loss: 1.9072 - val_accuracy: 0.2326\n",
            "Epoch 8/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.9249 - accuracy: 0.1294 - val_loss: 1.8999 - val_accuracy: 0.2326\n",
            "Epoch 9/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.9253 - accuracy: 0.1176 - val_loss: 1.8939 - val_accuracy: 0.2093\n",
            "Epoch 10/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.9247 - accuracy: 0.1471 - val_loss: 1.8887 - val_accuracy: 0.1860\n",
            "Epoch 11/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.9137 - accuracy: 0.1235 - val_loss: 1.8805 - val_accuracy: 0.1860\n",
            "Epoch 12/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.9171 - accuracy: 0.1118 - val_loss: 1.8716 - val_accuracy: 0.2093\n",
            "Epoch 13/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.9116 - accuracy: 0.1294 - val_loss: 1.8641 - val_accuracy: 0.2093\n",
            "Epoch 14/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.9028 - accuracy: 0.1176 - val_loss: 1.8552 - val_accuracy: 0.2093\n",
            "Epoch 15/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.9005 - accuracy: 0.1353 - val_loss: 1.8491 - val_accuracy: 0.2093\n",
            "Epoch 16/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.9042 - accuracy: 0.1294 - val_loss: 1.8439 - val_accuracy: 0.2326\n",
            "Epoch 17/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.8982 - accuracy: 0.1471 - val_loss: 1.8439 - val_accuracy: 0.1628\n",
            "Epoch 18/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.8904 - accuracy: 0.1765 - val_loss: 1.8417 - val_accuracy: 0.1628\n",
            "Epoch 19/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.8880 - accuracy: 0.2000 - val_loss: 1.8388 - val_accuracy: 0.1860\n",
            "Epoch 20/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.8852 - accuracy: 0.2118 - val_loss: 1.8276 - val_accuracy: 0.1860\n",
            "Epoch 21/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.8718 - accuracy: 0.1647 - val_loss: 1.8192 - val_accuracy: 0.1860\n",
            "Epoch 22/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.8732 - accuracy: 0.2059 - val_loss: 1.8130 - val_accuracy: 0.1860\n",
            "Epoch 23/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.8724 - accuracy: 0.2235 - val_loss: 1.8117 - val_accuracy: 0.2093\n",
            "Epoch 24/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.8625 - accuracy: 0.1941 - val_loss: 1.8015 - val_accuracy: 0.2093\n",
            "Epoch 25/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.8570 - accuracy: 0.2176 - val_loss: 1.7895 - val_accuracy: 0.2093\n",
            "Epoch 26/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.8454 - accuracy: 0.2471 - val_loss: 1.7810 - val_accuracy: 0.1860\n",
            "Epoch 27/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.8356 - accuracy: 0.2471 - val_loss: 1.7714 - val_accuracy: 0.1860\n",
            "Epoch 28/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.8279 - accuracy: 0.2059 - val_loss: 1.7647 - val_accuracy: 0.1860\n",
            "Epoch 29/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.8218 - accuracy: 0.2529 - val_loss: 1.7608 - val_accuracy: 0.1860\n",
            "Epoch 30/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.8099 - accuracy: 0.2824 - val_loss: 1.7562 - val_accuracy: 0.2326\n",
            "Epoch 31/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.8171 - accuracy: 0.2412 - val_loss: 1.7526 - val_accuracy: 0.2093\n",
            "Epoch 32/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7877 - accuracy: 0.2471 - val_loss: 1.7496 - val_accuracy: 0.2093\n",
            "Epoch 33/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.7937 - accuracy: 0.2588 - val_loss: 1.7445 - val_accuracy: 0.2093\n",
            "Epoch 34/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7749 - accuracy: 0.2588 - val_loss: 1.7395 - val_accuracy: 0.2093\n",
            "Epoch 35/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7876 - accuracy: 0.2824 - val_loss: 1.7348 - val_accuracy: 0.2326\n",
            "Epoch 36/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7668 - accuracy: 0.2765 - val_loss: 1.7393 - val_accuracy: 0.2326\n",
            "Epoch 37/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7705 - accuracy: 0.2529 - val_loss: 1.7368 - val_accuracy: 0.2326\n",
            "Epoch 38/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7613 - accuracy: 0.2647 - val_loss: 1.7311 - val_accuracy: 0.2326\n",
            "Epoch 39/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7535 - accuracy: 0.2647 - val_loss: 1.7300 - val_accuracy: 0.2093\n",
            "Epoch 40/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7500 - accuracy: 0.2529 - val_loss: 1.7283 - val_accuracy: 0.2093\n",
            "Epoch 41/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7470 - accuracy: 0.2471 - val_loss: 1.7271 - val_accuracy: 0.2093\n",
            "Epoch 42/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7401 - accuracy: 0.3118 - val_loss: 1.7281 - val_accuracy: 0.2093\n",
            "Epoch 43/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7429 - accuracy: 0.2471 - val_loss: 1.7280 - val_accuracy: 0.2326\n",
            "Epoch 44/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7410 - accuracy: 0.2647 - val_loss: 1.7261 - val_accuracy: 0.2326\n",
            "Epoch 45/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7121 - accuracy: 0.2706 - val_loss: 1.7258 - val_accuracy: 0.2093\n",
            "Epoch 46/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7324 - accuracy: 0.2647 - val_loss: 1.7300 - val_accuracy: 0.2558\n",
            "Epoch 47/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7215 - accuracy: 0.2824 - val_loss: 1.7373 - val_accuracy: 0.2326\n",
            "Epoch 48/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7215 - accuracy: 0.2412 - val_loss: 1.7426 - val_accuracy: 0.2093\n",
            "Epoch 49/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7294 - accuracy: 0.2882 - val_loss: 1.7316 - val_accuracy: 0.2326\n",
            "Epoch 50/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7070 - accuracy: 0.2824 - val_loss: 1.7311 - val_accuracy: 0.2558\n",
            "Epoch 51/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7127 - accuracy: 0.3059 - val_loss: 1.7281 - val_accuracy: 0.2558\n",
            "Epoch 52/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7317 - accuracy: 0.2706 - val_loss: 1.7279 - val_accuracy: 0.2326\n",
            "Epoch 53/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6998 - accuracy: 0.3294 - val_loss: 1.7319 - val_accuracy: 0.2558\n",
            "Epoch 54/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7103 - accuracy: 0.3353 - val_loss: 1.7287 - val_accuracy: 0.2326\n",
            "Epoch 55/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7102 - accuracy: 0.2647 - val_loss: 1.7294 - val_accuracy: 0.2093\n",
            "Epoch 56/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7276 - accuracy: 0.2412 - val_loss: 1.7291 - val_accuracy: 0.2326\n",
            "Epoch 57/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7148 - accuracy: 0.2647 - val_loss: 1.7296 - val_accuracy: 0.2558\n",
            "Epoch 58/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6983 - accuracy: 0.2941 - val_loss: 1.7305 - val_accuracy: 0.2326\n",
            "Epoch 59/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7051 - accuracy: 0.3118 - val_loss: 1.7336 - val_accuracy: 0.2326\n",
            "Epoch 60/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7051 - accuracy: 0.2529 - val_loss: 1.7291 - val_accuracy: 0.2326\n",
            "Epoch 61/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7174 - accuracy: 0.2588 - val_loss: 1.7313 - val_accuracy: 0.2558\n",
            "Epoch 62/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7052 - accuracy: 0.2765 - val_loss: 1.7330 - val_accuracy: 0.2791\n",
            "Epoch 63/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7028 - accuracy: 0.2647 - val_loss: 1.7403 - val_accuracy: 0.2558\n",
            "Epoch 64/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7105 - accuracy: 0.3059 - val_loss: 1.7322 - val_accuracy: 0.2791\n",
            "Epoch 65/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7182 - accuracy: 0.2824 - val_loss: 1.7348 - val_accuracy: 0.3023\n",
            "Epoch 66/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7145 - accuracy: 0.2824 - val_loss: 1.7314 - val_accuracy: 0.2791\n",
            "Epoch 67/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7146 - accuracy: 0.2706 - val_loss: 1.7315 - val_accuracy: 0.2791\n",
            "Epoch 68/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7099 - accuracy: 0.2647 - val_loss: 1.7308 - val_accuracy: 0.2326\n",
            "Epoch 69/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7054 - accuracy: 0.2706 - val_loss: 1.7329 - val_accuracy: 0.2326\n",
            "Epoch 70/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6815 - accuracy: 0.3000 - val_loss: 1.7318 - val_accuracy: 0.2326\n",
            "Epoch 71/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6933 - accuracy: 0.2647 - val_loss: 1.7288 - val_accuracy: 0.2326\n",
            "Epoch 72/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7171 - accuracy: 0.2647 - val_loss: 1.7248 - val_accuracy: 0.2326\n",
            "Epoch 73/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7129 - accuracy: 0.2588 - val_loss: 1.7278 - val_accuracy: 0.2558\n",
            "Epoch 74/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7004 - accuracy: 0.2765 - val_loss: 1.7249 - val_accuracy: 0.2326\n",
            "Epoch 75/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6768 - accuracy: 0.3000 - val_loss: 1.7293 - val_accuracy: 0.2326\n",
            "Epoch 76/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7001 - accuracy: 0.3176 - val_loss: 1.7308 - val_accuracy: 0.2326\n",
            "Epoch 77/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7026 - accuracy: 0.2588 - val_loss: 1.7342 - val_accuracy: 0.2326\n",
            "Epoch 78/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7206 - accuracy: 0.2765 - val_loss: 1.7295 - val_accuracy: 0.2326\n",
            "Epoch 79/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6910 - accuracy: 0.3412 - val_loss: 1.7233 - val_accuracy: 0.2326\n",
            "Epoch 80/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.7222 - accuracy: 0.2588 - val_loss: 1.7233 - val_accuracy: 0.2326\n",
            "Epoch 81/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7196 - accuracy: 0.2706 - val_loss: 1.7219 - val_accuracy: 0.2326\n",
            "Epoch 82/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6919 - accuracy: 0.3059 - val_loss: 1.7270 - val_accuracy: 0.2326\n",
            "Epoch 83/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7054 - accuracy: 0.2824 - val_loss: 1.7221 - val_accuracy: 0.2558\n",
            "Epoch 84/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7016 - accuracy: 0.2294 - val_loss: 1.7220 - val_accuracy: 0.2791\n",
            "Epoch 85/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7009 - accuracy: 0.3000 - val_loss: 1.7206 - val_accuracy: 0.2791\n",
            "Epoch 86/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6950 - accuracy: 0.3118 - val_loss: 1.7207 - val_accuracy: 0.2791\n",
            "Epoch 87/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6880 - accuracy: 0.3000 - val_loss: 1.7241 - val_accuracy: 0.2791\n",
            "Epoch 88/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6943 - accuracy: 0.3118 - val_loss: 1.7232 - val_accuracy: 0.2791\n",
            "Epoch 89/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6975 - accuracy: 0.3176 - val_loss: 1.7285 - val_accuracy: 0.2558\n",
            "Epoch 90/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.6942 - accuracy: 0.3059 - val_loss: 1.7210 - val_accuracy: 0.3023\n",
            "Epoch 91/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6952 - accuracy: 0.3176 - val_loss: 1.7205 - val_accuracy: 0.2326\n",
            "Epoch 92/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7069 - accuracy: 0.2235 - val_loss: 1.7224 - val_accuracy: 0.2093\n",
            "Epoch 93/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6872 - accuracy: 0.2882 - val_loss: 1.7202 - val_accuracy: 0.2326\n",
            "Epoch 94/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6885 - accuracy: 0.2647 - val_loss: 1.7199 - val_accuracy: 0.2326\n",
            "Epoch 95/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6756 - accuracy: 0.3294 - val_loss: 1.7210 - val_accuracy: 0.2326\n",
            "Epoch 96/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6973 - accuracy: 0.3059 - val_loss: 1.7218 - val_accuracy: 0.2326\n",
            "Epoch 97/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.7077 - accuracy: 0.2941 - val_loss: 1.7232 - val_accuracy: 0.2326\n",
            "Epoch 98/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6650 - accuracy: 0.2765 - val_loss: 1.7238 - val_accuracy: 0.2326\n",
            "Epoch 99/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6821 - accuracy: 0.3118 - val_loss: 1.7239 - val_accuracy: 0.2326\n",
            "Epoch 100/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6744 - accuracy: 0.2941 - val_loss: 1.7270 - val_accuracy: 0.2791\n",
            "Epoch 101/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6905 - accuracy: 0.3000 - val_loss: 1.7233 - val_accuracy: 0.2558\n",
            "Epoch 102/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6824 - accuracy: 0.3588 - val_loss: 1.7273 - val_accuracy: 0.2558\n",
            "Epoch 103/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6868 - accuracy: 0.3176 - val_loss: 1.7239 - val_accuracy: 0.3023\n",
            "Epoch 104/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7103 - accuracy: 0.2941 - val_loss: 1.7225 - val_accuracy: 0.2791\n",
            "Epoch 105/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7022 - accuracy: 0.2882 - val_loss: 1.7199 - val_accuracy: 0.3023\n",
            "Epoch 106/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6839 - accuracy: 0.3000 - val_loss: 1.7199 - val_accuracy: 0.3023\n",
            "Epoch 107/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6739 - accuracy: 0.3294 - val_loss: 1.7197 - val_accuracy: 0.2791\n",
            "Epoch 108/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6940 - accuracy: 0.3059 - val_loss: 1.7206 - val_accuracy: 0.2791\n",
            "Epoch 109/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6832 - accuracy: 0.3294 - val_loss: 1.7260 - val_accuracy: 0.2791\n",
            "Epoch 110/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6877 - accuracy: 0.2941 - val_loss: 1.7209 - val_accuracy: 0.2558\n",
            "Epoch 111/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6786 - accuracy: 0.2882 - val_loss: 1.7240 - val_accuracy: 0.2326\n",
            "Epoch 112/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6833 - accuracy: 0.2529 - val_loss: 1.7197 - val_accuracy: 0.2326\n",
            "Epoch 113/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6934 - accuracy: 0.3412 - val_loss: 1.7198 - val_accuracy: 0.2326\n",
            "Epoch 114/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6789 - accuracy: 0.2882 - val_loss: 1.7212 - val_accuracy: 0.2326\n",
            "Epoch 115/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6855 - accuracy: 0.3176 - val_loss: 1.7219 - val_accuracy: 0.2326\n",
            "Epoch 116/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6841 - accuracy: 0.3059 - val_loss: 1.7245 - val_accuracy: 0.2326\n",
            "Epoch 117/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6710 - accuracy: 0.3176 - val_loss: 1.7243 - val_accuracy: 0.2326\n",
            "Epoch 118/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6813 - accuracy: 0.3235 - val_loss: 1.7218 - val_accuracy: 0.2558\n",
            "Epoch 119/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6770 - accuracy: 0.3000 - val_loss: 1.7212 - val_accuracy: 0.2558\n",
            "Epoch 120/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.6735 - accuracy: 0.3176 - val_loss: 1.7139 - val_accuracy: 0.2326\n",
            "Epoch 121/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6973 - accuracy: 0.2824 - val_loss: 1.7165 - val_accuracy: 0.2326\n",
            "Epoch 122/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6748 - accuracy: 0.3235 - val_loss: 1.7089 - val_accuracy: 0.2326\n",
            "Epoch 123/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6737 - accuracy: 0.3412 - val_loss: 1.7138 - val_accuracy: 0.2326\n",
            "Epoch 124/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6767 - accuracy: 0.2588 - val_loss: 1.7127 - val_accuracy: 0.2326\n",
            "Epoch 125/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6990 - accuracy: 0.2765 - val_loss: 1.7185 - val_accuracy: 0.2326\n",
            "Epoch 126/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6779 - accuracy: 0.3353 - val_loss: 1.7135 - val_accuracy: 0.2326\n",
            "Epoch 127/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6897 - accuracy: 0.3353 - val_loss: 1.7100 - val_accuracy: 0.2326\n",
            "Epoch 128/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6807 - accuracy: 0.2941 - val_loss: 1.7079 - val_accuracy: 0.2326\n",
            "Epoch 129/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6447 - accuracy: 0.3294 - val_loss: 1.7060 - val_accuracy: 0.2326\n",
            "Epoch 130/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6770 - accuracy: 0.3471 - val_loss: 1.7072 - val_accuracy: 0.2326\n",
            "Epoch 131/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6636 - accuracy: 0.3941 - val_loss: 1.7029 - val_accuracy: 0.2326\n",
            "Epoch 132/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6805 - accuracy: 0.3118 - val_loss: 1.7026 - val_accuracy: 0.2791\n",
            "Epoch 133/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6865 - accuracy: 0.3059 - val_loss: 1.7022 - val_accuracy: 0.2791\n",
            "Epoch 134/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6644 - accuracy: 0.2941 - val_loss: 1.6965 - val_accuracy: 0.2326\n",
            "Epoch 135/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.6574 - accuracy: 0.3353 - val_loss: 1.6957 - val_accuracy: 0.2326\n",
            "Epoch 136/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6618 - accuracy: 0.3588 - val_loss: 1.6990 - val_accuracy: 0.2326\n",
            "Epoch 137/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6629 - accuracy: 0.2882 - val_loss: 1.7009 - val_accuracy: 0.2326\n",
            "Epoch 138/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6523 - accuracy: 0.3235 - val_loss: 1.7031 - val_accuracy: 0.2326\n",
            "Epoch 139/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6724 - accuracy: 0.3294 - val_loss: 1.7092 - val_accuracy: 0.2326\n",
            "Epoch 140/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6844 - accuracy: 0.3000 - val_loss: 1.7040 - val_accuracy: 0.2558\n",
            "Epoch 141/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6722 - accuracy: 0.3059 - val_loss: 1.7001 - val_accuracy: 0.2326\n",
            "Epoch 142/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6688 - accuracy: 0.3353 - val_loss: 1.6955 - val_accuracy: 0.2326\n",
            "Epoch 143/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6721 - accuracy: 0.3000 - val_loss: 1.6917 - val_accuracy: 0.2558\n",
            "Epoch 144/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6735 - accuracy: 0.3176 - val_loss: 1.6892 - val_accuracy: 0.2558\n",
            "Epoch 145/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6691 - accuracy: 0.3118 - val_loss: 1.6889 - val_accuracy: 0.2558\n",
            "Epoch 146/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6870 - accuracy: 0.3294 - val_loss: 1.6883 - val_accuracy: 0.2558\n",
            "Epoch 147/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6623 - accuracy: 0.3353 - val_loss: 1.6866 - val_accuracy: 0.2558\n",
            "Epoch 148/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6498 - accuracy: 0.3353 - val_loss: 1.6859 - val_accuracy: 0.2326\n",
            "Epoch 149/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6735 - accuracy: 0.2941 - val_loss: 1.6878 - val_accuracy: 0.2326\n",
            "Epoch 150/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6561 - accuracy: 0.3294 - val_loss: 1.6877 - val_accuracy: 0.2326\n",
            "Epoch 151/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.6622 - accuracy: 0.3647 - val_loss: 1.6836 - val_accuracy: 0.2326\n",
            "Epoch 152/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6425 - accuracy: 0.3353 - val_loss: 1.6765 - val_accuracy: 0.2558\n",
            "Epoch 153/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6407 - accuracy: 0.3353 - val_loss: 1.6732 - val_accuracy: 0.2791\n",
            "Epoch 154/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6571 - accuracy: 0.3412 - val_loss: 1.6713 - val_accuracy: 0.2558\n",
            "Epoch 155/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6657 - accuracy: 0.3118 - val_loss: 1.6710 - val_accuracy: 0.2558\n",
            "Epoch 156/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6512 - accuracy: 0.3412 - val_loss: 1.6719 - val_accuracy: 0.2558\n",
            "Epoch 157/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6577 - accuracy: 0.3353 - val_loss: 1.6683 - val_accuracy: 0.2558\n",
            "Epoch 158/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6678 - accuracy: 0.2941 - val_loss: 1.6688 - val_accuracy: 0.2791\n",
            "Epoch 159/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6484 - accuracy: 0.3412 - val_loss: 1.6602 - val_accuracy: 0.2558\n",
            "Epoch 160/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6447 - accuracy: 0.3235 - val_loss: 1.6583 - val_accuracy: 0.2791\n",
            "Epoch 161/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6364 - accuracy: 0.3588 - val_loss: 1.6584 - val_accuracy: 0.2558\n",
            "Epoch 162/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6239 - accuracy: 0.3529 - val_loss: 1.6569 - val_accuracy: 0.2791\n",
            "Epoch 163/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6325 - accuracy: 0.3529 - val_loss: 1.6578 - val_accuracy: 0.2791\n",
            "Epoch 164/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6392 - accuracy: 0.3588 - val_loss: 1.6562 - val_accuracy: 0.2791\n",
            "Epoch 165/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6469 - accuracy: 0.3118 - val_loss: 1.6585 - val_accuracy: 0.2558\n",
            "Epoch 166/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6317 - accuracy: 0.3176 - val_loss: 1.6620 - val_accuracy: 0.2558\n",
            "Epoch 167/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6357 - accuracy: 0.3294 - val_loss: 1.6527 - val_accuracy: 0.3256\n",
            "Epoch 168/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6334 - accuracy: 0.3235 - val_loss: 1.6518 - val_accuracy: 0.3721\n",
            "Epoch 169/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.6176 - accuracy: 0.3706 - val_loss: 1.6496 - val_accuracy: 0.3023\n",
            "Epoch 170/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6388 - accuracy: 0.3412 - val_loss: 1.6650 - val_accuracy: 0.2326\n",
            "Epoch 171/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6351 - accuracy: 0.3235 - val_loss: 1.6517 - val_accuracy: 0.3488\n",
            "Epoch 172/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6354 - accuracy: 0.3529 - val_loss: 1.6448 - val_accuracy: 0.3256\n",
            "Epoch 173/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6159 - accuracy: 0.3529 - val_loss: 1.6440 - val_accuracy: 0.3256\n",
            "Epoch 174/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6424 - accuracy: 0.3353 - val_loss: 1.6543 - val_accuracy: 0.3023\n",
            "Epoch 175/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6208 - accuracy: 0.3529 - val_loss: 1.6464 - val_accuracy: 0.3023\n",
            "Epoch 176/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6110 - accuracy: 0.3412 - val_loss: 1.6381 - val_accuracy: 0.3023\n",
            "Epoch 177/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6328 - accuracy: 0.3235 - val_loss: 1.6314 - val_accuracy: 0.3256\n",
            "Epoch 178/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6177 - accuracy: 0.3294 - val_loss: 1.6260 - val_accuracy: 0.3488\n",
            "Epoch 179/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6382 - accuracy: 0.3235 - val_loss: 1.6326 - val_accuracy: 0.2558\n",
            "Epoch 180/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6038 - accuracy: 0.3529 - val_loss: 1.6260 - val_accuracy: 0.3023\n",
            "Epoch 181/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6219 - accuracy: 0.3647 - val_loss: 1.6206 - val_accuracy: 0.3256\n",
            "Epoch 182/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6128 - accuracy: 0.3529 - val_loss: 1.6191 - val_accuracy: 0.2791\n",
            "Epoch 183/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6075 - accuracy: 0.3647 - val_loss: 1.6361 - val_accuracy: 0.2558\n",
            "Epoch 184/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6229 - accuracy: 0.3529 - val_loss: 1.6162 - val_accuracy: 0.2791\n",
            "Epoch 185/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5951 - accuracy: 0.3412 - val_loss: 1.6118 - val_accuracy: 0.3256\n",
            "Epoch 186/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6133 - accuracy: 0.4000 - val_loss: 1.6161 - val_accuracy: 0.2791\n",
            "Epoch 187/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5895 - accuracy: 0.3706 - val_loss: 1.6092 - val_accuracy: 0.3023\n",
            "Epoch 188/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5932 - accuracy: 0.3529 - val_loss: 1.6022 - val_accuracy: 0.3488\n",
            "Epoch 189/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5906 - accuracy: 0.3706 - val_loss: 1.6020 - val_accuracy: 0.3488\n",
            "Epoch 190/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5937 - accuracy: 0.3941 - val_loss: 1.6024 - val_accuracy: 0.3721\n",
            "Epoch 191/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6149 - accuracy: 0.3471 - val_loss: 1.6069 - val_accuracy: 0.3023\n",
            "Epoch 192/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5871 - accuracy: 0.3824 - val_loss: 1.6169 - val_accuracy: 0.2791\n",
            "Epoch 193/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5681 - accuracy: 0.3824 - val_loss: 1.6004 - val_accuracy: 0.3256\n",
            "Epoch 194/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5957 - accuracy: 0.3588 - val_loss: 1.5996 - val_accuracy: 0.3488\n",
            "Epoch 195/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6156 - accuracy: 0.3882 - val_loss: 1.5869 - val_accuracy: 0.3488\n",
            "Epoch 196/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6141 - accuracy: 0.3588 - val_loss: 1.5866 - val_accuracy: 0.3256\n",
            "Epoch 197/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5837 - accuracy: 0.3471 - val_loss: 1.5854 - val_accuracy: 0.3256\n",
            "Epoch 198/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5792 - accuracy: 0.3647 - val_loss: 1.5806 - val_accuracy: 0.3256\n",
            "Epoch 199/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5994 - accuracy: 0.3235 - val_loss: 1.5726 - val_accuracy: 0.3488\n",
            "Epoch 200/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5749 - accuracy: 0.3353 - val_loss: 1.5715 - val_accuracy: 0.3256\n",
            "Epoch 201/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5890 - accuracy: 0.3471 - val_loss: 1.5932 - val_accuracy: 0.2791\n",
            "Epoch 202/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5788 - accuracy: 0.3412 - val_loss: 1.5640 - val_accuracy: 0.3256\n",
            "Epoch 203/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5859 - accuracy: 0.3412 - val_loss: 1.5627 - val_accuracy: 0.3953\n",
            "Epoch 204/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5758 - accuracy: 0.3471 - val_loss: 1.5738 - val_accuracy: 0.3256\n",
            "Epoch 205/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5853 - accuracy: 0.3353 - val_loss: 1.5613 - val_accuracy: 0.3256\n",
            "Epoch 206/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5713 - accuracy: 0.3941 - val_loss: 1.5581 - val_accuracy: 0.3488\n",
            "Epoch 207/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5791 - accuracy: 0.3882 - val_loss: 1.5585 - val_accuracy: 0.3256\n",
            "Epoch 208/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5741 - accuracy: 0.3471 - val_loss: 1.5617 - val_accuracy: 0.3256\n",
            "Epoch 209/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.5818 - accuracy: 0.3412 - val_loss: 1.5561 - val_accuracy: 0.3721\n",
            "Epoch 210/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5654 - accuracy: 0.3235 - val_loss: 1.5564 - val_accuracy: 0.3488\n",
            "Epoch 211/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5613 - accuracy: 0.3647 - val_loss: 1.5674 - val_accuracy: 0.3023\n",
            "Epoch 212/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5584 - accuracy: 0.3588 - val_loss: 1.5433 - val_accuracy: 0.3488\n",
            "Epoch 213/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.5546 - accuracy: 0.3471 - val_loss: 1.5363 - val_accuracy: 0.3488\n",
            "Epoch 214/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5654 - accuracy: 0.3353 - val_loss: 1.5428 - val_accuracy: 0.3256\n",
            "Epoch 215/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5511 - accuracy: 0.3647 - val_loss: 1.5314 - val_accuracy: 0.3488\n",
            "Epoch 216/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5648 - accuracy: 0.3706 - val_loss: 1.5370 - val_accuracy: 0.3256\n",
            "Epoch 217/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5588 - accuracy: 0.3647 - val_loss: 1.5361 - val_accuracy: 0.3488\n",
            "Epoch 218/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5367 - accuracy: 0.3647 - val_loss: 1.5293 - val_accuracy: 0.3488\n",
            "Epoch 219/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5460 - accuracy: 0.3824 - val_loss: 1.5287 - val_accuracy: 0.3488\n",
            "Epoch 220/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5602 - accuracy: 0.3765 - val_loss: 1.5308 - val_accuracy: 0.3488\n",
            "Epoch 221/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5255 - accuracy: 0.3588 - val_loss: 1.5253 - val_accuracy: 0.3488\n",
            "Epoch 222/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5473 - accuracy: 0.3471 - val_loss: 1.5276 - val_accuracy: 0.3488\n",
            "Epoch 223/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5531 - accuracy: 0.3706 - val_loss: 1.5388 - val_accuracy: 0.3488\n",
            "Epoch 224/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5531 - accuracy: 0.3941 - val_loss: 1.5355 - val_accuracy: 0.3256\n",
            "Epoch 225/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5384 - accuracy: 0.3882 - val_loss: 1.5273 - val_accuracy: 0.3721\n",
            "Epoch 226/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5244 - accuracy: 0.4000 - val_loss: 1.5172 - val_accuracy: 0.3721\n",
            "Epoch 227/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5446 - accuracy: 0.4294 - val_loss: 1.5217 - val_accuracy: 0.3721\n",
            "Epoch 228/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5474 - accuracy: 0.3824 - val_loss: 1.5538 - val_accuracy: 0.3256\n",
            "Epoch 229/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5550 - accuracy: 0.3941 - val_loss: 1.5121 - val_accuracy: 0.3721\n",
            "Epoch 230/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5308 - accuracy: 0.3706 - val_loss: 1.5110 - val_accuracy: 0.3488\n",
            "Epoch 231/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5393 - accuracy: 0.3765 - val_loss: 1.5346 - val_accuracy: 0.3256\n",
            "Epoch 232/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5419 - accuracy: 0.3765 - val_loss: 1.5121 - val_accuracy: 0.3721\n",
            "Epoch 233/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5235 - accuracy: 0.3588 - val_loss: 1.5043 - val_accuracy: 0.3721\n",
            "Epoch 234/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5253 - accuracy: 0.3882 - val_loss: 1.5188 - val_accuracy: 0.3488\n",
            "Epoch 235/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5337 - accuracy: 0.3765 - val_loss: 1.5087 - val_accuracy: 0.3488\n",
            "Epoch 236/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5327 - accuracy: 0.3941 - val_loss: 1.5018 - val_accuracy: 0.3488\n",
            "Epoch 237/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5269 - accuracy: 0.3765 - val_loss: 1.5075 - val_accuracy: 0.3721\n",
            "Epoch 238/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5443 - accuracy: 0.3824 - val_loss: 1.5076 - val_accuracy: 0.3721\n",
            "Epoch 239/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5204 - accuracy: 0.3529 - val_loss: 1.5070 - val_accuracy: 0.3488\n",
            "Epoch 240/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5345 - accuracy: 0.4000 - val_loss: 1.5027 - val_accuracy: 0.3488\n",
            "Epoch 241/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5370 - accuracy: 0.3529 - val_loss: 1.4921 - val_accuracy: 0.3721\n",
            "Epoch 242/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5154 - accuracy: 0.3824 - val_loss: 1.4921 - val_accuracy: 0.3721\n",
            "Epoch 243/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5486 - accuracy: 0.3353 - val_loss: 1.4997 - val_accuracy: 0.3721\n",
            "Epoch 244/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5071 - accuracy: 0.3824 - val_loss: 1.4925 - val_accuracy: 0.3721\n",
            "Epoch 245/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5009 - accuracy: 0.3706 - val_loss: 1.4932 - val_accuracy: 0.3488\n",
            "Epoch 246/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5455 - accuracy: 0.3588 - val_loss: 1.4898 - val_accuracy: 0.3953\n",
            "Epoch 247/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5008 - accuracy: 0.3765 - val_loss: 1.5017 - val_accuracy: 0.3488\n",
            "Epoch 248/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5328 - accuracy: 0.3588 - val_loss: 1.4990 - val_accuracy: 0.3488\n",
            "Epoch 249/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5217 - accuracy: 0.3647 - val_loss: 1.4878 - val_accuracy: 0.3721\n",
            "Epoch 250/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4984 - accuracy: 0.3824 - val_loss: 1.4842 - val_accuracy: 0.3721\n",
            "Epoch 251/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5183 - accuracy: 0.3412 - val_loss: 1.4838 - val_accuracy: 0.3721\n",
            "Epoch 252/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4934 - accuracy: 0.3882 - val_loss: 1.4856 - val_accuracy: 0.3488\n",
            "Epoch 253/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4984 - accuracy: 0.3882 - val_loss: 1.5014 - val_accuracy: 0.3488\n",
            "Epoch 254/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4980 - accuracy: 0.4235 - val_loss: 1.4830 - val_accuracy: 0.3488\n",
            "Epoch 255/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5470 - accuracy: 0.3471 - val_loss: 1.4877 - val_accuracy: 0.3488\n",
            "Epoch 256/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5095 - accuracy: 0.3588 - val_loss: 1.4896 - val_accuracy: 0.3256\n",
            "Epoch 257/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5143 - accuracy: 0.3706 - val_loss: 1.4921 - val_accuracy: 0.3256\n",
            "Epoch 258/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4914 - accuracy: 0.4176 - val_loss: 1.4854 - val_accuracy: 0.3721\n",
            "Epoch 259/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4958 - accuracy: 0.3941 - val_loss: 1.4818 - val_accuracy: 0.3023\n",
            "Epoch 260/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4764 - accuracy: 0.3824 - val_loss: 1.4799 - val_accuracy: 0.3488\n",
            "Epoch 261/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4688 - accuracy: 0.3882 - val_loss: 1.4793 - val_accuracy: 0.3256\n",
            "Epoch 262/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5139 - accuracy: 0.3529 - val_loss: 1.4865 - val_accuracy: 0.3721\n",
            "Epoch 263/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4774 - accuracy: 0.3765 - val_loss: 1.4819 - val_accuracy: 0.3488\n",
            "Epoch 264/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4862 - accuracy: 0.3941 - val_loss: 1.4872 - val_accuracy: 0.3256\n",
            "Epoch 265/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5000 - accuracy: 0.3765 - val_loss: 1.4836 - val_accuracy: 0.3488\n",
            "Epoch 266/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4774 - accuracy: 0.3824 - val_loss: 1.4885 - val_accuracy: 0.3488\n",
            "Epoch 267/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4938 - accuracy: 0.3471 - val_loss: 1.4752 - val_accuracy: 0.3721\n",
            "Epoch 268/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5160 - accuracy: 0.3824 - val_loss: 1.4742 - val_accuracy: 0.3721\n",
            "Epoch 269/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4870 - accuracy: 0.3882 - val_loss: 1.4774 - val_accuracy: 0.3488\n",
            "Epoch 270/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4753 - accuracy: 0.3588 - val_loss: 1.4700 - val_accuracy: 0.3488\n",
            "Epoch 271/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4903 - accuracy: 0.3706 - val_loss: 1.4737 - val_accuracy: 0.3721\n",
            "Epoch 272/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4909 - accuracy: 0.3765 - val_loss: 1.4776 - val_accuracy: 0.3721\n",
            "Epoch 273/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4942 - accuracy: 0.4176 - val_loss: 1.4806 - val_accuracy: 0.3488\n",
            "Epoch 274/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4831 - accuracy: 0.3941 - val_loss: 1.4843 - val_accuracy: 0.3256\n",
            "Epoch 275/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4739 - accuracy: 0.3882 - val_loss: 1.4900 - val_accuracy: 0.3953\n",
            "Epoch 276/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5154 - accuracy: 0.4059 - val_loss: 1.4924 - val_accuracy: 0.3488\n",
            "Epoch 277/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4837 - accuracy: 0.3941 - val_loss: 1.4910 - val_accuracy: 0.3721\n",
            "Epoch 278/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5021 - accuracy: 0.3647 - val_loss: 1.4894 - val_accuracy: 0.3488\n",
            "Epoch 279/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5267 - accuracy: 0.3529 - val_loss: 1.4936 - val_accuracy: 0.3256\n",
            "Epoch 280/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4700 - accuracy: 0.4000 - val_loss: 1.4699 - val_accuracy: 0.3256\n",
            "Epoch 281/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5128 - accuracy: 0.3647 - val_loss: 1.4696 - val_accuracy: 0.3721\n",
            "Epoch 282/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4934 - accuracy: 0.3765 - val_loss: 1.4953 - val_accuracy: 0.3488\n",
            "Epoch 283/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5207 - accuracy: 0.3647 - val_loss: 1.4736 - val_accuracy: 0.3488\n",
            "Epoch 284/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4760 - accuracy: 0.4000 - val_loss: 1.4759 - val_accuracy: 0.3488\n",
            "Epoch 285/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4718 - accuracy: 0.3882 - val_loss: 1.4727 - val_accuracy: 0.3256\n",
            "Epoch 286/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4741 - accuracy: 0.3941 - val_loss: 1.4688 - val_accuracy: 0.3256\n",
            "Epoch 287/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4812 - accuracy: 0.3941 - val_loss: 1.4736 - val_accuracy: 0.3488\n",
            "Epoch 288/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4861 - accuracy: 0.3882 - val_loss: 1.4696 - val_accuracy: 0.3488\n",
            "Epoch 289/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4909 - accuracy: 0.3824 - val_loss: 1.4647 - val_accuracy: 0.3256\n",
            "Epoch 290/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4730 - accuracy: 0.3882 - val_loss: 1.4693 - val_accuracy: 0.3256\n",
            "Epoch 291/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4897 - accuracy: 0.3765 - val_loss: 1.4668 - val_accuracy: 0.3488\n",
            "Epoch 292/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4771 - accuracy: 0.3882 - val_loss: 1.4716 - val_accuracy: 0.3256\n",
            "Epoch 293/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4956 - accuracy: 0.3765 - val_loss: 1.4686 - val_accuracy: 0.3256\n",
            "Epoch 294/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5079 - accuracy: 0.3647 - val_loss: 1.4660 - val_accuracy: 0.3256\n",
            "Epoch 295/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4663 - accuracy: 0.4059 - val_loss: 1.4628 - val_accuracy: 0.3256\n",
            "Epoch 296/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4638 - accuracy: 0.3824 - val_loss: 1.4809 - val_accuracy: 0.3256\n",
            "Epoch 297/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5121 - accuracy: 0.3941 - val_loss: 1.4735 - val_accuracy: 0.3256\n",
            "Epoch 298/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5130 - accuracy: 0.4294 - val_loss: 1.4647 - val_accuracy: 0.3256\n",
            "Epoch 299/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4601 - accuracy: 0.4235 - val_loss: 1.4762 - val_accuracy: 0.3721\n",
            "Epoch 300/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5040 - accuracy: 0.3882 - val_loss: 1.4691 - val_accuracy: 0.3256\n",
            "Epoch 301/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4686 - accuracy: 0.3824 - val_loss: 1.4622 - val_accuracy: 0.3256\n",
            "Epoch 302/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4820 - accuracy: 0.3294 - val_loss: 1.4642 - val_accuracy: 0.3488\n",
            "Epoch 303/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4592 - accuracy: 0.4235 - val_loss: 1.4674 - val_accuracy: 0.3256\n",
            "Epoch 304/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4849 - accuracy: 0.4294 - val_loss: 1.4680 - val_accuracy: 0.3256\n",
            "Epoch 305/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4761 - accuracy: 0.4118 - val_loss: 1.4789 - val_accuracy: 0.3488\n",
            "Epoch 306/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4681 - accuracy: 0.4000 - val_loss: 1.4708 - val_accuracy: 0.3256\n",
            "Epoch 307/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4734 - accuracy: 0.4059 - val_loss: 1.4735 - val_accuracy: 0.3256\n",
            "Epoch 308/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4778 - accuracy: 0.3941 - val_loss: 1.4603 - val_accuracy: 0.3256\n",
            "Epoch 309/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4842 - accuracy: 0.3706 - val_loss: 1.4659 - val_accuracy: 0.3488\n",
            "Epoch 310/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4974 - accuracy: 0.3706 - val_loss: 1.4673 - val_accuracy: 0.3488\n",
            "Epoch 311/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4707 - accuracy: 0.3882 - val_loss: 1.4651 - val_accuracy: 0.3256\n",
            "Epoch 312/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4691 - accuracy: 0.4000 - val_loss: 1.4627 - val_accuracy: 0.3256\n",
            "Epoch 313/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4400 - accuracy: 0.4118 - val_loss: 1.4579 - val_accuracy: 0.3488\n",
            "Epoch 314/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4721 - accuracy: 0.3824 - val_loss: 1.4589 - val_accuracy: 0.3256\n",
            "Epoch 315/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4674 - accuracy: 0.4059 - val_loss: 1.4526 - val_accuracy: 0.3488\n",
            "Epoch 316/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4590 - accuracy: 0.3882 - val_loss: 1.4664 - val_accuracy: 0.3256\n",
            "Epoch 317/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5062 - accuracy: 0.3941 - val_loss: 1.4572 - val_accuracy: 0.3488\n",
            "Epoch 318/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4682 - accuracy: 0.4059 - val_loss: 1.4564 - val_accuracy: 0.3721\n",
            "Epoch 319/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4536 - accuracy: 0.4059 - val_loss: 1.4662 - val_accuracy: 0.3256\n",
            "Epoch 320/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4686 - accuracy: 0.3706 - val_loss: 1.4777 - val_accuracy: 0.3256\n",
            "Epoch 321/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4907 - accuracy: 0.3647 - val_loss: 1.4530 - val_accuracy: 0.3488\n",
            "Epoch 322/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4766 - accuracy: 0.3706 - val_loss: 1.4477 - val_accuracy: 0.3256\n",
            "Epoch 323/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4841 - accuracy: 0.4059 - val_loss: 1.4511 - val_accuracy: 0.3488\n",
            "Epoch 324/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4567 - accuracy: 0.4000 - val_loss: 1.4508 - val_accuracy: 0.3023\n",
            "Epoch 325/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4794 - accuracy: 0.4118 - val_loss: 1.4549 - val_accuracy: 0.3023\n",
            "Epoch 326/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4933 - accuracy: 0.3882 - val_loss: 1.4657 - val_accuracy: 0.3488\n",
            "Epoch 327/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4620 - accuracy: 0.3824 - val_loss: 1.4653 - val_accuracy: 0.3488\n",
            "Epoch 328/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5152 - accuracy: 0.3824 - val_loss: 1.4521 - val_accuracy: 0.3256\n",
            "Epoch 329/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4753 - accuracy: 0.3824 - val_loss: 1.5235 - val_accuracy: 0.3023\n",
            "Epoch 330/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4960 - accuracy: 0.3765 - val_loss: 1.4502 - val_accuracy: 0.3488\n",
            "Epoch 331/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4829 - accuracy: 0.3588 - val_loss: 1.4763 - val_accuracy: 0.3488\n",
            "Epoch 332/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4664 - accuracy: 0.4000 - val_loss: 1.4660 - val_accuracy: 0.3256\n",
            "Epoch 333/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4825 - accuracy: 0.3706 - val_loss: 1.4586 - val_accuracy: 0.3256\n",
            "Epoch 334/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4740 - accuracy: 0.3824 - val_loss: 1.4573 - val_accuracy: 0.3256\n",
            "Epoch 335/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4605 - accuracy: 0.4588 - val_loss: 1.4539 - val_accuracy: 0.3023\n",
            "Epoch 336/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4739 - accuracy: 0.3706 - val_loss: 1.4547 - val_accuracy: 0.3256\n",
            "Epoch 337/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4912 - accuracy: 0.3588 - val_loss: 1.4536 - val_accuracy: 0.3488\n",
            "Epoch 338/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4488 - accuracy: 0.4176 - val_loss: 1.4528 - val_accuracy: 0.3256\n",
            "Epoch 339/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4637 - accuracy: 0.3882 - val_loss: 1.4551 - val_accuracy: 0.3488\n",
            "Epoch 340/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4804 - accuracy: 0.3706 - val_loss: 1.4521 - val_accuracy: 0.3256\n",
            "Epoch 341/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4667 - accuracy: 0.3824 - val_loss: 1.4511 - val_accuracy: 0.3023\n",
            "Epoch 342/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4587 - accuracy: 0.4118 - val_loss: 1.4565 - val_accuracy: 0.3023\n",
            "Epoch 343/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4603 - accuracy: 0.4294 - val_loss: 1.4597 - val_accuracy: 0.3488\n",
            "Epoch 344/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4459 - accuracy: 0.4412 - val_loss: 1.4594 - val_accuracy: 0.3488\n",
            "Epoch 345/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4741 - accuracy: 0.3765 - val_loss: 1.4506 - val_accuracy: 0.3256\n",
            "Epoch 346/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4584 - accuracy: 0.3941 - val_loss: 1.4512 - val_accuracy: 0.3256\n",
            "Epoch 347/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4507 - accuracy: 0.4176 - val_loss: 1.4555 - val_accuracy: 0.3023\n",
            "Epoch 348/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4593 - accuracy: 0.4118 - val_loss: 1.4605 - val_accuracy: 0.3488\n",
            "Epoch 349/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4465 - accuracy: 0.4294 - val_loss: 1.4546 - val_accuracy: 0.3256\n",
            "Epoch 350/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4667 - accuracy: 0.4118 - val_loss: 1.4479 - val_accuracy: 0.3023\n",
            "Epoch 351/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4735 - accuracy: 0.3824 - val_loss: 1.4545 - val_accuracy: 0.3256\n",
            "Epoch 352/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4905 - accuracy: 0.4294 - val_loss: 1.4490 - val_accuracy: 0.3023\n",
            "Epoch 353/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4771 - accuracy: 0.3824 - val_loss: 1.4527 - val_accuracy: 0.3023\n",
            "Epoch 354/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4730 - accuracy: 0.4176 - val_loss: 1.4514 - val_accuracy: 0.3256\n",
            "Epoch 355/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4539 - accuracy: 0.4059 - val_loss: 1.4445 - val_accuracy: 0.3256\n",
            "Epoch 356/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4451 - accuracy: 0.4059 - val_loss: 1.4466 - val_accuracy: 0.3256\n",
            "Epoch 357/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4689 - accuracy: 0.4118 - val_loss: 1.4489 - val_accuracy: 0.3256\n",
            "Epoch 358/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4590 - accuracy: 0.4176 - val_loss: 1.4528 - val_accuracy: 0.3256\n",
            "Epoch 359/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4449 - accuracy: 0.4059 - val_loss: 1.4525 - val_accuracy: 0.3256\n",
            "Epoch 360/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4484 - accuracy: 0.4118 - val_loss: 1.4576 - val_accuracy: 0.3488\n",
            "Epoch 361/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4477 - accuracy: 0.3941 - val_loss: 1.4504 - val_accuracy: 0.3256\n",
            "Epoch 362/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4664 - accuracy: 0.3765 - val_loss: 1.4461 - val_accuracy: 0.3488\n",
            "Epoch 363/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4467 - accuracy: 0.4176 - val_loss: 1.4467 - val_accuracy: 0.3256\n",
            "Epoch 364/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4767 - accuracy: 0.4235 - val_loss: 1.4438 - val_accuracy: 0.3256\n",
            "Epoch 365/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4636 - accuracy: 0.4000 - val_loss: 1.4490 - val_accuracy: 0.3488\n",
            "Epoch 366/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4462 - accuracy: 0.4412 - val_loss: 1.4429 - val_accuracy: 0.3256\n",
            "Epoch 367/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4924 - accuracy: 0.4118 - val_loss: 1.4502 - val_accuracy: 0.3256\n",
            "Epoch 368/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4836 - accuracy: 0.3353 - val_loss: 1.4428 - val_accuracy: 0.3488\n",
            "Epoch 369/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4434 - accuracy: 0.3765 - val_loss: 1.4476 - val_accuracy: 0.3256\n",
            "Epoch 370/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4776 - accuracy: 0.3941 - val_loss: 1.4550 - val_accuracy: 0.3488\n",
            "Epoch 371/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4416 - accuracy: 0.3824 - val_loss: 1.4524 - val_accuracy: 0.3256\n",
            "Epoch 372/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4674 - accuracy: 0.4235 - val_loss: 1.4508 - val_accuracy: 0.3023\n",
            "Epoch 373/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4478 - accuracy: 0.3824 - val_loss: 1.4525 - val_accuracy: 0.3488\n",
            "Epoch 374/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4535 - accuracy: 0.4000 - val_loss: 1.4535 - val_accuracy: 0.3256\n",
            "Epoch 375/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4529 - accuracy: 0.4176 - val_loss: 1.4620 - val_accuracy: 0.3256\n",
            "Epoch 376/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5074 - accuracy: 0.3882 - val_loss: 1.4485 - val_accuracy: 0.3256\n",
            "Epoch 377/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4751 - accuracy: 0.3824 - val_loss: 1.4537 - val_accuracy: 0.3256\n",
            "Epoch 378/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4367 - accuracy: 0.3941 - val_loss: 1.4418 - val_accuracy: 0.3256\n",
            "Epoch 379/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4611 - accuracy: 0.3882 - val_loss: 1.4489 - val_accuracy: 0.3256\n",
            "Epoch 380/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4436 - accuracy: 0.3882 - val_loss: 1.4558 - val_accuracy: 0.3488\n",
            "Epoch 381/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4434 - accuracy: 0.4118 - val_loss: 1.4501 - val_accuracy: 0.3023\n",
            "Epoch 382/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4451 - accuracy: 0.4059 - val_loss: 1.4497 - val_accuracy: 0.3023\n",
            "Epoch 383/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4535 - accuracy: 0.3941 - val_loss: 1.4473 - val_accuracy: 0.3256\n",
            "Epoch 384/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4483 - accuracy: 0.3941 - val_loss: 1.4496 - val_accuracy: 0.3256\n",
            "Epoch 385/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4268 - accuracy: 0.4176 - val_loss: 1.4492 - val_accuracy: 0.3488\n",
            "Epoch 386/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4444 - accuracy: 0.4294 - val_loss: 1.4454 - val_accuracy: 0.3256\n",
            "Epoch 387/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4589 - accuracy: 0.4000 - val_loss: 1.4459 - val_accuracy: 0.3256\n",
            "Epoch 388/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4357 - accuracy: 0.4000 - val_loss: 1.4497 - val_accuracy: 0.3488\n",
            "Epoch 389/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4259 - accuracy: 0.4294 - val_loss: 1.4518 - val_accuracy: 0.3488\n",
            "Epoch 390/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4312 - accuracy: 0.3941 - val_loss: 1.4531 - val_accuracy: 0.3488\n",
            "Epoch 391/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4289 - accuracy: 0.4471 - val_loss: 1.4489 - val_accuracy: 0.3488\n",
            "Epoch 392/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4495 - accuracy: 0.3941 - val_loss: 1.4430 - val_accuracy: 0.3488\n",
            "Epoch 393/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4461 - accuracy: 0.3765 - val_loss: 1.4432 - val_accuracy: 0.3256\n",
            "Epoch 394/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4344 - accuracy: 0.4235 - val_loss: 1.4500 - val_accuracy: 0.3953\n",
            "Epoch 395/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4571 - accuracy: 0.3882 - val_loss: 1.4571 - val_accuracy: 0.3721\n",
            "Epoch 396/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4554 - accuracy: 0.3882 - val_loss: 1.4464 - val_accuracy: 0.3488\n",
            "Epoch 397/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4436 - accuracy: 0.4412 - val_loss: 1.4396 - val_accuracy: 0.3488\n",
            "Epoch 398/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4990 - accuracy: 0.3765 - val_loss: 1.4401 - val_accuracy: 0.3721\n",
            "Epoch 399/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4637 - accuracy: 0.4176 - val_loss: 1.4571 - val_accuracy: 0.3721\n",
            "Epoch 400/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4866 - accuracy: 0.4118 - val_loss: 1.4413 - val_accuracy: 0.3721\n",
            "Epoch 401/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4612 - accuracy: 0.4294 - val_loss: 1.4632 - val_accuracy: 0.3721\n",
            "Epoch 402/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4532 - accuracy: 0.3706 - val_loss: 1.4431 - val_accuracy: 0.3256\n",
            "Epoch 403/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4448 - accuracy: 0.4000 - val_loss: 1.4377 - val_accuracy: 0.3256\n",
            "Epoch 404/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4669 - accuracy: 0.3882 - val_loss: 1.4450 - val_accuracy: 0.3256\n",
            "Epoch 405/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4217 - accuracy: 0.4235 - val_loss: 1.4407 - val_accuracy: 0.3721\n",
            "Epoch 406/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4712 - accuracy: 0.3882 - val_loss: 1.4485 - val_accuracy: 0.3953\n",
            "Epoch 407/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4583 - accuracy: 0.4118 - val_loss: 1.4380 - val_accuracy: 0.3721\n",
            "Epoch 408/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4451 - accuracy: 0.4118 - val_loss: 1.4353 - val_accuracy: 0.3488\n",
            "Epoch 409/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4323 - accuracy: 0.4059 - val_loss: 1.4392 - val_accuracy: 0.3721\n",
            "Epoch 410/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4638 - accuracy: 0.3824 - val_loss: 1.4316 - val_accuracy: 0.3488\n",
            "Epoch 411/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4115 - accuracy: 0.4294 - val_loss: 1.4307 - val_accuracy: 0.3721\n",
            "Epoch 412/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4463 - accuracy: 0.4588 - val_loss: 1.4273 - val_accuracy: 0.3953\n",
            "Epoch 413/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.4347 - accuracy: 0.4176 - val_loss: 1.4243 - val_accuracy: 0.3721\n",
            "Epoch 414/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4252 - accuracy: 0.4235 - val_loss: 1.4331 - val_accuracy: 0.3721\n",
            "Epoch 415/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4406 - accuracy: 0.4059 - val_loss: 1.4390 - val_accuracy: 0.3488\n",
            "Epoch 416/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4171 - accuracy: 0.4294 - val_loss: 1.4333 - val_accuracy: 0.3721\n",
            "Epoch 417/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4457 - accuracy: 0.4118 - val_loss: 1.4431 - val_accuracy: 0.3256\n",
            "Epoch 418/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4321 - accuracy: 0.4059 - val_loss: 1.4572 - val_accuracy: 0.3721\n",
            "Epoch 419/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4524 - accuracy: 0.3765 - val_loss: 1.4398 - val_accuracy: 0.3256\n",
            "Epoch 420/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4504 - accuracy: 0.4412 - val_loss: 1.4456 - val_accuracy: 0.3023\n",
            "Epoch 421/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4496 - accuracy: 0.4176 - val_loss: 1.4372 - val_accuracy: 0.3488\n",
            "Epoch 422/2000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4379 - accuracy: 0.4118 - val_loss: 1.4521 - val_accuracy: 0.3256\n",
            "Epoch 423/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4815 - accuracy: 0.4176 - val_loss: 1.4265 - val_accuracy: 0.3488\n",
            "Epoch 424/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4515 - accuracy: 0.4235 - val_loss: 1.4407 - val_accuracy: 0.3953\n",
            "Epoch 425/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4988 - accuracy: 0.3765 - val_loss: 1.4331 - val_accuracy: 0.3721\n",
            "Epoch 426/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4643 - accuracy: 0.3824 - val_loss: 1.4213 - val_accuracy: 0.3256\n",
            "Epoch 427/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4299 - accuracy: 0.4235 - val_loss: 1.4214 - val_accuracy: 0.3256\n",
            "Epoch 428/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4328 - accuracy: 0.4176 - val_loss: 1.4330 - val_accuracy: 0.3488\n",
            "Epoch 429/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4099 - accuracy: 0.4353 - val_loss: 1.4314 - val_accuracy: 0.3721\n",
            "Epoch 430/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4238 - accuracy: 0.4176 - val_loss: 1.4283 - val_accuracy: 0.3721\n",
            "Epoch 431/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4396 - accuracy: 0.4059 - val_loss: 1.4268 - val_accuracy: 0.3488\n",
            "Epoch 432/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4294 - accuracy: 0.4059 - val_loss: 1.4270 - val_accuracy: 0.3256\n",
            "Epoch 433/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4306 - accuracy: 0.4412 - val_loss: 1.4279 - val_accuracy: 0.3488\n",
            "Epoch 434/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4386 - accuracy: 0.4059 - val_loss: 1.4266 - val_accuracy: 0.3721\n",
            "Epoch 435/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4315 - accuracy: 0.4118 - val_loss: 1.4386 - val_accuracy: 0.3256\n",
            "Epoch 436/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4137 - accuracy: 0.4294 - val_loss: 1.4312 - val_accuracy: 0.3256\n",
            "Epoch 437/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4352 - accuracy: 0.4176 - val_loss: 1.4395 - val_accuracy: 0.3256\n",
            "Epoch 438/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4015 - accuracy: 0.4412 - val_loss: 1.4287 - val_accuracy: 0.3023\n",
            "Epoch 439/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4229 - accuracy: 0.4118 - val_loss: 1.4329 - val_accuracy: 0.3488\n",
            "Epoch 440/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4756 - accuracy: 0.4118 - val_loss: 1.4303 - val_accuracy: 0.3721\n",
            "Epoch 441/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4454 - accuracy: 0.4176 - val_loss: 1.4336 - val_accuracy: 0.3721\n",
            "Epoch 442/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4061 - accuracy: 0.4176 - val_loss: 1.4335 - val_accuracy: 0.3721\n",
            "Epoch 443/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4518 - accuracy: 0.4000 - val_loss: 1.4310 - val_accuracy: 0.3256\n",
            "Epoch 444/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4244 - accuracy: 0.4412 - val_loss: 1.4334 - val_accuracy: 0.3488\n",
            "Epoch 445/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4434 - accuracy: 0.4118 - val_loss: 1.4301 - val_accuracy: 0.3488\n",
            "Epoch 446/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4654 - accuracy: 0.4412 - val_loss: 1.4260 - val_accuracy: 0.3488\n",
            "Epoch 447/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4567 - accuracy: 0.3824 - val_loss: 1.4244 - val_accuracy: 0.3256\n",
            "Epoch 448/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4068 - accuracy: 0.4118 - val_loss: 1.4247 - val_accuracy: 0.3256\n",
            "Epoch 449/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4208 - accuracy: 0.4176 - val_loss: 1.4302 - val_accuracy: 0.3721\n",
            "Epoch 450/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4203 - accuracy: 0.4118 - val_loss: 1.4289 - val_accuracy: 0.3488\n",
            "Epoch 451/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4157 - accuracy: 0.3941 - val_loss: 1.4322 - val_accuracy: 0.3488\n",
            "Epoch 452/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4321 - accuracy: 0.4529 - val_loss: 1.4304 - val_accuracy: 0.3488\n",
            "Epoch 453/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4542 - accuracy: 0.3941 - val_loss: 1.4350 - val_accuracy: 0.3488\n",
            "Epoch 454/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4256 - accuracy: 0.4059 - val_loss: 1.4311 - val_accuracy: 0.3488\n",
            "Epoch 455/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4381 - accuracy: 0.4059 - val_loss: 1.4312 - val_accuracy: 0.3488\n",
            "Epoch 456/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4105 - accuracy: 0.4353 - val_loss: 1.4296 - val_accuracy: 0.3953\n",
            "Epoch 457/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4341 - accuracy: 0.4294 - val_loss: 1.4284 - val_accuracy: 0.3953\n",
            "Epoch 458/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4441 - accuracy: 0.4118 - val_loss: 1.4245 - val_accuracy: 0.3488\n",
            "Epoch 459/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4489 - accuracy: 0.4176 - val_loss: 1.4235 - val_accuracy: 0.3488\n",
            "Epoch 460/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4613 - accuracy: 0.4118 - val_loss: 1.4230 - val_accuracy: 0.3488\n",
            "Epoch 461/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4512 - accuracy: 0.4176 - val_loss: 1.4221 - val_accuracy: 0.3721\n",
            "Epoch 462/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4503 - accuracy: 0.4294 - val_loss: 1.4228 - val_accuracy: 0.3721\n",
            "Epoch 463/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4187 - accuracy: 0.4294 - val_loss: 1.4236 - val_accuracy: 0.3721\n",
            "Epoch 464/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4346 - accuracy: 0.4353 - val_loss: 1.4233 - val_accuracy: 0.3953\n",
            "Epoch 465/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4535 - accuracy: 0.4529 - val_loss: 1.4190 - val_accuracy: 0.3721\n",
            "Epoch 466/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4380 - accuracy: 0.4294 - val_loss: 1.4215 - val_accuracy: 0.3721\n",
            "Epoch 467/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4376 - accuracy: 0.4235 - val_loss: 1.4191 - val_accuracy: 0.3721\n",
            "Epoch 468/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4578 - accuracy: 0.4353 - val_loss: 1.4161 - val_accuracy: 0.3721\n",
            "Epoch 469/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4161 - accuracy: 0.3882 - val_loss: 1.4122 - val_accuracy: 0.3256\n",
            "Epoch 470/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4492 - accuracy: 0.4176 - val_loss: 1.4138 - val_accuracy: 0.3721\n",
            "Epoch 471/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4236 - accuracy: 0.4118 - val_loss: 1.4134 - val_accuracy: 0.3721\n",
            "Epoch 472/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4347 - accuracy: 0.4412 - val_loss: 1.4208 - val_accuracy: 0.3488\n",
            "Epoch 473/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4361 - accuracy: 0.3941 - val_loss: 1.4264 - val_accuracy: 0.3721\n",
            "Epoch 474/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4234 - accuracy: 0.4000 - val_loss: 1.4195 - val_accuracy: 0.3488\n",
            "Epoch 475/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4400 - accuracy: 0.4118 - val_loss: 1.4202 - val_accuracy: 0.3488\n",
            "Epoch 476/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4376 - accuracy: 0.4000 - val_loss: 1.4231 - val_accuracy: 0.3721\n",
            "Epoch 477/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4093 - accuracy: 0.4353 - val_loss: 1.4250 - val_accuracy: 0.3721\n",
            "Epoch 478/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4050 - accuracy: 0.4118 - val_loss: 1.4214 - val_accuracy: 0.3953\n",
            "Epoch 479/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4269 - accuracy: 0.4118 - val_loss: 1.4244 - val_accuracy: 0.3721\n",
            "Epoch 480/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4237 - accuracy: 0.4412 - val_loss: 1.4268 - val_accuracy: 0.3721\n",
            "Epoch 481/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4126 - accuracy: 0.4235 - val_loss: 1.4246 - val_accuracy: 0.3721\n",
            "Epoch 482/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4192 - accuracy: 0.4000 - val_loss: 1.4284 - val_accuracy: 0.3953\n",
            "Epoch 483/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4511 - accuracy: 0.4412 - val_loss: 1.4308 - val_accuracy: 0.3953\n",
            "Epoch 484/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4564 - accuracy: 0.4059 - val_loss: 1.4292 - val_accuracy: 0.3721\n",
            "Epoch 485/2000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.4030 - accuracy: 0.4588 - val_loss: 1.4329 - val_accuracy: 0.3721\n",
            "Epoch 486/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.4375 - accuracy: 0.4294 - val_loss: 1.4255 - val_accuracy: 0.3488\n",
            "Epoch 487/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4000 - accuracy: 0.4176 - val_loss: 1.4251 - val_accuracy: 0.3721\n",
            "Epoch 488/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4105 - accuracy: 0.4471 - val_loss: 1.4267 - val_accuracy: 0.3953\n",
            "Epoch 489/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4347 - accuracy: 0.4235 - val_loss: 1.4225 - val_accuracy: 0.3721\n",
            "Epoch 490/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4235 - accuracy: 0.4118 - val_loss: 1.4262 - val_accuracy: 0.3488\n",
            "Epoch 491/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4363 - accuracy: 0.4471 - val_loss: 1.4297 - val_accuracy: 0.3953\n",
            "Epoch 492/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4157 - accuracy: 0.4294 - val_loss: 1.4373 - val_accuracy: 0.3953\n",
            "Epoch 493/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4273 - accuracy: 0.4235 - val_loss: 1.4338 - val_accuracy: 0.3721\n",
            "Epoch 494/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4316 - accuracy: 0.4353 - val_loss: 1.4275 - val_accuracy: 0.3721\n",
            "Epoch 495/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4225 - accuracy: 0.4235 - val_loss: 1.4267 - val_accuracy: 0.3953\n",
            "Epoch 496/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4318 - accuracy: 0.3941 - val_loss: 1.4237 - val_accuracy: 0.3953\n",
            "Epoch 497/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4144 - accuracy: 0.4235 - val_loss: 1.4172 - val_accuracy: 0.3721\n",
            "Epoch 498/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4112 - accuracy: 0.4412 - val_loss: 1.4182 - val_accuracy: 0.3953\n",
            "Epoch 499/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4232 - accuracy: 0.4118 - val_loss: 1.4232 - val_accuracy: 0.4186\n",
            "Epoch 500/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3985 - accuracy: 0.4471 - val_loss: 1.4228 - val_accuracy: 0.3953\n",
            "Epoch 501/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4245 - accuracy: 0.4471 - val_loss: 1.4306 - val_accuracy: 0.3953\n",
            "Epoch 502/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4332 - accuracy: 0.4412 - val_loss: 1.4282 - val_accuracy: 0.3721\n",
            "Epoch 503/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4211 - accuracy: 0.4353 - val_loss: 1.4324 - val_accuracy: 0.3488\n",
            "Epoch 504/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3934 - accuracy: 0.4412 - val_loss: 1.4332 - val_accuracy: 0.3721\n",
            "Epoch 505/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4293 - accuracy: 0.4118 - val_loss: 1.4317 - val_accuracy: 0.3721\n",
            "Epoch 506/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4320 - accuracy: 0.4235 - val_loss: 1.4231 - val_accuracy: 0.3953\n",
            "Epoch 507/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4120 - accuracy: 0.4118 - val_loss: 1.4154 - val_accuracy: 0.3721\n",
            "Epoch 508/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4123 - accuracy: 0.4118 - val_loss: 1.4144 - val_accuracy: 0.3488\n",
            "Epoch 509/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4250 - accuracy: 0.4000 - val_loss: 1.4156 - val_accuracy: 0.3721\n",
            "Epoch 510/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4231 - accuracy: 0.4235 - val_loss: 1.4180 - val_accuracy: 0.3721\n",
            "Epoch 511/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4105 - accuracy: 0.4412 - val_loss: 1.4195 - val_accuracy: 0.3721\n",
            "Epoch 512/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4229 - accuracy: 0.4471 - val_loss: 1.4215 - val_accuracy: 0.3953\n",
            "Epoch 513/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4187 - accuracy: 0.4176 - val_loss: 1.4226 - val_accuracy: 0.3953\n",
            "Epoch 514/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3986 - accuracy: 0.4471 - val_loss: 1.4187 - val_accuracy: 0.3953\n",
            "Epoch 515/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4058 - accuracy: 0.4529 - val_loss: 1.4187 - val_accuracy: 0.4186\n",
            "Epoch 516/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4459 - accuracy: 0.4412 - val_loss: 1.4133 - val_accuracy: 0.3953\n",
            "Epoch 517/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4041 - accuracy: 0.4412 - val_loss: 1.4162 - val_accuracy: 0.3488\n",
            "Epoch 518/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3950 - accuracy: 0.4235 - val_loss: 1.4153 - val_accuracy: 0.3721\n",
            "Epoch 519/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4253 - accuracy: 0.4000 - val_loss: 1.4161 - val_accuracy: 0.3488\n",
            "Epoch 520/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4012 - accuracy: 0.4471 - val_loss: 1.4190 - val_accuracy: 0.3721\n",
            "Epoch 521/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4325 - accuracy: 0.4235 - val_loss: 1.4212 - val_accuracy: 0.3721\n",
            "Epoch 522/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4149 - accuracy: 0.4588 - val_loss: 1.4208 - val_accuracy: 0.3721\n",
            "Epoch 523/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4286 - accuracy: 0.4059 - val_loss: 1.4190 - val_accuracy: 0.3721\n",
            "Epoch 524/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4167 - accuracy: 0.4118 - val_loss: 1.4211 - val_accuracy: 0.3721\n",
            "Epoch 525/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4365 - accuracy: 0.4294 - val_loss: 1.4275 - val_accuracy: 0.3953\n",
            "Epoch 526/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4339 - accuracy: 0.4059 - val_loss: 1.4228 - val_accuracy: 0.3721\n",
            "Epoch 527/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.4158 - accuracy: 0.4176 - val_loss: 1.4242 - val_accuracy: 0.3721\n",
            "Epoch 528/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3852 - accuracy: 0.4353 - val_loss: 1.4199 - val_accuracy: 0.3953\n",
            "Epoch 529/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4021 - accuracy: 0.4235 - val_loss: 1.4142 - val_accuracy: 0.3721\n",
            "Epoch 530/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3827 - accuracy: 0.3941 - val_loss: 1.4105 - val_accuracy: 0.3721\n",
            "Epoch 531/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4164 - accuracy: 0.4000 - val_loss: 1.4163 - val_accuracy: 0.3488\n",
            "Epoch 532/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4517 - accuracy: 0.4118 - val_loss: 1.4225 - val_accuracy: 0.4419\n",
            "Epoch 533/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4013 - accuracy: 0.4235 - val_loss: 1.4244 - val_accuracy: 0.3953\n",
            "Epoch 534/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4174 - accuracy: 0.4294 - val_loss: 1.4077 - val_accuracy: 0.3488\n",
            "Epoch 535/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4212 - accuracy: 0.4118 - val_loss: 1.4083 - val_accuracy: 0.3256\n",
            "Epoch 536/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4163 - accuracy: 0.4235 - val_loss: 1.4076 - val_accuracy: 0.3721\n",
            "Epoch 537/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.4432 - accuracy: 0.4353 - val_loss: 1.4147 - val_accuracy: 0.3953\n",
            "Epoch 538/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4059 - accuracy: 0.4294 - val_loss: 1.4176 - val_accuracy: 0.3953\n",
            "Epoch 539/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4259 - accuracy: 0.4412 - val_loss: 1.4164 - val_accuracy: 0.3953\n",
            "Epoch 540/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3804 - accuracy: 0.4412 - val_loss: 1.4110 - val_accuracy: 0.3721\n",
            "Epoch 541/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4221 - accuracy: 0.3941 - val_loss: 1.4136 - val_accuracy: 0.3953\n",
            "Epoch 542/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4046 - accuracy: 0.4235 - val_loss: 1.4191 - val_accuracy: 0.4186\n",
            "Epoch 543/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3904 - accuracy: 0.4529 - val_loss: 1.4133 - val_accuracy: 0.3721\n",
            "Epoch 544/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4068 - accuracy: 0.4294 - val_loss: 1.4118 - val_accuracy: 0.3721\n",
            "Epoch 545/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4310 - accuracy: 0.4471 - val_loss: 1.4084 - val_accuracy: 0.3488\n",
            "Epoch 546/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4210 - accuracy: 0.4529 - val_loss: 1.4088 - val_accuracy: 0.3953\n",
            "Epoch 547/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4186 - accuracy: 0.4059 - val_loss: 1.4226 - val_accuracy: 0.4419\n",
            "Epoch 548/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4300 - accuracy: 0.4412 - val_loss: 1.4160 - val_accuracy: 0.4186\n",
            "Epoch 549/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4205 - accuracy: 0.4294 - val_loss: 1.4083 - val_accuracy: 0.3488\n",
            "Epoch 550/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4089 - accuracy: 0.4118 - val_loss: 1.4085 - val_accuracy: 0.3488\n",
            "Epoch 551/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4392 - accuracy: 0.4294 - val_loss: 1.4114 - val_accuracy: 0.3953\n",
            "Epoch 552/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3947 - accuracy: 0.4235 - val_loss: 1.4210 - val_accuracy: 0.3953\n",
            "Epoch 553/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4142 - accuracy: 0.4235 - val_loss: 1.4237 - val_accuracy: 0.4419\n",
            "Epoch 554/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4174 - accuracy: 0.4471 - val_loss: 1.4118 - val_accuracy: 0.3953\n",
            "Epoch 555/2000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.3857 - accuracy: 0.4294 - val_loss: 1.4108 - val_accuracy: 0.3721\n",
            "Epoch 556/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.4092 - accuracy: 0.4000 - val_loss: 1.4081 - val_accuracy: 0.3721\n",
            "Epoch 557/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4216 - accuracy: 0.4176 - val_loss: 1.4173 - val_accuracy: 0.3953\n",
            "Epoch 558/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4222 - accuracy: 0.4294 - val_loss: 1.4341 - val_accuracy: 0.3953\n",
            "Epoch 559/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4036 - accuracy: 0.3765 - val_loss: 1.4223 - val_accuracy: 0.3953\n",
            "Epoch 560/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4140 - accuracy: 0.4294 - val_loss: 1.4289 - val_accuracy: 0.3721\n",
            "Epoch 561/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4173 - accuracy: 0.4353 - val_loss: 1.4272 - val_accuracy: 0.3488\n",
            "Epoch 562/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4072 - accuracy: 0.4588 - val_loss: 1.4208 - val_accuracy: 0.3953\n",
            "Epoch 563/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3900 - accuracy: 0.4176 - val_loss: 1.4256 - val_accuracy: 0.3721\n",
            "Epoch 564/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4069 - accuracy: 0.4353 - val_loss: 1.4188 - val_accuracy: 0.3953\n",
            "Epoch 565/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4067 - accuracy: 0.4176 - val_loss: 1.4237 - val_accuracy: 0.3721\n",
            "Epoch 566/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4137 - accuracy: 0.4412 - val_loss: 1.4240 - val_accuracy: 0.3488\n",
            "Epoch 567/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4158 - accuracy: 0.4235 - val_loss: 1.4240 - val_accuracy: 0.3721\n",
            "Epoch 568/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3728 - accuracy: 0.4471 - val_loss: 1.4336 - val_accuracy: 0.4419\n",
            "Epoch 569/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.4090 - accuracy: 0.4647 - val_loss: 1.4340 - val_accuracy: 0.4419\n",
            "Epoch 570/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4099 - accuracy: 0.4471 - val_loss: 1.4197 - val_accuracy: 0.3953\n",
            "Epoch 571/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3866 - accuracy: 0.4118 - val_loss: 1.4189 - val_accuracy: 0.3953\n",
            "Epoch 572/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3940 - accuracy: 0.4353 - val_loss: 1.4183 - val_accuracy: 0.3953\n",
            "Epoch 573/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3961 - accuracy: 0.4353 - val_loss: 1.4171 - val_accuracy: 0.4186\n",
            "Epoch 574/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.4068 - accuracy: 0.4294 - val_loss: 1.4107 - val_accuracy: 0.4186\n",
            "Epoch 575/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3969 - accuracy: 0.4294 - val_loss: 1.4128 - val_accuracy: 0.3953\n",
            "Epoch 576/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3741 - accuracy: 0.4412 - val_loss: 1.4168 - val_accuracy: 0.3953\n",
            "Epoch 577/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3777 - accuracy: 0.4471 - val_loss: 1.4339 - val_accuracy: 0.3488\n",
            "Epoch 578/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.4463 - accuracy: 0.3941 - val_loss: 1.4427 - val_accuracy: 0.3256\n",
            "Epoch 579/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3928 - accuracy: 0.4235 - val_loss: 1.4345 - val_accuracy: 0.3953\n",
            "Epoch 580/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3853 - accuracy: 0.4294 - val_loss: 1.4350 - val_accuracy: 0.4419\n",
            "Epoch 581/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4228 - accuracy: 0.4176 - val_loss: 1.4367 - val_accuracy: 0.3953\n",
            "Epoch 582/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4086 - accuracy: 0.4529 - val_loss: 1.4171 - val_accuracy: 0.4419\n",
            "Epoch 583/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3704 - accuracy: 0.4059 - val_loss: 1.4066 - val_accuracy: 0.4186\n",
            "Epoch 584/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3971 - accuracy: 0.4353 - val_loss: 1.4005 - val_accuracy: 0.3953\n",
            "Epoch 585/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4129 - accuracy: 0.4294 - val_loss: 1.4008 - val_accuracy: 0.3953\n",
            "Epoch 586/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3757 - accuracy: 0.4294 - val_loss: 1.4092 - val_accuracy: 0.3953\n",
            "Epoch 587/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3906 - accuracy: 0.4412 - val_loss: 1.4140 - val_accuracy: 0.4186\n",
            "Epoch 588/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3982 - accuracy: 0.4529 - val_loss: 1.4168 - val_accuracy: 0.4186\n",
            "Epoch 589/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3949 - accuracy: 0.4529 - val_loss: 1.4339 - val_accuracy: 0.3488\n",
            "Epoch 590/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4072 - accuracy: 0.4412 - val_loss: 1.4146 - val_accuracy: 0.3721\n",
            "Epoch 591/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4011 - accuracy: 0.4647 - val_loss: 1.4141 - val_accuracy: 0.4186\n",
            "Epoch 592/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3993 - accuracy: 0.4294 - val_loss: 1.4180 - val_accuracy: 0.4419\n",
            "Epoch 593/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3884 - accuracy: 0.4235 - val_loss: 1.4106 - val_accuracy: 0.4186\n",
            "Epoch 594/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3866 - accuracy: 0.4235 - val_loss: 1.4111 - val_accuracy: 0.3721\n",
            "Epoch 595/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4288 - accuracy: 0.4176 - val_loss: 1.4126 - val_accuracy: 0.3953\n",
            "Epoch 596/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4036 - accuracy: 0.4471 - val_loss: 1.4078 - val_accuracy: 0.3953\n",
            "Epoch 597/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4129 - accuracy: 0.4059 - val_loss: 1.4092 - val_accuracy: 0.3953\n",
            "Epoch 598/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4013 - accuracy: 0.4176 - val_loss: 1.4127 - val_accuracy: 0.3721\n",
            "Epoch 599/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3993 - accuracy: 0.4000 - val_loss: 1.4131 - val_accuracy: 0.3488\n",
            "Epoch 600/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3874 - accuracy: 0.4588 - val_loss: 1.4113 - val_accuracy: 0.4186\n",
            "Epoch 601/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3943 - accuracy: 0.4471 - val_loss: 1.4186 - val_accuracy: 0.3953\n",
            "Epoch 602/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.4046 - accuracy: 0.4706 - val_loss: 1.4087 - val_accuracy: 0.4186\n",
            "Epoch 603/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3945 - accuracy: 0.4529 - val_loss: 1.4084 - val_accuracy: 0.3953\n",
            "Epoch 604/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4178 - accuracy: 0.4294 - val_loss: 1.4060 - val_accuracy: 0.4186\n",
            "Epoch 605/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3772 - accuracy: 0.4118 - val_loss: 1.4072 - val_accuracy: 0.3953\n",
            "Epoch 606/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3897 - accuracy: 0.4176 - val_loss: 1.4177 - val_accuracy: 0.4419\n",
            "Epoch 607/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4005 - accuracy: 0.4412 - val_loss: 1.4275 - val_accuracy: 0.4419\n",
            "Epoch 608/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4243 - accuracy: 0.4471 - val_loss: 1.4075 - val_accuracy: 0.4186\n",
            "Epoch 609/2000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1.3815 - accuracy: 0.4647 - val_loss: 1.4062 - val_accuracy: 0.3953\n",
            "Epoch 610/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3900 - accuracy: 0.4529 - val_loss: 1.3964 - val_accuracy: 0.3953\n",
            "Epoch 611/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3959 - accuracy: 0.4529 - val_loss: 1.3995 - val_accuracy: 0.3721\n",
            "Epoch 612/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4068 - accuracy: 0.4412 - val_loss: 1.3902 - val_accuracy: 0.4186\n",
            "Epoch 613/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3834 - accuracy: 0.4118 - val_loss: 1.3928 - val_accuracy: 0.4419\n",
            "Epoch 614/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3881 - accuracy: 0.4529 - val_loss: 1.4032 - val_accuracy: 0.4186\n",
            "Epoch 615/2000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.3905 - accuracy: 0.4588 - val_loss: 1.4032 - val_accuracy: 0.3721\n",
            "Epoch 616/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3757 - accuracy: 0.4824 - val_loss: 1.4112 - val_accuracy: 0.4186\n",
            "Epoch 617/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3771 - accuracy: 0.4882 - val_loss: 1.4158 - val_accuracy: 0.4186\n",
            "Epoch 618/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3686 - accuracy: 0.4294 - val_loss: 1.4012 - val_accuracy: 0.4186\n",
            "Epoch 619/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3684 - accuracy: 0.4647 - val_loss: 1.3956 - val_accuracy: 0.4419\n",
            "Epoch 620/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3666 - accuracy: 0.4412 - val_loss: 1.4002 - val_accuracy: 0.3721\n",
            "Epoch 621/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3940 - accuracy: 0.4471 - val_loss: 1.3913 - val_accuracy: 0.3721\n",
            "Epoch 622/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3790 - accuracy: 0.4471 - val_loss: 1.3893 - val_accuracy: 0.4186\n",
            "Epoch 623/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3723 - accuracy: 0.4588 - val_loss: 1.3922 - val_accuracy: 0.4186\n",
            "Epoch 624/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3728 - accuracy: 0.4471 - val_loss: 1.3947 - val_accuracy: 0.3953\n",
            "Epoch 625/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3784 - accuracy: 0.4412 - val_loss: 1.3925 - val_accuracy: 0.4186\n",
            "Epoch 626/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4030 - accuracy: 0.4118 - val_loss: 1.3874 - val_accuracy: 0.3953\n",
            "Epoch 627/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3887 - accuracy: 0.4176 - val_loss: 1.3926 - val_accuracy: 0.3953\n",
            "Epoch 628/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.4035 - accuracy: 0.4412 - val_loss: 1.3921 - val_accuracy: 0.3953\n",
            "Epoch 629/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4075 - accuracy: 0.4176 - val_loss: 1.3879 - val_accuracy: 0.4186\n",
            "Epoch 630/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3879 - accuracy: 0.4353 - val_loss: 1.4063 - val_accuracy: 0.3721\n",
            "Epoch 631/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3603 - accuracy: 0.4235 - val_loss: 1.3931 - val_accuracy: 0.4419\n",
            "Epoch 632/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3835 - accuracy: 0.4353 - val_loss: 1.3884 - val_accuracy: 0.4419\n",
            "Epoch 633/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4054 - accuracy: 0.4471 - val_loss: 1.3988 - val_accuracy: 0.4186\n",
            "Epoch 634/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3918 - accuracy: 0.4529 - val_loss: 1.3922 - val_accuracy: 0.4651\n",
            "Epoch 635/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3839 - accuracy: 0.4294 - val_loss: 1.3940 - val_accuracy: 0.4186\n",
            "Epoch 636/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4123 - accuracy: 0.4176 - val_loss: 1.3898 - val_accuracy: 0.3953\n",
            "Epoch 637/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3882 - accuracy: 0.4176 - val_loss: 1.4016 - val_accuracy: 0.3721\n",
            "Epoch 638/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3803 - accuracy: 0.4235 - val_loss: 1.3903 - val_accuracy: 0.4419\n",
            "Epoch 639/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3896 - accuracy: 0.4471 - val_loss: 1.3913 - val_accuracy: 0.4419\n",
            "Epoch 640/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3917 - accuracy: 0.4353 - val_loss: 1.3961 - val_accuracy: 0.4186\n",
            "Epoch 641/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3759 - accuracy: 0.4941 - val_loss: 1.3981 - val_accuracy: 0.4419\n",
            "Epoch 642/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3545 - accuracy: 0.4706 - val_loss: 1.4030 - val_accuracy: 0.3953\n",
            "Epoch 643/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4009 - accuracy: 0.4588 - val_loss: 1.3999 - val_accuracy: 0.4186\n",
            "Epoch 644/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3864 - accuracy: 0.4412 - val_loss: 1.3992 - val_accuracy: 0.4186\n",
            "Epoch 645/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3600 - accuracy: 0.4176 - val_loss: 1.3956 - val_accuracy: 0.3953\n",
            "Epoch 646/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3698 - accuracy: 0.4353 - val_loss: 1.3912 - val_accuracy: 0.4419\n",
            "Epoch 647/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4008 - accuracy: 0.4353 - val_loss: 1.3908 - val_accuracy: 0.4186\n",
            "Epoch 648/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3923 - accuracy: 0.4529 - val_loss: 1.3959 - val_accuracy: 0.4419\n",
            "Epoch 649/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3889 - accuracy: 0.4176 - val_loss: 1.3889 - val_accuracy: 0.4186\n",
            "Epoch 650/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3926 - accuracy: 0.4529 - val_loss: 1.4017 - val_accuracy: 0.4186\n",
            "Epoch 651/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3810 - accuracy: 0.4235 - val_loss: 1.3907 - val_accuracy: 0.4186\n",
            "Epoch 652/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3767 - accuracy: 0.4471 - val_loss: 1.3922 - val_accuracy: 0.4419\n",
            "Epoch 653/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3905 - accuracy: 0.4176 - val_loss: 1.3964 - val_accuracy: 0.4419\n",
            "Epoch 654/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3900 - accuracy: 0.4588 - val_loss: 1.3930 - val_accuracy: 0.4186\n",
            "Epoch 655/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3644 - accuracy: 0.4471 - val_loss: 1.3967 - val_accuracy: 0.3953\n",
            "Epoch 656/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3831 - accuracy: 0.4118 - val_loss: 1.3979 - val_accuracy: 0.4186\n",
            "Epoch 657/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3974 - accuracy: 0.4471 - val_loss: 1.3988 - val_accuracy: 0.4186\n",
            "Epoch 658/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3991 - accuracy: 0.4529 - val_loss: 1.4005 - val_accuracy: 0.4186\n",
            "Epoch 659/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3887 - accuracy: 0.4471 - val_loss: 1.3984 - val_accuracy: 0.4186\n",
            "Epoch 660/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3901 - accuracy: 0.4471 - val_loss: 1.4001 - val_accuracy: 0.4186\n",
            "Epoch 661/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3682 - accuracy: 0.4588 - val_loss: 1.4051 - val_accuracy: 0.3953\n",
            "Epoch 662/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3639 - accuracy: 0.4176 - val_loss: 1.4007 - val_accuracy: 0.3953\n",
            "Epoch 663/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4050 - accuracy: 0.4235 - val_loss: 1.4035 - val_accuracy: 0.3721\n",
            "Epoch 664/2000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.3787 - accuracy: 0.4647 - val_loss: 1.4089 - val_accuracy: 0.4419\n",
            "Epoch 665/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3718 - accuracy: 0.4353 - val_loss: 1.3996 - val_accuracy: 0.4651\n",
            "Epoch 666/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3933 - accuracy: 0.4412 - val_loss: 1.3935 - val_accuracy: 0.3953\n",
            "Epoch 667/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4204 - accuracy: 0.4059 - val_loss: 1.3931 - val_accuracy: 0.4419\n",
            "Epoch 668/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3884 - accuracy: 0.4353 - val_loss: 1.3992 - val_accuracy: 0.4186\n",
            "Epoch 669/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3626 - accuracy: 0.4588 - val_loss: 1.4008 - val_accuracy: 0.4419\n",
            "Epoch 670/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3527 - accuracy: 0.4471 - val_loss: 1.3992 - val_accuracy: 0.4419\n",
            "Epoch 671/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3505 - accuracy: 0.4647 - val_loss: 1.4063 - val_accuracy: 0.3953\n",
            "Epoch 672/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3911 - accuracy: 0.4294 - val_loss: 1.3982 - val_accuracy: 0.3721\n",
            "Epoch 673/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3742 - accuracy: 0.4353 - val_loss: 1.3926 - val_accuracy: 0.3721\n",
            "Epoch 674/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3775 - accuracy: 0.4529 - val_loss: 1.3937 - val_accuracy: 0.4186\n",
            "Epoch 675/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3439 - accuracy: 0.4529 - val_loss: 1.3959 - val_accuracy: 0.3953\n",
            "Epoch 676/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3839 - accuracy: 0.4412 - val_loss: 1.3936 - val_accuracy: 0.3953\n",
            "Epoch 677/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3936 - accuracy: 0.4412 - val_loss: 1.3948 - val_accuracy: 0.3721\n",
            "Epoch 678/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3544 - accuracy: 0.4647 - val_loss: 1.4025 - val_accuracy: 0.3953\n",
            "Epoch 679/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3676 - accuracy: 0.4471 - val_loss: 1.4000 - val_accuracy: 0.4419\n",
            "Epoch 680/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3682 - accuracy: 0.4647 - val_loss: 1.4009 - val_accuracy: 0.4186\n",
            "Epoch 681/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3791 - accuracy: 0.4235 - val_loss: 1.4012 - val_accuracy: 0.4186\n",
            "Epoch 682/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3627 - accuracy: 0.4176 - val_loss: 1.4177 - val_accuracy: 0.3721\n",
            "Epoch 683/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3463 - accuracy: 0.4824 - val_loss: 1.3930 - val_accuracy: 0.4651\n",
            "Epoch 684/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3566 - accuracy: 0.4647 - val_loss: 1.3850 - val_accuracy: 0.4419\n",
            "Epoch 685/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3763 - accuracy: 0.4353 - val_loss: 1.3834 - val_accuracy: 0.4419\n",
            "Epoch 686/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3744 - accuracy: 0.4235 - val_loss: 1.3828 - val_accuracy: 0.4419\n",
            "Epoch 687/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3812 - accuracy: 0.4471 - val_loss: 1.3832 - val_accuracy: 0.4419\n",
            "Epoch 688/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3677 - accuracy: 0.4235 - val_loss: 1.3831 - val_accuracy: 0.4419\n",
            "Epoch 689/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3997 - accuracy: 0.4353 - val_loss: 1.3893 - val_accuracy: 0.4419\n",
            "Epoch 690/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4004 - accuracy: 0.4706 - val_loss: 1.3991 - val_accuracy: 0.4419\n",
            "Epoch 691/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3941 - accuracy: 0.4000 - val_loss: 1.3984 - val_accuracy: 0.4419\n",
            "Epoch 692/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3631 - accuracy: 0.4588 - val_loss: 1.3905 - val_accuracy: 0.4186\n",
            "Epoch 693/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3700 - accuracy: 0.4471 - val_loss: 1.3866 - val_accuracy: 0.4186\n",
            "Epoch 694/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3751 - accuracy: 0.4529 - val_loss: 1.3854 - val_accuracy: 0.4186\n",
            "Epoch 695/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3709 - accuracy: 0.4294 - val_loss: 1.4017 - val_accuracy: 0.3953\n",
            "Epoch 696/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3985 - accuracy: 0.4059 - val_loss: 1.3967 - val_accuracy: 0.4186\n",
            "Epoch 697/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3696 - accuracy: 0.4353 - val_loss: 1.3957 - val_accuracy: 0.4186\n",
            "Epoch 698/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3670 - accuracy: 0.4235 - val_loss: 1.3983 - val_accuracy: 0.3953\n",
            "Epoch 699/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3527 - accuracy: 0.4706 - val_loss: 1.3985 - val_accuracy: 0.3953\n",
            "Epoch 700/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3894 - accuracy: 0.4059 - val_loss: 1.3921 - val_accuracy: 0.4419\n",
            "Epoch 701/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3754 - accuracy: 0.4118 - val_loss: 1.3886 - val_accuracy: 0.4651\n",
            "Epoch 702/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3734 - accuracy: 0.4529 - val_loss: 1.3856 - val_accuracy: 0.4884\n",
            "Epoch 703/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3716 - accuracy: 0.4706 - val_loss: 1.3813 - val_accuracy: 0.4651\n",
            "Epoch 704/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3922 - accuracy: 0.4471 - val_loss: 1.3744 - val_accuracy: 0.4651\n",
            "Epoch 705/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3670 - accuracy: 0.4588 - val_loss: 1.3765 - val_accuracy: 0.4651\n",
            "Epoch 706/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4050 - accuracy: 0.4059 - val_loss: 1.3798 - val_accuracy: 0.4651\n",
            "Epoch 707/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3873 - accuracy: 0.4471 - val_loss: 1.3863 - val_accuracy: 0.4884\n",
            "Epoch 708/2000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.3796 - accuracy: 0.4588 - val_loss: 1.3880 - val_accuracy: 0.4419\n",
            "Epoch 709/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3569 - accuracy: 0.4765 - val_loss: 1.3892 - val_accuracy: 0.4651\n",
            "Epoch 710/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3588 - accuracy: 0.4529 - val_loss: 1.3800 - val_accuracy: 0.4186\n",
            "Epoch 711/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3829 - accuracy: 0.4471 - val_loss: 1.3819 - val_accuracy: 0.4186\n",
            "Epoch 712/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3671 - accuracy: 0.4706 - val_loss: 1.3937 - val_accuracy: 0.4419\n",
            "Epoch 713/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3464 - accuracy: 0.4588 - val_loss: 1.3952 - val_accuracy: 0.4186\n",
            "Epoch 714/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3447 - accuracy: 0.4412 - val_loss: 1.3969 - val_accuracy: 0.4419\n",
            "Epoch 715/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3651 - accuracy: 0.4706 - val_loss: 1.3906 - val_accuracy: 0.4186\n",
            "Epoch 716/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3683 - accuracy: 0.4235 - val_loss: 1.3864 - val_accuracy: 0.3721\n",
            "Epoch 717/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3661 - accuracy: 0.4588 - val_loss: 1.3951 - val_accuracy: 0.4419\n",
            "Epoch 718/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3520 - accuracy: 0.4765 - val_loss: 1.3881 - val_accuracy: 0.4186\n",
            "Epoch 719/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3422 - accuracy: 0.4647 - val_loss: 1.3882 - val_accuracy: 0.4186\n",
            "Epoch 720/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3660 - accuracy: 0.4529 - val_loss: 1.3927 - val_accuracy: 0.3953\n",
            "Epoch 721/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3310 - accuracy: 0.4765 - val_loss: 1.3967 - val_accuracy: 0.3953\n",
            "Epoch 722/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3807 - accuracy: 0.4353 - val_loss: 1.3954 - val_accuracy: 0.4186\n",
            "Epoch 723/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3474 - accuracy: 0.4353 - val_loss: 1.3974 - val_accuracy: 0.4419\n",
            "Epoch 724/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3382 - accuracy: 0.4706 - val_loss: 1.3919 - val_accuracy: 0.4186\n",
            "Epoch 725/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3643 - accuracy: 0.4118 - val_loss: 1.3841 - val_accuracy: 0.4186\n",
            "Epoch 726/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4015 - accuracy: 0.4471 - val_loss: 1.3754 - val_accuracy: 0.3953\n",
            "Epoch 727/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4080 - accuracy: 0.4529 - val_loss: 1.3775 - val_accuracy: 0.4419\n",
            "Epoch 728/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3675 - accuracy: 0.4529 - val_loss: 1.3803 - val_accuracy: 0.4651\n",
            "Epoch 729/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3666 - accuracy: 0.4941 - val_loss: 1.3768 - val_accuracy: 0.4419\n",
            "Epoch 730/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3847 - accuracy: 0.4471 - val_loss: 1.3811 - val_accuracy: 0.4419\n",
            "Epoch 731/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3605 - accuracy: 0.4647 - val_loss: 1.3844 - val_accuracy: 0.4651\n",
            "Epoch 732/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3978 - accuracy: 0.4412 - val_loss: 1.3769 - val_accuracy: 0.4419\n",
            "Epoch 733/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3409 - accuracy: 0.4588 - val_loss: 1.3871 - val_accuracy: 0.3953\n",
            "Epoch 734/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3476 - accuracy: 0.4412 - val_loss: 1.3848 - val_accuracy: 0.4186\n",
            "Epoch 735/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3623 - accuracy: 0.4529 - val_loss: 1.3845 - val_accuracy: 0.4419\n",
            "Epoch 736/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3677 - accuracy: 0.4529 - val_loss: 1.3775 - val_accuracy: 0.4651\n",
            "Epoch 737/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3584 - accuracy: 0.4235 - val_loss: 1.3803 - val_accuracy: 0.4419\n",
            "Epoch 738/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3403 - accuracy: 0.4765 - val_loss: 1.3840 - val_accuracy: 0.4186\n",
            "Epoch 739/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3386 - accuracy: 0.4412 - val_loss: 1.3767 - val_accuracy: 0.4419\n",
            "Epoch 740/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3625 - accuracy: 0.4471 - val_loss: 1.3758 - val_accuracy: 0.3953\n",
            "Epoch 741/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3656 - accuracy: 0.4765 - val_loss: 1.3741 - val_accuracy: 0.4186\n",
            "Epoch 742/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3166 - accuracy: 0.4529 - val_loss: 1.3750 - val_accuracy: 0.4419\n",
            "Epoch 743/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3719 - accuracy: 0.4118 - val_loss: 1.3707 - val_accuracy: 0.4419\n",
            "Epoch 744/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3602 - accuracy: 0.4471 - val_loss: 1.3714 - val_accuracy: 0.4419\n",
            "Epoch 745/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3546 - accuracy: 0.4824 - val_loss: 1.3822 - val_accuracy: 0.4186\n",
            "Epoch 746/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3393 - accuracy: 0.4588 - val_loss: 1.3810 - val_accuracy: 0.4419\n",
            "Epoch 747/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3411 - accuracy: 0.4647 - val_loss: 1.3847 - val_accuracy: 0.4186\n",
            "Epoch 748/2000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3662 - accuracy: 0.4882 - val_loss: 1.3862 - val_accuracy: 0.4186\n",
            "Epoch 749/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3423 - accuracy: 0.4706 - val_loss: 1.3885 - val_accuracy: 0.4186\n",
            "Epoch 750/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3681 - accuracy: 0.4176 - val_loss: 1.3877 - val_accuracy: 0.4186\n",
            "Epoch 751/2000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.3689 - accuracy: 0.4588 - val_loss: 1.3893 - val_accuracy: 0.3953\n",
            "Epoch 752/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3184 - accuracy: 0.4765 - val_loss: 1.3894 - val_accuracy: 0.4186\n",
            "Epoch 753/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3539 - accuracy: 0.4706 - val_loss: 1.3854 - val_accuracy: 0.4419\n",
            "Epoch 754/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3810 - accuracy: 0.4176 - val_loss: 1.3811 - val_accuracy: 0.4186\n",
            "Epoch 755/2000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.3424 - accuracy: 0.4353 - val_loss: 1.3833 - val_accuracy: 0.3953\n",
            "Epoch 756/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3576 - accuracy: 0.4412 - val_loss: 1.3837 - val_accuracy: 0.3953\n",
            "Epoch 757/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3518 - accuracy: 0.4412 - val_loss: 1.3866 - val_accuracy: 0.3953\n",
            "Epoch 758/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3790 - accuracy: 0.4588 - val_loss: 1.3771 - val_accuracy: 0.4419\n",
            "Epoch 759/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3991 - accuracy: 0.4294 - val_loss: 1.3807 - val_accuracy: 0.3953\n",
            "Epoch 760/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3461 - accuracy: 0.4412 - val_loss: 1.3884 - val_accuracy: 0.4186\n",
            "Epoch 761/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3487 - accuracy: 0.4353 - val_loss: 1.3919 - val_accuracy: 0.3953\n",
            "Epoch 762/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3796 - accuracy: 0.4000 - val_loss: 1.3800 - val_accuracy: 0.4186\n",
            "Epoch 763/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3757 - accuracy: 0.4294 - val_loss: 1.3899 - val_accuracy: 0.3721\n",
            "Epoch 764/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3612 - accuracy: 0.4294 - val_loss: 1.3853 - val_accuracy: 0.4651\n",
            "Epoch 765/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3350 - accuracy: 0.4706 - val_loss: 1.3849 - val_accuracy: 0.4419\n",
            "Epoch 766/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3715 - accuracy: 0.4647 - val_loss: 1.3769 - val_accuracy: 0.4186\n",
            "Epoch 767/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3259 - accuracy: 0.4706 - val_loss: 1.3766 - val_accuracy: 0.4419\n",
            "Epoch 768/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3384 - accuracy: 0.4471 - val_loss: 1.3768 - val_accuracy: 0.3953\n",
            "Epoch 769/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3274 - accuracy: 0.4824 - val_loss: 1.3795 - val_accuracy: 0.3953\n",
            "Epoch 770/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3473 - accuracy: 0.4235 - val_loss: 1.3918 - val_accuracy: 0.4186\n",
            "Epoch 771/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3767 - accuracy: 0.4529 - val_loss: 1.3833 - val_accuracy: 0.3953\n",
            "Epoch 772/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4004 - accuracy: 0.4588 - val_loss: 1.3787 - val_accuracy: 0.4419\n",
            "Epoch 773/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3895 - accuracy: 0.4353 - val_loss: 1.3848 - val_accuracy: 0.4651\n",
            "Epoch 774/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3686 - accuracy: 0.4412 - val_loss: 1.3846 - val_accuracy: 0.4651\n",
            "Epoch 775/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3551 - accuracy: 0.4471 - val_loss: 1.3834 - val_accuracy: 0.3953\n",
            "Epoch 776/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3994 - accuracy: 0.4529 - val_loss: 1.3797 - val_accuracy: 0.3953\n",
            "Epoch 777/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3495 - accuracy: 0.4529 - val_loss: 1.3852 - val_accuracy: 0.4186\n",
            "Epoch 778/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3692 - accuracy: 0.4647 - val_loss: 1.3879 - val_accuracy: 0.4186\n",
            "Epoch 779/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3593 - accuracy: 0.4412 - val_loss: 1.3866 - val_accuracy: 0.4186\n",
            "Epoch 780/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3713 - accuracy: 0.4294 - val_loss: 1.3865 - val_accuracy: 0.4419\n",
            "Epoch 781/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3953 - accuracy: 0.4353 - val_loss: 1.3916 - val_accuracy: 0.3721\n",
            "Epoch 782/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3629 - accuracy: 0.4412 - val_loss: 1.3757 - val_accuracy: 0.4186\n",
            "Epoch 783/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3556 - accuracy: 0.4529 - val_loss: 1.3784 - val_accuracy: 0.4186\n",
            "Epoch 784/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3538 - accuracy: 0.4706 - val_loss: 1.3802 - val_accuracy: 0.4651\n",
            "Epoch 785/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3802 - accuracy: 0.4588 - val_loss: 1.3772 - val_accuracy: 0.4419\n",
            "Epoch 786/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3678 - accuracy: 0.4118 - val_loss: 1.3843 - val_accuracy: 0.3953\n",
            "Epoch 787/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3263 - accuracy: 0.4824 - val_loss: 1.3725 - val_accuracy: 0.4186\n",
            "Epoch 788/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3677 - accuracy: 0.4412 - val_loss: 1.3858 - val_accuracy: 0.4419\n",
            "Epoch 789/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3574 - accuracy: 0.4765 - val_loss: 1.3798 - val_accuracy: 0.3953\n",
            "Epoch 790/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4153 - accuracy: 0.3824 - val_loss: 1.3844 - val_accuracy: 0.3953\n",
            "Epoch 791/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3571 - accuracy: 0.4765 - val_loss: 1.4027 - val_accuracy: 0.4419\n",
            "Epoch 792/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3442 - accuracy: 0.4529 - val_loss: 1.4030 - val_accuracy: 0.4419\n",
            "Epoch 793/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3878 - accuracy: 0.4294 - val_loss: 1.3838 - val_accuracy: 0.4186\n",
            "Epoch 794/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3779 - accuracy: 0.4235 - val_loss: 1.3968 - val_accuracy: 0.4186\n",
            "Epoch 795/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3732 - accuracy: 0.4529 - val_loss: 1.3801 - val_accuracy: 0.3953\n",
            "Epoch 796/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3483 - accuracy: 0.4647 - val_loss: 1.3865 - val_accuracy: 0.4419\n",
            "Epoch 797/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3617 - accuracy: 0.4294 - val_loss: 1.3754 - val_accuracy: 0.4419\n",
            "Epoch 798/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3641 - accuracy: 0.4882 - val_loss: 1.3703 - val_accuracy: 0.4186\n",
            "Epoch 799/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3632 - accuracy: 0.4059 - val_loss: 1.3636 - val_accuracy: 0.4186\n",
            "Epoch 800/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4014 - accuracy: 0.4176 - val_loss: 1.3679 - val_accuracy: 0.4186\n",
            "Epoch 801/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3520 - accuracy: 0.4471 - val_loss: 1.3785 - val_accuracy: 0.4419\n",
            "Epoch 802/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3418 - accuracy: 0.4529 - val_loss: 1.3906 - val_accuracy: 0.3721\n",
            "Epoch 803/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3621 - accuracy: 0.4588 - val_loss: 1.3915 - val_accuracy: 0.4186\n",
            "Epoch 804/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3114 - accuracy: 0.4882 - val_loss: 1.3889 - val_accuracy: 0.4186\n",
            "Epoch 805/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3139 - accuracy: 0.5059 - val_loss: 1.3914 - val_accuracy: 0.4186\n",
            "Epoch 806/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3424 - accuracy: 0.4353 - val_loss: 1.3869 - val_accuracy: 0.3953\n",
            "Epoch 807/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3296 - accuracy: 0.4529 - val_loss: 1.3854 - val_accuracy: 0.3953\n",
            "Epoch 808/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3610 - accuracy: 0.4118 - val_loss: 1.3868 - val_accuracy: 0.3721\n",
            "Epoch 809/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3387 - accuracy: 0.4588 - val_loss: 1.3934 - val_accuracy: 0.4186\n",
            "Epoch 810/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3534 - accuracy: 0.4588 - val_loss: 1.3753 - val_accuracy: 0.3953\n",
            "Epoch 811/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3777 - accuracy: 0.4588 - val_loss: 1.3745 - val_accuracy: 0.4419\n",
            "Epoch 812/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3197 - accuracy: 0.4765 - val_loss: 1.3846 - val_accuracy: 0.4186\n",
            "Epoch 813/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3731 - accuracy: 0.4353 - val_loss: 1.3877 - val_accuracy: 0.3953\n",
            "Epoch 814/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3345 - accuracy: 0.4588 - val_loss: 1.3922 - val_accuracy: 0.3953\n",
            "Epoch 815/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3330 - accuracy: 0.5059 - val_loss: 1.3923 - val_accuracy: 0.4186\n",
            "Epoch 816/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3698 - accuracy: 0.4706 - val_loss: 1.3899 - val_accuracy: 0.4186\n",
            "Epoch 817/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3301 - accuracy: 0.4765 - val_loss: 1.3821 - val_accuracy: 0.4186\n",
            "Epoch 818/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3512 - accuracy: 0.4706 - val_loss: 1.3767 - val_accuracy: 0.3953\n",
            "Epoch 819/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3303 - accuracy: 0.4529 - val_loss: 1.3771 - val_accuracy: 0.4186\n",
            "Epoch 820/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3725 - accuracy: 0.4176 - val_loss: 1.3779 - val_accuracy: 0.3953\n",
            "Epoch 821/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3221 - accuracy: 0.5176 - val_loss: 1.3896 - val_accuracy: 0.4186\n",
            "Epoch 822/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3377 - accuracy: 0.4882 - val_loss: 1.3857 - val_accuracy: 0.4186\n",
            "Epoch 823/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3808 - accuracy: 0.4412 - val_loss: 1.3747 - val_accuracy: 0.4186\n",
            "Epoch 824/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3220 - accuracy: 0.4824 - val_loss: 1.3664 - val_accuracy: 0.3953\n",
            "Epoch 825/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3406 - accuracy: 0.4588 - val_loss: 1.3782 - val_accuracy: 0.3953\n",
            "Epoch 826/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3555 - accuracy: 0.5000 - val_loss: 1.4005 - val_accuracy: 0.4186\n",
            "Epoch 827/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3635 - accuracy: 0.4353 - val_loss: 1.3812 - val_accuracy: 0.3953\n",
            "Epoch 828/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3538 - accuracy: 0.4529 - val_loss: 1.3795 - val_accuracy: 0.3721\n",
            "Epoch 829/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3321 - accuracy: 0.4765 - val_loss: 1.3797 - val_accuracy: 0.3721\n",
            "Epoch 830/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3598 - accuracy: 0.4294 - val_loss: 1.3826 - val_accuracy: 0.4186\n",
            "Epoch 831/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3350 - accuracy: 0.4353 - val_loss: 1.3838 - val_accuracy: 0.3721\n",
            "Epoch 832/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3614 - accuracy: 0.4529 - val_loss: 1.3875 - val_accuracy: 0.3953\n",
            "Epoch 833/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3257 - accuracy: 0.5176 - val_loss: 1.3902 - val_accuracy: 0.4186\n",
            "Epoch 834/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3127 - accuracy: 0.4588 - val_loss: 1.3889 - val_accuracy: 0.3953\n",
            "Epoch 835/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3603 - accuracy: 0.5059 - val_loss: 1.3913 - val_accuracy: 0.3953\n",
            "Epoch 836/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3658 - accuracy: 0.4294 - val_loss: 1.3994 - val_accuracy: 0.3953\n",
            "Epoch 837/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3341 - accuracy: 0.4765 - val_loss: 1.4009 - val_accuracy: 0.4419\n",
            "Epoch 838/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3636 - accuracy: 0.4471 - val_loss: 1.3932 - val_accuracy: 0.3953\n",
            "Epoch 839/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3491 - accuracy: 0.4824 - val_loss: 1.4003 - val_accuracy: 0.3721\n",
            "Epoch 840/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3904 - accuracy: 0.3882 - val_loss: 1.4014 - val_accuracy: 0.3721\n",
            "Epoch 841/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3353 - accuracy: 0.4706 - val_loss: 1.3984 - val_accuracy: 0.3953\n",
            "Epoch 842/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3300 - accuracy: 0.4588 - val_loss: 1.3992 - val_accuracy: 0.4186\n",
            "Epoch 843/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3381 - accuracy: 0.4647 - val_loss: 1.3868 - val_accuracy: 0.4186\n",
            "Epoch 844/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3486 - accuracy: 0.4941 - val_loss: 1.3844 - val_accuracy: 0.3953\n",
            "Epoch 845/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3710 - accuracy: 0.4294 - val_loss: 1.3978 - val_accuracy: 0.3953\n",
            "Epoch 846/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3388 - accuracy: 0.4529 - val_loss: 1.3909 - val_accuracy: 0.3953\n",
            "Epoch 847/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3391 - accuracy: 0.4529 - val_loss: 1.3849 - val_accuracy: 0.3953\n",
            "Epoch 848/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3627 - accuracy: 0.4353 - val_loss: 1.3897 - val_accuracy: 0.3953\n",
            "Epoch 849/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3283 - accuracy: 0.4882 - val_loss: 1.3898 - val_accuracy: 0.3721\n",
            "Epoch 850/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3353 - accuracy: 0.4647 - val_loss: 1.3846 - val_accuracy: 0.3953\n",
            "Epoch 851/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3394 - accuracy: 0.4588 - val_loss: 1.3830 - val_accuracy: 0.3953\n",
            "Epoch 852/2000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.3491 - accuracy: 0.4588 - val_loss: 1.3831 - val_accuracy: 0.3953\n",
            "Epoch 853/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3387 - accuracy: 0.4588 - val_loss: 1.3842 - val_accuracy: 0.3953\n",
            "Epoch 854/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3514 - accuracy: 0.4647 - val_loss: 1.3856 - val_accuracy: 0.3953\n",
            "Epoch 855/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3528 - accuracy: 0.4765 - val_loss: 1.3858 - val_accuracy: 0.3953\n",
            "Epoch 856/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3575 - accuracy: 0.4353 - val_loss: 1.3919 - val_accuracy: 0.3953\n",
            "Epoch 857/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3072 - accuracy: 0.4706 - val_loss: 1.3903 - val_accuracy: 0.3953\n",
            "Epoch 858/2000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.3129 - accuracy: 0.4706 - val_loss: 1.3868 - val_accuracy: 0.4186\n",
            "Epoch 859/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3324 - accuracy: 0.4647 - val_loss: 1.3845 - val_accuracy: 0.3953\n",
            "Epoch 860/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3442 - accuracy: 0.4824 - val_loss: 1.3848 - val_accuracy: 0.3953\n",
            "Epoch 861/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3432 - accuracy: 0.4882 - val_loss: 1.3907 - val_accuracy: 0.4186\n",
            "Epoch 862/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3674 - accuracy: 0.4529 - val_loss: 1.3899 - val_accuracy: 0.4419\n",
            "Epoch 863/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3480 - accuracy: 0.4647 - val_loss: 1.3778 - val_accuracy: 0.3953\n",
            "Epoch 864/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3527 - accuracy: 0.4353 - val_loss: 1.3800 - val_accuracy: 0.4186\n",
            "Epoch 865/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3062 - accuracy: 0.4882 - val_loss: 1.3770 - val_accuracy: 0.3953\n",
            "Epoch 866/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3321 - accuracy: 0.4412 - val_loss: 1.3777 - val_accuracy: 0.3488\n",
            "Epoch 867/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3412 - accuracy: 0.4529 - val_loss: 1.3895 - val_accuracy: 0.4186\n",
            "Epoch 868/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3398 - accuracy: 0.4706 - val_loss: 1.3784 - val_accuracy: 0.3953\n",
            "Epoch 869/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3418 - accuracy: 0.4647 - val_loss: 1.3843 - val_accuracy: 0.3721\n",
            "Epoch 870/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3387 - accuracy: 0.4706 - val_loss: 1.3976 - val_accuracy: 0.3953\n",
            "Epoch 871/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3406 - accuracy: 0.4588 - val_loss: 1.3744 - val_accuracy: 0.4186\n",
            "Epoch 872/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3433 - accuracy: 0.4882 - val_loss: 1.3669 - val_accuracy: 0.4186\n",
            "Epoch 873/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3176 - accuracy: 0.4588 - val_loss: 1.3565 - val_accuracy: 0.3953\n",
            "Epoch 874/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3604 - accuracy: 0.4706 - val_loss: 1.3627 - val_accuracy: 0.3953\n",
            "Epoch 875/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3340 - accuracy: 0.4353 - val_loss: 1.3722 - val_accuracy: 0.3721\n",
            "Epoch 876/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3422 - accuracy: 0.5176 - val_loss: 1.3686 - val_accuracy: 0.3953\n",
            "Epoch 877/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3633 - accuracy: 0.4176 - val_loss: 1.3680 - val_accuracy: 0.4186\n",
            "Epoch 878/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3185 - accuracy: 0.5059 - val_loss: 1.3720 - val_accuracy: 0.4419\n",
            "Epoch 879/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3297 - accuracy: 0.4353 - val_loss: 1.3704 - val_accuracy: 0.4186\n",
            "Epoch 880/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3463 - accuracy: 0.4588 - val_loss: 1.3649 - val_accuracy: 0.3953\n",
            "Epoch 881/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3324 - accuracy: 0.4765 - val_loss: 1.3686 - val_accuracy: 0.3953\n",
            "Epoch 882/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3524 - accuracy: 0.4118 - val_loss: 1.3718 - val_accuracy: 0.3721\n",
            "Epoch 883/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3373 - accuracy: 0.4412 - val_loss: 1.3935 - val_accuracy: 0.4419\n",
            "Epoch 884/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3732 - accuracy: 0.4529 - val_loss: 1.3925 - val_accuracy: 0.4186\n",
            "Epoch 885/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2858 - accuracy: 0.4765 - val_loss: 1.3731 - val_accuracy: 0.3953\n",
            "Epoch 886/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3092 - accuracy: 0.4824 - val_loss: 1.3670 - val_accuracy: 0.3488\n",
            "Epoch 887/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3449 - accuracy: 0.5000 - val_loss: 1.3822 - val_accuracy: 0.4186\n",
            "Epoch 888/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3364 - accuracy: 0.4882 - val_loss: 1.3900 - val_accuracy: 0.4186\n",
            "Epoch 889/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3223 - accuracy: 0.4647 - val_loss: 1.3807 - val_accuracy: 0.3721\n",
            "Epoch 890/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3513 - accuracy: 0.4412 - val_loss: 1.3749 - val_accuracy: 0.3953\n",
            "Epoch 891/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3215 - accuracy: 0.5176 - val_loss: 1.3803 - val_accuracy: 0.4419\n",
            "Epoch 892/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3357 - accuracy: 0.4588 - val_loss: 1.3744 - val_accuracy: 0.4186\n",
            "Epoch 893/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3508 - accuracy: 0.4706 - val_loss: 1.3711 - val_accuracy: 0.3953\n",
            "Epoch 894/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3553 - accuracy: 0.4824 - val_loss: 1.3676 - val_accuracy: 0.4186\n",
            "Epoch 895/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3098 - accuracy: 0.5000 - val_loss: 1.3776 - val_accuracy: 0.4186\n",
            "Epoch 896/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3215 - accuracy: 0.5118 - val_loss: 1.3742 - val_accuracy: 0.3953\n",
            "Epoch 897/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3386 - accuracy: 0.4882 - val_loss: 1.3749 - val_accuracy: 0.4186\n",
            "Epoch 898/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3690 - accuracy: 0.4529 - val_loss: 1.3735 - val_accuracy: 0.3488\n",
            "Epoch 899/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3548 - accuracy: 0.4647 - val_loss: 1.3851 - val_accuracy: 0.3721\n",
            "Epoch 900/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3470 - accuracy: 0.4647 - val_loss: 1.3873 - val_accuracy: 0.4186\n",
            "Epoch 901/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3704 - accuracy: 0.4588 - val_loss: 1.3859 - val_accuracy: 0.4419\n",
            "Epoch 902/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3662 - accuracy: 0.4412 - val_loss: 1.3735 - val_accuracy: 0.3721\n",
            "Epoch 903/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3263 - accuracy: 0.4647 - val_loss: 1.3838 - val_accuracy: 0.3721\n",
            "Epoch 904/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3477 - accuracy: 0.4471 - val_loss: 1.4093 - val_accuracy: 0.3721\n",
            "Epoch 905/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3410 - accuracy: 0.4706 - val_loss: 1.3908 - val_accuracy: 0.3721\n",
            "Epoch 906/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3391 - accuracy: 0.4647 - val_loss: 1.3902 - val_accuracy: 0.3721\n",
            "Epoch 907/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2917 - accuracy: 0.4765 - val_loss: 1.3834 - val_accuracy: 0.4186\n",
            "Epoch 908/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3549 - accuracy: 0.4529 - val_loss: 1.3797 - val_accuracy: 0.4186\n",
            "Epoch 909/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3516 - accuracy: 0.4706 - val_loss: 1.3860 - val_accuracy: 0.4186\n",
            "Epoch 910/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3079 - accuracy: 0.4706 - val_loss: 1.3875 - val_accuracy: 0.3953\n",
            "Epoch 911/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3211 - accuracy: 0.5059 - val_loss: 1.3858 - val_accuracy: 0.3953\n",
            "Epoch 912/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3734 - accuracy: 0.4529 - val_loss: 1.3801 - val_accuracy: 0.3721\n",
            "Epoch 913/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3100 - accuracy: 0.4706 - val_loss: 1.3742 - val_accuracy: 0.3488\n",
            "Epoch 914/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3350 - accuracy: 0.4647 - val_loss: 1.3709 - val_accuracy: 0.3721\n",
            "Epoch 915/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3315 - accuracy: 0.5000 - val_loss: 1.3792 - val_accuracy: 0.4419\n",
            "Epoch 916/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3493 - accuracy: 0.4706 - val_loss: 1.3697 - val_accuracy: 0.4186\n",
            "Epoch 917/2000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.3171 - accuracy: 0.4941 - val_loss: 1.3681 - val_accuracy: 0.3721\n",
            "Epoch 918/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3509 - accuracy: 0.4765 - val_loss: 1.3822 - val_accuracy: 0.4419\n",
            "Epoch 919/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3536 - accuracy: 0.4706 - val_loss: 1.3840 - val_accuracy: 0.3953\n",
            "Epoch 920/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3360 - accuracy: 0.4647 - val_loss: 1.3891 - val_accuracy: 0.3953\n",
            "Epoch 921/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3481 - accuracy: 0.4588 - val_loss: 1.3885 - val_accuracy: 0.3953\n",
            "Epoch 922/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3518 - accuracy: 0.4765 - val_loss: 1.3834 - val_accuracy: 0.4186\n",
            "Epoch 923/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3375 - accuracy: 0.4471 - val_loss: 1.3863 - val_accuracy: 0.4419\n",
            "Epoch 924/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3280 - accuracy: 0.4765 - val_loss: 1.3675 - val_accuracy: 0.3953\n",
            "Epoch 925/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3292 - accuracy: 0.4588 - val_loss: 1.3680 - val_accuracy: 0.3953\n",
            "Epoch 926/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3123 - accuracy: 0.4765 - val_loss: 1.3705 - val_accuracy: 0.3721\n",
            "Epoch 927/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3439 - accuracy: 0.4882 - val_loss: 1.3719 - val_accuracy: 0.3721\n",
            "Epoch 928/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3277 - accuracy: 0.4824 - val_loss: 1.3813 - val_accuracy: 0.4186\n",
            "Epoch 929/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3518 - accuracy: 0.4235 - val_loss: 1.3848 - val_accuracy: 0.4186\n",
            "Epoch 930/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3321 - accuracy: 0.4588 - val_loss: 1.3847 - val_accuracy: 0.3953\n",
            "Epoch 931/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3177 - accuracy: 0.4471 - val_loss: 1.3798 - val_accuracy: 0.4419\n",
            "Epoch 932/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3587 - accuracy: 0.4471 - val_loss: 1.3673 - val_accuracy: 0.4186\n",
            "Epoch 933/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3048 - accuracy: 0.4471 - val_loss: 1.3738 - val_accuracy: 0.3953\n",
            "Epoch 934/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3318 - accuracy: 0.4706 - val_loss: 1.3771 - val_accuracy: 0.4186\n",
            "Epoch 935/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3036 - accuracy: 0.4765 - val_loss: 1.3808 - val_accuracy: 0.4186\n",
            "Epoch 936/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3405 - accuracy: 0.4588 - val_loss: 1.3739 - val_accuracy: 0.3953\n",
            "Epoch 937/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2847 - accuracy: 0.4647 - val_loss: 1.3822 - val_accuracy: 0.4186\n",
            "Epoch 938/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3206 - accuracy: 0.4941 - val_loss: 1.3868 - val_accuracy: 0.4186\n",
            "Epoch 939/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3398 - accuracy: 0.4647 - val_loss: 1.3845 - val_accuracy: 0.4186\n",
            "Epoch 940/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3317 - accuracy: 0.4294 - val_loss: 1.3795 - val_accuracy: 0.4186\n",
            "Epoch 941/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3318 - accuracy: 0.4647 - val_loss: 1.3757 - val_accuracy: 0.4419\n",
            "Epoch 942/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3213 - accuracy: 0.4471 - val_loss: 1.3734 - val_accuracy: 0.3721\n",
            "Epoch 943/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3474 - accuracy: 0.4647 - val_loss: 1.3732 - val_accuracy: 0.3953\n",
            "Epoch 944/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2908 - accuracy: 0.4647 - val_loss: 1.3757 - val_accuracy: 0.3721\n",
            "Epoch 945/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3514 - accuracy: 0.4647 - val_loss: 1.3759 - val_accuracy: 0.4186\n",
            "Epoch 946/2000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.3442 - accuracy: 0.4294 - val_loss: 1.4032 - val_accuracy: 0.4419\n",
            "Epoch 947/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3502 - accuracy: 0.4824 - val_loss: 1.3746 - val_accuracy: 0.3953\n",
            "Epoch 948/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3061 - accuracy: 0.4941 - val_loss: 1.3727 - val_accuracy: 0.3953\n",
            "Epoch 949/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3074 - accuracy: 0.4647 - val_loss: 1.3746 - val_accuracy: 0.3953\n",
            "Epoch 950/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2990 - accuracy: 0.4706 - val_loss: 1.3764 - val_accuracy: 0.4186\n",
            "Epoch 951/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3182 - accuracy: 0.4765 - val_loss: 1.3836 - val_accuracy: 0.4419\n",
            "Epoch 952/2000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.3088 - accuracy: 0.4529 - val_loss: 1.3833 - val_accuracy: 0.4419\n",
            "Epoch 953/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3473 - accuracy: 0.4588 - val_loss: 1.3735 - val_accuracy: 0.4186\n",
            "Epoch 954/2000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.3230 - accuracy: 0.4059 - val_loss: 1.3756 - val_accuracy: 0.3953\n",
            "Epoch 955/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3276 - accuracy: 0.4647 - val_loss: 1.3726 - val_accuracy: 0.3953\n",
            "Epoch 956/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3201 - accuracy: 0.4529 - val_loss: 1.3755 - val_accuracy: 0.3953\n",
            "Epoch 957/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3365 - accuracy: 0.4824 - val_loss: 1.3764 - val_accuracy: 0.4186\n",
            "Epoch 958/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3057 - accuracy: 0.5059 - val_loss: 1.3765 - val_accuracy: 0.4186\n",
            "Epoch 959/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3313 - accuracy: 0.4824 - val_loss: 1.3673 - val_accuracy: 0.4186\n",
            "Epoch 960/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3364 - accuracy: 0.4647 - val_loss: 1.3716 - val_accuracy: 0.3953\n",
            "Epoch 961/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3146 - accuracy: 0.4765 - val_loss: 1.4001 - val_accuracy: 0.4651\n",
            "Epoch 962/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3713 - accuracy: 0.4529 - val_loss: 1.3836 - val_accuracy: 0.4651\n",
            "Epoch 963/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3083 - accuracy: 0.4824 - val_loss: 1.3789 - val_accuracy: 0.3953\n",
            "Epoch 964/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3354 - accuracy: 0.4529 - val_loss: 1.3931 - val_accuracy: 0.4186\n",
            "Epoch 965/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3024 - accuracy: 0.4647 - val_loss: 1.3960 - val_accuracy: 0.3953\n",
            "Epoch 966/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3244 - accuracy: 0.4706 - val_loss: 1.3948 - val_accuracy: 0.4186\n",
            "Epoch 967/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3248 - accuracy: 0.4765 - val_loss: 1.3943 - val_accuracy: 0.3953\n",
            "Epoch 968/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2845 - accuracy: 0.5059 - val_loss: 1.3925 - val_accuracy: 0.3953\n",
            "Epoch 969/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3073 - accuracy: 0.4353 - val_loss: 1.3739 - val_accuracy: 0.3721\n",
            "Epoch 970/2000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1.3121 - accuracy: 0.4588 - val_loss: 1.3780 - val_accuracy: 0.4419\n",
            "Epoch 971/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3130 - accuracy: 0.4824 - val_loss: 1.3697 - val_accuracy: 0.4419\n",
            "Epoch 972/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3062 - accuracy: 0.5118 - val_loss: 1.3689 - val_accuracy: 0.3721\n",
            "Epoch 973/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3620 - accuracy: 0.4412 - val_loss: 1.3905 - val_accuracy: 0.3953\n",
            "Epoch 974/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3297 - accuracy: 0.4529 - val_loss: 1.3870 - val_accuracy: 0.3953\n",
            "Epoch 975/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2868 - accuracy: 0.4824 - val_loss: 1.3957 - val_accuracy: 0.3953\n",
            "Epoch 976/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3421 - accuracy: 0.4941 - val_loss: 1.3776 - val_accuracy: 0.4186\n",
            "Epoch 977/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.2920 - accuracy: 0.5000 - val_loss: 1.3826 - val_accuracy: 0.3721\n",
            "Epoch 978/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2896 - accuracy: 0.4882 - val_loss: 1.3760 - val_accuracy: 0.3721\n",
            "Epoch 979/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2879 - accuracy: 0.5000 - val_loss: 1.3832 - val_accuracy: 0.3953\n",
            "Epoch 980/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3172 - accuracy: 0.4647 - val_loss: 1.3809 - val_accuracy: 0.3721\n",
            "Epoch 981/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3403 - accuracy: 0.4588 - val_loss: 1.3697 - val_accuracy: 0.3721\n",
            "Epoch 982/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3420 - accuracy: 0.4882 - val_loss: 1.3680 - val_accuracy: 0.3721\n",
            "Epoch 983/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3526 - accuracy: 0.4765 - val_loss: 1.3844 - val_accuracy: 0.3721\n",
            "Epoch 984/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3541 - accuracy: 0.4471 - val_loss: 1.3859 - val_accuracy: 0.3953\n",
            "Epoch 985/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3325 - accuracy: 0.4706 - val_loss: 1.3852 - val_accuracy: 0.3953\n",
            "Epoch 986/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3093 - accuracy: 0.4824 - val_loss: 1.3794 - val_accuracy: 0.3953\n",
            "Epoch 987/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3151 - accuracy: 0.4765 - val_loss: 1.3705 - val_accuracy: 0.3953\n",
            "Epoch 988/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3211 - accuracy: 0.4941 - val_loss: 1.3722 - val_accuracy: 0.4186\n",
            "Epoch 989/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3355 - accuracy: 0.4882 - val_loss: 1.3793 - val_accuracy: 0.4419\n",
            "Epoch 990/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3121 - accuracy: 0.4353 - val_loss: 1.3661 - val_accuracy: 0.4186\n",
            "Epoch 991/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2900 - accuracy: 0.4647 - val_loss: 1.3628 - val_accuracy: 0.4419\n",
            "Epoch 992/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3220 - accuracy: 0.4647 - val_loss: 1.3734 - val_accuracy: 0.3488\n",
            "Epoch 993/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3092 - accuracy: 0.4765 - val_loss: 1.3727 - val_accuracy: 0.3953\n",
            "Epoch 994/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3076 - accuracy: 0.4706 - val_loss: 1.3636 - val_accuracy: 0.4419\n",
            "Epoch 995/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3299 - accuracy: 0.4706 - val_loss: 1.3590 - val_accuracy: 0.4186\n",
            "Epoch 996/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3115 - accuracy: 0.4706 - val_loss: 1.3661 - val_accuracy: 0.4186\n",
            "Epoch 997/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3090 - accuracy: 0.5059 - val_loss: 1.3665 - val_accuracy: 0.4419\n",
            "Epoch 998/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3084 - accuracy: 0.4706 - val_loss: 1.3652 - val_accuracy: 0.4186\n",
            "Epoch 999/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3113 - accuracy: 0.4824 - val_loss: 1.3673 - val_accuracy: 0.3721\n",
            "Epoch 1000/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3343 - accuracy: 0.5059 - val_loss: 1.3727 - val_accuracy: 0.4186\n",
            "Epoch 1001/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3469 - accuracy: 0.4471 - val_loss: 1.3705 - val_accuracy: 0.3953\n",
            "Epoch 1002/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3193 - accuracy: 0.4765 - val_loss: 1.3751 - val_accuracy: 0.4186\n",
            "Epoch 1003/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3281 - accuracy: 0.4647 - val_loss: 1.3715 - val_accuracy: 0.3953\n",
            "Epoch 1004/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3092 - accuracy: 0.4529 - val_loss: 1.3722 - val_accuracy: 0.3953\n",
            "Epoch 1005/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.2788 - accuracy: 0.4941 - val_loss: 1.3769 - val_accuracy: 0.3953\n",
            "Epoch 1006/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3237 - accuracy: 0.4588 - val_loss: 1.3869 - val_accuracy: 0.3721\n",
            "Epoch 1007/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3278 - accuracy: 0.4647 - val_loss: 1.3861 - val_accuracy: 0.3953\n",
            "Epoch 1008/2000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.3187 - accuracy: 0.5118 - val_loss: 1.3921 - val_accuracy: 0.3953\n",
            "Epoch 1009/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3465 - accuracy: 0.4882 - val_loss: 1.3847 - val_accuracy: 0.4419\n",
            "Epoch 1010/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2989 - accuracy: 0.4824 - val_loss: 1.3752 - val_accuracy: 0.3721\n",
            "Epoch 1011/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3064 - accuracy: 0.5176 - val_loss: 1.3815 - val_accuracy: 0.3721\n",
            "Epoch 1012/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3235 - accuracy: 0.4294 - val_loss: 1.3854 - val_accuracy: 0.4186\n",
            "Epoch 1013/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3323 - accuracy: 0.4471 - val_loss: 1.4038 - val_accuracy: 0.4186\n",
            "Epoch 1014/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3161 - accuracy: 0.4941 - val_loss: 1.3957 - val_accuracy: 0.4186\n",
            "Epoch 1015/2000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.3048 - accuracy: 0.5118 - val_loss: 1.3874 - val_accuracy: 0.3721\n",
            "Epoch 1016/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.2789 - accuracy: 0.4588 - val_loss: 1.3761 - val_accuracy: 0.3488\n",
            "Epoch 1017/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3205 - accuracy: 0.4882 - val_loss: 1.3872 - val_accuracy: 0.3721\n",
            "Epoch 1018/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3230 - accuracy: 0.4353 - val_loss: 1.3897 - val_accuracy: 0.3721\n",
            "Epoch 1019/2000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.3288 - accuracy: 0.4706 - val_loss: 1.3831 - val_accuracy: 0.3721\n",
            "Epoch 1020/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3347 - accuracy: 0.4588 - val_loss: 1.3755 - val_accuracy: 0.4186\n",
            "Epoch 1021/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3004 - accuracy: 0.4824 - val_loss: 1.3648 - val_accuracy: 0.4419\n",
            "Epoch 1022/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3394 - accuracy: 0.4765 - val_loss: 1.3605 - val_accuracy: 0.4186\n",
            "Epoch 1023/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3364 - accuracy: 0.4765 - val_loss: 1.3816 - val_accuracy: 0.4651\n",
            "Epoch 1024/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2880 - accuracy: 0.4765 - val_loss: 1.3846 - val_accuracy: 0.3953\n",
            "Epoch 1025/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3291 - accuracy: 0.4882 - val_loss: 1.3805 - val_accuracy: 0.3953\n",
            "Epoch 1026/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3016 - accuracy: 0.4706 - val_loss: 1.3713 - val_accuracy: 0.3721\n",
            "Epoch 1027/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3107 - accuracy: 0.4529 - val_loss: 1.3775 - val_accuracy: 0.4419\n",
            "Epoch 1028/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3291 - accuracy: 0.4647 - val_loss: 1.3725 - val_accuracy: 0.4186\n",
            "Epoch 1029/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3190 - accuracy: 0.4765 - val_loss: 1.3662 - val_accuracy: 0.3953\n",
            "Epoch 1030/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2863 - accuracy: 0.5000 - val_loss: 1.3773 - val_accuracy: 0.3721\n",
            "Epoch 1031/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3054 - accuracy: 0.4824 - val_loss: 1.3832 - val_accuracy: 0.3953\n",
            "Epoch 1032/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3067 - accuracy: 0.4882 - val_loss: 1.3716 - val_accuracy: 0.3721\n",
            "Epoch 1033/2000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 1.3099 - accuracy: 0.4471 - val_loss: 1.3717 - val_accuracy: 0.3721\n",
            "Epoch 1034/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3012 - accuracy: 0.4882 - val_loss: 1.3774 - val_accuracy: 0.3721\n",
            "Epoch 1035/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3155 - accuracy: 0.4706 - val_loss: 1.3797 - val_accuracy: 0.4186\n",
            "Epoch 1036/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3083 - accuracy: 0.5000 - val_loss: 1.3688 - val_accuracy: 0.4186\n",
            "Epoch 1037/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3102 - accuracy: 0.4588 - val_loss: 1.3691 - val_accuracy: 0.4419\n",
            "Epoch 1038/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3136 - accuracy: 0.4882 - val_loss: 1.3897 - val_accuracy: 0.4651\n",
            "Epoch 1039/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3024 - accuracy: 0.4765 - val_loss: 1.3742 - val_accuracy: 0.3953\n",
            "Epoch 1040/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3418 - accuracy: 0.4529 - val_loss: 1.3728 - val_accuracy: 0.3953\n",
            "Epoch 1041/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3146 - accuracy: 0.4647 - val_loss: 1.3870 - val_accuracy: 0.3721\n",
            "Epoch 1042/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3468 - accuracy: 0.4471 - val_loss: 1.3835 - val_accuracy: 0.3721\n",
            "Epoch 1043/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3424 - accuracy: 0.4706 - val_loss: 1.3822 - val_accuracy: 0.4186\n",
            "Epoch 1044/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2922 - accuracy: 0.5059 - val_loss: 1.3761 - val_accuracy: 0.3953\n",
            "Epoch 1045/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3249 - accuracy: 0.4824 - val_loss: 1.3734 - val_accuracy: 0.3721\n",
            "Epoch 1046/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3086 - accuracy: 0.4882 - val_loss: 1.3767 - val_accuracy: 0.3721\n",
            "Epoch 1047/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2917 - accuracy: 0.4824 - val_loss: 1.3752 - val_accuracy: 0.3953\n",
            "Epoch 1048/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3032 - accuracy: 0.5059 - val_loss: 1.3784 - val_accuracy: 0.3721\n",
            "Epoch 1049/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2925 - accuracy: 0.4588 - val_loss: 1.3806 - val_accuracy: 0.3721\n",
            "Epoch 1050/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3121 - accuracy: 0.4529 - val_loss: 1.3787 - val_accuracy: 0.3721\n",
            "Epoch 1051/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3296 - accuracy: 0.4529 - val_loss: 1.3805 - val_accuracy: 0.3953\n",
            "Epoch 1052/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3281 - accuracy: 0.4824 - val_loss: 1.3856 - val_accuracy: 0.3953\n",
            "Epoch 1053/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2966 - accuracy: 0.4941 - val_loss: 1.3847 - val_accuracy: 0.3953\n",
            "Epoch 1054/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3168 - accuracy: 0.5235 - val_loss: 1.3840 - val_accuracy: 0.3953\n",
            "Epoch 1055/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2755 - accuracy: 0.5059 - val_loss: 1.3833 - val_accuracy: 0.3953\n",
            "Epoch 1056/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3146 - accuracy: 0.4824 - val_loss: 1.3850 - val_accuracy: 0.3953\n",
            "Epoch 1057/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3091 - accuracy: 0.4706 - val_loss: 1.4019 - val_accuracy: 0.4186\n",
            "Epoch 1058/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3028 - accuracy: 0.4647 - val_loss: 1.3998 - val_accuracy: 0.4186\n",
            "Epoch 1059/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3040 - accuracy: 0.4882 - val_loss: 1.3833 - val_accuracy: 0.4419\n",
            "Epoch 1060/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3399 - accuracy: 0.4941 - val_loss: 1.3704 - val_accuracy: 0.3953\n",
            "Epoch 1061/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3079 - accuracy: 0.5059 - val_loss: 1.3629 - val_accuracy: 0.4651\n",
            "Epoch 1062/2000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 1.2860 - accuracy: 0.4882 - val_loss: 1.3720 - val_accuracy: 0.3721\n",
            "Epoch 1063/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2950 - accuracy: 0.4824 - val_loss: 1.3749 - val_accuracy: 0.3721\n",
            "Epoch 1064/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3072 - accuracy: 0.4882 - val_loss: 1.3811 - val_accuracy: 0.3953\n",
            "Epoch 1065/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3275 - accuracy: 0.4765 - val_loss: 1.3731 - val_accuracy: 0.3953\n",
            "Epoch 1066/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2590 - accuracy: 0.4706 - val_loss: 1.3772 - val_accuracy: 0.3721\n",
            "Epoch 1067/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3102 - accuracy: 0.4765 - val_loss: 1.3681 - val_accuracy: 0.3721\n",
            "Epoch 1068/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2827 - accuracy: 0.5176 - val_loss: 1.3803 - val_accuracy: 0.3953\n",
            "Epoch 1069/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3171 - accuracy: 0.5118 - val_loss: 1.3927 - val_accuracy: 0.4186\n",
            "Epoch 1070/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3439 - accuracy: 0.4706 - val_loss: 1.3923 - val_accuracy: 0.3953\n",
            "Epoch 1071/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3395 - accuracy: 0.4588 - val_loss: 1.3912 - val_accuracy: 0.4186\n",
            "Epoch 1072/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3118 - accuracy: 0.4882 - val_loss: 1.3929 - val_accuracy: 0.4419\n",
            "Epoch 1073/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3070 - accuracy: 0.4882 - val_loss: 1.3870 - val_accuracy: 0.4186\n",
            "Epoch 1074/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3115 - accuracy: 0.4647 - val_loss: 1.3932 - val_accuracy: 0.4186\n",
            "Epoch 1075/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3182 - accuracy: 0.4647 - val_loss: 1.3884 - val_accuracy: 0.3953\n",
            "Epoch 1076/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3137 - accuracy: 0.4765 - val_loss: 1.3832 - val_accuracy: 0.4186\n",
            "Epoch 1077/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3232 - accuracy: 0.4412 - val_loss: 1.4067 - val_accuracy: 0.4186\n",
            "Epoch 1078/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3198 - accuracy: 0.4765 - val_loss: 1.3801 - val_accuracy: 0.3721\n",
            "Epoch 1079/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3035 - accuracy: 0.5000 - val_loss: 1.3704 - val_accuracy: 0.3721\n",
            "Epoch 1080/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2753 - accuracy: 0.4882 - val_loss: 1.3623 - val_accuracy: 0.4186\n",
            "Epoch 1081/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.2882 - accuracy: 0.4824 - val_loss: 1.3745 - val_accuracy: 0.4419\n",
            "Epoch 1082/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2909 - accuracy: 0.4882 - val_loss: 1.3831 - val_accuracy: 0.3953\n",
            "Epoch 1083/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3167 - accuracy: 0.4647 - val_loss: 1.3863 - val_accuracy: 0.4419\n",
            "Epoch 1084/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3193 - accuracy: 0.4529 - val_loss: 1.3833 - val_accuracy: 0.4186\n",
            "Epoch 1085/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2851 - accuracy: 0.5000 - val_loss: 1.3854 - val_accuracy: 0.4186\n",
            "Epoch 1086/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2655 - accuracy: 0.4941 - val_loss: 1.3793 - val_accuracy: 0.3953\n",
            "Epoch 1087/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3150 - accuracy: 0.4882 - val_loss: 1.3805 - val_accuracy: 0.4186\n",
            "Epoch 1088/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3104 - accuracy: 0.4824 - val_loss: 1.3957 - val_accuracy: 0.3953\n",
            "Epoch 1089/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3156 - accuracy: 0.4824 - val_loss: 1.3908 - val_accuracy: 0.3721\n",
            "Epoch 1090/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2744 - accuracy: 0.5059 - val_loss: 1.3977 - val_accuracy: 0.3953\n",
            "Epoch 1091/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3339 - accuracy: 0.4588 - val_loss: 1.3942 - val_accuracy: 0.3953\n",
            "Epoch 1092/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2767 - accuracy: 0.4882 - val_loss: 1.3871 - val_accuracy: 0.3953\n",
            "Epoch 1093/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2724 - accuracy: 0.5059 - val_loss: 1.3714 - val_accuracy: 0.3953\n",
            "Epoch 1094/2000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.3178 - accuracy: 0.4765 - val_loss: 1.3757 - val_accuracy: 0.3953\n",
            "Epoch 1095/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2873 - accuracy: 0.5000 - val_loss: 1.3756 - val_accuracy: 0.3721\n",
            "Epoch 1096/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2945 - accuracy: 0.4824 - val_loss: 1.3800 - val_accuracy: 0.3721\n",
            "Epoch 1097/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3008 - accuracy: 0.4706 - val_loss: 1.3914 - val_accuracy: 0.3953\n",
            "Epoch 1098/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2682 - accuracy: 0.5176 - val_loss: 1.3905 - val_accuracy: 0.3953\n",
            "Epoch 1099/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3027 - accuracy: 0.4882 - val_loss: 1.3897 - val_accuracy: 0.3721\n",
            "Epoch 1100/2000\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.2798 - accuracy: 0.4941 - val_loss: 1.3888 - val_accuracy: 0.3721\n",
            "Epoch 1101/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2989 - accuracy: 0.4647 - val_loss: 1.3874 - val_accuracy: 0.4186\n",
            "Epoch 1102/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3053 - accuracy: 0.4647 - val_loss: 1.3830 - val_accuracy: 0.4186\n",
            "Epoch 1103/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3023 - accuracy: 0.5294 - val_loss: 1.3891 - val_accuracy: 0.3953\n",
            "Epoch 1104/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3175 - accuracy: 0.4882 - val_loss: 1.3968 - val_accuracy: 0.3953\n",
            "Epoch 1105/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3148 - accuracy: 0.4529 - val_loss: 1.3904 - val_accuracy: 0.3953\n",
            "Epoch 1106/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3150 - accuracy: 0.4765 - val_loss: 1.3991 - val_accuracy: 0.3953\n",
            "Epoch 1107/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2911 - accuracy: 0.4941 - val_loss: 1.3940 - val_accuracy: 0.3721\n",
            "Epoch 1108/2000\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2861 - accuracy: 0.4824 - val_loss: 1.3954 - val_accuracy: 0.3721\n",
            "Epoch 1109/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3127 - accuracy: 0.4706 - val_loss: 1.3768 - val_accuracy: 0.3721\n",
            "Epoch 1110/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2855 - accuracy: 0.5118 - val_loss: 1.3731 - val_accuracy: 0.3721\n",
            "Epoch 1111/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2777 - accuracy: 0.5412 - val_loss: 1.3810 - val_accuracy: 0.3953\n",
            "Epoch 1112/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2762 - accuracy: 0.4706 - val_loss: 1.3722 - val_accuracy: 0.3721\n",
            "Epoch 1113/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3216 - accuracy: 0.4647 - val_loss: 1.3843 - val_accuracy: 0.3721\n",
            "Epoch 1114/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2768 - accuracy: 0.4824 - val_loss: 1.4034 - val_accuracy: 0.3953\n",
            "Epoch 1115/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2970 - accuracy: 0.4588 - val_loss: 1.3908 - val_accuracy: 0.4419\n",
            "Epoch 1116/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2723 - accuracy: 0.4824 - val_loss: 1.3810 - val_accuracy: 0.3721\n",
            "Epoch 1117/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3100 - accuracy: 0.5235 - val_loss: 1.3742 - val_accuracy: 0.3953\n",
            "Epoch 1118/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2633 - accuracy: 0.4941 - val_loss: 1.3634 - val_accuracy: 0.3953\n",
            "Epoch 1119/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3009 - accuracy: 0.4471 - val_loss: 1.3701 - val_accuracy: 0.4186\n",
            "Epoch 1120/2000\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3192 - accuracy: 0.4941 - val_loss: 1.3859 - val_accuracy: 0.4186\n",
            "Epoch 1121/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2970 - accuracy: 0.4647 - val_loss: 1.3752 - val_accuracy: 0.3721\n",
            "Epoch 1122/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3128 - accuracy: 0.4765 - val_loss: 1.3759 - val_accuracy: 0.3721\n",
            "Epoch 1123/2000\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3047 - accuracy: 0.5059 - val_loss: 1.3847 - val_accuracy: 0.3721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AU1rJeJtdqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69affe90-6415-44b5-f074-b50781fd2dc3"
      },
      "source": [
        "np.argmax(model.predict(X_test),axis=1)\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 6, 2, 6, 5, 1, 4, 4, 4, 0, 0, 4, 1, 3, 5, 5, 6, 0, 4, 4, 3, 4,\n",
              "       6, 6, 4, 3, 1, 5, 0, 5, 5, 5, 0, 1, 6, 6, 2, 4, 3, 4, 3, 5, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD__VauavyE7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cf6159c-c154-4db8-fa9c-88863d1d3e14"
      },
      "source": [
        "np.array(y_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 6, 2, 6, 3, 3, 0, 2, 2, 4, 5, 5, 4, 2, 5, 5, 6, 0, 1, 6, 3, 6,\n",
              "       6, 6, 4, 3, 1, 0, 5, 0, 1, 4, 5, 3, 2, 6, 5, 5, 3, 2, 3, 6, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7UlpY_fv87b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y56bJyxMtQIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804839d7-bfb0-4f31-d6b0-4346b1881e4e"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, np.argmax(model.predict(X_test),axis=1)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.20      0.20         5\n",
            "           1       0.25      0.33      0.29         3\n",
            "           2       0.67      0.29      0.40         7\n",
            "           3       0.80      0.57      0.67         7\n",
            "           4       0.09      0.25      0.13         4\n",
            "           5       0.25      0.25      0.25         8\n",
            "           6       0.86      0.67      0.75         9\n",
            "\n",
            "    accuracy                           0.40        43\n",
            "   macro avg       0.44      0.37      0.38        43\n",
            "weighted avg       0.51      0.40      0.43        43\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBmDRQ7Jwolv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP6qXQWSi-DX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "538e1cd0-de3e-42af-bf49-b941381d466e"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 1.3565 - accuracy: 0.3953\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.356489896774292, 0.39534884691238403]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MBwjeEqw4Fr"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAory2TZw51n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e976f87a-b412-4086-b1f7-a31fd46ed0f4"
      },
      "source": [
        "# training a linear SVM classifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train)\n",
        "svm_predictions = svm_model_linear.predict(X_test)\n",
        "  \n",
        "# model accuracy for X_test  \n",
        "accuracy = svm_model_linear.score(X_test, y_test)\n",
        "\n",
        "# creating a confusion matrix\n",
        "cm = confusion_matrix(y_test, svm_predictions)\n",
        "cm"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 5, 0, 0],\n",
              "       [0, 0, 0, 0, 3, 0, 0],\n",
              "       [0, 0, 1, 0, 3, 0, 3],\n",
              "       [0, 0, 0, 0, 4, 0, 3],\n",
              "       [0, 1, 0, 0, 3, 0, 0],\n",
              "       [0, 0, 1, 0, 7, 0, 0],\n",
              "       [0, 0, 0, 0, 3, 0, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGHlN1CtxTFJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8035432a-4d79-4ac4-8bba-412bab4a5f8e"
      },
      "source": [
        "accuracy"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23255813953488372"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE8u4I-HxXDq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzyVP7opxjl8"
      },
      "source": [
        "GNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T61LNLKExoju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff52c043-86ec-4ddf-d394-47867e3279bd"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB().fit(X_train, y_train)\n",
        "gnb_predictions = gnb.predict(X_test)\n",
        "  \n",
        "# accuracy on X_test\n",
        "accuracy = gnb.score(X_test, y_test)\n",
        "\n",
        "  \n",
        "# creating a confusion matrix\n",
        "cm = confusion_matrix(y_test, gnb_predictions)\n",
        "cm"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 1, 3, 0],\n",
              "       [1, 0, 0, 0, 1, 1, 0],\n",
              "       [0, 0, 0, 1, 0, 3, 3],\n",
              "       [1, 1, 0, 0, 0, 2, 3],\n",
              "       [1, 1, 0, 0, 0, 2, 0],\n",
              "       [1, 0, 0, 1, 2, 4, 0],\n",
              "       [0, 0, 0, 0, 0, 3, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1uBl1C8xugs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de2a5da-ba88-4d22-b0be-186781df83d8"
      },
      "source": [
        "accuracy"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2558139534883721"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKEGwm6Ux3_p"
      },
      "source": [
        "# KNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDvrAGePx3gY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1783f1b-25ae-4330-85d9-c6732f8c68b2"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors = 2).fit(X_train, y_train)\n",
        "  \n",
        "# accuracy on X_test\n",
        "accuracy = knn.score(X_test, y_test)\n",
        "  \n",
        "# creating a confusion matrix\n",
        "knn_predictions = knn.predict(X_test) \n",
        "cm = confusion_matrix(y_test, knn_predictions)\n",
        "cm"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 2, 1, 0, 0, 0, 0],\n",
              "       [0, 2, 1, 0, 0, 0, 0],\n",
              "       [0, 2, 3, 0, 1, 1, 0],\n",
              "       [1, 1, 0, 5, 0, 0, 0],\n",
              "       [0, 1, 2, 0, 1, 0, 0],\n",
              "       [5, 1, 1, 0, 1, 0, 0],\n",
              "       [1, 2, 1, 0, 1, 0, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIkjwDJPx-ht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ee52979-b31d-4d89-da46-8d794c22834f"
      },
      "source": [
        "accuracy"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3953488372093023"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peAK1v3iyy9I"
      },
      "source": [
        "# Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttvj91L9y2jI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f851d296-2f42-4c96-ccb8-c2577dec7a34"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dtree_model = DecisionTreeClassifier(max_depth = 13).fit(X_train, y_train)\n",
        "dtree_predictions = dtree_model.predict(X_test)\n",
        "  \n",
        "# creating a confusion matrix\n",
        "cm = confusion_matrix(y_test, dtree_predictions)\n",
        "cm"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 0, 1, 2, 0],\n",
              "       [1, 1, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 2, 1, 0, 1, 3],\n",
              "       [1, 0, 0, 3, 0, 1, 2],\n",
              "       [0, 1, 1, 0, 2, 0, 0],\n",
              "       [3, 2, 1, 0, 1, 0, 1],\n",
              "       [0, 0, 2, 0, 1, 2, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yJBPHjmy47M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4738eebc-dd0e-435a-cdc5-6ee634a9223f"
      },
      "source": [
        "dtree_model.score(X_test, y_test)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.27906976744186046"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuhTbiRh-_BF"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6V3fBm--8D0"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUPEhyKc_3FT"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtI3WUpk--cl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "outputId": "72016cc7-d386-46d5-bb1c-e06f6f5b9cc1"
      },
      "source": [
        "np.set_printoptions(precision=2)\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "class newmodel(MLPClassifier):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "    def predict(self, X):\n",
        "        y = self.model.predict(X)\n",
        "        return np.argmax(y,axis=1)\n",
        "\n",
        "model1 = newmodel(model)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
        "                  (\"Normalized confusion matrix\", 'true')]\n",
        "\n",
        "for title, normalize in titles_options:\n",
        "    disp = plot_confusion_matrix(model1, X_test, y_test,\n",
        "                                 display_labels=uniqueValues,\n",
        "                                 cmap=plt.cm.Blues,\n",
        "                                 normalize=normalize)\n",
        "    disp.ax_.set_title(title)\n",
        "\n",
        "    print(title)\n",
        "    print(disp.confusion_matrix)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[1 0 0 0 2 2 0]\n",
            " [0 1 0 0 1 1 0]\n",
            " [0 0 2 1 3 0 1]\n",
            " [0 2 0 4 0 1 0]\n",
            " [1 1 0 0 1 1 0]\n",
            " [3 0 1 0 2 2 0]\n",
            " [0 0 0 0 2 1 6]]\n",
            "Normalized confusion matrix\n",
            "[[0.2  0.   0.   0.   0.4  0.4  0.  ]\n",
            " [0.   0.33 0.   0.   0.33 0.33 0.  ]\n",
            " [0.   0.   0.29 0.14 0.43 0.   0.14]\n",
            " [0.   0.29 0.   0.57 0.   0.14 0.  ]\n",
            " [0.25 0.25 0.   0.   0.25 0.25 0.  ]\n",
            " [0.38 0.   0.12 0.   0.25 0.25 0.  ]\n",
            " [0.   0.   0.   0.   0.22 0.11 0.67]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hdE6EQfZ6tU"
      },
      "source": [
        "### Evaluation and Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gLH2mdEZ74z",
        "outputId": "2427ef13-059e-4dae-9619-2230723dbefd"
      },
      "source": [
        "# Evaluate our model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Model loss on the test set: {loss}\")\n",
        "print(f\"Model accuracy on the test set: {100*accuracy:.2f}%\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 1.3565 - accuracy: 0.3953\n",
            "Model loss on the test set: 1.356489896774292\n",
            "Model accuracy on the test set: 39.53%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Zr5zUN7waFYr",
        "outputId": "fbf2ebf0-e23e-4880-a62f-315d710a6d4c"
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history_1.history['loss'])#[5:])\n",
        "plt.plot(history_1.history['val_loss'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Ol8la_eiaHBH",
        "outputId": "ef85a3ba-211b-4afc-cc2b-18e0e653a7f0"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history_1.history['accuracy'])#[5:])\n",
        "plt.plot(history_1.history['val_accuracy'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Binary Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpFz87FZrNWm"
      },
      "source": [
        ""
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvLBB1x4c9g2"
      },
      "source": [
        "## Model 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTEe3fbAc9g3"
      },
      "source": [
        "### Declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd08u9vRc9g3"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model_2 = keras.Sequential([\n",
        "    layers.Dense(512, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(256, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(128, activation='relu'),    \n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "model_2.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate = .0003),\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    patience=250,\n",
        "    min_delta=0.0001,\n",
        "    restore_best_weights=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUgoNB_Ic9g3"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHPgDrOyc9g4",
        "outputId": "8e05d1ae-8ff4-4871-9f55-316fb9543263"
      },
      "source": [
        "history_2 = model_2.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=2000,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1, \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "10/10 [==============================] - 1s 36ms/step - loss: 1.9899 - accuracy: 0.1856 - val_loss: 1.9204 - val_accuracy: 0.2466\n",
            "Epoch 2/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9459 - accuracy: 0.2027 - val_loss: 1.9368 - val_accuracy: 0.2466\n",
            "Epoch 3/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9410 - accuracy: 0.1787 - val_loss: 1.9181 - val_accuracy: 0.2466\n",
            "Epoch 4/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9096 - accuracy: 0.2131 - val_loss: 1.9360 - val_accuracy: 0.1233\n",
            "Epoch 5/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8897 - accuracy: 0.2199 - val_loss: 1.8801 - val_accuracy: 0.2466\n",
            "Epoch 6/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9329 - accuracy: 0.2027 - val_loss: 1.8763 - val_accuracy: 0.2466\n",
            "Epoch 7/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9016 - accuracy: 0.2268 - val_loss: 1.8795 - val_accuracy: 0.2466\n",
            "Epoch 8/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9305 - accuracy: 0.1753 - val_loss: 1.9101 - val_accuracy: 0.1233\n",
            "Epoch 9/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9260 - accuracy: 0.1718 - val_loss: 1.8958 - val_accuracy: 0.2466\n",
            "Epoch 10/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8918 - accuracy: 0.2096 - val_loss: 1.8782 - val_accuracy: 0.2466\n",
            "Epoch 11/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9363 - accuracy: 0.1753 - val_loss: 1.8799 - val_accuracy: 0.2466\n",
            "Epoch 12/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8866 - accuracy: 0.2371 - val_loss: 1.8970 - val_accuracy: 0.2466\n",
            "Epoch 13/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8847 - accuracy: 0.1924 - val_loss: 1.9108 - val_accuracy: 0.1233\n",
            "Epoch 14/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8944 - accuracy: 0.2165 - val_loss: 1.9101 - val_accuracy: 0.1233\n",
            "Epoch 15/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9024 - accuracy: 0.1959 - val_loss: 1.8947 - val_accuracy: 0.2466\n",
            "Epoch 16/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8828 - accuracy: 0.2027 - val_loss: 1.8896 - val_accuracy: 0.1233\n",
            "Epoch 17/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9034 - accuracy: 0.2096 - val_loss: 1.8771 - val_accuracy: 0.1233\n",
            "Epoch 18/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8941 - accuracy: 0.1959 - val_loss: 1.8752 - val_accuracy: 0.2466\n",
            "Epoch 19/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8893 - accuracy: 0.2302 - val_loss: 1.8800 - val_accuracy: 0.2466\n",
            "Epoch 20/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8753 - accuracy: 0.1890 - val_loss: 1.8747 - val_accuracy: 0.2466\n",
            "Epoch 21/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8979 - accuracy: 0.2234 - val_loss: 1.8790 - val_accuracy: 0.2466\n",
            "Epoch 22/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8821 - accuracy: 0.2199 - val_loss: 1.8932 - val_accuracy: 0.2466\n",
            "Epoch 23/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9011 - accuracy: 0.2371 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 24/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9011 - accuracy: 0.2096 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 25/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9074 - accuracy: 0.1787 - val_loss: 1.8949 - val_accuracy: 0.2466\n",
            "Epoch 26/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8808 - accuracy: 0.2131 - val_loss: 1.9126 - val_accuracy: 0.2466\n",
            "Epoch 27/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9201 - accuracy: 0.2199 - val_loss: 1.9098 - val_accuracy: 0.2466\n",
            "Epoch 28/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8885 - accuracy: 0.2131 - val_loss: 1.9039 - val_accuracy: 0.2466\n",
            "Epoch 29/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8855 - accuracy: 0.2509 - val_loss: 1.8972 - val_accuracy: 0.3562\n",
            "Epoch 30/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8860 - accuracy: 0.2337 - val_loss: 1.8975 - val_accuracy: 0.1233\n",
            "Epoch 31/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8821 - accuracy: 0.2062 - val_loss: 1.8960 - val_accuracy: 0.1233\n",
            "Epoch 32/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8973 - accuracy: 0.2371 - val_loss: 1.8950 - val_accuracy: 0.2466\n",
            "Epoch 33/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8902 - accuracy: 0.2268 - val_loss: 1.8961 - val_accuracy: 0.2466\n",
            "Epoch 34/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8844 - accuracy: 0.2096 - val_loss: 1.8946 - val_accuracy: 0.2466\n",
            "Epoch 35/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8891 - accuracy: 0.2440 - val_loss: 1.8858 - val_accuracy: 0.2466\n",
            "Epoch 36/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8807 - accuracy: 0.2062 - val_loss: 1.8804 - val_accuracy: 0.2466\n",
            "Epoch 37/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8853 - accuracy: 0.2371 - val_loss: 1.8881 - val_accuracy: 0.2466\n",
            "Epoch 38/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8821 - accuracy: 0.2268 - val_loss: 1.8911 - val_accuracy: 0.2466\n",
            "Epoch 39/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8837 - accuracy: 0.2199 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 40/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8928 - accuracy: 0.2165 - val_loss: 1.8885 - val_accuracy: 0.2466\n",
            "Epoch 41/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8911 - accuracy: 0.2165 - val_loss: 1.8946 - val_accuracy: 0.2466\n",
            "Epoch 42/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8800 - accuracy: 0.1924 - val_loss: 1.8916 - val_accuracy: 0.2466\n",
            "Epoch 43/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8843 - accuracy: 0.2302 - val_loss: 1.8945 - val_accuracy: 0.3562\n",
            "Epoch 44/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8892 - accuracy: 0.2199 - val_loss: 1.8834 - val_accuracy: 0.2466\n",
            "Epoch 45/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8869 - accuracy: 0.1959 - val_loss: 1.8808 - val_accuracy: 0.2466\n",
            "Epoch 46/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8688 - accuracy: 0.2131 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 47/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8814 - accuracy: 0.2268 - val_loss: 1.8844 - val_accuracy: 0.2466\n",
            "Epoch 48/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8763 - accuracy: 0.2234 - val_loss: 1.8920 - val_accuracy: 0.2466\n",
            "Epoch 49/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8739 - accuracy: 0.2268 - val_loss: 1.8892 - val_accuracy: 0.2466\n",
            "Epoch 50/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8921 - accuracy: 0.2165 - val_loss: 1.8885 - val_accuracy: 0.2466\n",
            "Epoch 51/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8732 - accuracy: 0.2131 - val_loss: 1.8922 - val_accuracy: 0.2466\n",
            "Epoch 52/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8901 - accuracy: 0.1959 - val_loss: 1.8917 - val_accuracy: 0.2466\n",
            "Epoch 53/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8679 - accuracy: 0.2268 - val_loss: 1.8833 - val_accuracy: 0.2603\n",
            "Epoch 54/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8815 - accuracy: 0.2612 - val_loss: 1.8858 - val_accuracy: 0.3425\n",
            "Epoch 55/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8697 - accuracy: 0.2096 - val_loss: 1.8915 - val_accuracy: 0.1233\n",
            "Epoch 56/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8940 - accuracy: 0.2302 - val_loss: 1.8944 - val_accuracy: 0.1233\n",
            "Epoch 57/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8772 - accuracy: 0.2405 - val_loss: 1.8920 - val_accuracy: 0.1233\n",
            "Epoch 58/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8817 - accuracy: 0.2474 - val_loss: 1.8773 - val_accuracy: 0.2055\n",
            "Epoch 59/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8686 - accuracy: 0.2337 - val_loss: 1.8713 - val_accuracy: 0.2466\n",
            "Epoch 60/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8725 - accuracy: 0.2474 - val_loss: 1.8746 - val_accuracy: 0.2466\n",
            "Epoch 61/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8848 - accuracy: 0.2268 - val_loss: 1.8704 - val_accuracy: 0.2466\n",
            "Epoch 62/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8717 - accuracy: 0.2199 - val_loss: 1.8659 - val_accuracy: 0.2466\n",
            "Epoch 63/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8711 - accuracy: 0.2302 - val_loss: 1.8706 - val_accuracy: 0.2466\n",
            "Epoch 64/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8657 - accuracy: 0.2302 - val_loss: 1.8716 - val_accuracy: 0.2466\n",
            "Epoch 65/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8808 - accuracy: 0.2199 - val_loss: 1.8668 - val_accuracy: 0.3151\n",
            "Epoch 66/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8627 - accuracy: 0.2955 - val_loss: 1.8673 - val_accuracy: 0.3699\n",
            "Epoch 67/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8618 - accuracy: 0.2405 - val_loss: 1.8599 - val_accuracy: 0.2603\n",
            "Epoch 68/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8636 - accuracy: 0.2337 - val_loss: 1.8594 - val_accuracy: 0.2466\n",
            "Epoch 69/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8568 - accuracy: 0.2749 - val_loss: 1.8560 - val_accuracy: 0.2466\n",
            "Epoch 70/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8708 - accuracy: 0.2405 - val_loss: 1.8617 - val_accuracy: 0.2466\n",
            "Epoch 71/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8825 - accuracy: 0.2199 - val_loss: 1.8641 - val_accuracy: 0.2466\n",
            "Epoch 72/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8636 - accuracy: 0.2474 - val_loss: 1.8614 - val_accuracy: 0.2466\n",
            "Epoch 73/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8518 - accuracy: 0.2715 - val_loss: 1.8505 - val_accuracy: 0.2466\n",
            "Epoch 74/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8640 - accuracy: 0.2440 - val_loss: 1.8424 - val_accuracy: 0.2466\n",
            "Epoch 75/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8583 - accuracy: 0.2577 - val_loss: 1.8431 - val_accuracy: 0.3151\n",
            "Epoch 76/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8643 - accuracy: 0.3024 - val_loss: 1.8264 - val_accuracy: 0.2603\n",
            "Epoch 77/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8422 - accuracy: 0.2543 - val_loss: 1.8283 - val_accuracy: 0.2466\n",
            "Epoch 78/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8396 - accuracy: 0.2680 - val_loss: 1.8355 - val_accuracy: 0.3699\n",
            "Epoch 79/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8536 - accuracy: 0.2749 - val_loss: 1.8157 - val_accuracy: 0.2603\n",
            "Epoch 80/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8442 - accuracy: 0.2921 - val_loss: 1.8048 - val_accuracy: 0.3699\n",
            "Epoch 81/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8426 - accuracy: 0.2887 - val_loss: 1.7915 - val_accuracy: 0.3014\n",
            "Epoch 82/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8248 - accuracy: 0.2818 - val_loss: 1.7868 - val_accuracy: 0.3699\n",
            "Epoch 83/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8128 - accuracy: 0.2749 - val_loss: 1.7792 - val_accuracy: 0.3014\n",
            "Epoch 84/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8568 - accuracy: 0.2818 - val_loss: 1.7522 - val_accuracy: 0.3288\n",
            "Epoch 85/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8098 - accuracy: 0.2784 - val_loss: 1.7504 - val_accuracy: 0.3699\n",
            "Epoch 86/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8059 - accuracy: 0.2990 - val_loss: 1.7585 - val_accuracy: 0.3014\n",
            "Epoch 87/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7903 - accuracy: 0.3368 - val_loss: 1.7446 - val_accuracy: 0.2603\n",
            "Epoch 88/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7793 - accuracy: 0.3196 - val_loss: 1.7001 - val_accuracy: 0.3699\n",
            "Epoch 89/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7744 - accuracy: 0.3127 - val_loss: 1.7828 - val_accuracy: 0.2740\n",
            "Epoch 90/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7713 - accuracy: 0.3127 - val_loss: 1.6506 - val_accuracy: 0.3562\n",
            "Epoch 91/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7496 - accuracy: 0.3333 - val_loss: 1.6615 - val_accuracy: 0.3562\n",
            "Epoch 92/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7074 - accuracy: 0.3986 - val_loss: 1.6254 - val_accuracy: 0.3562\n",
            "Epoch 93/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6802 - accuracy: 0.3814 - val_loss: 1.6550 - val_accuracy: 0.3151\n",
            "Epoch 94/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6708 - accuracy: 0.3780 - val_loss: 1.5539 - val_accuracy: 0.3699\n",
            "Epoch 95/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6138 - accuracy: 0.4158 - val_loss: 1.5708 - val_accuracy: 0.3699\n",
            "Epoch 96/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5997 - accuracy: 0.4227 - val_loss: 1.5482 - val_accuracy: 0.3699\n",
            "Epoch 97/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5853 - accuracy: 0.4089 - val_loss: 1.5999 - val_accuracy: 0.3151\n",
            "Epoch 98/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6466 - accuracy: 0.3608 - val_loss: 1.5208 - val_accuracy: 0.3699\n",
            "Epoch 99/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6461 - accuracy: 0.3711 - val_loss: 1.4938 - val_accuracy: 0.3699\n",
            "Epoch 100/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.5707 - accuracy: 0.4021 - val_loss: 1.4876 - val_accuracy: 0.3699\n",
            "Epoch 101/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5520 - accuracy: 0.4055 - val_loss: 1.4994 - val_accuracy: 0.3699\n",
            "Epoch 102/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5216 - accuracy: 0.4261 - val_loss: 1.4598 - val_accuracy: 0.3699\n",
            "Epoch 103/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5297 - accuracy: 0.4055 - val_loss: 1.5262 - val_accuracy: 0.3151\n",
            "Epoch 104/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5750 - accuracy: 0.3883 - val_loss: 1.5114 - val_accuracy: 0.3288\n",
            "Epoch 105/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5508 - accuracy: 0.3883 - val_loss: 1.5118 - val_accuracy: 0.3425\n",
            "Epoch 106/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5417 - accuracy: 0.3986 - val_loss: 1.4639 - val_accuracy: 0.3699\n",
            "Epoch 107/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5699 - accuracy: 0.3849 - val_loss: 1.5327 - val_accuracy: 0.3151\n",
            "Epoch 108/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6745 - accuracy: 0.3471 - val_loss: 1.4863 - val_accuracy: 0.3699\n",
            "Epoch 109/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6007 - accuracy: 0.3883 - val_loss: 1.5419 - val_accuracy: 0.3562\n",
            "Epoch 110/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5367 - accuracy: 0.4124 - val_loss: 1.4456 - val_accuracy: 0.3699\n",
            "Epoch 111/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4900 - accuracy: 0.4192 - val_loss: 1.4315 - val_accuracy: 0.3699\n",
            "Epoch 112/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4631 - accuracy: 0.4192 - val_loss: 1.4273 - val_accuracy: 0.3699\n",
            "Epoch 113/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4590 - accuracy: 0.4227 - val_loss: 1.4204 - val_accuracy: 0.3699\n",
            "Epoch 114/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4291 - accuracy: 0.4124 - val_loss: 1.4287 - val_accuracy: 0.3699\n",
            "Epoch 115/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5105 - accuracy: 0.4089 - val_loss: 1.5691 - val_accuracy: 0.3973\n",
            "Epoch 116/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5738 - accuracy: 0.3883 - val_loss: 1.4225 - val_accuracy: 0.3699\n",
            "Epoch 117/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5680 - accuracy: 0.3608 - val_loss: 1.4041 - val_accuracy: 0.3699\n",
            "Epoch 118/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4379 - accuracy: 0.4192 - val_loss: 1.4097 - val_accuracy: 0.3699\n",
            "Epoch 119/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4349 - accuracy: 0.4261 - val_loss: 1.4596 - val_accuracy: 0.3699\n",
            "Epoch 120/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4335 - accuracy: 0.4227 - val_loss: 1.4252 - val_accuracy: 0.3699\n",
            "Epoch 121/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4498 - accuracy: 0.4261 - val_loss: 1.4304 - val_accuracy: 0.3699\n",
            "Epoch 122/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4132 - accuracy: 0.4330 - val_loss: 1.4163 - val_accuracy: 0.3836\n",
            "Epoch 123/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4246 - accuracy: 0.4124 - val_loss: 1.4043 - val_accuracy: 0.3699\n",
            "Epoch 124/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4146 - accuracy: 0.4261 - val_loss: 1.3995 - val_accuracy: 0.3699\n",
            "Epoch 125/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.3998 - accuracy: 0.4261 - val_loss: 1.4017 - val_accuracy: 0.3836\n",
            "Epoch 126/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5168 - accuracy: 0.4055 - val_loss: 1.3963 - val_accuracy: 0.3699\n",
            "Epoch 127/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4652 - accuracy: 0.4158 - val_loss: 1.4320 - val_accuracy: 0.3836\n",
            "Epoch 128/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4557 - accuracy: 0.4158 - val_loss: 1.4748 - val_accuracy: 0.3562\n",
            "Epoch 129/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4595 - accuracy: 0.4158 - val_loss: 1.3975 - val_accuracy: 0.3699\n",
            "Epoch 130/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4252 - accuracy: 0.4364 - val_loss: 1.4105 - val_accuracy: 0.3836\n",
            "Epoch 131/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.3960 - accuracy: 0.4261 - val_loss: 1.3769 - val_accuracy: 0.3699\n",
            "Epoch 132/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.3824 - accuracy: 0.4296 - val_loss: 1.3752 - val_accuracy: 0.3699\n",
            "Epoch 133/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.3816 - accuracy: 0.4330 - val_loss: 1.4003 - val_accuracy: 0.3973\n",
            "Epoch 134/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5426 - accuracy: 0.3746 - val_loss: 1.4770 - val_accuracy: 0.3562\n",
            "Epoch 135/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5766 - accuracy: 0.3814 - val_loss: 1.5091 - val_accuracy: 0.3425\n",
            "Epoch 136/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5559 - accuracy: 0.3986 - val_loss: 1.6507 - val_accuracy: 0.2877\n",
            "Epoch 137/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6260 - accuracy: 0.3505 - val_loss: 1.4669 - val_accuracy: 0.3699\n",
            "Epoch 138/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5609 - accuracy: 0.3918 - val_loss: 1.4552 - val_accuracy: 0.3836\n",
            "Epoch 139/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5279 - accuracy: 0.4055 - val_loss: 1.4913 - val_accuracy: 0.3425\n",
            "Epoch 140/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4824 - accuracy: 0.3952 - val_loss: 1.4373 - val_accuracy: 0.3699\n",
            "Epoch 141/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5070 - accuracy: 0.4158 - val_loss: 1.4143 - val_accuracy: 0.3699\n",
            "Epoch 142/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4711 - accuracy: 0.3986 - val_loss: 1.5481 - val_accuracy: 0.3014\n",
            "Epoch 143/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5735 - accuracy: 0.3883 - val_loss: 1.3915 - val_accuracy: 0.3699\n",
            "Epoch 144/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5413 - accuracy: 0.3814 - val_loss: 1.4892 - val_accuracy: 0.3425\n",
            "Epoch 145/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6841 - accuracy: 0.3677 - val_loss: 1.5847 - val_accuracy: 0.3699\n",
            "Epoch 146/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6338 - accuracy: 0.3849 - val_loss: 1.5018 - val_accuracy: 0.3836\n",
            "Epoch 147/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5606 - accuracy: 0.3952 - val_loss: 1.4390 - val_accuracy: 0.3699\n",
            "Epoch 148/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5776 - accuracy: 0.4192 - val_loss: 1.4371 - val_accuracy: 0.3699\n",
            "Epoch 149/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5698 - accuracy: 0.4021 - val_loss: 1.4448 - val_accuracy: 0.3836\n",
            "Epoch 150/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5869 - accuracy: 0.3849 - val_loss: 1.5571 - val_accuracy: 0.3973\n",
            "Epoch 151/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5844 - accuracy: 0.3986 - val_loss: 1.4521 - val_accuracy: 0.3699\n",
            "Epoch 152/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5289 - accuracy: 0.3986 - val_loss: 1.4434 - val_accuracy: 0.3699\n",
            "Epoch 153/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5071 - accuracy: 0.4055 - val_loss: 1.4571 - val_accuracy: 0.3699\n",
            "Epoch 154/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5112 - accuracy: 0.4192 - val_loss: 1.4071 - val_accuracy: 0.3699\n",
            "Epoch 155/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6443 - accuracy: 0.3849 - val_loss: 1.4160 - val_accuracy: 0.3699\n",
            "Epoch 156/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6746 - accuracy: 0.3918 - val_loss: 1.4664 - val_accuracy: 0.3699\n",
            "Epoch 157/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6231 - accuracy: 0.3883 - val_loss: 1.5041 - val_accuracy: 0.3836\n",
            "Epoch 158/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6702 - accuracy: 0.3677 - val_loss: 1.4954 - val_accuracy: 0.3836\n",
            "Epoch 159/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6224 - accuracy: 0.4055 - val_loss: 1.4845 - val_accuracy: 0.3836\n",
            "Epoch 160/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6435 - accuracy: 0.3780 - val_loss: 1.4620 - val_accuracy: 0.3699\n",
            "Epoch 161/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6286 - accuracy: 0.3952 - val_loss: 1.4654 - val_accuracy: 0.3836\n",
            "Epoch 162/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6495 - accuracy: 0.3849 - val_loss: 1.4561 - val_accuracy: 0.3699\n",
            "Epoch 163/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6136 - accuracy: 0.3883 - val_loss: 1.4539 - val_accuracy: 0.3699\n",
            "Epoch 164/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5855 - accuracy: 0.4021 - val_loss: 1.5132 - val_accuracy: 0.3699\n",
            "Epoch 165/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6258 - accuracy: 0.3711 - val_loss: 1.4591 - val_accuracy: 0.3699\n",
            "Epoch 166/2000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6223 - accuracy: 0.3746 - val_loss: 1.5393 - val_accuracy: 0.3288\n",
            "Epoch 167/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6432 - accuracy: 0.3849 - val_loss: 1.4433 - val_accuracy: 0.3699\n",
            "Epoch 168/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6296 - accuracy: 0.3814 - val_loss: 1.4378 - val_accuracy: 0.3699\n",
            "Epoch 169/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5721 - accuracy: 0.4261 - val_loss: 1.4459 - val_accuracy: 0.3836\n",
            "Epoch 170/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5976 - accuracy: 0.3918 - val_loss: 1.4422 - val_accuracy: 0.3699\n",
            "Epoch 171/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5989 - accuracy: 0.4021 - val_loss: 1.5012 - val_accuracy: 0.3425\n",
            "Epoch 172/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6919 - accuracy: 0.3643 - val_loss: 1.4357 - val_accuracy: 0.3699\n",
            "Epoch 173/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6760 - accuracy: 0.3574 - val_loss: 1.4876 - val_accuracy: 0.3836\n",
            "Epoch 174/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6150 - accuracy: 0.3883 - val_loss: 1.4540 - val_accuracy: 0.3699\n",
            "Epoch 175/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5560 - accuracy: 0.4021 - val_loss: 1.4447 - val_accuracy: 0.3699\n",
            "Epoch 176/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6318 - accuracy: 0.3814 - val_loss: 1.4482 - val_accuracy: 0.3699\n",
            "Epoch 177/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6200 - accuracy: 0.3711 - val_loss: 1.4619 - val_accuracy: 0.3836\n",
            "Epoch 178/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6123 - accuracy: 0.4158 - val_loss: 1.4757 - val_accuracy: 0.3836\n",
            "Epoch 179/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6252 - accuracy: 0.3986 - val_loss: 1.5221 - val_accuracy: 0.3562\n",
            "Epoch 180/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6370 - accuracy: 0.3849 - val_loss: 1.5217 - val_accuracy: 0.3836\n",
            "Epoch 181/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6251 - accuracy: 0.3814 - val_loss: 1.5450 - val_accuracy: 0.3836\n",
            "Epoch 182/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6276 - accuracy: 0.3883 - val_loss: 1.5438 - val_accuracy: 0.3425\n",
            "Epoch 183/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6207 - accuracy: 0.3849 - val_loss: 1.5142 - val_accuracy: 0.3836\n",
            "Epoch 184/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6528 - accuracy: 0.3711 - val_loss: 1.4686 - val_accuracy: 0.3836\n",
            "Epoch 185/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5756 - accuracy: 0.4089 - val_loss: 1.4622 - val_accuracy: 0.3836\n",
            "Epoch 186/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6148 - accuracy: 0.3883 - val_loss: 1.4719 - val_accuracy: 0.3836\n",
            "Epoch 187/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6193 - accuracy: 0.3849 - val_loss: 1.4379 - val_accuracy: 0.3699\n",
            "Epoch 188/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6281 - accuracy: 0.3883 - val_loss: 1.4710 - val_accuracy: 0.3836\n",
            "Epoch 189/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5727 - accuracy: 0.4021 - val_loss: 1.4391 - val_accuracy: 0.3836\n",
            "Epoch 190/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6099 - accuracy: 0.3918 - val_loss: 1.4453 - val_accuracy: 0.3836\n",
            "Epoch 191/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5355 - accuracy: 0.4021 - val_loss: 1.4375 - val_accuracy: 0.3699\n",
            "Epoch 192/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6291 - accuracy: 0.3849 - val_loss: 1.4525 - val_accuracy: 0.3836\n",
            "Epoch 193/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6145 - accuracy: 0.3711 - val_loss: 1.4879 - val_accuracy: 0.3973\n",
            "Epoch 194/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6236 - accuracy: 0.3883 - val_loss: 1.4701 - val_accuracy: 0.3973\n",
            "Epoch 195/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5522 - accuracy: 0.4124 - val_loss: 1.4654 - val_accuracy: 0.3836\n",
            "Epoch 196/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6429 - accuracy: 0.3746 - val_loss: 1.4531 - val_accuracy: 0.3699\n",
            "Epoch 197/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6070 - accuracy: 0.4021 - val_loss: 1.4529 - val_accuracy: 0.3836\n",
            "Epoch 198/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6246 - accuracy: 0.3883 - val_loss: 1.5108 - val_accuracy: 0.4110\n",
            "Epoch 199/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5944 - accuracy: 0.3883 - val_loss: 1.4446 - val_accuracy: 0.3699\n",
            "Epoch 200/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6287 - accuracy: 0.3780 - val_loss: 1.4480 - val_accuracy: 0.3836\n",
            "Epoch 201/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5787 - accuracy: 0.3986 - val_loss: 1.4416 - val_accuracy: 0.3836\n",
            "Epoch 202/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5727 - accuracy: 0.3986 - val_loss: 1.4311 - val_accuracy: 0.3836\n",
            "Epoch 203/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5717 - accuracy: 0.3849 - val_loss: 1.4265 - val_accuracy: 0.3836\n",
            "Epoch 204/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5574 - accuracy: 0.4089 - val_loss: 1.4197 - val_accuracy: 0.3836\n",
            "Epoch 205/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5845 - accuracy: 0.4055 - val_loss: 1.4149 - val_accuracy: 0.3836\n",
            "Epoch 206/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6064 - accuracy: 0.3849 - val_loss: 1.4314 - val_accuracy: 0.4247\n",
            "Epoch 207/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6527 - accuracy: 0.3952 - val_loss: 1.4482 - val_accuracy: 0.3973\n",
            "Epoch 208/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5939 - accuracy: 0.4055 - val_loss: 1.4561 - val_accuracy: 0.4247\n",
            "Epoch 209/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6040 - accuracy: 0.4192 - val_loss: 1.4499 - val_accuracy: 0.4384\n",
            "Epoch 210/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6243 - accuracy: 0.3952 - val_loss: 1.4407 - val_accuracy: 0.3973\n",
            "Epoch 211/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6216 - accuracy: 0.3986 - val_loss: 1.4297 - val_accuracy: 0.3836\n",
            "Epoch 212/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5885 - accuracy: 0.4089 - val_loss: 1.4355 - val_accuracy: 0.3836\n",
            "Epoch 213/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6493 - accuracy: 0.3505 - val_loss: 1.4694 - val_accuracy: 0.4247\n",
            "Epoch 214/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5856 - accuracy: 0.3986 - val_loss: 1.4322 - val_accuracy: 0.3973\n",
            "Epoch 215/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5986 - accuracy: 0.3986 - val_loss: 1.4586 - val_accuracy: 0.4247\n",
            "Epoch 216/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5546 - accuracy: 0.4124 - val_loss: 1.4883 - val_accuracy: 0.3699\n",
            "Epoch 217/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7074 - accuracy: 0.3608 - val_loss: 1.6052 - val_accuracy: 0.3425\n",
            "Epoch 218/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6284 - accuracy: 0.3952 - val_loss: 1.4416 - val_accuracy: 0.3836\n",
            "Epoch 219/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6051 - accuracy: 0.3986 - val_loss: 1.4478 - val_accuracy: 0.3836\n",
            "Epoch 220/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6093 - accuracy: 0.4055 - val_loss: 1.4514 - val_accuracy: 0.3973\n",
            "Epoch 221/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5991 - accuracy: 0.3952 - val_loss: 1.4553 - val_accuracy: 0.4110\n",
            "Epoch 222/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5980 - accuracy: 0.4021 - val_loss: 1.4233 - val_accuracy: 0.3973\n",
            "Epoch 223/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5683 - accuracy: 0.3986 - val_loss: 1.4303 - val_accuracy: 0.3836\n",
            "Epoch 224/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5798 - accuracy: 0.4089 - val_loss: 1.4336 - val_accuracy: 0.3836\n",
            "Epoch 225/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5395 - accuracy: 0.4158 - val_loss: 1.4612 - val_accuracy: 0.4247\n",
            "Epoch 226/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6147 - accuracy: 0.3918 - val_loss: 1.4810 - val_accuracy: 0.4110\n",
            "Epoch 227/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5945 - accuracy: 0.3780 - val_loss: 1.4236 - val_accuracy: 0.3836\n",
            "Epoch 228/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6257 - accuracy: 0.4021 - val_loss: 1.4710 - val_accuracy: 0.4384\n",
            "Epoch 229/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5921 - accuracy: 0.3986 - val_loss: 1.4181 - val_accuracy: 0.3836\n",
            "Epoch 230/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5600 - accuracy: 0.4158 - val_loss: 1.4152 - val_accuracy: 0.3973\n",
            "Epoch 231/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5883 - accuracy: 0.3814 - val_loss: 1.4418 - val_accuracy: 0.4247\n",
            "Epoch 232/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5528 - accuracy: 0.3918 - val_loss: 1.4574 - val_accuracy: 0.4384\n",
            "Epoch 233/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6315 - accuracy: 0.4055 - val_loss: 1.4270 - val_accuracy: 0.3973\n",
            "Epoch 234/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6085 - accuracy: 0.4055 - val_loss: 1.4370 - val_accuracy: 0.4247\n",
            "Epoch 235/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5757 - accuracy: 0.4089 - val_loss: 1.5057 - val_accuracy: 0.4110\n",
            "Epoch 236/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5349 - accuracy: 0.4158 - val_loss: 1.4238 - val_accuracy: 0.4110\n",
            "Epoch 237/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5640 - accuracy: 0.4158 - val_loss: 1.4098 - val_accuracy: 0.4110\n",
            "Epoch 238/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5792 - accuracy: 0.4158 - val_loss: 1.5072 - val_accuracy: 0.4110\n",
            "Epoch 239/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6284 - accuracy: 0.3918 - val_loss: 1.4182 - val_accuracy: 0.4110\n",
            "Epoch 240/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5926 - accuracy: 0.3814 - val_loss: 1.4051 - val_accuracy: 0.3973\n",
            "Epoch 241/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5259 - accuracy: 0.4021 - val_loss: 1.4333 - val_accuracy: 0.4384\n",
            "Epoch 242/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5765 - accuracy: 0.4192 - val_loss: 1.3916 - val_accuracy: 0.4247\n",
            "Epoch 243/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5981 - accuracy: 0.3883 - val_loss: 1.5059 - val_accuracy: 0.3699\n",
            "Epoch 244/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5737 - accuracy: 0.3952 - val_loss: 1.4027 - val_accuracy: 0.4247\n",
            "Epoch 245/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6438 - accuracy: 0.3952 - val_loss: 1.4006 - val_accuracy: 0.4110\n",
            "Epoch 246/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6214 - accuracy: 0.3986 - val_loss: 1.4334 - val_accuracy: 0.3973\n",
            "Epoch 247/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6817 - accuracy: 0.3711 - val_loss: 1.5306 - val_accuracy: 0.4110\n",
            "Epoch 248/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5675 - accuracy: 0.4227 - val_loss: 1.4289 - val_accuracy: 0.3973\n",
            "Epoch 249/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5912 - accuracy: 0.3746 - val_loss: 1.4645 - val_accuracy: 0.4384\n",
            "Epoch 250/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5651 - accuracy: 0.4055 - val_loss: 1.4458 - val_accuracy: 0.4247\n",
            "Epoch 251/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5619 - accuracy: 0.4089 - val_loss: 1.4158 - val_accuracy: 0.4110\n",
            "Epoch 252/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5871 - accuracy: 0.3849 - val_loss: 1.4871 - val_accuracy: 0.4384\n",
            "Epoch 253/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5728 - accuracy: 0.4330 - val_loss: 1.4238 - val_accuracy: 0.4247\n",
            "Epoch 254/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6334 - accuracy: 0.4192 - val_loss: 1.4473 - val_accuracy: 0.3836\n",
            "Epoch 255/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6013 - accuracy: 0.4192 - val_loss: 1.4341 - val_accuracy: 0.4247\n",
            "Epoch 256/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5996 - accuracy: 0.3918 - val_loss: 1.5103 - val_accuracy: 0.4247\n",
            "Epoch 257/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6116 - accuracy: 0.4158 - val_loss: 1.4582 - val_accuracy: 0.4658\n",
            "Epoch 258/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5838 - accuracy: 0.4261 - val_loss: 1.4767 - val_accuracy: 0.4384\n",
            "Epoch 259/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5886 - accuracy: 0.4021 - val_loss: 1.4449 - val_accuracy: 0.4521\n",
            "Epoch 260/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5471 - accuracy: 0.4124 - val_loss: 1.4246 - val_accuracy: 0.3973\n",
            "Epoch 261/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5903 - accuracy: 0.3952 - val_loss: 1.4241 - val_accuracy: 0.4247\n",
            "Epoch 262/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5858 - accuracy: 0.3986 - val_loss: 1.4262 - val_accuracy: 0.4384\n",
            "Epoch 263/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5683 - accuracy: 0.4055 - val_loss: 1.4385 - val_accuracy: 0.4384\n",
            "Epoch 264/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5704 - accuracy: 0.4158 - val_loss: 1.3964 - val_accuracy: 0.4110\n",
            "Epoch 265/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5628 - accuracy: 0.4261 - val_loss: 1.4013 - val_accuracy: 0.4521\n",
            "Epoch 266/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5460 - accuracy: 0.4399 - val_loss: 1.4087 - val_accuracy: 0.4521\n",
            "Epoch 267/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5633 - accuracy: 0.3986 - val_loss: 1.4162 - val_accuracy: 0.4521\n",
            "Epoch 268/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5411 - accuracy: 0.4261 - val_loss: 1.4312 - val_accuracy: 0.4384\n",
            "Epoch 269/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5780 - accuracy: 0.4261 - val_loss: 1.4028 - val_accuracy: 0.4384\n",
            "Epoch 270/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5425 - accuracy: 0.4021 - val_loss: 1.4066 - val_accuracy: 0.4247\n",
            "Epoch 271/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5222 - accuracy: 0.4364 - val_loss: 1.5809 - val_accuracy: 0.3836\n",
            "Epoch 272/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6618 - accuracy: 0.3780 - val_loss: 1.4260 - val_accuracy: 0.4110\n",
            "Epoch 273/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6362 - accuracy: 0.3711 - val_loss: 1.4639 - val_accuracy: 0.4384\n",
            "Epoch 274/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6125 - accuracy: 0.3952 - val_loss: 1.4880 - val_accuracy: 0.4247\n",
            "Epoch 275/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5576 - accuracy: 0.4089 - val_loss: 1.4526 - val_accuracy: 0.4384\n",
            "Epoch 276/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6301 - accuracy: 0.4158 - val_loss: 1.4345 - val_accuracy: 0.4384\n",
            "Epoch 277/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5623 - accuracy: 0.4330 - val_loss: 1.4397 - val_accuracy: 0.4384\n",
            "Epoch 278/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5536 - accuracy: 0.4330 - val_loss: 1.4325 - val_accuracy: 0.4384\n",
            "Epoch 279/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6104 - accuracy: 0.4055 - val_loss: 1.4823 - val_accuracy: 0.4384\n",
            "Epoch 280/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5956 - accuracy: 0.3746 - val_loss: 1.4761 - val_accuracy: 0.4384\n",
            "Epoch 281/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5880 - accuracy: 0.4261 - val_loss: 1.4070 - val_accuracy: 0.4384\n",
            "Epoch 282/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5988 - accuracy: 0.3711 - val_loss: 1.4372 - val_accuracy: 0.4658\n",
            "Epoch 283/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5437 - accuracy: 0.4192 - val_loss: 1.5251 - val_accuracy: 0.4110\n",
            "Epoch 284/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5628 - accuracy: 0.4124 - val_loss: 1.4068 - val_accuracy: 0.4658\n",
            "Epoch 285/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5538 - accuracy: 0.4124 - val_loss: 1.4058 - val_accuracy: 0.4384\n",
            "Epoch 286/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5576 - accuracy: 0.4433 - val_loss: 1.4304 - val_accuracy: 0.4521\n",
            "Epoch 287/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5381 - accuracy: 0.4261 - val_loss: 1.4627 - val_accuracy: 0.4247\n",
            "Epoch 288/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5773 - accuracy: 0.4124 - val_loss: 1.3875 - val_accuracy: 0.4384\n",
            "Epoch 289/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5588 - accuracy: 0.4261 - val_loss: 1.4000 - val_accuracy: 0.4658\n",
            "Epoch 290/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5998 - accuracy: 0.3986 - val_loss: 1.4824 - val_accuracy: 0.4110\n",
            "Epoch 291/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5223 - accuracy: 0.4261 - val_loss: 1.5353 - val_accuracy: 0.3973\n",
            "Epoch 292/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6120 - accuracy: 0.4261 - val_loss: 1.3959 - val_accuracy: 0.4384\n",
            "Epoch 293/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5954 - accuracy: 0.4227 - val_loss: 1.4192 - val_accuracy: 0.4658\n",
            "Epoch 294/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5634 - accuracy: 0.4296 - val_loss: 1.5257 - val_accuracy: 0.4247\n",
            "Epoch 295/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5372 - accuracy: 0.4433 - val_loss: 1.4238 - val_accuracy: 0.4658\n",
            "Epoch 296/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5483 - accuracy: 0.4399 - val_loss: 1.3994 - val_accuracy: 0.4384\n",
            "Epoch 297/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5689 - accuracy: 0.4227 - val_loss: 1.4482 - val_accuracy: 0.4247\n",
            "Epoch 298/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5350 - accuracy: 0.4433 - val_loss: 1.5410 - val_accuracy: 0.3973\n",
            "Epoch 299/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6311 - accuracy: 0.4158 - val_loss: 1.4608 - val_accuracy: 0.4247\n",
            "Epoch 300/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0148 - accuracy: 0.2680 - val_loss: 1.9967 - val_accuracy: 0.2466\n",
            "Epoch 301/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.7931 - accuracy: 0.3196 - val_loss: 1.5967 - val_accuracy: 0.3288\n",
            "Epoch 302/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6718 - accuracy: 0.3643 - val_loss: 1.6305 - val_accuracy: 0.3836\n",
            "Epoch 303/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6287 - accuracy: 0.3986 - val_loss: 1.4896 - val_accuracy: 0.4521\n",
            "Epoch 304/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6154 - accuracy: 0.4399 - val_loss: 1.4781 - val_accuracy: 0.4110\n",
            "Epoch 305/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7089 - accuracy: 0.3505 - val_loss: 1.7087 - val_accuracy: 0.3288\n",
            "Epoch 306/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6514 - accuracy: 0.3746 - val_loss: 1.5372 - val_accuracy: 0.3425\n",
            "Epoch 307/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6168 - accuracy: 0.4021 - val_loss: 1.5750 - val_accuracy: 0.3973\n",
            "Epoch 308/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5953 - accuracy: 0.4192 - val_loss: 1.4433 - val_accuracy: 0.4384\n",
            "Epoch 309/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5521 - accuracy: 0.4330 - val_loss: 1.4536 - val_accuracy: 0.4521\n",
            "Epoch 310/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5439 - accuracy: 0.4467 - val_loss: 1.5132 - val_accuracy: 0.4110\n",
            "Epoch 311/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5950 - accuracy: 0.4330 - val_loss: 1.4403 - val_accuracy: 0.4521\n",
            "Epoch 312/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5920 - accuracy: 0.4227 - val_loss: 1.4280 - val_accuracy: 0.4521\n",
            "Epoch 313/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5509 - accuracy: 0.4399 - val_loss: 1.4167 - val_accuracy: 0.4795\n",
            "Epoch 314/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5704 - accuracy: 0.4192 - val_loss: 1.4930 - val_accuracy: 0.3973\n",
            "Epoch 315/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5472 - accuracy: 0.4261 - val_loss: 1.3878 - val_accuracy: 0.4795\n",
            "Epoch 316/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5497 - accuracy: 0.4399 - val_loss: 1.4822 - val_accuracy: 0.3973\n",
            "Epoch 317/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5681 - accuracy: 0.4124 - val_loss: 1.3800 - val_accuracy: 0.4658\n",
            "Epoch 318/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5304 - accuracy: 0.4502 - val_loss: 1.4087 - val_accuracy: 0.4384\n",
            "Epoch 319/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5414 - accuracy: 0.4399 - val_loss: 1.4194 - val_accuracy: 0.4384\n",
            "Epoch 320/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5475 - accuracy: 0.4296 - val_loss: 1.3869 - val_accuracy: 0.4521\n",
            "Epoch 321/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6043 - accuracy: 0.3986 - val_loss: 1.4578 - val_accuracy: 0.4247\n",
            "Epoch 322/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5450 - accuracy: 0.4227 - val_loss: 1.4952 - val_accuracy: 0.3973\n",
            "Epoch 323/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.8172 - accuracy: 0.3024 - val_loss: 1.4217 - val_accuracy: 0.4521\n",
            "Epoch 324/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5732 - accuracy: 0.4055 - val_loss: 1.5212 - val_accuracy: 0.3973\n",
            "Epoch 325/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5756 - accuracy: 0.4124 - val_loss: 1.4286 - val_accuracy: 0.4521\n",
            "Epoch 326/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5585 - accuracy: 0.4261 - val_loss: 1.4170 - val_accuracy: 0.4795\n",
            "Epoch 327/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5705 - accuracy: 0.4158 - val_loss: 1.4560 - val_accuracy: 0.4384\n",
            "Epoch 328/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5348 - accuracy: 0.4399 - val_loss: 1.4723 - val_accuracy: 0.4247\n",
            "Epoch 329/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5391 - accuracy: 0.4502 - val_loss: 1.4141 - val_accuracy: 0.4795\n",
            "Epoch 330/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4821 - accuracy: 0.4708 - val_loss: 1.4007 - val_accuracy: 0.4795\n",
            "Epoch 331/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5495 - accuracy: 0.3918 - val_loss: 1.5552 - val_accuracy: 0.3973\n",
            "Epoch 332/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5986 - accuracy: 0.4192 - val_loss: 1.4082 - val_accuracy: 0.4658\n",
            "Epoch 333/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5134 - accuracy: 0.4502 - val_loss: 1.4135 - val_accuracy: 0.4521\n",
            "Epoch 334/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5194 - accuracy: 0.4467 - val_loss: 1.4871 - val_accuracy: 0.3973\n",
            "Epoch 335/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.6058 - accuracy: 0.3883 - val_loss: 1.4845 - val_accuracy: 0.4110\n",
            "Epoch 336/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5994 - accuracy: 0.4192 - val_loss: 1.4499 - val_accuracy: 0.4247\n",
            "Epoch 337/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5911 - accuracy: 0.4330 - val_loss: 1.4028 - val_accuracy: 0.4932\n",
            "Epoch 338/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5764 - accuracy: 0.4296 - val_loss: 1.5705 - val_accuracy: 0.3973\n",
            "Epoch 339/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6605 - accuracy: 0.3746 - val_loss: 1.4414 - val_accuracy: 0.3973\n",
            "Epoch 340/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6300 - accuracy: 0.4055 - val_loss: 1.5742 - val_accuracy: 0.3699\n",
            "Epoch 341/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5563 - accuracy: 0.3986 - val_loss: 1.5095 - val_accuracy: 0.3973\n",
            "Epoch 342/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5889 - accuracy: 0.3986 - val_loss: 1.3822 - val_accuracy: 0.4795\n",
            "Epoch 343/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5664 - accuracy: 0.4089 - val_loss: 1.4896 - val_accuracy: 0.4110\n",
            "Epoch 344/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5756 - accuracy: 0.4089 - val_loss: 1.4747 - val_accuracy: 0.4247\n",
            "Epoch 345/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5652 - accuracy: 0.4261 - val_loss: 1.3963 - val_accuracy: 0.4795\n",
            "Epoch 346/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5208 - accuracy: 0.4399 - val_loss: 1.5834 - val_accuracy: 0.3699\n",
            "Epoch 347/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5796 - accuracy: 0.4158 - val_loss: 1.3857 - val_accuracy: 0.4932\n",
            "Epoch 348/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5405 - accuracy: 0.4467 - val_loss: 1.4179 - val_accuracy: 0.4384\n",
            "Epoch 349/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5478 - accuracy: 0.4296 - val_loss: 1.4113 - val_accuracy: 0.4384\n",
            "Epoch 350/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5567 - accuracy: 0.4124 - val_loss: 1.5152 - val_accuracy: 0.3973\n",
            "Epoch 351/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5519 - accuracy: 0.4261 - val_loss: 1.3832 - val_accuracy: 0.4795\n",
            "Epoch 352/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4765 - accuracy: 0.4570 - val_loss: 1.4621 - val_accuracy: 0.4110\n",
            "Epoch 353/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5318 - accuracy: 0.4364 - val_loss: 1.4105 - val_accuracy: 0.4384\n",
            "Epoch 354/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5097 - accuracy: 0.4433 - val_loss: 1.4281 - val_accuracy: 0.4384\n",
            "Epoch 355/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5829 - accuracy: 0.4399 - val_loss: 1.3859 - val_accuracy: 0.4658\n",
            "Epoch 356/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4942 - accuracy: 0.4605 - val_loss: 1.3938 - val_accuracy: 0.4384\n",
            "Epoch 357/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5017 - accuracy: 0.4742 - val_loss: 1.5256 - val_accuracy: 0.3973\n",
            "Epoch 358/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4891 - accuracy: 0.4639 - val_loss: 1.3576 - val_accuracy: 0.4932\n",
            "Epoch 359/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5369 - accuracy: 0.4570 - val_loss: 1.4455 - val_accuracy: 0.4384\n",
            "Epoch 360/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5066 - accuracy: 0.4536 - val_loss: 1.3684 - val_accuracy: 0.4932\n",
            "Epoch 361/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5835 - accuracy: 0.4330 - val_loss: 1.5085 - val_accuracy: 0.3973\n",
            "Epoch 362/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5544 - accuracy: 0.4467 - val_loss: 1.4219 - val_accuracy: 0.4384\n",
            "Epoch 363/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.6366 - accuracy: 0.4055 - val_loss: 1.3781 - val_accuracy: 0.4521\n",
            "Epoch 364/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5624 - accuracy: 0.4089 - val_loss: 1.5660 - val_accuracy: 0.3973\n",
            "Epoch 365/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5097 - accuracy: 0.4433 - val_loss: 1.3956 - val_accuracy: 0.4384\n",
            "Epoch 366/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5661 - accuracy: 0.4399 - val_loss: 1.3681 - val_accuracy: 0.4932\n",
            "Epoch 367/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5038 - accuracy: 0.4639 - val_loss: 1.4376 - val_accuracy: 0.4384\n",
            "Epoch 368/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5123 - accuracy: 0.4502 - val_loss: 1.4764 - val_accuracy: 0.4247\n",
            "Epoch 369/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5281 - accuracy: 0.4399 - val_loss: 1.4190 - val_accuracy: 0.4384\n",
            "Epoch 370/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5502 - accuracy: 0.4399 - val_loss: 1.4144 - val_accuracy: 0.4384\n",
            "Epoch 371/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5833 - accuracy: 0.4261 - val_loss: 1.3895 - val_accuracy: 0.4795\n",
            "Epoch 372/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5782 - accuracy: 0.4296 - val_loss: 1.6534 - val_accuracy: 0.3699\n",
            "Epoch 373/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5901 - accuracy: 0.4192 - val_loss: 1.4188 - val_accuracy: 0.4384\n",
            "Epoch 374/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5275 - accuracy: 0.4364 - val_loss: 1.3832 - val_accuracy: 0.4795\n",
            "Epoch 375/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5333 - accuracy: 0.4605 - val_loss: 1.4660 - val_accuracy: 0.4247\n",
            "Epoch 376/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5386 - accuracy: 0.4124 - val_loss: 1.4789 - val_accuracy: 0.4110\n",
            "Epoch 377/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5751 - accuracy: 0.4364 - val_loss: 1.5597 - val_accuracy: 0.3836\n",
            "Epoch 378/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5667 - accuracy: 0.4330 - val_loss: 1.3558 - val_accuracy: 0.4932\n",
            "Epoch 379/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5296 - accuracy: 0.4433 - val_loss: 1.4757 - val_accuracy: 0.4247\n",
            "Epoch 380/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5420 - accuracy: 0.4433 - val_loss: 1.4049 - val_accuracy: 0.4384\n",
            "Epoch 381/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5140 - accuracy: 0.4433 - val_loss: 1.4853 - val_accuracy: 0.4110\n",
            "Epoch 382/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4992 - accuracy: 0.4364 - val_loss: 1.4220 - val_accuracy: 0.4521\n",
            "Epoch 383/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5048 - accuracy: 0.4433 - val_loss: 1.3756 - val_accuracy: 0.4795\n",
            "Epoch 384/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5259 - accuracy: 0.4364 - val_loss: 1.4375 - val_accuracy: 0.4384\n",
            "Epoch 385/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5057 - accuracy: 0.4570 - val_loss: 1.4140 - val_accuracy: 0.4384\n",
            "Epoch 386/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4870 - accuracy: 0.4674 - val_loss: 1.5340 - val_accuracy: 0.3973\n",
            "Epoch 387/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5166 - accuracy: 0.4399 - val_loss: 1.3938 - val_accuracy: 0.4521\n",
            "Epoch 388/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5016 - accuracy: 0.4536 - val_loss: 1.3452 - val_accuracy: 0.4932\n",
            "Epoch 389/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5137 - accuracy: 0.4364 - val_loss: 1.5538 - val_accuracy: 0.3973\n",
            "Epoch 390/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5607 - accuracy: 0.4330 - val_loss: 1.3763 - val_accuracy: 0.4521\n",
            "Epoch 391/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5033 - accuracy: 0.4570 - val_loss: 1.4139 - val_accuracy: 0.4384\n",
            "Epoch 392/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5080 - accuracy: 0.4674 - val_loss: 1.4564 - val_accuracy: 0.4247\n",
            "Epoch 393/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4789 - accuracy: 0.4502 - val_loss: 1.4121 - val_accuracy: 0.4384\n",
            "Epoch 394/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4937 - accuracy: 0.4742 - val_loss: 1.5024 - val_accuracy: 0.3973\n",
            "Epoch 395/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5313 - accuracy: 0.4261 - val_loss: 1.3897 - val_accuracy: 0.4521\n",
            "Epoch 396/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5337 - accuracy: 0.4502 - val_loss: 1.3516 - val_accuracy: 0.4795\n",
            "Epoch 397/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5697 - accuracy: 0.4192 - val_loss: 1.4906 - val_accuracy: 0.4247\n",
            "Epoch 398/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5116 - accuracy: 0.4261 - val_loss: 1.4720 - val_accuracy: 0.4247\n",
            "Epoch 399/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5326 - accuracy: 0.4364 - val_loss: 1.4237 - val_accuracy: 0.4384\n",
            "Epoch 400/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5466 - accuracy: 0.4227 - val_loss: 1.3719 - val_accuracy: 0.4658\n",
            "Epoch 401/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5892 - accuracy: 0.4433 - val_loss: 1.3730 - val_accuracy: 0.4795\n",
            "Epoch 402/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.5297 - accuracy: 0.4364 - val_loss: 1.4102 - val_accuracy: 0.4384\n",
            "Epoch 403/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5686 - accuracy: 0.4055 - val_loss: 1.6397 - val_accuracy: 0.3699\n",
            "Epoch 404/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5205 - accuracy: 0.4399 - val_loss: 1.4452 - val_accuracy: 0.4384\n",
            "Epoch 405/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5251 - accuracy: 0.4055 - val_loss: 1.4065 - val_accuracy: 0.4384\n",
            "Epoch 406/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5241 - accuracy: 0.4777 - val_loss: 1.3574 - val_accuracy: 0.4795\n",
            "Epoch 407/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4594 - accuracy: 0.4399 - val_loss: 1.4238 - val_accuracy: 0.4384\n",
            "Epoch 408/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4598 - accuracy: 0.4674 - val_loss: 1.3359 - val_accuracy: 0.4795\n",
            "Epoch 409/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4905 - accuracy: 0.4399 - val_loss: 1.4189 - val_accuracy: 0.4384\n",
            "Epoch 410/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5052 - accuracy: 0.4399 - val_loss: 1.3741 - val_accuracy: 0.4521\n",
            "Epoch 411/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5299 - accuracy: 0.4364 - val_loss: 1.3198 - val_accuracy: 0.4932\n",
            "Epoch 412/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5605 - accuracy: 0.4330 - val_loss: 1.3427 - val_accuracy: 0.4932\n",
            "Epoch 413/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5795 - accuracy: 0.4055 - val_loss: 1.5585 - val_accuracy: 0.3973\n",
            "Epoch 414/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5800 - accuracy: 0.4124 - val_loss: 1.4967 - val_accuracy: 0.4110\n",
            "Epoch 415/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4736 - accuracy: 0.4570 - val_loss: 1.4171 - val_accuracy: 0.4384\n",
            "Epoch 416/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5564 - accuracy: 0.4330 - val_loss: 1.4102 - val_accuracy: 0.4384\n",
            "Epoch 417/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5298 - accuracy: 0.4467 - val_loss: 1.5698 - val_accuracy: 0.3973\n",
            "Epoch 418/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5238 - accuracy: 0.4399 - val_loss: 1.3789 - val_accuracy: 0.4658\n",
            "Epoch 419/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4930 - accuracy: 0.4467 - val_loss: 1.3761 - val_accuracy: 0.4658\n",
            "Epoch 420/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4707 - accuracy: 0.4777 - val_loss: 1.5258 - val_accuracy: 0.3973\n",
            "Epoch 421/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5025 - accuracy: 0.4639 - val_loss: 1.3804 - val_accuracy: 0.4658\n",
            "Epoch 422/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5618 - accuracy: 0.4296 - val_loss: 1.3394 - val_accuracy: 0.4932\n",
            "Epoch 423/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5480 - accuracy: 0.4089 - val_loss: 1.4167 - val_accuracy: 0.4521\n",
            "Epoch 424/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5272 - accuracy: 0.4399 - val_loss: 1.4882 - val_accuracy: 0.4384\n",
            "Epoch 425/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4625 - accuracy: 0.4777 - val_loss: 1.4601 - val_accuracy: 0.4384\n",
            "Epoch 426/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4676 - accuracy: 0.4570 - val_loss: 1.3417 - val_accuracy: 0.4795\n",
            "Epoch 427/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4946 - accuracy: 0.4261 - val_loss: 1.5530 - val_accuracy: 0.3973\n",
            "Epoch 428/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5280 - accuracy: 0.4467 - val_loss: 1.5396 - val_accuracy: 0.4110\n",
            "Epoch 429/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4847 - accuracy: 0.4777 - val_loss: 1.4440 - val_accuracy: 0.4384\n",
            "Epoch 430/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5714 - accuracy: 0.4055 - val_loss: 1.3332 - val_accuracy: 0.4932\n",
            "Epoch 431/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5351 - accuracy: 0.4296 - val_loss: 1.3907 - val_accuracy: 0.4521\n",
            "Epoch 432/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5067 - accuracy: 0.4330 - val_loss: 1.4505 - val_accuracy: 0.4384\n",
            "Epoch 433/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4954 - accuracy: 0.4605 - val_loss: 1.4577 - val_accuracy: 0.4247\n",
            "Epoch 434/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5157 - accuracy: 0.4330 - val_loss: 1.3746 - val_accuracy: 0.4384\n",
            "Epoch 435/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5413 - accuracy: 0.4536 - val_loss: 1.6445 - val_accuracy: 0.3699\n",
            "Epoch 436/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5594 - accuracy: 0.4261 - val_loss: 1.5570 - val_accuracy: 0.3973\n",
            "Epoch 437/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5807 - accuracy: 0.4089 - val_loss: 1.3478 - val_accuracy: 0.4932\n",
            "Epoch 438/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6106 - accuracy: 0.4158 - val_loss: 1.3751 - val_accuracy: 0.4658\n",
            "Epoch 439/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5567 - accuracy: 0.4296 - val_loss: 1.5701 - val_accuracy: 0.3973\n",
            "Epoch 440/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5008 - accuracy: 0.4364 - val_loss: 1.4740 - val_accuracy: 0.4384\n",
            "Epoch 441/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4979 - accuracy: 0.4502 - val_loss: 1.5054 - val_accuracy: 0.4384\n",
            "Epoch 442/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5225 - accuracy: 0.4330 - val_loss: 1.4062 - val_accuracy: 0.4658\n",
            "Epoch 443/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5528 - accuracy: 0.4296 - val_loss: 1.3995 - val_accuracy: 0.4795\n",
            "Epoch 444/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5471 - accuracy: 0.4227 - val_loss: 1.6560 - val_accuracy: 0.3836\n",
            "Epoch 445/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5683 - accuracy: 0.4055 - val_loss: 1.4332 - val_accuracy: 0.4384\n",
            "Epoch 446/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4881 - accuracy: 0.4399 - val_loss: 1.3669 - val_accuracy: 0.4795\n",
            "Epoch 447/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4832 - accuracy: 0.4330 - val_loss: 1.4024 - val_accuracy: 0.4384\n",
            "Epoch 448/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4793 - accuracy: 0.4433 - val_loss: 1.4831 - val_accuracy: 0.4110\n",
            "Epoch 449/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5082 - accuracy: 0.4502 - val_loss: 1.3615 - val_accuracy: 0.4658\n",
            "Epoch 450/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4756 - accuracy: 0.4742 - val_loss: 1.4669 - val_accuracy: 0.4384\n",
            "Epoch 451/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4700 - accuracy: 0.4674 - val_loss: 1.4761 - val_accuracy: 0.4384\n",
            "Epoch 452/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4996 - accuracy: 0.4536 - val_loss: 1.4399 - val_accuracy: 0.4384\n",
            "Epoch 453/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5200 - accuracy: 0.4467 - val_loss: 1.4536 - val_accuracy: 0.4384\n",
            "Epoch 454/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4557 - accuracy: 0.4570 - val_loss: 1.3963 - val_accuracy: 0.4521\n",
            "Epoch 455/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5204 - accuracy: 0.4433 - val_loss: 1.5133 - val_accuracy: 0.4110\n",
            "Epoch 456/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5122 - accuracy: 0.4467 - val_loss: 1.6028 - val_accuracy: 0.3973\n",
            "Epoch 457/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5865 - accuracy: 0.4089 - val_loss: 1.3701 - val_accuracy: 0.4384\n",
            "Epoch 458/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5117 - accuracy: 0.4399 - val_loss: 1.3867 - val_accuracy: 0.4521\n",
            "Epoch 459/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5402 - accuracy: 0.4433 - val_loss: 1.5448 - val_accuracy: 0.4110\n",
            "Epoch 460/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5197 - accuracy: 0.4467 - val_loss: 1.4551 - val_accuracy: 0.4384\n",
            "Epoch 461/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4750 - accuracy: 0.4502 - val_loss: 1.3233 - val_accuracy: 0.4932\n",
            "Epoch 462/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5058 - accuracy: 0.4674 - val_loss: 1.4299 - val_accuracy: 0.4384\n",
            "Epoch 463/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4813 - accuracy: 0.4433 - val_loss: 1.4207 - val_accuracy: 0.4384\n",
            "Epoch 464/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4437 - accuracy: 0.4742 - val_loss: 1.3696 - val_accuracy: 0.4795\n",
            "Epoch 465/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4522 - accuracy: 0.4674 - val_loss: 1.3282 - val_accuracy: 0.4932\n",
            "Epoch 466/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5264 - accuracy: 0.4502 - val_loss: 1.4002 - val_accuracy: 0.4384\n",
            "Epoch 467/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4473 - accuracy: 0.4708 - val_loss: 1.4180 - val_accuracy: 0.4384\n",
            "Epoch 468/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5068 - accuracy: 0.4261 - val_loss: 1.4842 - val_accuracy: 0.4384\n",
            "Epoch 469/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4915 - accuracy: 0.4639 - val_loss: 1.7290 - val_accuracy: 0.3562\n",
            "Epoch 470/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5420 - accuracy: 0.4433 - val_loss: 1.3611 - val_accuracy: 0.4795\n",
            "Epoch 471/2000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4660 - accuracy: 0.4811 - val_loss: 1.4506 - val_accuracy: 0.4384\n",
            "Epoch 472/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5007 - accuracy: 0.4777 - val_loss: 1.4595 - val_accuracy: 0.4384\n",
            "Epoch 473/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5318 - accuracy: 0.4399 - val_loss: 1.3256 - val_accuracy: 0.4932\n",
            "Epoch 474/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5731 - accuracy: 0.4261 - val_loss: 1.3735 - val_accuracy: 0.4795\n",
            "Epoch 475/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4726 - accuracy: 0.4845 - val_loss: 1.5279 - val_accuracy: 0.4110\n",
            "Epoch 476/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4789 - accuracy: 0.4605 - val_loss: 1.3638 - val_accuracy: 0.4795\n",
            "Epoch 477/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5268 - accuracy: 0.4330 - val_loss: 1.3368 - val_accuracy: 0.4932\n",
            "Epoch 478/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4921 - accuracy: 0.4433 - val_loss: 1.5036 - val_accuracy: 0.4110\n",
            "Epoch 479/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.5013 - accuracy: 0.4467 - val_loss: 1.4901 - val_accuracy: 0.4384\n",
            "Epoch 480/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4925 - accuracy: 0.4742 - val_loss: 1.3440 - val_accuracy: 0.4932\n",
            "Epoch 481/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5241 - accuracy: 0.4605 - val_loss: 1.3341 - val_accuracy: 0.4932\n",
            "Epoch 482/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5225 - accuracy: 0.4433 - val_loss: 1.5460 - val_accuracy: 0.3973\n",
            "Epoch 483/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4812 - accuracy: 0.4674 - val_loss: 1.4087 - val_accuracy: 0.4384\n",
            "Epoch 484/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4392 - accuracy: 0.4639 - val_loss: 1.4700 - val_accuracy: 0.4110\n",
            "Epoch 485/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4846 - accuracy: 0.4777 - val_loss: 1.5394 - val_accuracy: 0.4110\n",
            "Epoch 486/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4410 - accuracy: 0.4708 - val_loss: 1.3590 - val_accuracy: 0.4521\n",
            "Epoch 487/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4709 - accuracy: 0.4742 - val_loss: 1.3864 - val_accuracy: 0.4521\n",
            "Epoch 488/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4674 - accuracy: 0.4570 - val_loss: 1.5084 - val_accuracy: 0.4110\n",
            "Epoch 489/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4673 - accuracy: 0.4536 - val_loss: 1.3717 - val_accuracy: 0.4521\n",
            "Epoch 490/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4624 - accuracy: 0.4742 - val_loss: 1.3655 - val_accuracy: 0.4658\n",
            "Epoch 491/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4682 - accuracy: 0.4811 - val_loss: 1.4850 - val_accuracy: 0.4110\n",
            "Epoch 492/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4223 - accuracy: 0.4708 - val_loss: 1.4010 - val_accuracy: 0.4384\n",
            "Epoch 493/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4609 - accuracy: 0.4433 - val_loss: 1.3048 - val_accuracy: 0.5068\n",
            "Epoch 494/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.4751 - accuracy: 0.4605 - val_loss: 1.2860 - val_accuracy: 0.4932\n",
            "Epoch 495/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.5952 - accuracy: 0.4158 - val_loss: 1.5932 - val_accuracy: 0.4110\n",
            "Epoch 496/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5145 - accuracy: 0.4330 - val_loss: 1.5584 - val_accuracy: 0.3973\n",
            "Epoch 497/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.5048 - accuracy: 0.4364 - val_loss: 1.3277 - val_accuracy: 0.4795\n",
            "Epoch 498/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.4955 - accuracy: 0.4742 - val_loss: 1.2930 - val_accuracy: 0.4932\n",
            "Epoch 499/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5838 - accuracy: 0.4364 - val_loss: 1.5844 - val_accuracy: 0.3973\n",
            "Epoch 500/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4652 - accuracy: 0.4845 - val_loss: 1.5468 - val_accuracy: 0.4110\n",
            "Epoch 501/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.5012 - accuracy: 0.4399 - val_loss: 1.5196 - val_accuracy: 0.4110\n",
            "Epoch 502/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.0206 - accuracy: 0.2646 - val_loss: 2.0544 - val_accuracy: 0.2466\n",
            "Epoch 503/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 2.0117 - accuracy: 0.2199 - val_loss: 1.9519 - val_accuracy: 0.2466\n",
            "Epoch 504/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9291 - accuracy: 0.2199 - val_loss: 1.9164 - val_accuracy: 0.2466\n",
            "Epoch 505/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9163 - accuracy: 0.2199 - val_loss: 1.9061 - val_accuracy: 0.2466\n",
            "Epoch 506/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8933 - accuracy: 0.2199 - val_loss: 1.8986 - val_accuracy: 0.2466\n",
            "Epoch 507/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8940 - accuracy: 0.2199 - val_loss: 1.8952 - val_accuracy: 0.2466\n",
            "Epoch 508/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8869 - accuracy: 0.2199 - val_loss: 1.8912 - val_accuracy: 0.2466\n",
            "Epoch 509/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8910 - accuracy: 0.2199 - val_loss: 1.8901 - val_accuracy: 0.2466\n",
            "Epoch 510/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8831 - accuracy: 0.2199 - val_loss: 1.8890 - val_accuracy: 0.2466\n",
            "Epoch 511/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8827 - accuracy: 0.2199 - val_loss: 1.8880 - val_accuracy: 0.2466\n",
            "Epoch 512/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8788 - accuracy: 0.2199 - val_loss: 1.8882 - val_accuracy: 0.2466\n",
            "Epoch 513/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8798 - accuracy: 0.2199 - val_loss: 1.8876 - val_accuracy: 0.2466\n",
            "Epoch 514/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8863 - accuracy: 0.2165 - val_loss: 1.8876 - val_accuracy: 0.2466\n",
            "Epoch 515/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8814 - accuracy: 0.2199 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 516/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8820 - accuracy: 0.2165 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 517/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8821 - accuracy: 0.2199 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 518/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8836 - accuracy: 0.2268 - val_loss: 1.8860 - val_accuracy: 0.2466\n",
            "Epoch 519/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8761 - accuracy: 0.2199 - val_loss: 1.8858 - val_accuracy: 0.2466\n",
            "Epoch 520/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8842 - accuracy: 0.2131 - val_loss: 1.8864 - val_accuracy: 0.2466\n",
            "Epoch 521/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8757 - accuracy: 0.2234 - val_loss: 1.8862 - val_accuracy: 0.2466\n",
            "Epoch 522/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8820 - accuracy: 0.2165 - val_loss: 1.8868 - val_accuracy: 0.2466\n",
            "Epoch 523/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8814 - accuracy: 0.2234 - val_loss: 1.8868 - val_accuracy: 0.2466\n",
            "Epoch 524/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8776 - accuracy: 0.2165 - val_loss: 1.8877 - val_accuracy: 0.2466\n",
            "Epoch 525/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8840 - accuracy: 0.2234 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 526/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8766 - accuracy: 0.2440 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 527/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8779 - accuracy: 0.2131 - val_loss: 1.8889 - val_accuracy: 0.2466\n",
            "Epoch 528/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8718 - accuracy: 0.2371 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 529/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8794 - accuracy: 0.2062 - val_loss: 1.8900 - val_accuracy: 0.2466\n",
            "Epoch 530/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8810 - accuracy: 0.2165 - val_loss: 1.8910 - val_accuracy: 0.2466\n",
            "Epoch 531/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8825 - accuracy: 0.2062 - val_loss: 1.8904 - val_accuracy: 0.2466\n",
            "Epoch 532/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8752 - accuracy: 0.2199 - val_loss: 1.8892 - val_accuracy: 0.2466\n",
            "Epoch 533/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8808 - accuracy: 0.2096 - val_loss: 1.8893 - val_accuracy: 0.2466\n",
            "Epoch 534/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8763 - accuracy: 0.2234 - val_loss: 1.8895 - val_accuracy: 0.2466\n",
            "Epoch 535/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8848 - accuracy: 0.2096 - val_loss: 1.8899 - val_accuracy: 0.2466\n",
            "Epoch 536/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8718 - accuracy: 0.2234 - val_loss: 1.8905 - val_accuracy: 0.2466\n",
            "Epoch 537/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8814 - accuracy: 0.1821 - val_loss: 1.8908 - val_accuracy: 0.2466\n",
            "Epoch 538/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8781 - accuracy: 0.2062 - val_loss: 1.8912 - val_accuracy: 0.2466\n",
            "Epoch 539/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8771 - accuracy: 0.2268 - val_loss: 1.8913 - val_accuracy: 0.2466\n",
            "Epoch 540/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8826 - accuracy: 0.2165 - val_loss: 1.8918 - val_accuracy: 0.2466\n",
            "Epoch 541/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8745 - accuracy: 0.2337 - val_loss: 1.8921 - val_accuracy: 0.2466\n",
            "Epoch 542/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8751 - accuracy: 0.2234 - val_loss: 1.8906 - val_accuracy: 0.2466\n",
            "Epoch 543/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8718 - accuracy: 0.2199 - val_loss: 1.8895 - val_accuracy: 0.2466\n",
            "Epoch 544/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8790 - accuracy: 0.2199 - val_loss: 1.8888 - val_accuracy: 0.2466\n",
            "Epoch 545/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8749 - accuracy: 0.2062 - val_loss: 1.8890 - val_accuracy: 0.2466\n",
            "Epoch 546/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8755 - accuracy: 0.2337 - val_loss: 1.8879 - val_accuracy: 0.2466\n",
            "Epoch 547/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8735 - accuracy: 0.2131 - val_loss: 1.8873 - val_accuracy: 0.2466\n",
            "Epoch 548/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8824 - accuracy: 0.1856 - val_loss: 1.8866 - val_accuracy: 0.2466\n",
            "Epoch 549/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8751 - accuracy: 0.2199 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 550/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8822 - accuracy: 0.1959 - val_loss: 1.8859 - val_accuracy: 0.2466\n",
            "Epoch 551/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8775 - accuracy: 0.2268 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 552/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8757 - accuracy: 0.2062 - val_loss: 1.8884 - val_accuracy: 0.2466\n",
            "Epoch 553/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8753 - accuracy: 0.1959 - val_loss: 1.8891 - val_accuracy: 0.2466\n",
            "Epoch 554/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8749 - accuracy: 0.2165 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 555/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8732 - accuracy: 0.2268 - val_loss: 1.8886 - val_accuracy: 0.2466\n",
            "Epoch 556/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8791 - accuracy: 0.2096 - val_loss: 1.8904 - val_accuracy: 0.2466\n",
            "Epoch 557/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8748 - accuracy: 0.2096 - val_loss: 1.8921 - val_accuracy: 0.2466\n",
            "Epoch 558/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8697 - accuracy: 0.2096 - val_loss: 1.8920 - val_accuracy: 0.2466\n",
            "Epoch 559/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8828 - accuracy: 0.2302 - val_loss: 1.8909 - val_accuracy: 0.2466\n",
            "Epoch 560/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8765 - accuracy: 0.2337 - val_loss: 1.8897 - val_accuracy: 0.2466\n",
            "Epoch 561/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8740 - accuracy: 0.2131 - val_loss: 1.8891 - val_accuracy: 0.2466\n",
            "Epoch 562/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8820 - accuracy: 0.2199 - val_loss: 1.8885 - val_accuracy: 0.2466\n",
            "Epoch 563/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8764 - accuracy: 0.2234 - val_loss: 1.8852 - val_accuracy: 0.2466\n",
            "Epoch 564/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8766 - accuracy: 0.2234 - val_loss: 1.8840 - val_accuracy: 0.2466\n",
            "Epoch 565/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8761 - accuracy: 0.2131 - val_loss: 1.8846 - val_accuracy: 0.2466\n",
            "Epoch 566/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8768 - accuracy: 0.2131 - val_loss: 1.8864 - val_accuracy: 0.2466\n",
            "Epoch 567/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8738 - accuracy: 0.2096 - val_loss: 1.8868 - val_accuracy: 0.2466\n",
            "Epoch 568/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8737 - accuracy: 0.2062 - val_loss: 1.8868 - val_accuracy: 0.2466\n",
            "Epoch 569/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8775 - accuracy: 0.2199 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 570/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8731 - accuracy: 0.2131 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 571/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8786 - accuracy: 0.2062 - val_loss: 1.8867 - val_accuracy: 0.2466\n",
            "Epoch 572/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8763 - accuracy: 0.2062 - val_loss: 1.8866 - val_accuracy: 0.2466\n",
            "Epoch 573/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8725 - accuracy: 0.2165 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 574/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8753 - accuracy: 0.2131 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 575/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8753 - accuracy: 0.2096 - val_loss: 1.8882 - val_accuracy: 0.2466\n",
            "Epoch 576/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8719 - accuracy: 0.2199 - val_loss: 1.8888 - val_accuracy: 0.2466\n",
            "Epoch 577/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8712 - accuracy: 0.2027 - val_loss: 1.8886 - val_accuracy: 0.2466\n",
            "Epoch 578/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8706 - accuracy: 0.2165 - val_loss: 1.8904 - val_accuracy: 0.2466\n",
            "Epoch 579/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8793 - accuracy: 0.2199 - val_loss: 1.8907 - val_accuracy: 0.2466\n",
            "Epoch 580/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8789 - accuracy: 0.2165 - val_loss: 1.8909 - val_accuracy: 0.2466\n",
            "Epoch 581/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8749 - accuracy: 0.2268 - val_loss: 1.8908 - val_accuracy: 0.2466\n",
            "Epoch 582/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8729 - accuracy: 0.2234 - val_loss: 1.8890 - val_accuracy: 0.2466\n",
            "Epoch 583/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8751 - accuracy: 0.2405 - val_loss: 1.8880 - val_accuracy: 0.2466\n",
            "Epoch 584/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8748 - accuracy: 0.2199 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 585/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8749 - accuracy: 0.2096 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 586/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8723 - accuracy: 0.2268 - val_loss: 1.8854 - val_accuracy: 0.2466\n",
            "Epoch 587/2000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.8779 - accuracy: 0.2096 - val_loss: 1.8849 - val_accuracy: 0.2466\n",
            "Epoch 588/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8742 - accuracy: 0.2096 - val_loss: 1.8849 - val_accuracy: 0.2466\n",
            "Epoch 589/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8833 - accuracy: 0.2096 - val_loss: 1.8853 - val_accuracy: 0.2466\n",
            "Epoch 590/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8767 - accuracy: 0.2234 - val_loss: 1.8864 - val_accuracy: 0.2466\n",
            "Epoch 591/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8766 - accuracy: 0.2199 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 592/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8827 - accuracy: 0.2165 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 593/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8801 - accuracy: 0.2302 - val_loss: 1.8861 - val_accuracy: 0.2466\n",
            "Epoch 594/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8759 - accuracy: 0.2027 - val_loss: 1.8869 - val_accuracy: 0.2466\n",
            "Epoch 595/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8761 - accuracy: 0.2302 - val_loss: 1.8886 - val_accuracy: 0.2466\n",
            "Epoch 596/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8778 - accuracy: 0.1959 - val_loss: 1.8883 - val_accuracy: 0.2466\n",
            "Epoch 597/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8794 - accuracy: 0.2234 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 598/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8760 - accuracy: 0.2165 - val_loss: 1.8860 - val_accuracy: 0.2466\n",
            "Epoch 599/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8710 - accuracy: 0.2199 - val_loss: 1.8860 - val_accuracy: 0.2466\n",
            "Epoch 600/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8741 - accuracy: 0.2165 - val_loss: 1.8857 - val_accuracy: 0.2466\n",
            "Epoch 601/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8783 - accuracy: 0.2096 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 602/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8764 - accuracy: 0.2165 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 603/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8799 - accuracy: 0.2234 - val_loss: 1.8862 - val_accuracy: 0.2466\n",
            "Epoch 604/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8743 - accuracy: 0.2199 - val_loss: 1.8846 - val_accuracy: 0.2466\n",
            "Epoch 605/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8774 - accuracy: 0.2131 - val_loss: 1.8837 - val_accuracy: 0.2466\n",
            "Epoch 606/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8739 - accuracy: 0.2234 - val_loss: 1.8833 - val_accuracy: 0.2466\n",
            "Epoch 607/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8747 - accuracy: 0.2234 - val_loss: 1.8836 - val_accuracy: 0.2466\n",
            "Epoch 608/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8760 - accuracy: 0.2234 - val_loss: 1.8832 - val_accuracy: 0.2466\n",
            "Epoch 609/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8755 - accuracy: 0.2268 - val_loss: 1.8834 - val_accuracy: 0.2466\n",
            "Epoch 610/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8788 - accuracy: 0.2131 - val_loss: 1.8835 - val_accuracy: 0.2466\n",
            "Epoch 611/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8778 - accuracy: 0.2131 - val_loss: 1.8847 - val_accuracy: 0.2466\n",
            "Epoch 612/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8704 - accuracy: 0.2302 - val_loss: 1.8862 - val_accuracy: 0.2466\n",
            "Epoch 613/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8840 - accuracy: 0.2302 - val_loss: 1.8876 - val_accuracy: 0.2466\n",
            "Epoch 614/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8759 - accuracy: 0.1959 - val_loss: 1.8890 - val_accuracy: 0.2466\n",
            "Epoch 615/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8786 - accuracy: 0.2165 - val_loss: 1.8905 - val_accuracy: 0.2466\n",
            "Epoch 616/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8831 - accuracy: 0.1993 - val_loss: 1.8909 - val_accuracy: 0.2466\n",
            "Epoch 617/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8793 - accuracy: 0.2165 - val_loss: 1.8909 - val_accuracy: 0.2466\n",
            "Epoch 618/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8731 - accuracy: 0.2509 - val_loss: 1.8903 - val_accuracy: 0.2466\n",
            "Epoch 619/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8749 - accuracy: 0.1890 - val_loss: 1.8889 - val_accuracy: 0.2466\n",
            "Epoch 620/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8772 - accuracy: 0.2234 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 621/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8678 - accuracy: 0.2337 - val_loss: 1.8884 - val_accuracy: 0.2466\n",
            "Epoch 622/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8793 - accuracy: 0.1993 - val_loss: 1.8879 - val_accuracy: 0.2466\n",
            "Epoch 623/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8796 - accuracy: 0.2062 - val_loss: 1.8864 - val_accuracy: 0.2466\n",
            "Epoch 624/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8814 - accuracy: 0.2096 - val_loss: 1.8856 - val_accuracy: 0.2466\n",
            "Epoch 625/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8726 - accuracy: 0.2165 - val_loss: 1.8847 - val_accuracy: 0.2466\n",
            "Epoch 626/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8726 - accuracy: 0.2337 - val_loss: 1.8839 - val_accuracy: 0.2466\n",
            "Epoch 627/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8805 - accuracy: 0.2234 - val_loss: 1.8834 - val_accuracy: 0.2466\n",
            "Epoch 628/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8779 - accuracy: 0.2268 - val_loss: 1.8827 - val_accuracy: 0.2466\n",
            "Epoch 629/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8722 - accuracy: 0.2096 - val_loss: 1.8826 - val_accuracy: 0.2466\n",
            "Epoch 630/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8711 - accuracy: 0.2199 - val_loss: 1.8831 - val_accuracy: 0.2466\n",
            "Epoch 631/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8725 - accuracy: 0.2199 - val_loss: 1.8835 - val_accuracy: 0.2466\n",
            "Epoch 632/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8728 - accuracy: 0.2268 - val_loss: 1.8835 - val_accuracy: 0.2466\n",
            "Epoch 633/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8751 - accuracy: 0.2234 - val_loss: 1.8829 - val_accuracy: 0.2466\n",
            "Epoch 634/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8707 - accuracy: 0.2096 - val_loss: 1.8823 - val_accuracy: 0.2466\n",
            "Epoch 635/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8733 - accuracy: 0.2131 - val_loss: 1.8824 - val_accuracy: 0.2466\n",
            "Epoch 636/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8800 - accuracy: 0.2302 - val_loss: 1.8839 - val_accuracy: 0.2466\n",
            "Epoch 637/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8751 - accuracy: 0.2131 - val_loss: 1.8864 - val_accuracy: 0.2466\n",
            "Epoch 638/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8787 - accuracy: 0.2027 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 639/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8731 - accuracy: 0.2199 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 640/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8699 - accuracy: 0.2096 - val_loss: 1.8861 - val_accuracy: 0.2466\n",
            "Epoch 641/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8780 - accuracy: 0.2199 - val_loss: 1.8850 - val_accuracy: 0.2466\n",
            "Epoch 642/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8708 - accuracy: 0.2199 - val_loss: 1.8848 - val_accuracy: 0.2466\n",
            "Epoch 643/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8799 - accuracy: 0.2131 - val_loss: 1.8856 - val_accuracy: 0.2466\n",
            "Epoch 644/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8745 - accuracy: 0.1993 - val_loss: 1.8857 - val_accuracy: 0.2466\n",
            "Epoch 645/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8739 - accuracy: 0.2199 - val_loss: 1.8845 - val_accuracy: 0.2466\n",
            "Epoch 646/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8746 - accuracy: 0.2096 - val_loss: 1.8840 - val_accuracy: 0.2466\n",
            "Epoch 647/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8772 - accuracy: 0.2268 - val_loss: 1.8832 - val_accuracy: 0.2466\n",
            "Epoch 648/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8733 - accuracy: 0.1993 - val_loss: 1.8833 - val_accuracy: 0.2466\n",
            "Epoch 649/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8751 - accuracy: 0.2027 - val_loss: 1.8834 - val_accuracy: 0.2466\n",
            "Epoch 650/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8783 - accuracy: 0.1959 - val_loss: 1.8829 - val_accuracy: 0.2466\n",
            "Epoch 651/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8749 - accuracy: 0.2165 - val_loss: 1.8827 - val_accuracy: 0.2466\n",
            "Epoch 652/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8747 - accuracy: 0.2199 - val_loss: 1.8836 - val_accuracy: 0.2466\n",
            "Epoch 653/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8810 - accuracy: 0.1993 - val_loss: 1.8838 - val_accuracy: 0.2466\n",
            "Epoch 654/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8761 - accuracy: 0.2234 - val_loss: 1.8834 - val_accuracy: 0.2466\n",
            "Epoch 655/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8736 - accuracy: 0.2199 - val_loss: 1.8823 - val_accuracy: 0.2466\n",
            "Epoch 656/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8731 - accuracy: 0.2131 - val_loss: 1.8824 - val_accuracy: 0.2466\n",
            "Epoch 657/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8760 - accuracy: 0.2027 - val_loss: 1.8819 - val_accuracy: 0.2466\n",
            "Epoch 658/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8789 - accuracy: 0.2062 - val_loss: 1.8820 - val_accuracy: 0.2466\n",
            "Epoch 659/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8714 - accuracy: 0.2302 - val_loss: 1.8819 - val_accuracy: 0.2466\n",
            "Epoch 660/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8747 - accuracy: 0.2131 - val_loss: 1.8816 - val_accuracy: 0.2466\n",
            "Epoch 661/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8700 - accuracy: 0.2165 - val_loss: 1.8816 - val_accuracy: 0.2466\n",
            "Epoch 662/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8702 - accuracy: 0.2234 - val_loss: 1.8814 - val_accuracy: 0.2466\n",
            "Epoch 663/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8797 - accuracy: 0.2199 - val_loss: 1.8815 - val_accuracy: 0.2466\n",
            "Epoch 664/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8661 - accuracy: 0.2199 - val_loss: 1.8806 - val_accuracy: 0.2466\n",
            "Epoch 665/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8756 - accuracy: 0.2268 - val_loss: 1.8814 - val_accuracy: 0.2466\n",
            "Epoch 666/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8792 - accuracy: 0.2199 - val_loss: 1.8816 - val_accuracy: 0.2466\n",
            "Epoch 667/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8784 - accuracy: 0.2165 - val_loss: 1.8822 - val_accuracy: 0.2466\n",
            "Epoch 668/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8716 - accuracy: 0.2234 - val_loss: 1.8835 - val_accuracy: 0.2466\n",
            "Epoch 669/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8709 - accuracy: 0.2096 - val_loss: 1.8829 - val_accuracy: 0.2466\n",
            "Epoch 670/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8736 - accuracy: 0.2165 - val_loss: 1.8824 - val_accuracy: 0.2466\n",
            "Epoch 671/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8707 - accuracy: 0.2268 - val_loss: 1.8830 - val_accuracy: 0.2466\n",
            "Epoch 672/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8795 - accuracy: 0.2199 - val_loss: 1.8832 - val_accuracy: 0.2466\n",
            "Epoch 673/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8644 - accuracy: 0.2199 - val_loss: 1.8838 - val_accuracy: 0.2466\n",
            "Epoch 674/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8716 - accuracy: 0.2096 - val_loss: 1.8841 - val_accuracy: 0.2466\n",
            "Epoch 675/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8743 - accuracy: 0.2371 - val_loss: 1.8859 - val_accuracy: 0.2466\n",
            "Epoch 676/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8781 - accuracy: 0.2302 - val_loss: 1.8857 - val_accuracy: 0.2466\n",
            "Epoch 677/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8705 - accuracy: 0.2234 - val_loss: 1.8854 - val_accuracy: 0.2466\n",
            "Epoch 678/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8770 - accuracy: 0.2199 - val_loss: 1.8857 - val_accuracy: 0.2466\n",
            "Epoch 679/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8799 - accuracy: 0.2131 - val_loss: 1.8860 - val_accuracy: 0.2466\n",
            "Epoch 680/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8743 - accuracy: 0.2337 - val_loss: 1.8861 - val_accuracy: 0.2466\n",
            "Epoch 681/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8668 - accuracy: 0.2131 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 682/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8739 - accuracy: 0.2131 - val_loss: 1.8873 - val_accuracy: 0.2466\n",
            "Epoch 683/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8753 - accuracy: 0.2062 - val_loss: 1.8884 - val_accuracy: 0.2466\n",
            "Epoch 684/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8750 - accuracy: 0.2199 - val_loss: 1.8880 - val_accuracy: 0.2466\n",
            "Epoch 685/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8805 - accuracy: 0.2096 - val_loss: 1.8887 - val_accuracy: 0.2466\n",
            "Epoch 686/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8745 - accuracy: 0.2405 - val_loss: 1.8901 - val_accuracy: 0.2466\n",
            "Epoch 687/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8740 - accuracy: 0.2062 - val_loss: 1.8893 - val_accuracy: 0.2466\n",
            "Epoch 688/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8739 - accuracy: 0.2096 - val_loss: 1.8880 - val_accuracy: 0.2466\n",
            "Epoch 689/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8701 - accuracy: 0.2096 - val_loss: 1.8881 - val_accuracy: 0.2466\n",
            "Epoch 690/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8748 - accuracy: 0.2062 - val_loss: 1.8883 - val_accuracy: 0.2466\n",
            "Epoch 691/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8775 - accuracy: 0.2405 - val_loss: 1.8880 - val_accuracy: 0.2466\n",
            "Epoch 692/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8748 - accuracy: 0.2131 - val_loss: 1.8878 - val_accuracy: 0.2466\n",
            "Epoch 693/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8728 - accuracy: 0.2027 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 694/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8758 - accuracy: 0.2234 - val_loss: 1.8877 - val_accuracy: 0.2466\n",
            "Epoch 695/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8765 - accuracy: 0.2131 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 696/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8797 - accuracy: 0.2131 - val_loss: 1.8869 - val_accuracy: 0.2466\n",
            "Epoch 697/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8728 - accuracy: 0.2062 - val_loss: 1.8859 - val_accuracy: 0.2466\n",
            "Epoch 698/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8745 - accuracy: 0.2268 - val_loss: 1.8859 - val_accuracy: 0.2466\n",
            "Epoch 699/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8780 - accuracy: 0.2199 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 700/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8751 - accuracy: 0.2268 - val_loss: 1.8858 - val_accuracy: 0.2466\n",
            "Epoch 701/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8799 - accuracy: 0.2096 - val_loss: 1.8854 - val_accuracy: 0.2466\n",
            "Epoch 702/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8701 - accuracy: 0.2234 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 703/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8718 - accuracy: 0.2268 - val_loss: 1.8872 - val_accuracy: 0.2466\n",
            "Epoch 704/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8785 - accuracy: 0.2268 - val_loss: 1.8863 - val_accuracy: 0.2466\n",
            "Epoch 705/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8730 - accuracy: 0.2302 - val_loss: 1.8857 - val_accuracy: 0.2466\n",
            "Epoch 706/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8722 - accuracy: 0.2131 - val_loss: 1.8851 - val_accuracy: 0.2466\n",
            "Epoch 707/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8696 - accuracy: 0.2165 - val_loss: 1.8847 - val_accuracy: 0.2466\n",
            "Epoch 708/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8842 - accuracy: 0.1993 - val_loss: 1.8836 - val_accuracy: 0.2466\n",
            "Epoch 709/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8812 - accuracy: 0.2234 - val_loss: 1.8836 - val_accuracy: 0.2466\n",
            "Epoch 710/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8760 - accuracy: 0.2199 - val_loss: 1.8841 - val_accuracy: 0.2466\n",
            "Epoch 711/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8754 - accuracy: 0.2199 - val_loss: 1.8839 - val_accuracy: 0.2466\n",
            "Epoch 712/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8808 - accuracy: 0.2199 - val_loss: 1.8851 - val_accuracy: 0.2466\n",
            "Epoch 713/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8743 - accuracy: 0.2302 - val_loss: 1.8867 - val_accuracy: 0.2466\n",
            "Epoch 714/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8745 - accuracy: 0.2096 - val_loss: 1.8870 - val_accuracy: 0.2466\n",
            "Epoch 715/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8740 - accuracy: 0.2474 - val_loss: 1.8873 - val_accuracy: 0.2466\n",
            "Epoch 716/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8769 - accuracy: 0.2096 - val_loss: 1.8872 - val_accuracy: 0.2466\n",
            "Epoch 717/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8747 - accuracy: 0.2062 - val_loss: 1.8866 - val_accuracy: 0.2466\n",
            "Epoch 718/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8791 - accuracy: 0.1993 - val_loss: 1.8862 - val_accuracy: 0.2466\n",
            "Epoch 719/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8730 - accuracy: 0.2096 - val_loss: 1.8872 - val_accuracy: 0.2466\n",
            "Epoch 720/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8808 - accuracy: 0.2062 - val_loss: 1.8867 - val_accuracy: 0.2466\n",
            "Epoch 721/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8786 - accuracy: 0.2337 - val_loss: 1.8867 - val_accuracy: 0.2466\n",
            "Epoch 722/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8782 - accuracy: 0.2268 - val_loss: 1.8862 - val_accuracy: 0.2466\n",
            "Epoch 723/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8702 - accuracy: 0.2440 - val_loss: 1.8862 - val_accuracy: 0.2466\n",
            "Epoch 724/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8759 - accuracy: 0.2131 - val_loss: 1.8865 - val_accuracy: 0.2466\n",
            "Epoch 725/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8703 - accuracy: 0.2268 - val_loss: 1.8875 - val_accuracy: 0.2466\n",
            "Epoch 726/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8705 - accuracy: 0.2268 - val_loss: 1.8885 - val_accuracy: 0.2466\n",
            "Epoch 727/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8731 - accuracy: 0.2199 - val_loss: 1.8893 - val_accuracy: 0.2466\n",
            "Epoch 728/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8725 - accuracy: 0.2165 - val_loss: 1.8903 - val_accuracy: 0.2466\n",
            "Epoch 729/2000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.8746 - accuracy: 0.2268 - val_loss: 1.8911 - val_accuracy: 0.2466\n",
            "Epoch 730/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8711 - accuracy: 0.2131 - val_loss: 1.8915 - val_accuracy: 0.2466\n",
            "Epoch 731/2000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8788 - accuracy: 0.1993 - val_loss: 1.8925 - val_accuracy: 0.2466\n",
            "Epoch 732/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8722 - accuracy: 0.2027 - val_loss: 1.8928 - val_accuracy: 0.2466\n",
            "Epoch 733/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8752 - accuracy: 0.2302 - val_loss: 1.8923 - val_accuracy: 0.2466\n",
            "Epoch 734/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8745 - accuracy: 0.2337 - val_loss: 1.8924 - val_accuracy: 0.2466\n",
            "Epoch 735/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8761 - accuracy: 0.2268 - val_loss: 1.8917 - val_accuracy: 0.2466\n",
            "Epoch 736/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8720 - accuracy: 0.2096 - val_loss: 1.8910 - val_accuracy: 0.2466\n",
            "Epoch 737/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8761 - accuracy: 0.2509 - val_loss: 1.8903 - val_accuracy: 0.2466\n",
            "Epoch 738/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8754 - accuracy: 0.2062 - val_loss: 1.8899 - val_accuracy: 0.2466\n",
            "Epoch 739/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8736 - accuracy: 0.2234 - val_loss: 1.8899 - val_accuracy: 0.2466\n",
            "Epoch 740/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8742 - accuracy: 0.2337 - val_loss: 1.8902 - val_accuracy: 0.2466\n",
            "Epoch 741/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8839 - accuracy: 0.1787 - val_loss: 1.8902 - val_accuracy: 0.2466\n",
            "Epoch 742/2000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.8800 - accuracy: 0.2302 - val_loss: 1.8896 - val_accuracy: 0.2466\n",
            "Epoch 743/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8748 - accuracy: 0.2199 - val_loss: 1.8896 - val_accuracy: 0.2466\n",
            "Epoch 744/2000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.8735 - accuracy: 0.2199 - val_loss: 1.8899 - val_accuracy: 0.2466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJR5pfQ1c9g4"
      },
      "source": [
        "### Evaluation and Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "413JtwURc9g5",
        "outputId": "4725b60f-af5e-4113-9da3-031d483b06ea"
      },
      "source": [
        "# Evaluate our model on the test set\n",
        "loss, accuracy = model_2.evaluate(X_test, y_test)\n",
        "print(f\"Model loss on the test set: {loss}\")\n",
        "print(f\"Model accuracy on the test set: {100*accuracy:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 5ms/step - loss: 0.7995 - accuracy: 0.6410\n",
            "Model loss on the test set: 0.7994661927223206\n",
            "Model accuracy on the test set: 64.10%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "OJB0Jvw9c9g5",
        "outputId": "124252bd-a206-48f1-edaa-5107209b8409"
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history_2.history['loss'])#[5:])\n",
        "plt.plot(history_2.history['val_loss'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "NOjoGnLic9g6",
        "outputId": "671609fd-bb22-48e4-f317-16e0fa7a3e45"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history_2.history['accuracy'])#[5:])\n",
        "plt.plot(history_2.history['val_accuracy'])#[5:])\n",
        "#plt.title('model loss')\n",
        "plt.ylabel('Binary Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}